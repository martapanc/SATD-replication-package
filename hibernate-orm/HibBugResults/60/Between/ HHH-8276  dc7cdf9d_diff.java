diff --git a/hibernate-core/src/main/java/org/hibernate/PropertyAccessException.java b/hibernate-core/src/main/java/org/hibernate/PropertyAccessException.java
index 95d31f5145..7d6f8200ad 100644
--- a/hibernate-core/src/main/java/org/hibernate/PropertyAccessException.java
+++ b/hibernate-core/src/main/java/org/hibernate/PropertyAccessException.java
@@ -1,80 +1,84 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate;
 
 import org.hibernate.internal.util.StringHelper;
 
 /**
  * A problem occurred accessing a property of an instance of a
  * persistent class by reflection, or via CGLIB. There are a
  * number of possible underlying causes, including
  * <ul>
  * <li>failure of a security check
  * <li>an exception occurring inside the getter or setter method
  * <li>a nullable database column was mapped to a primitive-type property
  * <li>the Hibernate type was not castable to the property type (or vice-versa)
  * </ul>
  * @author Gavin King
  */
 public class PropertyAccessException extends HibernateException {
 	private final Class persistentClass;
 	private final String propertyName;
 	private final boolean wasSetter;
 
 	/**
 	 * Constructs a PropertyAccessException using the specified information.
 	 *
 	 * @param cause The underlying cause
 	 * @param message A message explaining the exception condition
 	 * @param wasSetter Was the attempting to access the setter the cause of the exception?
 	 * @param persistentClass The class which is supposed to contain the property in question
 	 * @param propertyName The name of the property.
 	 */
 	public PropertyAccessException(
 			Throwable cause,
 			String message,
 			boolean wasSetter,
 			Class persistentClass,
 			String propertyName) {
 		super( message, cause );
 		this.persistentClass = persistentClass;
 		this.wasSetter = wasSetter;
 		this.propertyName = propertyName;
 	}
 
 	public Class getPersistentClass() {
 		return persistentClass;
 	}
 
 	public String getPropertyName() {
 		return propertyName;
 	}
 
+	protected String originalMessage() {
+		return super.getMessage();
+	}
+
 	@Override
 	public String getMessage() {
-		return super.getMessage()
+		return originalMessage()
 				+ ( wasSetter ? " setter of " : " getter of " )
 				+ StringHelper.qualify( persistentClass.getName(), propertyName );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/PropertySetterAccessException.java b/hibernate-core/src/main/java/org/hibernate/PropertySetterAccessException.java
new file mode 100644
index 0000000000..d84a4e68f8
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/PropertySetterAccessException.java
@@ -0,0 +1,68 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate;
+
+/**
+ * @author Steve Ebersole
+ */
+public class PropertySetterAccessException extends PropertyAccessException {
+	/**
+	 * Constructs a PropertyAccessException using the specified information.
+	 *
+	 * @param cause The underlying cause
+	 * @param persistentClass The class which is supposed to contain the property in question
+	 * @param propertyName The name of the property.
+	 * @param expectedType The expected property type
+	 * @param target The target, which should be of type 'persistentClass'
+	 * @param value The property value we are trying to set
+	 */
+	public PropertySetterAccessException(
+			Throwable cause,
+			Class persistentClass,
+			String propertyName,
+			Class expectedType,
+			Object target,
+			Object value) {
+		super(
+				cause,
+				String.format(
+						"IllegalArgumentException occurred while calling setter for property [%s.%s (expected type = %s)]; " +
+								"target = [%s], property value = [%s]",
+						persistentClass.getName(),
+						propertyName,
+						expectedType.getName(),
+						target,
+						value
+				),
+				true,
+				persistentClass,
+				propertyName
+		);
+	}
+
+	@Override
+	public String toString() {
+		return super.originalMessage();
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/annotations/Any.java b/hibernate-core/src/main/java/org/hibernate/annotations/Any.java
index 7ec5a179f5..786695cc9b 100644
--- a/hibernate-core/src/main/java/org/hibernate/annotations/Any.java
+++ b/hibernate-core/src/main/java/org/hibernate/annotations/Any.java
@@ -1,87 +1,89 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.annotations;
 import java.lang.annotation.Retention;
 import javax.persistence.Column;
 import javax.persistence.FetchType;
 
 import static java.lang.annotation.ElementType.FIELD;
 import static java.lang.annotation.ElementType.METHOD;
 import static java.lang.annotation.RetentionPolicy.RUNTIME;
 
 /**
  * Defines a ToOne-style association pointing to one of several entity types depending on a local discriminator,
  * as opposed to discriminated inheritance where the discriminator is kept as part of the entity hierarchy.
  *
  * For example, if you consider an Order entity containing Payment information where Payment might be of type
  * CashPayment or CreditCardPayment the @Any approach would be to keep that discriminator and matching value on the
  * Order itself.  Thought of another way, the "foreign-key" really is made up of the value and discriminator
  * (there is no physical foreign key here as databases do not support this):
  * <blockquote><pre>
  *    &#064;Entity
  *    class Order {
  *        ...
  *        &#064;Any( metaColumn = @Column( name="payment_type" ) )
  *        &#064;AnyMetDef(
  *                idType = "long"
  *                metaValues = {
  *                        &#064;MetaValue( value="C", targetEntity=CashPayment.class ),
  *                        &#064;MetaValue( value="CC", targetEntity=CreditCardPayment.class ),
  *                }
  *        )
  *        pubic Payment getPayment() { ... }
  *    }
  * }
  * </pre></blockquote>
  *
  * @author Emmanuel Bernard
  * @author Steve Ebersole
+ *
+ * @see AnyMetaDef
  */
 @java.lang.annotation.Target({METHOD, FIELD})
 @Retention(RUNTIME)
 public @interface Any {
 	/**
 	 * Metadata definition used.
 	 * If defined, should point to a @AnyMetaDef name
 	 * If not defined, the local (ie in the same field or property) @AnyMetaDef is used
 	 */
 	String metaDef() default "";
 
 	/**
 	 * Identifies the discriminator column.  This column will hold the value that identifies the targeted entity.
 	 */
 	Column metaColumn();
 
 	/**
 	 * Defines whether the value of the field or property should be lazily loaded or must be
 	 * eagerly fetched. The EAGER strategy is a requirement on the persistence provider runtime
 	 * that the value must be eagerly fetched. The LAZY strategy is applied when bytecode
 	 * enhancement is used. If not specified, defaults to EAGER.
 	 */
 	FetchType fetch() default FetchType.EAGER;
 	/**
 	 * Whether the association is optional. If set to false then a non-null relationship must always exist.
 	 */
 	boolean optional() default true;
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/spi/SessionFactoryImplementor.java b/hibernate-core/src/main/java/org/hibernate/engine/spi/SessionFactoryImplementor.java
index aee333ad27..899e98a32d 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/spi/SessionFactoryImplementor.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/spi/SessionFactoryImplementor.java
@@ -1,293 +1,296 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.spi;
 
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 
 import org.hibernate.CustomEntityDirtinessStrategy;
+import org.hibernate.EntityNameResolver;
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.MappingException;
 import org.hibernate.Session;
 import org.hibernate.SessionFactory;
 import org.hibernate.SessionFactoryObserver;
 import org.hibernate.cache.spi.QueryCache;
 import org.hibernate.cache.spi.Region;
 import org.hibernate.cache.spi.UpdateTimestampsCache;
 import org.hibernate.cfg.Settings;
 import org.hibernate.context.spi.CurrentTenantIdentifierResolver;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.function.SQLFunctionRegistry;
 import org.hibernate.engine.ResultSetMappingDefinition;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.profile.FetchProfile;
 import org.hibernate.engine.query.spi.QueryPlanCache;
 import org.hibernate.exception.spi.SQLExceptionConverter;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.internal.NamedQueryRepository;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.procedure.ProcedureCallMemento;
 import org.hibernate.proxy.EntityNotFoundDelegate;
 import org.hibernate.engine.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.stat.spi.StatisticsImplementor;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeResolver;
 
 /**
  * Defines the internal contract between the <tt>SessionFactory</tt> and other parts of
  * Hibernate such as implementors of <tt>Type</tt>.
  *
  * @see org.hibernate.SessionFactory
  * @see org.hibernate.internal.SessionFactoryImpl
  * @author Gavin King
  */
 public interface SessionFactoryImplementor extends Mapping, SessionFactory {
 	@Override
 	public SessionBuilderImplementor withOptions();
 
 	/**
 	 * Retrieve the {@link Type} resolver associated with this factory.
 	 *
 	 * @return The type resolver
 	 */
 	public TypeResolver getTypeResolver();
 
 	/**
 	 * Get a copy of the Properties used to configure this session factory.
 	 *
 	 * @return The properties.
 	 */
 	public Properties getProperties();
 
 	/**
 	 * Get the persister for the named entity
 	 *
 	 * @param entityName The name of the entity for which to retrieve the persister.
 	 * @return The persister
 	 * @throws MappingException Indicates persister could not be found with that name.
 	 */
 	public EntityPersister getEntityPersister(String entityName) throws MappingException;
 
 	/**
 	 * Get all entity persisters as a Map, which entity name its the key and the persister is the value.
 	 *
 	 * @return The Map contains all entity persisters.
 	 */
 	public Map<String,EntityPersister> getEntityPersisters();
 
 	/**
 	 * Get the persister object for a collection role.
 	 *
 	 * @param role The role (name) of the collection for which to retrieve the
 	 * persister.
 	 * @return The persister
 	 * @throws MappingException Indicates persister could not be found with that role.
 	 */
 	public CollectionPersister getCollectionPersister(String role) throws MappingException;
 
 	/**
 	 * Get all collection persisters as a Map, which collection role as the key and the persister is the value.
 	 *
 	 * @return The Map contains all collection persisters.
 	 */
 	public Map<String, CollectionPersister> getCollectionPersisters();
 
 	/**
 	 * Get the JdbcServices.
 	 * @return the JdbcServices
 	 */
 	public JdbcServices getJdbcServices();
 
 	/**
 	 * Get the SQL dialect.
 	 * <p/>
 	 * Shorthand for {@code getJdbcServices().getDialect()}
 	 *
 	 * @return The dialect
 	 */
 	public Dialect getDialect();
 
 	/**
 	 * Get the factory scoped interceptor for this factory.
 	 *
 	 * @return The factory scope interceptor, or null if none.
 	 */
 	public Interceptor getInterceptor();
 
 	public QueryPlanCache getQueryPlanCache();
 
 	/**
 	 * Get the return types of a query
 	 */
 	public Type[] getReturnTypes(String queryString) throws HibernateException;
 
 	/**
 	 * Get the return aliases of a query
 	 */
 	public String[] getReturnAliases(String queryString) throws HibernateException;
 
 	/**
 	 * Get the connection provider
 	 *
 	 * @deprecated Access to connections via {@link org.hibernate.engine.jdbc.spi.JdbcConnectionAccess} should
 	 * be preferred over access via {@link ConnectionProvider}, whenever possible.
 	 * {@link org.hibernate.engine.jdbc.spi.JdbcConnectionAccess} is tied to the Hibernate Session to
 	 * properly account for contextual information.  See {@link SessionImplementor#getJdbcConnectionAccess()}
 	 */
 	@Deprecated
 	public ConnectionProvider getConnectionProvider();
 	/**
 	 * Get the names of all persistent classes that implement/extend the given interface/class
 	 */
 	public String[] getImplementors(String className) throws MappingException;
 	/**
 	 * Get a class name, using query language imports
 	 */
 	public String getImportedClassName(String name);
 
 	/**
 	 * Get the default query cache
 	 */
 	public QueryCache getQueryCache();
 	/**
 	 * Get a particular named query cache, or the default cache
 	 * @param regionName the name of the cache region, or null for the default query cache
 	 * @return the existing cache, or a newly created cache if none by that region name
 	 */
 	public QueryCache getQueryCache(String regionName) throws HibernateException;
 
 	/**
 	 * Get the cache of table update timestamps
 	 */
 	public UpdateTimestampsCache getUpdateTimestampsCache();
 	/**
 	 * Statistics SPI
 	 */
 	public StatisticsImplementor getStatisticsImplementor();
 
 	public NamedQueryDefinition getNamedQuery(String queryName);
 
 	public void registerNamedQueryDefinition(String name, NamedQueryDefinition definition);
 
 	public NamedSQLQueryDefinition getNamedSQLQuery(String queryName);
 
 	public void registerNamedSQLQueryDefinition(String name, NamedSQLQueryDefinition definition);
 
 	public ResultSetMappingDefinition getResultSetMapping(String name);
 
 	/**
 	 * Get the identifier generator for the hierarchy
 	 */
 	public IdentifierGenerator getIdentifierGenerator(String rootEntityName);
 
 	/**
 	 * Get a named second-level cache region
 	 *
 	 * @param regionName The name of the region to retrieve.
 	 * @return The region
 	 */
 	public Region getSecondLevelCacheRegion(String regionName);
 	
 	/**
 	 * Get a named naturalId cache region
 	 *
 	 * @param regionName The name of the region to retrieve.
 	 * @return The region
 	 */
 	public Region getNaturalIdCacheRegion(String regionName);
 
 	/**
 	 * Get a map of all the second level cache regions currently maintained in
 	 * this session factory.  The map is structured with the region name as the
 	 * key and the {@link Region} instances as the values.
 	 *
 	 * @return The map of regions
 	 */
 	public Map getAllSecondLevelCacheRegions();
 
 	/**
 	 * Retrieves the SQLExceptionConverter in effect for this SessionFactory.
 	 *
 	 * @return The SQLExceptionConverter for this SessionFactory.
 	 *
 	 */
 	public SQLExceptionConverter getSQLExceptionConverter();
 	   // TODO: deprecate???
 
 	/**
 	 * Retrieves the SqlExceptionHelper in effect for this SessionFactory.
 	 *
 	 * @return The SqlExceptionHelper for this SessionFactory.
 	 *
 	 */
     public SqlExceptionHelper getSQLExceptionHelper();
 
 	public Settings getSettings();
 
 	/**
 	 * Get a nontransactional "current" session for Hibernate EntityManager
 	 */
 	public Session openTemporarySession() throws HibernateException;
 
 	/**
 	 * Retrieves a set of all the collection roles in which the given entity
 	 * is a participant, as either an index or an element.
 	 *
 	 * @param entityName The entity name for which to get the collection roles.
 	 * @return set of all the collection roles in which the given entityName participates.
 	 */
 	public Set<String> getCollectionRolesByEntityParticipant(String entityName);
 
 	public EntityNotFoundDelegate getEntityNotFoundDelegate();
 
 	public SQLFunctionRegistry getSqlFunctionRegistry();
 
 	/**
 	 * Retrieve fetch profile by name.
 	 *
 	 * @param name The name of the profile to retrieve.
 	 * @return The profile definition
 	 */
 	public FetchProfile getFetchProfile(String name);
 
 	public ServiceRegistryImplementor getServiceRegistry();
 
 	public void addObserver(SessionFactoryObserver observer);
 
 	public CustomEntityDirtinessStrategy getCustomEntityDirtinessStrategy();
 
 	public CurrentTenantIdentifierResolver getCurrentTenantIdentifierResolver();
 
 	/**
 	 * Provides access to the named query repository
 	 *
 	 * @return
 	 */
 	public NamedQueryRepository getNamedQueryRepository();
+
+	Iterable<EntityNameResolver> iterateEntityNameResolvers();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/NameGenerator.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/NameGenerator.java
index 434f432fdf..adad67ae05 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/NameGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/NameGenerator.java
@@ -1,63 +1,73 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal;
 import org.hibernate.MappingException;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.type.Type;
 
 /**
  * Provides utility methods for generating HQL / SQL names.   Shared by both the 'classic' and 'new' query translators.
  *
  * @author josh
  */
 public final class NameGenerator {
 	/**
 	 * Private empty constructor (checkstyle says utility classes should not have default constructors).
 	 */
 	private NameGenerator() {
 	}
 
 	public static String[][] generateColumnNames(Type[] types, SessionFactoryImplementor f) throws MappingException {
 		String[][] columnNames = new String[types.length][];
 		for ( int i = 0; i < types.length; i++ ) {
 			int span = types[i].getColumnSpan( f );
 			columnNames[i] = new String[span];
 			for ( int j = 0; j < span; j++ ) {
 				columnNames[i][j] = NameGenerator.scalarName( i, j );
 			}
 		}
 		return columnNames;
 	}
 
 	public static String scalarName(int x, int y) {
-		return new StringBuilder()
-				.append( "col_" )
-				.append( x )
-				.append( '_' )
-				.append( y )
-				.append( '_' )
-				.toString();
+		return scalarName( "col_" + x, y );
+	}
+
+	public static String scalarName(String base, int num) {
+		return base + '_' + num + '_';
+	}
+
+	public static String[] scalarNames(String base, int count) {
+		final String[] names = new String[count];
+		for ( int j = 0; j < count; j++ ) {
+			names[j] = scalarName( base, j );
+		}
+		return names;
+	}
+
+	public static String[] scalarNames(int uniqueness, int count) {
+		return scalarNames( "col_" + uniqueness, count );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/HqlSqlWalker.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/HqlSqlWalker.java
index 81003e2284..a37f769b7d 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/HqlSqlWalker.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/HqlSqlWalker.java
@@ -1,1276 +1,1281 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.ast;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Calendar;
 import java.util.Date;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.HibernateException;
 import org.hibernate.QueryException;
 import org.hibernate.engine.internal.JoinSequence;
 import org.hibernate.engine.internal.ParameterBinder;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.hql.internal.antlr.HqlSqlBaseWalker;
 import org.hibernate.hql.internal.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.internal.antlr.HqlTokenTypes;
 import org.hibernate.hql.internal.antlr.SqlTokenTypes;
 import org.hibernate.hql.internal.ast.tree.AggregateNode;
 import org.hibernate.hql.internal.ast.tree.AssignmentSpecification;
 import org.hibernate.hql.internal.ast.tree.CollectionFunction;
 import org.hibernate.hql.internal.ast.tree.ConstructorNode;
 import org.hibernate.hql.internal.ast.tree.DeleteStatement;
 import org.hibernate.hql.internal.ast.tree.DotNode;
 import org.hibernate.hql.internal.ast.tree.FromClause;
 import org.hibernate.hql.internal.ast.tree.FromElement;
 import org.hibernate.hql.internal.ast.tree.FromElementFactory;
 import org.hibernate.hql.internal.ast.tree.FromReferenceNode;
 import org.hibernate.hql.internal.ast.tree.IdentNode;
 import org.hibernate.hql.internal.ast.tree.IndexNode;
 import org.hibernate.hql.internal.ast.tree.InsertStatement;
 import org.hibernate.hql.internal.ast.tree.IntoClause;
 import org.hibernate.hql.internal.ast.tree.MethodNode;
 import org.hibernate.hql.internal.ast.tree.OperatorNode;
 import org.hibernate.hql.internal.ast.tree.ParameterContainer;
 import org.hibernate.hql.internal.ast.tree.ParameterNode;
 import org.hibernate.hql.internal.ast.tree.QueryNode;
 import org.hibernate.hql.internal.ast.tree.ResolvableNode;
 import org.hibernate.hql.internal.ast.tree.RestrictableStatement;
 import org.hibernate.hql.internal.ast.tree.ResultVariableRefNode;
 import org.hibernate.hql.internal.ast.tree.SelectClause;
 import org.hibernate.hql.internal.ast.tree.SelectExpression;
 import org.hibernate.hql.internal.ast.tree.UpdateStatement;
 import org.hibernate.hql.internal.ast.util.ASTPrinter;
 import org.hibernate.hql.internal.ast.util.ASTUtil;
 import org.hibernate.hql.internal.ast.util.AliasGenerator;
 import org.hibernate.hql.internal.ast.util.JoinProcessor;
 import org.hibernate.hql.internal.ast.util.LiteralProcessor;
 import org.hibernate.hql.internal.ast.util.NodeTraverser;
 import org.hibernate.hql.internal.ast.util.SessionFactoryHelper;
 import org.hibernate.hql.internal.ast.util.SyntheticAndFactory;
 import org.hibernate.hql.spi.QueryTranslator;
 import org.hibernate.id.BulkInsertionCapableIdentifierGenerator;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.param.CollectionFilterKeyParameterSpecification;
 import org.hibernate.param.NamedParameterSpecification;
 import org.hibernate.param.ParameterSpecification;
 import org.hibernate.param.PositionalParameterSpecification;
 import org.hibernate.param.VersionTypeSeedParameterSpecification;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.JoinType;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.ComponentType;
 import org.hibernate.type.DbTimestampType;
 import org.hibernate.type.Type;
 import org.hibernate.type.VersionType;
 import org.hibernate.usertype.UserVersionType;
 import org.jboss.logging.Logger;
 
 import antlr.ASTFactory;
 import antlr.RecognitionException;
 import antlr.SemanticException;
 import antlr.collections.AST;
 
 /**
  * Implements methods used by the HQL->SQL tree transform grammar (a.k.a. the second phase).
  * <ul>
  * <li>Isolates the Hibernate API-specific code from the ANTLR generated code.</li>
  * <li>Handles the SQL fragments generated by the persisters in order to create the SELECT and FROM clauses,
  * taking into account the joins and projections that are implied by the mappings (persister/queryable).</li>
  * <li>Uses SqlASTFactory to create customized AST nodes.</li>
  * </ul>
  *
  * @see SqlASTFactory
  */
 public class HqlSqlWalker extends HqlSqlBaseWalker implements ErrorReporter, ParameterBinder.NamedParameterSource {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, HqlSqlWalker.class.getName());
 
 	private final QueryTranslatorImpl queryTranslatorImpl;
 	private final HqlParser hqlParser;
 	private final SessionFactoryHelper sessionFactoryHelper;
 	private final Map tokenReplacements;
 	private final AliasGenerator aliasGenerator = new AliasGenerator();
 	private final LiteralProcessor literalProcessor;
 	private final ParseErrorHandler parseErrorHandler;
 	private final ASTPrinter printer;
 	private final String collectionFilterRole;
 
 	private FromClause currentFromClause = null;
 	private SelectClause selectClause;
 
 	/**
 	 * Maps each top-level result variable to its SelectExpression;
 	 * (excludes result variables defined in subqueries)
 	 **/
 	private Map<String, SelectExpression> selectExpressionsByResultVariable = new HashMap<String, SelectExpression>();
 
 	private Set<Serializable> querySpaces = new HashSet<Serializable>();
 
 	private int parameterCount;
 	private Map namedParameters = new HashMap();
 	private ArrayList parameters = new ArrayList();
 	private int numberOfParametersInSetClause;
 	private int positionalParameterCount;
 
 	private ArrayList assignmentSpecifications = new ArrayList();
 
 	private JoinType impliedJoinType = JoinType.INNER_JOIN;
 
 	/**
 	 * Create a new tree transformer.
 	 *
 	 * @param qti Back pointer to the query translator implementation that is using this tree transform.
 	 * @param sfi The session factory implementor where the Hibernate mappings can be found.
 	 * @param parser A reference to the phase-1 parser
 	 * @param tokenReplacements Registers the token replacement map with the walker.  This map will
 	 * be used to substitute function names and constants.
 	 * @param collectionRole The collection role name of the collection used as the basis for the
 	 * filter, NULL if this is not a collection filter compilation.
 	 */
 	public HqlSqlWalker(
 			QueryTranslatorImpl qti,
 			SessionFactoryImplementor sfi,
 			HqlParser parser,
 			Map tokenReplacements,
 			String collectionRole) {
 		setASTFactory( new SqlASTFactory( this ) );
 		// Initialize the error handling delegate.
 		this.parseErrorHandler = new ErrorCounter( qti.getQueryString() );
 		this.queryTranslatorImpl = qti;
 		this.sessionFactoryHelper = new SessionFactoryHelper( sfi );
 		this.literalProcessor = new LiteralProcessor( this );
 		this.tokenReplacements = tokenReplacements;
 		this.collectionFilterRole = collectionRole;
 		this.hqlParser = parser;
 		this.printer = new ASTPrinter( SqlTokenTypes.class );
 	}
 
 
 	// handle trace logging ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private int traceDepth = 0;
 
 	@Override
 	public void traceIn(String ruleName, AST tree) {
 		if ( !LOG.isTraceEnabled() ) return;
 		if ( inputState.guessing > 0 ) return;
 		String prefix = StringHelper.repeat( '-', ( traceDepth++ * 2 ) ) + "-> ";
 		String traceText = ruleName + " (" + buildTraceNodeName( tree ) + ")";
 		LOG.trace( prefix + traceText );
 	}
 
 	private String buildTraceNodeName(AST tree) {
 		return tree == null
 				? "???"
 				: tree.getText() + " [" + printer.getTokenTypeName( tree.getType() ) + "]";
 	}
 
 	@Override
 	public void traceOut(String ruleName, AST tree) {
 		if ( !LOG.isTraceEnabled() ) return;
 		if ( inputState.guessing > 0 ) return;
 		String prefix = "<-" + StringHelper.repeat( '-', ( --traceDepth * 2 ) ) + " ";
 		LOG.trace( prefix + ruleName );
 	}
 
 	@Override
     protected void prepareFromClauseInputTree(AST fromClauseInput) {
 		if ( !isSubQuery() ) {
 //			// inject param specifications to account for dynamic filter param values
 //			if ( ! getEnabledFilters().isEmpty() ) {
 //				Iterator filterItr = getEnabledFilters().values().iterator();
 //				while ( filterItr.hasNext() ) {
 //					FilterImpl filter = ( FilterImpl ) filterItr.next();
 //					if ( ! filter.getFilterDefinition().getParameterNames().isEmpty() ) {
 //						Iterator paramItr = filter.getFilterDefinition().getParameterNames().iterator();
 //						while ( paramItr.hasNext() ) {
 //							String parameterName = ( String ) paramItr.next();
 //							// currently param filters *only* work with single-column parameter types;
 //							// if that limitation is ever lifted, this logic will need to change to account for that
 //							ParameterNode collectionFilterKeyParameter = ( ParameterNode ) astFactory.create( PARAM, "?" );
 //							DynamicFilterParameterSpecification paramSpec = new DynamicFilterParameterSpecification(
 //									filter.getName(),
 //									parameterName,
 //									filter.getFilterDefinition().getParameterType( parameterName ),
 //									 positionalParameterCount++
 //							);
 //							collectionFilterKeyParameter.setHqlParameterSpecification( paramSpec );
 //							parameters.add( paramSpec );
 //						}
 //					}
 //				}
 //			}
 
 			if ( isFilter() ) {
                 // Handle collection-filter compilation.
 				// IMPORTANT NOTE: This is modifying the INPUT (HQL) tree, not the output tree!
 				QueryableCollection persister = sessionFactoryHelper.getCollectionPersister( collectionFilterRole );
 				Type collectionElementType = persister.getElementType();
 				if ( !collectionElementType.isEntityType() ) {
 					throw new QueryException( "collection of values in filter: this" );
 				}
 
 				String collectionElementEntityName = persister.getElementPersister().getEntityName();
 				ASTFactory inputAstFactory = hqlParser.getASTFactory();
 				AST fromElement = ASTUtil.create( inputAstFactory, HqlTokenTypes.FILTER_ENTITY, collectionElementEntityName );
 				ASTUtil.createSibling( inputAstFactory, HqlTokenTypes.ALIAS, "this", fromElement );
 				fromClauseInput.addChild( fromElement );
 				// Show the modified AST.
                 LOG.debug("prepareFromClauseInputTree() : Filter - Added 'this' as a from element...");
 				queryTranslatorImpl.showHqlAst( hqlParser.getAST() );
 
 				// Create a parameter specification for the collection filter...
 				Type collectionFilterKeyType = sessionFactoryHelper.requireQueryableCollection( collectionFilterRole ).getKeyType();
 				ParameterNode collectionFilterKeyParameter = ( ParameterNode ) astFactory.create( PARAM, "?" );
 				CollectionFilterKeyParameterSpecification collectionFilterKeyParameterSpec = new CollectionFilterKeyParameterSpecification(
 						collectionFilterRole, collectionFilterKeyType, positionalParameterCount++
 				);
 				collectionFilterKeyParameter.setHqlParameterSpecification( collectionFilterKeyParameterSpec );
 				parameters.add( collectionFilterKeyParameterSpec );
 			}
 		}
 	}
 
 	public boolean isFilter() {
 		return collectionFilterRole != null;
 	}
 
 	public String getCollectionFilterRole() {
 		return collectionFilterRole;
 	}
 
 	public SessionFactoryHelper getSessionFactoryHelper() {
 		return sessionFactoryHelper;
 	}
 
 	public Map getTokenReplacements() {
 		return tokenReplacements;
 	}
 
 	public AliasGenerator getAliasGenerator() {
 		return aliasGenerator;
 	}
 
 	public FromClause getCurrentFromClause() {
 		return currentFromClause;
 	}
 
 	public ParseErrorHandler getParseErrorHandler() {
 		return parseErrorHandler;
 	}
 
 	@Override
     public void reportError(RecognitionException e) {
 		parseErrorHandler.reportError( e ); // Use the delegate.
 	}
 
 	@Override
     public void reportError(String s) {
 		parseErrorHandler.reportError( s ); // Use the delegate.
 	}
 
 	@Override
     public void reportWarning(String s) {
 		parseErrorHandler.reportWarning( s );
 	}
 
 	/**
 	 * Returns the set of unique query spaces (a.k.a.
 	 * table names) that occurred in the query.
 	 *
 	 * @return A set of table names (Strings).
 	 */
 	public Set<Serializable> getQuerySpaces() {
 		return querySpaces;
 	}
 
 	@Override
     protected AST createFromElement(String path, AST alias, AST propertyFetch) throws SemanticException {
 		FromElement fromElement = currentFromClause.addFromElement( path, alias );
 		fromElement.setAllPropertyFetch(propertyFetch!=null);
 		return fromElement;
 	}
 
 	@Override
     protected AST createFromFilterElement(AST filterEntity, AST alias) throws SemanticException {
 		FromElement fromElement = currentFromClause.addFromElement( filterEntity.getText(), alias );
 		FromClause fromClause = fromElement.getFromClause();
 		QueryableCollection persister = sessionFactoryHelper.getCollectionPersister( collectionFilterRole );
 		// Get the names of the columns used to link between the collection
 		// owner and the collection elements.
 		String[] keyColumnNames = persister.getKeyColumnNames();
 		String fkTableAlias = persister.isOneToMany()
 				? fromElement.getTableAlias()
 				: fromClause.getAliasGenerator().createName( collectionFilterRole );
 		JoinSequence join = sessionFactoryHelper.createJoinSequence();
 		join.setRoot( persister, fkTableAlias );
 		if ( !persister.isOneToMany() ) {
 			join.addJoin( ( AssociationType ) persister.getElementType(),
 					fromElement.getTableAlias(),
 					JoinType.INNER_JOIN,
 					persister.getElementColumnNames( fkTableAlias ) );
 		}
 		join.addCondition( fkTableAlias, keyColumnNames, " = ?" );
 		fromElement.setJoinSequence( join );
 		fromElement.setFilter( true );
         LOG.debug("createFromFilterElement() : processed filter FROM element.");
 		return fromElement;
 	}
 
 	@Override
     protected void createFromJoinElement(
 	        AST path,
 	        AST alias,
 	        int joinType,
 	        AST fetchNode,
 	        AST propertyFetch,
 	        AST with) throws SemanticException {
 		boolean fetch = fetchNode != null;
 		if ( fetch && isSubQuery() ) {
 			throw new QueryException( "fetch not allowed in subquery from-elements" );
 		}
 		// The path AST should be a DotNode, and it should have been evaluated already.
 		if ( path.getType() != SqlTokenTypes.DOT ) {
 			throw new SemanticException( "Path expected for join!" );
 		}
 		DotNode dot = ( DotNode ) path;
 		JoinType hibernateJoinType = JoinProcessor.toHibernateJoinType( joinType );
 		dot.setJoinType( hibernateJoinType );	// Tell the dot node about the join type.
 		dot.setFetch( fetch );
 		// Generate an explicit join for the root dot node.   The implied joins will be collected and passed up
 		// to the root dot node.
 		dot.resolve( true, false, alias == null ? null : alias.getText() );
 
 		final FromElement fromElement;
 		if ( dot.getDataType() != null && dot.getDataType().isComponentType() ) {
+			if ( dot.getDataType().isAnyType() ) {
+				throw new SemanticException( "An AnyType attribute cannot be join fetched" );
+				// ^^ because the discriminator (aka, the "meta columns") must be known to the SQL in
+				// 		a non-parameterized way.
+			}
 			FromElementFactory factory = new FromElementFactory(
 					getCurrentFromClause(),
 					dot.getLhs().getFromElement(),
 					dot.getPropertyPath(),
 					alias == null ? null : alias.getText(),
 					null,
 					false
 			);
 			fromElement = factory.createComponentJoin( (ComponentType) dot.getDataType() );
 		}
 		else {
 			fromElement = dot.getImpliedJoin();
 			fromElement.setAllPropertyFetch( propertyFetch != null );
 
 			if ( with != null ) {
 				if ( fetch ) {
 					throw new SemanticException( "with-clause not allowed on fetched associations; use filters" );
 				}
 				handleWithFragment( fromElement, with );
 			}
 		}
 
         if ( LOG.isDebugEnabled() ) {
 			LOG.debug("createFromJoinElement() : " + getASTPrinter().showAsString(fromElement, "-- join tree --") );
 		}
 	}
 
 	private void handleWithFragment(FromElement fromElement, AST hqlWithNode) throws SemanticException {
 		try {
 			withClause( hqlWithNode );
 			AST hqlSqlWithNode = returnAST;
             if ( LOG.isDebugEnabled() ) {
 				LOG.debug( "handleWithFragment() : " + getASTPrinter().showAsString(hqlSqlWithNode, "-- with clause --") );
 			}
 			WithClauseVisitor visitor = new WithClauseVisitor( fromElement, queryTranslatorImpl );
 			NodeTraverser traverser = new NodeTraverser( visitor );
 			traverser.traverseDepthFirst( hqlSqlWithNode );
 
 			String withClauseJoinAlias = visitor.getJoinAlias();
 			if ( withClauseJoinAlias == null ) {
 				withClauseJoinAlias = fromElement.getCollectionTableAlias();
 			}
 			else {
 				FromElement referencedFromElement = visitor.getReferencedFromElement();
 				if ( referencedFromElement != fromElement ) {
 					LOG.warnf(
 							"with-clause expressions do not reference the from-clause element to which the " +
 									"with-clause was associated.  The query may not work as expected [%s]",
 							queryTranslatorImpl.getQueryString()
 					);
 				}
 			}
 
 			SqlGenerator sql = new SqlGenerator( getSessionFactoryHelper().getFactory() );
 			sql.whereExpr( hqlSqlWithNode.getFirstChild() );
 
 			fromElement.setWithClauseFragment( withClauseJoinAlias, "(" + sql.getSQL() + ")" );
 		}
 		catch( SemanticException e ) {
 			throw e;
 		}
 		catch( InvalidWithClauseException e ) {
 			throw e;
 		}
 		catch ( Exception e) {
 			throw new SemanticException( e.getMessage() );
 		}
 	}
 
 	private static class WithClauseVisitor implements NodeTraverser.VisitationStrategy {
 		private final FromElement joinFragment;
 		private final QueryTranslatorImpl queryTranslatorImpl;
 
 		private FromElement referencedFromElement;
 		private String joinAlias;
 
 		public WithClauseVisitor(FromElement fromElement, QueryTranslatorImpl queryTranslatorImpl) {
 			this.joinFragment = fromElement;
 			this.queryTranslatorImpl = queryTranslatorImpl;
 		}
 
 		public void visit(AST node) {
             // TODO : currently expects that the individual with expressions apply to the same sql table join.
 			//      This may not be the case for joined-subclass where the property values
 			//      might be coming from different tables in the joined hierarchy.  At some
 			//      point we should expand this to support that capability.  However, that has
 			//      some difficulties:
 			//          1) the biggest is how to handle ORs when the individual comparisons are
 			//              linked to different sql joins.
 			//          2) here we would need to track each comparison individually, along with
 			//              the join alias to which it applies and then pass that information
 			//              back to the FromElement so it can pass it along to the JoinSequence
 			if ( node instanceof DotNode ) {
 				DotNode dotNode = ( DotNode ) node;
 				FromElement fromElement = dotNode.getFromElement();
 				if ( referencedFromElement != null ) {
 					if ( fromElement != referencedFromElement ) {
 						throw new HibernateException( "with-clause referenced two different from-clause elements" );
 					}
 				}
 				else {
 					referencedFromElement = fromElement;
 					joinAlias = extractAppliedAlias( dotNode );
                     // TODO : temporary
 					//      needed because currently persister is the one that
                     // creates and renders the join fragments for inheritance
 					//      hierarchies...
 					if ( !joinAlias.equals( referencedFromElement.getTableAlias() ) ) {
 						throw new InvalidWithClauseException(
 								"with clause can only reference columns in the driving table",
 								queryTranslatorImpl.getQueryString()
 						);
 					}
 				}
 			}
 			else if ( node instanceof ParameterNode ) {
 				applyParameterSpecification( ( ( ParameterNode ) node ).getHqlParameterSpecification() );
 			}
 			else if ( node instanceof ParameterContainer ) {
 				applyParameterSpecifications( ( ParameterContainer ) node );
 			}
 		}
 
 		private void applyParameterSpecifications(ParameterContainer parameterContainer) {
 			if ( parameterContainer.hasEmbeddedParameters() ) {
 				ParameterSpecification[] specs = parameterContainer.getEmbeddedParameters();
 				for ( ParameterSpecification spec : specs ) {
 					applyParameterSpecification( spec );
 				}
 			}
 		}
 
 		private void applyParameterSpecification(ParameterSpecification paramSpec) {
 			joinFragment.addEmbeddedParameter( paramSpec );
 		}
 
 		private String extractAppliedAlias(DotNode dotNode) {
 			return dotNode.getText().substring( 0, dotNode.getText().indexOf( '.' ) );
 		}
 
 		public FromElement getReferencedFromElement() {
 			return referencedFromElement;
 		}
 
 		public String getJoinAlias() {
 			return joinAlias;
 		}
 	}
 
 	/**
 	 * Sets the current 'FROM' context.
 	 *
 	 * @param fromNode      The new 'FROM' context.
 	 * @param inputFromNode The from node from the input AST.
 	 */
 	@Override
     protected void pushFromClause(AST fromNode, AST inputFromNode) {
 		FromClause newFromClause = ( FromClause ) fromNode;
 		newFromClause.setParentFromClause( currentFromClause );
 		currentFromClause = newFromClause;
 	}
 
 	/**
 	 * Returns to the previous 'FROM' context.
 	 */
 	private void popFromClause() {
 		currentFromClause = currentFromClause.getParentFromClause();
 	}
 
 	@Override
     protected void lookupAlias(AST aliasRef)
 			throws SemanticException {
 		FromElement alias = currentFromClause.getFromElement( aliasRef.getText() );
 		FromReferenceNode aliasRefNode = ( FromReferenceNode ) aliasRef;
 		aliasRefNode.setFromElement( alias );
 	}
 
 	@Override
     protected void setImpliedJoinType(int joinType) {
 		impliedJoinType = JoinProcessor.toHibernateJoinType( joinType );
 	}
 
 	public JoinType getImpliedJoinType() {
 		return impliedJoinType;
 	}
 
 	@Override
     protected AST lookupProperty(AST dot, boolean root, boolean inSelect) throws SemanticException {
 		DotNode dotNode = ( DotNode ) dot;
 		FromReferenceNode lhs = dotNode.getLhs();
 		AST rhs = lhs.getNextSibling();
 		switch ( rhs.getType() ) {
 			case SqlTokenTypes.ELEMENTS:
 			case SqlTokenTypes.INDICES:
                 if (LOG.isDebugEnabled()) LOG.debugf("lookupProperty() %s => %s(%s)",
                                                      dotNode.getPath(),
                                                      rhs.getText(),
                                                      lhs.getPath());
 				CollectionFunction f = ( CollectionFunction ) rhs;
 				// Re-arrange the tree so that the collection function is the root and the lhs is the path.
 				f.setFirstChild( lhs );
 				lhs.setNextSibling( null );
 				dotNode.setFirstChild( f );
 				resolve( lhs );			// Don't forget to resolve the argument!
 				f.resolve( inSelect );	// Resolve the collection function now.
 				return f;
 			default:
 				// Resolve everything up to this dot, but don't resolve the placeholders yet.
 				dotNode.resolveFirstChild();
 				return dotNode;
 		}
 	}
 
 	@Override
     protected boolean isNonQualifiedPropertyRef(AST ident) {
 		final String identText = ident.getText();
 		if ( currentFromClause.isFromElementAlias( identText ) ) {
 			return false;
 		}
 
 		List fromElements = currentFromClause.getExplicitFromElements();
 		if ( fromElements.size() == 1 ) {
 			final FromElement fromElement = ( FromElement ) fromElements.get( 0 );
 			try {
 				LOG.tracev( "Attempting to resolve property [{0}] as a non-qualified ref", identText );
 				return fromElement.getPropertyMapping( identText ).toType( identText ) != null;
 			}
 			catch( QueryException e ) {
 				// Should mean that no such property was found
 			}
 		}
 
 		return false;
 	}
 
 	@Override
 	protected AST lookupNonQualifiedProperty(AST property) throws SemanticException {
 		final FromElement fromElement = ( FromElement ) currentFromClause.getExplicitFromElements().get( 0 );
 		AST syntheticDotNode = generateSyntheticDotNodeForNonQualifiedPropertyRef( property, fromElement );
 		return lookupProperty( syntheticDotNode, false, getCurrentClauseType() == HqlSqlTokenTypes.SELECT );
 	}
 
 	private AST generateSyntheticDotNodeForNonQualifiedPropertyRef(AST property, FromElement fromElement) {
 		AST dot = getASTFactory().create( DOT, "{non-qualified-property-ref}" );
 		// TODO : better way?!?
 		( ( DotNode ) dot ).setPropertyPath( ( ( FromReferenceNode ) property ).getPath() );
 
 		IdentNode syntheticAlias = ( IdentNode ) getASTFactory().create( IDENT, "{synthetic-alias}" );
 		syntheticAlias.setFromElement( fromElement );
 		syntheticAlias.setResolved();
 
 		dot.setFirstChild( syntheticAlias );
 		dot.addChild( property );
 
 		return dot;
 	}
 
 	@Override
 	protected void processQuery(AST select, AST query) throws SemanticException {
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "processQuery() : %s", query.toStringTree() );
 		}
 
 		try {
 			QueryNode qn = ( QueryNode ) query;
 
 			// Was there an explicit select expression?
 			boolean explicitSelect = select != null && select.getNumberOfChildren() > 0;
 
 			if ( !explicitSelect ) {
 				// No explicit select expression; render the id and properties
 				// projection lists for every persister in the from clause into
 				// a single 'token node'.
 				//TODO: the only reason we need this stuff now is collection filters,
 				//      we should get rid of derived select clause completely!
 				createSelectClauseFromFromClause( qn );
 			}
 			else {
 				// Use the explicitly declared select expression; determine the
 				// return types indicated by each select token
 				useSelectClause( select );
 			}
 
 			// After that, process the JOINs.
 			// Invoke a delegate to do the work, as this is farily complex.
 			JoinProcessor joinProcessor = new JoinProcessor( this );
 			joinProcessor.processJoins( qn );
 
 			// Attach any mapping-defined "ORDER BY" fragments
 			Iterator itr = qn.getFromClause().getProjectionList().iterator();
 			while ( itr.hasNext() ) {
 				final FromElement fromElement = ( FromElement ) itr.next();
 //			if ( fromElement.isFetch() && fromElement.isCollectionJoin() ) {
 				if ( fromElement.isFetch() && fromElement.getQueryableCollection() != null ) {
 					// Does the collection referenced by this FromElement
 					// specify an order-by attribute?  If so, attach it to
 					// the query's order-by
 					if ( fromElement.getQueryableCollection().hasOrdering() ) {
 						String orderByFragment = fromElement
 								.getQueryableCollection()
 								.getSQLOrderByString( fromElement.getCollectionTableAlias() );
 						qn.getOrderByClause().addOrderFragment( orderByFragment );
 					}
 					if ( fromElement.getQueryableCollection().hasManyToManyOrdering() ) {
 						String orderByFragment = fromElement.getQueryableCollection()
 								.getManyToManyOrderByString( fromElement.getTableAlias() );
 						qn.getOrderByClause().addOrderFragment( orderByFragment );
 					}
 				}
 			}
 		}
 		finally {
 			popFromClause();
 		}
 	}
 
 	protected void postProcessDML(RestrictableStatement statement) throws SemanticException {
 		statement.getFromClause().resolve();
 
 		FromElement fromElement = ( FromElement ) statement.getFromClause().getFromElements().get( 0 );
 		Queryable persister = fromElement.getQueryable();
 		// Make #@%$^#^&# sure no alias is applied to the table name
 		fromElement.setText( persister.getTableName() );
 
 //		// append any filter fragments; the EMPTY_MAP is used under the assumption that
 //		// currently enabled filters should not affect this process
 //		if ( persister.getDiscriminatorType() != null ) {
 //			new SyntheticAndFactory( getASTFactory() ).addDiscriminatorWhereFragment(
 //			        statement,
 //			        persister,
 //			        java.util.Collections.EMPTY_MAP,
 //			        fromElement.getTableAlias()
 //			);
 //		}
 		if ( persister.getDiscriminatorType() != null || ! queryTranslatorImpl.getEnabledFilters().isEmpty() ) {
 			new SyntheticAndFactory( this ).addDiscriminatorWhereFragment(
 			        statement,
 			        persister,
 			        queryTranslatorImpl.getEnabledFilters(),
 			        fromElement.getTableAlias()
 			);
 		}
 
 	}
 
 	@Override
     protected void postProcessUpdate(AST update) throws SemanticException {
 		UpdateStatement updateStatement = ( UpdateStatement ) update;
 
 		postProcessDML( updateStatement );
 	}
 
 	@Override
     protected void postProcessDelete(AST delete) throws SemanticException {
 		postProcessDML( ( DeleteStatement ) delete );
 	}
 
 	@Override
     protected void postProcessInsert(AST insert) throws SemanticException, QueryException {
 		InsertStatement insertStatement = ( InsertStatement ) insert;
 		insertStatement.validate();
 
 		SelectClause selectClause = insertStatement.getSelectClause();
 		Queryable persister = insertStatement.getIntoClause().getQueryable();
 
 		if ( !insertStatement.getIntoClause().isExplicitIdInsertion() ) {
 			// the insert did not explicitly reference the id.  See if
 			//		1) that is allowed
 			//		2) whether we need to alter the SQL tree to account for id
 			final IdentifierGenerator generator = persister.getIdentifierGenerator();
 			if ( !BulkInsertionCapableIdentifierGenerator.class.isInstance( generator ) ) {
 				throw new QueryException(
 						"Invalid identifier generator encountered for implicit id handling as part of bulk insertions"
 				);
 			}
 			final BulkInsertionCapableIdentifierGenerator capableGenerator =
 					BulkInsertionCapableIdentifierGenerator.class.cast( generator );
 			if ( ! capableGenerator.supportsBulkInsertionIdentifierGeneration() ) {
 				throw new QueryException(
 						"Identifier generator reported it does not support implicit id handling as part of bulk insertions"
 				);
 			}
 
             final String fragment = capableGenerator.determineBulkInsertionIdentifierGenerationSelectFragment(
 					sessionFactoryHelper.getFactory().getDialect()
 			);
 			if ( fragment != null ) {
                 // we got a fragment from the generator, so alter the sql tree...
                 //
                 // first, wrap the fragment as a node
                 AST fragmentNode = getASTFactory().create( HqlSqlTokenTypes.SQL_TOKEN, fragment );
                 // next, rearrange the SQL tree to add the fragment node as the first select expression
                 AST originalFirstSelectExprNode = selectClause.getFirstChild();
                 selectClause.setFirstChild( fragmentNode );
                 fragmentNode.setNextSibling( originalFirstSelectExprNode );
                 // finally, prepend the id column name(s) to the insert-spec
                 insertStatement.getIntoClause().prependIdColumnSpec();
 			}
 		}
 
 		if ( sessionFactoryHelper.getFactory().getDialect().supportsParametersInInsertSelect() ) {
 			AST child = selectClause.getFirstChild();
 			int i = 0;
 			while(child != null) {
 				if(child instanceof ParameterNode) {
 					// infer the parameter type from the type listed in the INSERT INTO clause
 					((ParameterNode)child).setExpectedType(insertStatement.getIntoClause()
 							.getInsertionTypes()[selectClause.getParameterPositions().get(i)]);
 					i++;
 				}
 				child = child.getNextSibling();
 			}
 		}
 
 		final boolean includeVersionProperty = persister.isVersioned() &&
 				!insertStatement.getIntoClause().isExplicitVersionInsertion() &&
 				persister.isVersionPropertyInsertable();
 		if ( includeVersionProperty ) {
 			// We need to seed the version value as part of this bulk insert
 			VersionType versionType = persister.getVersionType();
 			AST versionValueNode = null;
 
 			if ( sessionFactoryHelper.getFactory().getDialect().supportsParametersInInsertSelect() ) {
 				int sqlTypes[] = versionType.sqlTypes( sessionFactoryHelper.getFactory() );
 				if ( sqlTypes == null || sqlTypes.length == 0 ) {
 					throw new IllegalStateException( versionType.getClass() + ".sqlTypes() returns null or empty array" );
 				}
 				if ( sqlTypes.length > 1 ) {
 					throw new IllegalStateException(
 							versionType.getClass() +
 									".sqlTypes() returns > 1 element; only single-valued versions are allowed."
 					);
 				}
 				versionValueNode = getASTFactory().create( HqlSqlTokenTypes.PARAM, "?" );
 				ParameterSpecification paramSpec = new VersionTypeSeedParameterSpecification( versionType );
 				( ( ParameterNode ) versionValueNode ).setHqlParameterSpecification( paramSpec );
 				parameters.add( 0, paramSpec );
 
 				if ( sessionFactoryHelper.getFactory().getDialect().requiresCastingOfParametersInSelectClause() ) {
 					// we need to wrtap the param in a cast()
 					MethodNode versionMethodNode = ( MethodNode ) getASTFactory().create( HqlSqlTokenTypes.METHOD_CALL, "(" );
 					AST methodIdentNode = getASTFactory().create( HqlSqlTokenTypes.IDENT, "cast" );
 					versionMethodNode.addChild( methodIdentNode );
 					versionMethodNode.initializeMethodNode(methodIdentNode, true );
 					AST castExprListNode = getASTFactory().create( HqlSqlTokenTypes.EXPR_LIST, "exprList" );
 					methodIdentNode.setNextSibling( castExprListNode );
 					castExprListNode.addChild( versionValueNode );
 					versionValueNode.setNextSibling(
 							getASTFactory().create(
 									HqlSqlTokenTypes.IDENT,
 									sessionFactoryHelper.getFactory().getDialect().getTypeName( sqlTypes[0] ) )
 					);
 					processFunction( versionMethodNode, true );
 					versionValueNode = versionMethodNode;
 				}
 			}
 			else {
 				if ( isIntegral( versionType ) ) {
 					try {
 						Object seedValue = versionType.seed( null );
 						versionValueNode = getASTFactory().create( HqlSqlTokenTypes.SQL_TOKEN, seedValue.toString() );
 					}
 					catch( Throwable t ) {
 						throw new QueryException( "could not determine seed value for version on bulk insert [" + versionType + "]" );
 					}
 				}
 				else if ( isDatabaseGeneratedTimestamp( versionType ) ) {
 					String functionName = sessionFactoryHelper.getFactory().getDialect().getCurrentTimestampSQLFunctionName();
 					versionValueNode = getASTFactory().create( HqlSqlTokenTypes.SQL_TOKEN, functionName );
 				}
 				else {
 					throw new QueryException( "cannot handle version type [" + versionType + "] on bulk inserts with dialects not supporting parameters in insert-select statements" );
 				}
 			}
 
 			AST currentFirstSelectExprNode = selectClause.getFirstChild();
 			selectClause.setFirstChild( versionValueNode );
 			versionValueNode.setNextSibling( currentFirstSelectExprNode );
 
 			insertStatement.getIntoClause().prependVersionColumnSpec();
 		}
 
 		if ( insertStatement.getIntoClause().isDiscriminated() ) {
 			String sqlValue = insertStatement.getIntoClause().getQueryable().getDiscriminatorSQLValue();
 			AST discrimValue = getASTFactory().create( HqlSqlTokenTypes.SQL_TOKEN, sqlValue );
 			insertStatement.getSelectClause().addChild( discrimValue );
 		}
 
 	}
 
 	private boolean isDatabaseGeneratedTimestamp(Type type) {
 		// currently only the Hibernate-supplied DbTimestampType is supported here
 		return DbTimestampType.class.isAssignableFrom( type.getClass() );
 	}
 
 	private boolean isIntegral(Type type) {
 		return Long.class.isAssignableFrom( type.getReturnedClass() )
 		       || Integer.class.isAssignableFrom( type.getReturnedClass() )
 		       || long.class.isAssignableFrom( type.getReturnedClass() )
 		       || int.class.isAssignableFrom( type.getReturnedClass() );
 	}
 
 	private void useSelectClause(AST select) throws SemanticException {
 		selectClause = ( SelectClause ) select;
 		selectClause.initializeExplicitSelectClause( currentFromClause );
 	}
 
 	private void createSelectClauseFromFromClause(QueryNode qn) throws SemanticException {
 		AST select = astFactory.create( SELECT_CLAUSE, "{derived select clause}" );
 		AST sibling = qn.getFromClause();
 		qn.setFirstChild( select );
 		select.setNextSibling( sibling );
 		selectClause = ( SelectClause ) select;
 		selectClause.initializeDerivedSelectClause( currentFromClause );
 		LOG.debug( "Derived SELECT clause created." );
 	}
 
 	@Override
     protected void resolve(AST node) throws SemanticException {
 		if ( node != null ) {
 			// This is called when it's time to fully resolve a path expression.
 			ResolvableNode r = ( ResolvableNode ) node;
 			if ( isInFunctionCall() ) {
 				r.resolveInFunctionCall( false, true );
 			}
 			else {
 				r.resolve( false, true );	// Generate implicit joins, only if necessary.
 			}
 		}
 	}
 
 	@Override
     protected void resolveSelectExpression(AST node) throws SemanticException {
 		// This is called when it's time to fully resolve a path expression.
 		int type = node.getType();
 		switch ( type ) {
 			case DOT: {
 				DotNode dot = ( DotNode ) node;
 				dot.resolveSelectExpression();
 				break;
 			}
 			case ALIAS_REF: {
 				// Notify the FROM element that it is being referenced by the select.
 				FromReferenceNode aliasRefNode = ( FromReferenceNode ) node;
 				//aliasRefNode.resolve( false, false, aliasRefNode.getText() ); //TODO: is it kosher to do it here?
 				aliasRefNode.resolve( false, false ); //TODO: is it kosher to do it here?
 				FromElement fromElement = aliasRefNode.getFromElement();
 				if ( fromElement != null ) {
 					fromElement.setIncludeSubclasses( true );
 				}
 				break;
 			}
 			default: {
 				break;
 			}
 		}
 	}
 
 	@Override
     protected void beforeSelectClause() throws SemanticException {
 		// Turn off includeSubclasses on all FromElements.
 		FromClause from = getCurrentFromClause();
 		List fromElements = from.getFromElements();
 		for ( Iterator iterator = fromElements.iterator(); iterator.hasNext(); ) {
 			FromElement fromElement = ( FromElement ) iterator.next();
 			fromElement.setIncludeSubclasses( false );
 		}
 	}
 
 	@Override
     protected AST generatePositionalParameter(AST inputNode) throws SemanticException {
 		if ( namedParameters.size() > 0 ) {
 			throw new SemanticException( "cannot define positional parameter after any named parameters have been defined" );
 		}
 		LOG.warnf(
 				"[DEPRECATION] Encountered positional parameter near line %s, column %s.  Positional parameter " +
 						"are considered deprecated; use named parameters or JPA-style positional parameters instead.",
 				inputNode.getLine(),
 				inputNode.getColumn()
 		);
 		ParameterNode parameter = ( ParameterNode ) astFactory.create( PARAM, "?" );
 		PositionalParameterSpecification paramSpec = new PositionalParameterSpecification(
 				inputNode.getLine(),
 		        inputNode.getColumn(),
 				positionalParameterCount++
 		);
 		parameter.setHqlParameterSpecification( paramSpec );
 		parameters.add( paramSpec );
 		return parameter;
 	}
 
 	@Override
     protected AST generateNamedParameter(AST delimiterNode, AST nameNode) throws SemanticException {
 		String name = nameNode.getText();
 		trackNamedParameterPositions( name );
 
 		// create the node initially with the param name so that it shows
 		// appropriately in the "original text" attribute
 		ParameterNode parameter = ( ParameterNode ) astFactory.create( NAMED_PARAM, name );
 		parameter.setText( "?" );
 
 		NamedParameterSpecification paramSpec = new NamedParameterSpecification(
 				delimiterNode.getLine(),
 		        delimiterNode.getColumn(),
 				name
 		);
 		parameter.setHqlParameterSpecification( paramSpec );
 		parameters.add( paramSpec );
 		return parameter;
 	}
 
 	private void trackNamedParameterPositions(String name) {
 		Integer loc = parameterCount++;
 		Object o = namedParameters.get( name );
 		if ( o == null ) {
 			namedParameters.put( name, loc );
 		}
 		else if ( o instanceof Integer ) {
 			ArrayList list = new ArrayList( 4 );
 			list.add( o );
 			list.add( loc );
 			namedParameters.put( name, list );
 		}
 		else {
 			( ( ArrayList ) o ).add( loc );
 		}
 	}
 
 	@Override
     protected void processConstant(AST constant) throws SemanticException {
 		literalProcessor.processConstant( constant, true );  // Use the delegate, resolve identifiers as FROM element aliases.
 	}
 
 	@Override
     protected void processBoolean(AST constant) throws SemanticException {
 		literalProcessor.processBoolean( constant );  // Use the delegate.
 	}
 
 	@Override
     protected void processNumericLiteral(AST literal) {
 		literalProcessor.processNumeric( literal );
 	}
 
 	@Override
     protected void processIndex(AST indexOp) throws SemanticException {
 		IndexNode indexNode = ( IndexNode ) indexOp;
 		indexNode.resolve( true, true );
 	}
 
 	@Override
     protected void processFunction(AST functionCall, boolean inSelect) throws SemanticException {
 		MethodNode methodNode = ( MethodNode ) functionCall;
 		methodNode.resolve( inSelect );
 	}
 
 	@Override
     protected void processAggregation(AST node, boolean inSelect) throws SemanticException {
 		AggregateNode aggregateNode = ( AggregateNode ) node;
 		aggregateNode.resolve();
 	}
 
 	@Override
     protected void processConstructor(AST constructor) throws SemanticException {
 		ConstructorNode constructorNode = ( ConstructorNode ) constructor;
 		constructorNode.prepare();
 	}
 
     @Override
     protected void setAlias(AST selectExpr, AST ident) {
         ((SelectExpression) selectExpr).setAlias(ident.getText());
 		// only put the alias (i.e., result variable) in selectExpressionsByResultVariable
 		// if is not defined in a subquery.
 		if ( ! isSubQuery() ) {
 			selectExpressionsByResultVariable.put( ident.getText(), ( SelectExpression ) selectExpr );
 		}
     }
 
 	@Override
     protected boolean isOrderExpressionResultVariableRef(AST orderExpressionNode) throws SemanticException {
 		// ORDER BY is not supported in a subquery
 		// TODO: should an exception be thrown if an ORDER BY is in a subquery?
 		if ( ! isSubQuery() &&
 				orderExpressionNode.getType() == IDENT &&
 				selectExpressionsByResultVariable.containsKey( orderExpressionNode.getText() ) ) {
 			return true;
 		}
 		return false;
 	}
 
 	@Override
     protected void handleResultVariableRef(AST resultVariableRef) throws SemanticException {
 		if ( isSubQuery() ) {
 			throw new SemanticException(
 					"References to result variables in subqueries are not supported."
 			);
 		}
 		( ( ResultVariableRefNode ) resultVariableRef ).setSelectExpression(
 				selectExpressionsByResultVariable.get( resultVariableRef.getText() )
 		);
 	}
 
 	/**
 	 * Returns the locations of all occurrences of the named parameter.
 	 */
 	public int[] getNamedParameterLocations(String name) throws QueryException {
 		Object o = namedParameters.get( name );
 		if ( o == null ) {
 			throw new QueryException( QueryTranslator.ERROR_NAMED_PARAMETER_DOES_NOT_APPEAR + name, queryTranslatorImpl.getQueryString() );
 		}
 		if ( o instanceof Integer ) {
 			return new int[]{ (Integer) o };
 		}
 		else {
 			return ArrayHelper.toIntArray( (ArrayList) o );
 		}
 	}
 
 	public void addQuerySpaces(Serializable[] spaces) {
 		querySpaces.addAll( Arrays.asList( spaces ) );
 	}
 
 	public Type[] getReturnTypes() {
 		return selectClause.getQueryReturnTypes();
 	}
 
 	public String[] getReturnAliases() {
 		return selectClause.getQueryReturnAliases();
 	}
 
 	public SelectClause getSelectClause() {
 		return selectClause;
 	}
 
 	public FromClause getFinalFromClause() {
 		FromClause top = currentFromClause;
 		while ( top.getParentFromClause() != null ) {
 			top = top.getParentFromClause();
 		}
 		return top;
 	}
 
 	public boolean isShallowQuery() {
 		// select clauses for insert statements should alwasy be treated as shallow
 		return getStatementType() == INSERT || queryTranslatorImpl.isShallowQuery();
 	}
 
 	public Map getEnabledFilters() {
 		return queryTranslatorImpl.getEnabledFilters();
 	}
 
 	public LiteralProcessor getLiteralProcessor() {
 		return literalProcessor;
 	}
 
 	public ASTPrinter getASTPrinter() {
 		return printer;
 	}
 
 	public ArrayList getParameters() {
 		return parameters;
 	}
 
 	public int getNumberOfParametersInSetClause() {
 		return numberOfParametersInSetClause;
 	}
 
 	@Override
     protected void evaluateAssignment(AST eq) throws SemanticException {
 		prepareLogicOperator( eq );
 		Queryable persister = getCurrentFromClause().getFromElement().getQueryable();
 		evaluateAssignment( eq, persister, -1 );
 	}
 
 	private void evaluateAssignment(AST eq, Queryable persister, int targetIndex) {
 		if ( persister.isMultiTable() ) {
 			// no need to even collect this information if the persister is considered multi-table
 			AssignmentSpecification specification = new AssignmentSpecification( eq, persister );
 			if ( targetIndex >= 0 ) {
 				assignmentSpecifications.add( targetIndex, specification );
 			}
 			else {
 				assignmentSpecifications.add( specification );
 			}
 			numberOfParametersInSetClause += specification.getParameters().length;
 		}
 	}
 
 	public ArrayList getAssignmentSpecifications() {
 		return assignmentSpecifications;
 	}
 
 	@Override
     protected AST createIntoClause(String path, AST propertySpec) throws SemanticException {
 		Queryable persister = ( Queryable ) getSessionFactoryHelper().requireClassPersister( path );
 
 		IntoClause intoClause = ( IntoClause ) getASTFactory().create( INTO, persister.getEntityName() );
 		intoClause.setFirstChild( propertySpec );
 		intoClause.initialize( persister );
 
 		addQuerySpaces( persister.getQuerySpaces() );
 
 		return intoClause;
 	}
 
 	@Override
     protected void prepareVersioned(AST updateNode, AST versioned) throws SemanticException {
 		UpdateStatement updateStatement = ( UpdateStatement ) updateNode;
 		FromClause fromClause = updateStatement.getFromClause();
 		if ( versioned != null ) {
 			// Make sure that the persister is versioned
 			Queryable persister = fromClause.getFromElement().getQueryable();
 			if ( !persister.isVersioned() ) {
 				throw new SemanticException( "increment option specified for update of non-versioned entity" );
 			}
 
 			VersionType versionType = persister.getVersionType();
 			if ( versionType instanceof UserVersionType ) {
 				throw new SemanticException( "user-defined version types not supported for increment option" );
 			}
 
 			AST eq = getASTFactory().create( HqlSqlTokenTypes.EQ, "=" );
 			AST versionPropertyNode = generateVersionPropertyNode( persister );
 
 			eq.setFirstChild( versionPropertyNode );
 
 			AST versionIncrementNode = null;
 			if ( isTimestampBasedVersion( versionType ) ) {
 				versionIncrementNode = getASTFactory().create( HqlSqlTokenTypes.PARAM, "?" );
 				ParameterSpecification paramSpec = new VersionTypeSeedParameterSpecification( versionType );
 				( ( ParameterNode ) versionIncrementNode ).setHqlParameterSpecification( paramSpec );
 				parameters.add( 0, paramSpec );
 			}
 			else {
 				// Not possible to simply re-use the versionPropertyNode here as it causes
 				// OOM errors due to circularity :(
 				versionIncrementNode = getASTFactory().create( HqlSqlTokenTypes.PLUS, "+" );
 				versionIncrementNode.setFirstChild( generateVersionPropertyNode( persister ) );
 				versionIncrementNode.addChild( getASTFactory().create( HqlSqlTokenTypes.IDENT, "1" ) );
 			}
 
 			eq.addChild( versionIncrementNode );
 
 			evaluateAssignment( eq, persister, 0 );
 
 			AST setClause = updateStatement.getSetClause();
 			AST currentFirstSetElement = setClause.getFirstChild();
 			setClause.setFirstChild( eq );
 			eq.setNextSibling( currentFirstSetElement );
 		}
 	}
 
 	private boolean isTimestampBasedVersion(VersionType versionType) {
 		final Class javaType = versionType.getReturnedClass();
 		return Date.class.isAssignableFrom( javaType )
 				|| Calendar.class.isAssignableFrom( javaType );
 	}
 
 	private AST generateVersionPropertyNode(Queryable persister) throws SemanticException {
 		String versionPropertyName = persister.getPropertyNames()[ persister.getVersionProperty() ];
 		AST versionPropertyRef = getASTFactory().create( HqlSqlTokenTypes.IDENT, versionPropertyName );
 		AST versionPropertyNode = lookupNonQualifiedProperty( versionPropertyRef );
 		resolve( versionPropertyNode );
 		return versionPropertyNode;
 	}
 
 	@Override
     protected void prepareLogicOperator(AST operator) throws SemanticException {
 		( ( OperatorNode ) operator ).initialize();
 	}
 
 	@Override
     protected void prepareArithmeticOperator(AST operator) throws SemanticException {
 		( ( OperatorNode ) operator ).initialize();
 	}
 
 	@Override
     protected void validateMapPropertyExpression(AST node) throws SemanticException {
 		try {
 			FromReferenceNode fromReferenceNode = (FromReferenceNode) node;
 			QueryableCollection collectionPersister = fromReferenceNode.getFromElement().getQueryableCollection();
 			if ( ! Map.class.isAssignableFrom( collectionPersister.getCollectionType().getReturnedClass() ) ) {
 				throw new SemanticException( "node did not reference a map" );
 			}
 		}
 		catch ( SemanticException se ) {
 			throw se;
 		}
 		catch ( Throwable t ) {
 			throw new SemanticException( "node did not reference a map" );
 		}
 	}
 
 	public static void panic() {
 		throw new QueryException( "TreeWalker: panic" );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java
index 2f52e18f3b..a5d70ad49e 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java
@@ -1,1778 +1,1778 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import java.io.IOException;
 import java.io.InvalidObjectException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
-import java.util.List;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 import java.util.concurrent.ConcurrentHashMap;
 
 import javax.naming.Reference;
 import javax.naming.StringRefAddr;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.Cache;
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.CustomEntityDirtinessStrategy;
 import org.hibernate.EmptyInterceptor;
 import org.hibernate.EntityNameResolver;
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.MappingException;
 import org.hibernate.MultiTenancyStrategy;
 import org.hibernate.ObjectNotFoundException;
 import org.hibernate.Session;
 import org.hibernate.SessionBuilder;
 import org.hibernate.SessionFactory;
 import org.hibernate.SessionFactoryObserver;
 import org.hibernate.StatelessSession;
 import org.hibernate.StatelessSessionBuilder;
 import org.hibernate.TypeHelper;
 import org.hibernate.boot.registry.StandardServiceRegistry;
 import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
 import org.hibernate.boot.registry.classloading.spi.ClassLoadingException;
 import org.hibernate.cache.internal.CacheDataDescriptionImpl;
 import org.hibernate.cache.spi.CollectionRegion;
 import org.hibernate.cache.spi.EntityRegion;
 import org.hibernate.cache.spi.NaturalIdRegion;
 import org.hibernate.cache.spi.QueryCache;
 import org.hibernate.cache.spi.Region;
 import org.hibernate.cache.spi.RegionFactory;
 import org.hibernate.cache.spi.UpdateTimestampsCache;
 import org.hibernate.cache.spi.access.AccessType;
 import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
 import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.cache.spi.access.NaturalIdRegionAccessStrategy;
 import org.hibernate.cache.spi.access.RegionAccessStrategy;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.Settings;
 import org.hibernate.cfg.SettingsFactory;
 import org.hibernate.cfg.annotations.NamedProcedureCallDefinition;
 import org.hibernate.context.internal.JTASessionContext;
 import org.hibernate.context.internal.ManagedSessionContext;
 import org.hibernate.context.internal.ThreadLocalSessionContext;
 import org.hibernate.context.spi.CurrentSessionContext;
 import org.hibernate.context.spi.CurrentTenantIdentifierResolver;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.dialect.function.SQLFunctionRegistry;
 import org.hibernate.engine.ResultSetMappingDefinition;
 import org.hibernate.engine.config.spi.ConfigurationService;
 import org.hibernate.engine.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.engine.jdbc.connections.spi.MultiTenantConnectionProvider;
 import org.hibernate.engine.jdbc.spi.JdbcConnectionAccess;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.jndi.spi.JndiService;
 import org.hibernate.engine.profile.Association;
 import org.hibernate.engine.profile.Fetch;
 import org.hibernate.engine.profile.FetchProfile;
 import org.hibernate.engine.query.spi.QueryPlanCache;
 import org.hibernate.engine.spi.CacheImplementor;
 import org.hibernate.engine.spi.FilterDefinition;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.engine.spi.NamedQueryDefinition;
 import org.hibernate.engine.spi.NamedSQLQueryDefinition;
 import org.hibernate.engine.spi.SessionBuilderImplementor;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionOwner;
 import org.hibernate.engine.transaction.internal.TransactionCoordinatorImpl;
 import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
 import org.hibernate.engine.transaction.spi.TransactionEnvironment;
 import org.hibernate.engine.transaction.spi.TransactionFactory;
 import org.hibernate.exception.spi.SQLExceptionConverter;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.UUIDGenerator;
 import org.hibernate.id.factory.IdentifierGeneratorFactory;
 import org.hibernate.integrator.spi.Integrator;
 import org.hibernate.integrator.spi.IntegratorService;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.RootClass;
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.metadata.CollectionMetadata;
 import org.hibernate.metamodel.binding.EntityBinding;
 import org.hibernate.metamodel.binding.PluralAttributeBinding;
 import org.hibernate.metamodel.source.MetadataImplementor;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.persister.spi.PersisterFactory;
 import org.hibernate.procedure.ProcedureCallMemento;
 import org.hibernate.proxy.EntityNotFoundDelegate;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.service.spi.SessionFactoryServiceRegistry;
 import org.hibernate.service.spi.SessionFactoryServiceRegistryFactory;
 import org.hibernate.stat.Statistics;
 import org.hibernate.stat.spi.StatisticsImplementor;
 import org.hibernate.tool.hbm2ddl.ImportSqlCommandExtractor;
 import org.hibernate.tool.hbm2ddl.SchemaExport;
 import org.hibernate.tool.hbm2ddl.SchemaUpdate;
 import org.hibernate.tool.hbm2ddl.SchemaValidator;
 import org.hibernate.tuple.entity.EntityTuplizer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeResolver;
 import org.jboss.logging.Logger;
 
 
 /**
  * Concrete implementation of the <tt>SessionFactory</tt> interface. Has the following
  * responsibilities
  * <ul>
  * <li>caches configuration settings (immutably)
  * <li>caches "compiled" mappings ie. <tt>EntityPersister</tt>s and
  *     <tt>CollectionPersister</tt>s (immutable)
  * <li>caches "compiled" queries (memory sensitive cache)
  * <li>manages <tt>PreparedStatement</tt>s
  * <li> delegates JDBC <tt>Connection</tt> management to the <tt>ConnectionProvider</tt>
  * <li>factory for instances of <tt>SessionImpl</tt>
  * </ul>
  * This class must appear immutable to clients, even if it does all kinds of caching
  * and pooling under the covers. It is crucial that the class is not only thread
  * safe, but also highly concurrent. Synchronization must be used extremely sparingly.
  *
  * @see org.hibernate.engine.jdbc.connections.spi.ConnectionProvider
  * @see org.hibernate.Session
  * @see org.hibernate.hql.spi.QueryTranslator
  * @see org.hibernate.persister.entity.EntityPersister
  * @see org.hibernate.persister.collection.CollectionPersister
  * @author Gavin King
  */
 public final class SessionFactoryImpl
 		implements SessionFactoryImplementor {
 
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SessionFactoryImpl.class.getName());
 	private static final IdentifierGenerator UUID_GENERATOR = UUIDGenerator.buildSessionFactoryUniqueIdentifierGenerator();
 
 	private final String name;
 	private final String uuid;
 
 	private final transient Map<String,EntityPersister> entityPersisters;
 	private final transient Map<String,ClassMetadata> classMetadata;
 	private final transient Map<String,CollectionPersister> collectionPersisters;
 	private final transient Map<String,CollectionMetadata> collectionMetadata;
 	private final transient Map<String,Set<String>> collectionRolesByEntityParticipant;
 	private final transient Map<String,IdentifierGenerator> identifierGenerators;
 	private final transient NamedQueryRepository namedQueryRepository;
 	private final transient Map<String, FilterDefinition> filters;
 	private final transient Map<String, FetchProfile> fetchProfiles;
 	private final transient Map<String,String> imports;
 	private final transient SessionFactoryServiceRegistry serviceRegistry;
 	private final transient JdbcServices jdbcServices;
 	private final transient Dialect dialect;
 	private final transient Settings settings;
 	private final transient Properties properties;
 	private transient SchemaExport schemaExport;
 	private final transient CurrentSessionContext currentSessionContext;
 	private final transient SQLFunctionRegistry sqlFunctionRegistry;
 	private final transient SessionFactoryObserverChain observer = new SessionFactoryObserverChain();
 	private final transient ConcurrentHashMap<EntityNameResolver,Object> entityNameResolvers = new ConcurrentHashMap<EntityNameResolver, Object>();
 	private final transient QueryPlanCache queryPlanCache;
 	private final transient CacheImplementor cacheAccess;
 	private transient boolean isClosed = false;
 	private final transient TypeResolver typeResolver;
 	private final transient TypeHelper typeHelper;
 	private final transient TransactionEnvironment transactionEnvironment;
 	private final transient SessionFactoryOptions sessionFactoryOptions;
 	private final transient CustomEntityDirtinessStrategy customEntityDirtinessStrategy;
 	private final transient CurrentTenantIdentifierResolver currentTenantIdentifierResolver;
 
 	@SuppressWarnings( {"unchecked", "ThrowableResultOfMethodCallIgnored"})
 	public SessionFactoryImpl(
 			final Configuration cfg,
 			Mapping mapping,
 			final ServiceRegistry serviceRegistry,
 			Settings settings,
 			SessionFactoryObserver observer) throws HibernateException {
 			LOG.debug( "Building session factory" );
 
 		sessionFactoryOptions = new SessionFactoryOptions() {
 			private EntityNotFoundDelegate entityNotFoundDelegate;
 
 			@Override
 			public StandardServiceRegistry getServiceRegistry() {
 				return (StandardServiceRegistry) serviceRegistry;
 			}
 
 			@Override
 			public Interceptor getInterceptor() {
 				return cfg.getInterceptor();
 			}
 
 			@Override
 			public EntityNotFoundDelegate getEntityNotFoundDelegate() {
 				if ( entityNotFoundDelegate == null ) {
 					if ( cfg.getEntityNotFoundDelegate() != null ) {
 						entityNotFoundDelegate = cfg.getEntityNotFoundDelegate();
 					}
 					else {
 						entityNotFoundDelegate = new EntityNotFoundDelegate() {
 							public void handleEntityNotFound(String entityName, Serializable id) {
 								throw new ObjectNotFoundException( id, entityName );
 							}
 						};
 					}
 				}
 				return entityNotFoundDelegate;
 			}
 		};
 
 		this.settings = settings;
 
 		this.properties = new Properties();
 		this.properties.putAll( cfg.getProperties() );
 
 		this.serviceRegistry = serviceRegistry.getService( SessionFactoryServiceRegistryFactory.class ).buildServiceRegistry(
 				this,
 				cfg
 		);
         this.jdbcServices = this.serviceRegistry.getService( JdbcServices.class );
         this.dialect = this.jdbcServices.getDialect();
 		this.cacheAccess = this.serviceRegistry.getService( CacheImplementor.class );
-		final RegionFactory regionFactory = cacheAccess.getRegionFactory();
 		this.sqlFunctionRegistry = new SQLFunctionRegistry( getDialect(), cfg.getSqlFunctions() );
 		if ( observer != null ) {
 			this.observer.addObserver( observer );
 		}
 
 		this.typeResolver = cfg.getTypeResolver().scope( this );
 		this.typeHelper = new TypeLocatorImpl( typeResolver );
 
 		this.filters = new HashMap<String, FilterDefinition>();
 		this.filters.putAll( cfg.getFilterDefinitions() );
 
 		LOG.debugf( "Session factory constructed with filter configurations : %s", filters );
 		LOG.debugf( "Instantiating session factory with properties: %s", properties );
 
 
 		this.queryPlanCache = new QueryPlanCache( this );
 
 		// todo : everything above here consider implementing as standard SF service.  specifically: stats, caches, types, function-reg
 
 		class IntegratorObserver implements SessionFactoryObserver {
 			private ArrayList<Integrator> integrators = new ArrayList<Integrator>();
 
 			@Override
 			public void sessionFactoryCreated(SessionFactory factory) {
 			}
 
 			@Override
 			public void sessionFactoryClosed(SessionFactory factory) {
 				for ( Integrator integrator : integrators ) {
 					integrator.disintegrate( SessionFactoryImpl.this, SessionFactoryImpl.this.serviceRegistry );
 				}
                 integrators.clear();
 			}
 		}
 
 		final IntegratorObserver integratorObserver = new IntegratorObserver();
 		this.observer.addObserver( integratorObserver );
 		for ( Integrator integrator : serviceRegistry.getService( IntegratorService.class ).getIntegrators() ) {
 			integrator.integrate( cfg, this, this.serviceRegistry );
 			integratorObserver.integrators.add( integrator );
 		}
 
 		//Generators:
 
 		identifierGenerators = new HashMap();
 		Iterator classes = cfg.getClassMappings();
 		while ( classes.hasNext() ) {
 			PersistentClass model = (PersistentClass) classes.next();
 			if ( !model.isInherited() ) {
 				IdentifierGenerator generator = model.getIdentifier().createIdentifierGenerator(
 						cfg.getIdentifierGeneratorFactory(),
 						getDialect(),
 				        settings.getDefaultCatalogName(),
 				        settings.getDefaultSchemaName(),
 				        (RootClass) model
 				);
 				identifierGenerators.put( model.getEntityName(), generator );
 			}
 		}
 
+		imports = new HashMap<String,String>( cfg.getImports() );
 
 		///////////////////////////////////////////////////////////////////////
 		// Prepare persisters and link them up with their cache
 		// region/access-strategy
 
+		final RegionFactory regionFactory = cacheAccess.getRegionFactory();
 		final String cacheRegionPrefix = settings.getCacheRegionPrefix() == null ? "" : settings.getCacheRegionPrefix() + ".";
-
 		final PersisterFactory persisterFactory = serviceRegistry.getService( PersisterFactory.class );
 
+		// todo : consider removing this silliness and just have EntityPersister directly implement ClassMetadata
+		//		EntityPersister.getClassMetadata() for the internal impls simply "return this";
+		//		collapsing those would allow us to remove this "extra" Map
+		//
+		// todo : similar for CollectionPersister/CollectionMetadata
+
 		entityPersisters = new HashMap();
 		Map entityAccessStrategies = new HashMap();
 		Map<String,ClassMetadata> classMeta = new HashMap<String,ClassMetadata>();
 		classes = cfg.getClassMappings();
 		while ( classes.hasNext() ) {
 			final PersistentClass model = (PersistentClass) classes.next();
 			model.prepareTemporaryTables( mapping, getDialect() );
 			final String cacheRegionName = cacheRegionPrefix + model.getRootClass().getCacheRegionName();
 			// cache region is defined by the root-class in the hierarchy...
 			EntityRegionAccessStrategy accessStrategy = ( EntityRegionAccessStrategy ) entityAccessStrategies.get( cacheRegionName );
 			if ( accessStrategy == null && settings.isSecondLevelCacheEnabled() ) {
 				final AccessType accessType = AccessType.fromExternalName( model.getCacheConcurrencyStrategy() );
 				if ( accessType != null ) {
 					LOG.tracef( "Building shared cache region for entity data [%s]", model.getEntityName() );
 					EntityRegion entityRegion = regionFactory.buildEntityRegion( cacheRegionName, properties, CacheDataDescriptionImpl.decode( model ) );
 					accessStrategy = entityRegion.buildAccessStrategy( accessType );
 					entityAccessStrategies.put( cacheRegionName, accessStrategy );
 					cacheAccess.addCacheRegion( cacheRegionName, entityRegion );
 				}
 			}
-			
+
 			NaturalIdRegionAccessStrategy naturalIdAccessStrategy = null;
 			if ( model.hasNaturalId() && model.getNaturalIdCacheRegionName() != null ) {
 				final String naturalIdCacheRegionName = cacheRegionPrefix + model.getNaturalIdCacheRegionName();
 				naturalIdAccessStrategy = ( NaturalIdRegionAccessStrategy ) entityAccessStrategies.get( naturalIdCacheRegionName );
-				
+
 				if ( naturalIdAccessStrategy == null && settings.isSecondLevelCacheEnabled() ) {
 					final CacheDataDescriptionImpl cacheDataDescription = CacheDataDescriptionImpl.decode( model );
-					
+
 					NaturalIdRegion naturalIdRegion = null;
 					try {
 						naturalIdRegion = regionFactory.buildNaturalIdRegion( naturalIdCacheRegionName, properties,
 								cacheDataDescription );
 					}
 					catch ( UnsupportedOperationException e ) {
 						LOG.warnf(
 								"Shared cache region factory [%s] does not support natural id caching; " +
 										"shared NaturalId caching will be disabled for not be enabled for %s",
 								regionFactory.getClass().getName(),
 								model.getEntityName()
 						);
 					}
-					
+
 					if (naturalIdRegion != null) {
 						naturalIdAccessStrategy = naturalIdRegion.buildAccessStrategy( regionFactory.getDefaultAccessType() );
 						entityAccessStrategies.put( naturalIdCacheRegionName, naturalIdAccessStrategy );
 						cacheAccess.addCacheRegion(  naturalIdCacheRegionName, naturalIdRegion );
 					}
 				}
 			}
-			
+
 			EntityPersister cp = persisterFactory.createEntityPersister(
 					model,
 					accessStrategy,
 					naturalIdAccessStrategy,
 					this,
 					mapping
 			);
 			entityPersisters.put( model.getEntityName(), cp );
 			classMeta.put( model.getEntityName(), cp.getClassMetadata() );
 		}
 		this.classMetadata = Collections.unmodifiableMap(classMeta);
 
 		Map<String,Set<String>> tmpEntityToCollectionRoleMap = new HashMap<String,Set<String>>();
 		collectionPersisters = new HashMap<String,CollectionPersister>();
 		Map<String,CollectionMetadata> tmpCollectionMetadata = new HashMap<String,CollectionMetadata>();
 		Iterator collections = cfg.getCollectionMappings();
 		while ( collections.hasNext() ) {
 			Collection model = (Collection) collections.next();
 			final String cacheRegionName = cacheRegionPrefix + model.getCacheRegionName();
 			final AccessType accessType = AccessType.fromExternalName( model.getCacheConcurrencyStrategy() );
 			CollectionRegionAccessStrategy accessStrategy = null;
 			if ( accessType != null && settings.isSecondLevelCacheEnabled() ) {
 				LOG.tracev( "Building shared cache region for collection data [{0}]", model.getRole() );
 				CollectionRegion collectionRegion = regionFactory.buildCollectionRegion( cacheRegionName, properties, CacheDataDescriptionImpl
 						.decode( model ) );
 				accessStrategy = collectionRegion.buildAccessStrategy( accessType );
 				entityAccessStrategies.put( cacheRegionName, accessStrategy );
 				cacheAccess.addCacheRegion( cacheRegionName, collectionRegion );
 			}
 			CollectionPersister persister = persisterFactory.createCollectionPersister(
 					cfg,
 					model,
 					accessStrategy,
 					this
 			) ;
 			collectionPersisters.put( model.getRole(), persister );
 			tmpCollectionMetadata.put( model.getRole(), persister.getCollectionMetadata() );
 			Type indexType = persister.getIndexType();
 			if ( indexType != null && indexType.isAssociationType() && !indexType.isAnyType() ) {
 				String entityName = ( ( AssociationType ) indexType ).getAssociatedEntityName( this );
 				Set roles = tmpEntityToCollectionRoleMap.get( entityName );
 				if ( roles == null ) {
 					roles = new HashSet();
 					tmpEntityToCollectionRoleMap.put( entityName, roles );
 				}
 				roles.add( persister.getRole() );
 			}
 			Type elementType = persister.getElementType();
 			if ( elementType.isAssociationType() && !elementType.isAnyType() ) {
 				String entityName = ( ( AssociationType ) elementType ).getAssociatedEntityName( this );
 				Set roles = tmpEntityToCollectionRoleMap.get( entityName );
 				if ( roles == null ) {
 					roles = new HashSet();
 					tmpEntityToCollectionRoleMap.put( entityName, roles );
 				}
 				roles.add( persister.getRole() );
 			}
 		}
 		collectionMetadata = Collections.unmodifiableMap( tmpCollectionMetadata );
 		Iterator itr = tmpEntityToCollectionRoleMap.entrySet().iterator();
 		while ( itr.hasNext() ) {
 			final Map.Entry entry = ( Map.Entry ) itr.next();
 			entry.setValue( Collections.unmodifiableSet( ( Set ) entry.getValue() ) );
 		}
 		collectionRolesByEntityParticipant = Collections.unmodifiableMap( tmpEntityToCollectionRoleMap );
 
 		//Named Queries:
 		this.namedQueryRepository = new NamedQueryRepository(
 				cfg.getNamedQueries().values(),
 				cfg.getNamedSQLQueries().values(),
 				cfg.getSqlResultSetMappings().values(),
 				toProcedureCallMementos( cfg.getNamedProcedureCallMap(), cfg.getSqlResultSetMappings() )
 		);
-		imports = new HashMap<String,String>( cfg.getImports() );
 
 		// after *all* persisters and named queries are registered
-		Iterator iter = entityPersisters.values().iterator();
-		while ( iter.hasNext() ) {
-			final EntityPersister persister = ( ( EntityPersister ) iter.next() );
+		for ( EntityPersister persister : entityPersisters.values() ) {
 			persister.postInstantiate();
 			registerEntityNameResolvers( persister );
-
 		}
-		iter = collectionPersisters.values().iterator();
-		while ( iter.hasNext() ) {
-			final CollectionPersister persister = ( ( CollectionPersister ) iter.next() );
+		for ( CollectionPersister persister : collectionPersisters.values() ) {
 			persister.postInstantiate();
 		}
 
 		//JNDI + Serialization:
 
 		name = settings.getSessionFactoryName();
 		try {
 			uuid = (String) UUID_GENERATOR.generate(null, null);
 		}
 		catch (Exception e) {
 			throw new AssertionFailure("Could not generate UUID");
 		}
 		SessionFactoryRegistry.INSTANCE.addSessionFactory(
 				uuid,
 				name,
 				settings.isSessionFactoryNameAlsoJndiName(),
 				this,
 				serviceRegistry.getService( JndiService.class )
 		);
 
 		LOG.debug( "Instantiated session factory" );
 
 		settings.getMultiTableBulkIdStrategy().prepare(
 				jdbcServices,
 				buildLocalConnectionAccess(),
 				cfg.createMappings(),
 				cfg.buildMapping(),
 				properties
 		);
 
 
 		if ( settings.isAutoCreateSchema() ) {
 			new SchemaExport( serviceRegistry, cfg )
 					.setImportSqlCommandExtractor( serviceRegistry.getService( ImportSqlCommandExtractor.class ) )
 					.create( false, true );
 		}
 		if ( settings.isAutoUpdateSchema() ) {
 			new SchemaUpdate( serviceRegistry, cfg ).execute( false, true );
 		}
 		if ( settings.isAutoValidateSchema() ) {
 			new SchemaValidator( serviceRegistry, cfg ).validate();
 		}
 		if ( settings.isAutoDropSchema() ) {
 			schemaExport = new SchemaExport( serviceRegistry, cfg )
 					.setImportSqlCommandExtractor( serviceRegistry.getService( ImportSqlCommandExtractor.class ) );
 		}
 
 		currentSessionContext = buildCurrentSessionContext();
 
 		//checking for named queries
 		if ( settings.isNamedQueryStartupCheckingEnabled() ) {
 			final Map<String,HibernateException> errors = checkNamedQueries();
 			if ( ! errors.isEmpty() ) {
 				StringBuilder failingQueries = new StringBuilder( "Errors in named queries: " );
 				String sep = "";
 				for ( Map.Entry<String,HibernateException> entry : errors.entrySet() ) {
 					LOG.namedQueryError( entry.getKey(), entry.getValue() );
 					failingQueries.append( sep ).append( entry.getKey() );
 					sep = ", ";
 				}
 				throw new HibernateException( failingQueries.toString() );
 			}
 		}
 
 		// this needs to happen after persisters are all ready to go...
 		this.fetchProfiles = new HashMap();
 		itr = cfg.iterateFetchProfiles();
 		while ( itr.hasNext() ) {
 			final org.hibernate.mapping.FetchProfile mappingProfile =
 					( org.hibernate.mapping.FetchProfile ) itr.next();
 			final FetchProfile fetchProfile = new FetchProfile( mappingProfile.getName() );
 			for ( org.hibernate.mapping.FetchProfile.Fetch mappingFetch : mappingProfile.getFetches() ) {
 				// resolve the persister owning the fetch
 				final String entityName = getImportedClassName( mappingFetch.getEntity() );
 				final EntityPersister owner = entityName == null
 						? null
 						: entityPersisters.get( entityName );
 				if ( owner == null ) {
 					throw new HibernateException(
 							"Unable to resolve entity reference [" + mappingFetch.getEntity()
 									+ "] in fetch profile [" + fetchProfile.getName() + "]"
 					);
 				}
 
 				// validate the specified association fetch
 				Type associationType = owner.getPropertyType( mappingFetch.getAssociation() );
 				if ( associationType == null || !associationType.isAssociationType() ) {
 					throw new HibernateException( "Fetch profile [" + fetchProfile.getName() + "] specified an invalid association" );
 				}
 
 				// resolve the style
 				final Fetch.Style fetchStyle = Fetch.Style.parse( mappingFetch.getStyle() );
 
 				// then construct the fetch instance...
 				fetchProfile.addFetch( new Association( owner, mappingFetch.getAssociation() ), fetchStyle );
 				((Loadable) owner).registerAffectingFetchProfile( fetchProfile.getName() );
 			}
 			fetchProfiles.put( fetchProfile.getName(), fetchProfile );
 		}
 
 		this.customEntityDirtinessStrategy = determineCustomEntityDirtinessStrategy();
 		this.currentTenantIdentifierResolver = determineCurrentTenantIdentifierResolver( cfg.getCurrentTenantIdentifierResolver() );
 		this.transactionEnvironment = new TransactionEnvironmentImpl( this );
 		this.observer.sessionFactoryCreated( this );
 	}
 
 	private Map<String, ProcedureCallMemento> toProcedureCallMementos(
 			Map<String, NamedProcedureCallDefinition> definitions,
 			Map<String, ResultSetMappingDefinition> resultSetMappingMap) {
 		final Map<String, ProcedureCallMemento> rtn = new HashMap<String, ProcedureCallMemento>();
 		if ( definitions != null ) {
 			for (String name : definitions.keySet()){
 				rtn.put( name,  definitions.get( name ).toMemento( this, resultSetMappingMap ));
 			}
 		}
 		return rtn;
 	}
 
 	private JdbcConnectionAccess buildLocalConnectionAccess() {
 		return new JdbcConnectionAccess() {
 			@Override
 			public Connection obtainConnection() throws SQLException {
 				return settings.getMultiTenancyStrategy() == MultiTenancyStrategy.NONE
 						? serviceRegistry.getService( ConnectionProvider.class ).getConnection()
 						: serviceRegistry.getService( MultiTenantConnectionProvider.class ).getAnyConnection();
 			}
 
 			@Override
 			public void releaseConnection(Connection connection) throws SQLException {
 				if ( settings.getMultiTenancyStrategy() == MultiTenancyStrategy.NONE ) {
 					serviceRegistry.getService( ConnectionProvider.class ).closeConnection( connection );
 				}
 				else {
 					serviceRegistry.getService( MultiTenantConnectionProvider.class ).releaseAnyConnection( connection );
 				}
 			}
 
 			@Override
 			public boolean supportsAggressiveRelease() {
 				return false;
 			}
 		};
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	private CustomEntityDirtinessStrategy determineCustomEntityDirtinessStrategy() {
 		CustomEntityDirtinessStrategy defaultValue = new CustomEntityDirtinessStrategy() {
 			@Override
 			public boolean canDirtyCheck(Object entity, EntityPersister persister, Session session) {
 				return false;
 			}
 
 			@Override
 			public boolean isDirty(Object entity, EntityPersister persister, Session session) {
 				return false;
 			}
 
 			@Override
 			public void resetDirty(Object entity, EntityPersister persister, Session session) {
 			}
 
 			@Override
 			public void findDirty(
 					Object entity,
 					EntityPersister persister,
 					Session session,
 					DirtyCheckContext dirtyCheckContext) {
 				// todo : implement proper method body
 			}
 		};
 		return serviceRegistry.getService( ConfigurationService.class ).getSetting(
 				AvailableSettings.CUSTOM_ENTITY_DIRTINESS_STRATEGY,
 				CustomEntityDirtinessStrategy.class,
 				defaultValue
 		);
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	private CurrentTenantIdentifierResolver determineCurrentTenantIdentifierResolver(
 			CurrentTenantIdentifierResolver explicitResolver) {
 		if ( explicitResolver != null ) {
 			return explicitResolver;
 		}
 		return serviceRegistry.getService( ConfigurationService.class )
 				.getSetting(
 						AvailableSettings.MULTI_TENANT_IDENTIFIER_RESOLVER,
 						CurrentTenantIdentifierResolver.class,
 						null
 				);
 
 	}
 
 	@SuppressWarnings( {"ThrowableResultOfMethodCallIgnored"})
 	public SessionFactoryImpl(
 			MetadataImplementor metadata,
 			SessionFactoryOptions sessionFactoryOptions,
 			SessionFactoryObserver observer) throws HibernateException {
 
 		final boolean traceEnabled = LOG.isTraceEnabled();
 		final boolean debugEnabled = traceEnabled || LOG.isDebugEnabled();
 		if ( debugEnabled ) {
 			LOG.debug( "Building session factory" );
 		}
 
 		this.sessionFactoryOptions = sessionFactoryOptions;
 
 		this.properties = createPropertiesFromMap(
 				metadata.getServiceRegistry().getService( ConfigurationService.class ).getSettings()
 		);
 
 		// TODO: these should be moved into SessionFactoryOptions
 		this.settings = new SettingsFactory().buildSettings(
 				properties,
 				metadata.getServiceRegistry()
 		);
 
 		this.serviceRegistry =
 				sessionFactoryOptions.getServiceRegistry()
 						.getService( SessionFactoryServiceRegistryFactory.class )
 						.buildServiceRegistry( this, metadata );
 
 		this.jdbcServices = this.serviceRegistry.getService( JdbcServices.class );
 		this.dialect = this.jdbcServices.getDialect();
 		this.cacheAccess = this.serviceRegistry.getService( CacheImplementor.class );
 
 		// TODO: get SQL functions from JdbcServices (HHH-6559)
 		//this.sqlFunctionRegistry = new SQLFunctionRegistry( this.jdbcServices.getSqlFunctions() );
 		this.sqlFunctionRegistry = new SQLFunctionRegistry( this.dialect, new HashMap<String, SQLFunction>() );
 
 		// TODO: get SQL functions from a new service
 		// this.sqlFunctionRegistry = new SQLFunctionRegistry( getDialect(), cfg.getSqlFunctions() );
 
 		if ( observer != null ) {
 			this.observer.addObserver( observer );
 		}
 
 		this.typeResolver = metadata.getTypeResolver().scope( this );
 		this.typeHelper = new TypeLocatorImpl( typeResolver );
 
 		this.filters = new HashMap<String, FilterDefinition>();
 		for ( FilterDefinition filterDefinition : metadata.getFilterDefinitions() ) {
 			filters.put( filterDefinition.getFilterName(), filterDefinition );
 		}
 
 		if ( debugEnabled ) {
 			LOG.debugf( "Session factory constructed with filter configurations : %s", filters );
 			LOG.debugf( "Instantiating session factory with properties: %s", properties );
 		}
 		this.queryPlanCache = new QueryPlanCache( this );
 
 		class IntegratorObserver implements SessionFactoryObserver {
 			private ArrayList<Integrator> integrators = new ArrayList<Integrator>();
 
 			@Override
 			public void sessionFactoryCreated(SessionFactory factory) {
 			}
 
 			@Override
 			public void sessionFactoryClosed(SessionFactory factory) {
 				for ( Integrator integrator : integrators ) {
 					integrator.disintegrate( SessionFactoryImpl.this, SessionFactoryImpl.this.serviceRegistry );
 				}
                 integrators.clear();
 			}
 		}
 
         final IntegratorObserver integratorObserver = new IntegratorObserver();
         this.observer.addObserver(integratorObserver);
         for (Integrator integrator : serviceRegistry.getService(IntegratorService.class).getIntegrators()) {
             integrator.integrate(metadata, this, this.serviceRegistry);
             integratorObserver.integrators.add(integrator);
         }
 
 
 		//Generators:
 
 		identifierGenerators = new HashMap<String,IdentifierGenerator>();
 		for ( EntityBinding entityBinding : metadata.getEntityBindings() ) {
 			if ( entityBinding.isRoot() ) {
 				identifierGenerators.put(
 						entityBinding.getEntity().getName(),
 						entityBinding.getHierarchyDetails().getEntityIdentifier().getIdentifierGenerator()
 				);
 			}
 		}
 
 		///////////////////////////////////////////////////////////////////////
 		// Prepare persisters and link them up with their cache
 		// region/access-strategy
 
 		StringBuilder stringBuilder = new StringBuilder();
 		if ( settings.getCacheRegionPrefix() != null) {
 			stringBuilder
 					.append( settings.getCacheRegionPrefix() )
 					.append( '.' );
 		}
 		final String cacheRegionPrefix = stringBuilder.toString();
 
 		entityPersisters = new HashMap<String,EntityPersister>();
 		Map<String, RegionAccessStrategy> entityAccessStrategies = new HashMap<String, RegionAccessStrategy>();
 		Map<String,ClassMetadata> classMeta = new HashMap<String,ClassMetadata>();
 		for ( EntityBinding model : metadata.getEntityBindings() ) {
 			// TODO: should temp table prep happen when metadata is being built?
 			//model.prepareTemporaryTables( metadata, getDialect() );
 			// cache region is defined by the root-class in the hierarchy...
 			EntityBinding rootEntityBinding = metadata.getRootEntityBinding( model.getEntity().getName() );
 			EntityRegionAccessStrategy accessStrategy = null;
 			if ( settings.isSecondLevelCacheEnabled() &&
 					rootEntityBinding.getHierarchyDetails().getCaching() != null &&
 					model.getHierarchyDetails().getCaching() != null &&
 					model.getHierarchyDetails().getCaching().getAccessType() != null ) {
 				final String cacheRegionName = cacheRegionPrefix + rootEntityBinding.getHierarchyDetails().getCaching().getRegion();
 				accessStrategy = EntityRegionAccessStrategy.class.cast( entityAccessStrategies.get( cacheRegionName ) );
 				if ( accessStrategy == null ) {
 					final AccessType accessType = model.getHierarchyDetails().getCaching().getAccessType();
 					if ( traceEnabled ) {
 						LOG.tracev( "Building cache for entity data [{0}]", model.getEntity().getName() );
 					}
 					EntityRegion entityRegion = settings.getRegionFactory().buildEntityRegion(
 							cacheRegionName, properties, CacheDataDescriptionImpl.decode( model )
 					);
 					accessStrategy = entityRegion.buildAccessStrategy( accessType );
 					entityAccessStrategies.put( cacheRegionName, accessStrategy );
 					cacheAccess.addCacheRegion( cacheRegionName, entityRegion );
 				}
 			}
 			EntityPersister cp = serviceRegistry.getService( PersisterFactory.class ).createEntityPersister(
 					model, accessStrategy, this, metadata
 			);
 			entityPersisters.put( model.getEntity().getName(), cp );
 			classMeta.put( model.getEntity().getName(), cp.getClassMetadata() );
 		}
 		this.classMetadata = Collections.unmodifiableMap(classMeta);
 
 		Map<String,Set<String>> tmpEntityToCollectionRoleMap = new HashMap<String,Set<String>>();
 		collectionPersisters = new HashMap<String,CollectionPersister>();
 		Map<String, CollectionMetadata> tmpCollectionMetadata = new HashMap<String, CollectionMetadata>();
 		for ( PluralAttributeBinding model : metadata.getCollectionBindings() ) {
 			if ( model.getAttribute() == null ) {
 				throw new IllegalStateException( "No attribute defined for a AbstractPluralAttributeBinding: " +  model );
 			}
 			if ( model.getAttribute().isSingular() ) {
 				throw new IllegalStateException(
 						"AbstractPluralAttributeBinding has a Singular attribute defined: " + model.getAttribute().getName()
 				);
 			}
 			final String cacheRegionName = cacheRegionPrefix + model.getCaching().getRegion();
 			final AccessType accessType = model.getCaching().getAccessType();
 			CollectionRegionAccessStrategy accessStrategy = null;
 			if ( accessType != null && settings.isSecondLevelCacheEnabled() ) {
 				if ( traceEnabled ) {
 					LOG.tracev( "Building cache for collection data [{0}]", model.getAttribute().getRole() );
 				}
 				CollectionRegion collectionRegion = settings.getRegionFactory().buildCollectionRegion(
 						cacheRegionName, properties, CacheDataDescriptionImpl.decode( model )
 				);
 				accessStrategy = collectionRegion.buildAccessStrategy( accessType );
 				entityAccessStrategies.put( cacheRegionName, accessStrategy );
 				cacheAccess.addCacheRegion(  cacheRegionName, collectionRegion );
 			}
 			CollectionPersister persister = serviceRegistry
 					.getService( PersisterFactory.class )
 					.createCollectionPersister( metadata, model, accessStrategy, this );
 			collectionPersisters.put( model.getAttribute().getRole(), persister );
 			tmpCollectionMetadata.put( model.getAttribute().getRole(), persister.getCollectionMetadata() );
 			Type indexType = persister.getIndexType();
 			if ( indexType != null && indexType.isAssociationType() && !indexType.isAnyType() ) {
 				String entityName = ( ( AssociationType ) indexType ).getAssociatedEntityName( this );
 				Set<String> roles = tmpEntityToCollectionRoleMap.get( entityName );
 				if ( roles == null ) {
 					roles = new HashSet<String>();
 					tmpEntityToCollectionRoleMap.put( entityName, roles );
 				}
 				roles.add( persister.getRole() );
 			}
 			Type elementType = persister.getElementType();
 			if ( elementType.isAssociationType() && !elementType.isAnyType() ) {
 				String entityName = ( ( AssociationType ) elementType ).getAssociatedEntityName( this );
 				Set<String> roles = tmpEntityToCollectionRoleMap.get( entityName );
 				if ( roles == null ) {
 					roles = new HashSet<String>();
 					tmpEntityToCollectionRoleMap.put( entityName, roles );
 				}
 				roles.add( persister.getRole() );
 			}
 		}
 		collectionMetadata = Collections.unmodifiableMap( tmpCollectionMetadata );
 		for ( Map.Entry<String, Set<String>> entry : tmpEntityToCollectionRoleMap.entrySet() ) {
 			entry.setValue( Collections.unmodifiableSet( entry.getValue() ) );
 		}
 		collectionRolesByEntityParticipant = Collections.unmodifiableMap( tmpEntityToCollectionRoleMap );
 
 
 		//Named Queries:
 		namedQueryRepository = new NamedQueryRepository(
 				metadata.getNamedQueryDefinitions(),
 				metadata.getNamedNativeQueryDefinitions(),
 				metadata.getResultSetMappingDefinitions(),
 				new HashMap<String, ProcedureCallMemento>(  )
 		);
 
 		imports = new HashMap<String,String>();
 		for ( Map.Entry<String,String> importEntry : metadata.getImports() ) {
 			imports.put( importEntry.getKey(), importEntry.getValue() );
 		}
 
 		// after *all* persisters and named queries are registered
 		Iterator iter = entityPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			final EntityPersister persister = ( ( EntityPersister ) iter.next() );
 			persister.postInstantiate();
 			registerEntityNameResolvers( persister );
 
 		}
 		iter = collectionPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			final CollectionPersister persister = ( ( CollectionPersister ) iter.next() );
 			persister.postInstantiate();
 		}
 
 		//JNDI + Serialization:
 
 		name = settings.getSessionFactoryName();
 		try {
 			uuid = (String) UUID_GENERATOR.generate(null, null);
 		}
 		catch (Exception e) {
 			throw new AssertionFailure("Could not generate UUID");
 		}
 		SessionFactoryRegistry.INSTANCE.addSessionFactory(
 				uuid, 
 				name,
 				settings.isSessionFactoryNameAlsoJndiName(),
 				this,
 				serviceRegistry.getService( JndiService.class )
 		);
 
 		if ( debugEnabled ) {
 			LOG.debug("Instantiated session factory");
 		}
 
 		if ( settings.isAutoCreateSchema() ) {
 			new SchemaExport( metadata )
 					.setImportSqlCommandExtractor( serviceRegistry.getService( ImportSqlCommandExtractor.class ) )
 					.create( false, true );
 		}
 
 		if ( settings.isAutoDropSchema() ) {
 			schemaExport = new SchemaExport( metadata )
 					.setImportSqlCommandExtractor( serviceRegistry.getService( ImportSqlCommandExtractor.class ) );
 		}
 
 		currentSessionContext = buildCurrentSessionContext();
 
 		//checking for named queries
 		if ( settings.isNamedQueryStartupCheckingEnabled() ) {
 			final Map<String,HibernateException> errors = checkNamedQueries();
 			if ( ! errors.isEmpty() ) {
 				StringBuilder failingQueries = new StringBuilder( "Errors in named queries: " );
 				String sep = "";
 				for ( Map.Entry<String,HibernateException> entry : errors.entrySet() ) {
 					LOG.namedQueryError( entry.getKey(), entry.getValue() );
 					failingQueries.append( entry.getKey() ).append( sep );
 					sep = ", ";
 				}
 				throw new HibernateException( failingQueries.toString() );
 			}
 		}
 
 		// this needs to happen after persisters are all ready to go...
 		this.fetchProfiles = new HashMap<String,FetchProfile>();
 		for ( org.hibernate.metamodel.binding.FetchProfile mappingProfile : metadata.getFetchProfiles() ) {
 			final FetchProfile fetchProfile = new FetchProfile( mappingProfile.getName() );
 			for ( org.hibernate.metamodel.binding.FetchProfile.Fetch mappingFetch : mappingProfile.getFetches() ) {
 				// resolve the persister owning the fetch
 				final String entityName = getImportedClassName( mappingFetch.getEntity() );
 				final EntityPersister owner = entityName == null ? null : entityPersisters.get( entityName );
 				if ( owner == null ) {
 					throw new HibernateException(
 							"Unable to resolve entity reference [" + mappingFetch.getEntity()
 									+ "] in fetch profile [" + fetchProfile.getName() + "]"
 					);
 				}
 
 				// validate the specified association fetch
 				Type associationType = owner.getPropertyType( mappingFetch.getAssociation() );
 				if ( associationType == null || ! associationType.isAssociationType() ) {
 					throw new HibernateException( "Fetch profile [" + fetchProfile.getName() + "] specified an invalid association" );
 				}
 
 				// resolve the style
 				final Fetch.Style fetchStyle = Fetch.Style.parse( mappingFetch.getStyle() );
 
 				// then construct the fetch instance...
 				fetchProfile.addFetch( new Association( owner, mappingFetch.getAssociation() ), fetchStyle );
 				( ( Loadable ) owner ).registerAffectingFetchProfile( fetchProfile.getName() );
 			}
 			fetchProfiles.put( fetchProfile.getName(), fetchProfile );
 		}
 
 		this.customEntityDirtinessStrategy = determineCustomEntityDirtinessStrategy();
 		this.currentTenantIdentifierResolver = determineCurrentTenantIdentifierResolver( null );
 		this.transactionEnvironment = new TransactionEnvironmentImpl( this );
 		this.observer.sessionFactoryCreated( this );
 	}
 
 	@SuppressWarnings( {"unchecked"} )
 	private static Properties createPropertiesFromMap(Map map) {
 		Properties properties = new Properties();
 		properties.putAll( map );
 		return properties;
 	}
 
 	public Session openSession() throws HibernateException {
 		return withOptions().openSession();
 	}
 
 	public Session openTemporarySession() throws HibernateException {
 		return withOptions()
 				.autoClose( false )
 				.flushBeforeCompletion( false )
 				.connectionReleaseMode( ConnectionReleaseMode.AFTER_STATEMENT )
 				.openSession();
 	}
 
 	public Session getCurrentSession() throws HibernateException {
 		if ( currentSessionContext == null ) {
 			throw new HibernateException( "No CurrentSessionContext configured!" );
 		}
 		return currentSessionContext.currentSession();
 	}
 
 	@Override
 	public SessionBuilderImplementor withOptions() {
 		return new SessionBuilderImpl( this );
 	}
 
 	@Override
 	public StatelessSessionBuilder withStatelessOptions() {
 		return new StatelessSessionBuilderImpl( this );
 	}
 
 	public StatelessSession openStatelessSession() {
 		return withStatelessOptions().openStatelessSession();
 	}
 
 	public StatelessSession openStatelessSession(Connection connection) {
 		return withStatelessOptions().connection( connection ).openStatelessSession();
 	}
 
 	@Override
 	public void addObserver(SessionFactoryObserver observer) {
 		this.observer.addObserver( observer );
 	}
 
 	public TransactionEnvironment getTransactionEnvironment() {
 		return transactionEnvironment;
 	}
 
 	public Properties getProperties() {
 		return properties;
 	}
 
 	public IdentifierGeneratorFactory getIdentifierGeneratorFactory() {
 		return null;
 	}
 
 	public TypeResolver getTypeResolver() {
 		return typeResolver;
 	}
 
 	private void registerEntityNameResolvers(EntityPersister persister) {
 		if ( persister.getEntityMetamodel() == null || persister.getEntityMetamodel().getTuplizer() == null ) {
 			return;
 		}
 		registerEntityNameResolvers( persister.getEntityMetamodel().getTuplizer() );
 	}
 
 	private void registerEntityNameResolvers(EntityTuplizer tuplizer) {
 		EntityNameResolver[] resolvers = tuplizer.getEntityNameResolvers();
 		if ( resolvers == null ) {
 			return;
 		}
 
 		for ( EntityNameResolver resolver : resolvers ) {
 			registerEntityNameResolver( resolver );
 		}
 	}
 
 	private static final Object ENTITY_NAME_RESOLVER_MAP_VALUE = new Object();
 
 	public void registerEntityNameResolver(EntityNameResolver resolver) {
 		entityNameResolvers.put( resolver, ENTITY_NAME_RESOLVER_MAP_VALUE );
 	}
 
+	@Override
 	public Iterable<EntityNameResolver> iterateEntityNameResolvers() {
 		return entityNameResolvers.keySet();
 	}
 
 	public QueryPlanCache getQueryPlanCache() {
 		return queryPlanCache;
 	}
 
 	private Map<String,HibernateException> checkNamedQueries() throws HibernateException {
 		return namedQueryRepository.checkNamedQueries( queryPlanCache );
 	}
 
 	public EntityPersister getEntityPersister(String entityName) throws MappingException {
 		EntityPersister result = entityPersisters.get(entityName);
 		if ( result == null ) {
 			throw new MappingException( "Unknown entity: " + entityName );
 		}
 		return result;
 	}
 
 	@Override
 	public Map<String, CollectionPersister> getCollectionPersisters() {
 		return collectionPersisters;
 	}
 
 	@Override
 	public Map<String, EntityPersister> getEntityPersisters() {
 		return entityPersisters;
 	}
 
 	public CollectionPersister getCollectionPersister(String role) throws MappingException {
 		CollectionPersister result = collectionPersisters.get(role);
 		if ( result == null ) {
 			throw new MappingException( "Unknown collection role: " + role );
 		}
 		return result;
 	}
 
 	public Settings getSettings() {
 		return settings;
 	}
 
 	@Override
 	public SessionFactoryOptions getSessionFactoryOptions() {
 		return sessionFactoryOptions;
 	}
 
 	public JdbcServices getJdbcServices() {
 		return jdbcServices;
 	}
 
 	public Dialect getDialect() {
 		if ( serviceRegistry == null ) {
 			throw new IllegalStateException( "Cannot determine dialect because serviceRegistry is null." );
 		}
 		return dialect;
 	}
 
 	public Interceptor getInterceptor() {
 		return sessionFactoryOptions.getInterceptor();
 	}
 
 	public SQLExceptionConverter getSQLExceptionConverter() {
 		return getSQLExceptionHelper().getSqlExceptionConverter();
 	}
 
 	public SqlExceptionHelper getSQLExceptionHelper() {
 		return getJdbcServices().getSqlExceptionHelper();
 	}
 
 	public Set<String> getCollectionRolesByEntityParticipant(String entityName) {
 		return collectionRolesByEntityParticipant.get( entityName );
 	}
 
 	@Override
 	public Reference getReference() {
 		// from javax.naming.Referenceable
         LOG.debug( "Returning a Reference to the SessionFactory" );
 		return new Reference(
 				SessionFactoryImpl.class.getName(),
 				new StringRefAddr("uuid", uuid),
 				SessionFactoryRegistry.ObjectFactoryImpl.class.getName(),
 				null
 		);
 	}
 
 	@Override
 	public NamedQueryRepository getNamedQueryRepository() {
 		return namedQueryRepository;
 	}
 
 	public void registerNamedQueryDefinition(String name, NamedQueryDefinition definition) {
 		namedQueryRepository.registerNamedQueryDefinition( name, definition );
 	}
 
 	public NamedQueryDefinition getNamedQuery(String queryName) {
 		return namedQueryRepository.getNamedQueryDefinition( queryName );
 	}
 
 	public void registerNamedSQLQueryDefinition(String name, NamedSQLQueryDefinition definition) {
 		namedQueryRepository.registerNamedSQLQueryDefinition( name, definition );
 	}
 
 	public NamedSQLQueryDefinition getNamedSQLQuery(String queryName) {
 		return namedQueryRepository.getNamedSQLQueryDefinition( queryName );
 	}
 
 	public ResultSetMappingDefinition getResultSetMapping(String mappingName) {
 		return namedQueryRepository.getResultSetMappingDefinition( mappingName );
 	}
 
 	public Type getIdentifierType(String className) throws MappingException {
 		return getEntityPersister(className).getIdentifierType();
 	}
 	public String getIdentifierPropertyName(String className) throws MappingException {
 		return getEntityPersister(className).getIdentifierPropertyName();
 	}
 
 	public Type[] getReturnTypes(String queryString) throws HibernateException {
 		return queryPlanCache.getHQLQueryPlan( queryString, false, Collections.EMPTY_MAP )
 				.getReturnMetadata()
 				.getReturnTypes();
 	}
 
 	public String[] getReturnAliases(String queryString) throws HibernateException {
 		return queryPlanCache.getHQLQueryPlan( queryString, false, Collections.EMPTY_MAP )
 				.getReturnMetadata()
 				.getReturnAliases();
 	}
 
 	public ClassMetadata getClassMetadata(Class persistentClass) throws HibernateException {
 		return getClassMetadata( persistentClass.getName() );
 	}
 
 	public CollectionMetadata getCollectionMetadata(String roleName) throws HibernateException {
 		return collectionMetadata.get(roleName);
 	}
 
 	public ClassMetadata getClassMetadata(String entityName) throws HibernateException {
 		return classMetadata.get( entityName );
 	}
 
 	/**
 	 * Given the name of an entity class, determine all the class and interface names by which it can be
 	 * referenced in an HQL query.
 	 *
      * @param className The name of the entity class
 	 *
 	 * @return the names of all persistent (mapped) classes that extend or implement the
 	 *     given class or interface, accounting for implicit/explicit polymorphism settings
 	 *     and excluding mapped subclasses/joined-subclasses of other classes in the result.
 	 * @throws MappingException
 	 */
 	public String[] getImplementors(String className) throws MappingException {
 
 		final Class clazz;
 		try {
 			clazz = serviceRegistry.getService( ClassLoaderService.class ).classForName( className );
 		}
 		catch (ClassLoadingException cnfe) {
 			return new String[] { className }; //for a dynamic-class
 		}
 
 		ArrayList<String> results = new ArrayList<String>();
 		for ( EntityPersister checkPersister : entityPersisters.values() ) {
 			if ( ! Queryable.class.isInstance( checkPersister ) ) {
 				continue;
 			}
 			final Queryable checkQueryable = Queryable.class.cast( checkPersister );
 			final String checkQueryableEntityName = checkQueryable.getEntityName();
 			final boolean isMappedClass = className.equals( checkQueryableEntityName );
 			if ( checkQueryable.isExplicitPolymorphism() ) {
 				if ( isMappedClass ) {
 					return new String[] { className }; //NOTE EARLY EXIT
 				}
 			}
 			else {
 				if ( isMappedClass ) {
 					results.add( checkQueryableEntityName );
 				}
 				else {
 					final Class mappedClass = checkQueryable.getMappedClass();
 					if ( mappedClass != null && clazz.isAssignableFrom( mappedClass ) ) {
 						final boolean assignableSuperclass;
 						if ( checkQueryable.isInherited() ) {
 							Class mappedSuperclass = getEntityPersister( checkQueryable.getMappedSuperclass() ).getMappedClass();
 							assignableSuperclass = clazz.isAssignableFrom( mappedSuperclass );
 						}
 						else {
 							assignableSuperclass = false;
 						}
 						if ( !assignableSuperclass ) {
 							results.add( checkQueryableEntityName );
 						}
 					}
 				}
 			}
 		}
 		return results.toArray( new String[results.size()] );
 	}
 
 	@Override
 	public String getImportedClassName(String className) {
 		String result = imports.get( className );
 		if ( result == null ) {
 			try {
 				serviceRegistry.getService( ClassLoaderService.class ).classForName( className );
 				imports.put( className, className );
 				return className;
 			}
 			catch ( ClassLoadingException cnfe ) {
 				return null;
 			}
 		}
 		else {
 			return result;
 		}
 	}
 
 	public Map<String,ClassMetadata> getAllClassMetadata() throws HibernateException {
 		return classMetadata;
 	}
 
 	public Map getAllCollectionMetadata() throws HibernateException {
 		return collectionMetadata;
 	}
 
 	public Type getReferencedPropertyType(String className, String propertyName)
 		throws MappingException {
 		return getEntityPersister( className ).getPropertyType( propertyName );
 	}
 
 	public ConnectionProvider getConnectionProvider() {
 		return jdbcServices.getConnectionProvider();
 	}
 
 	/**
 	 * Closes the session factory, releasing all held resources.
 	 *
 	 * <ol>
 	 * <li>cleans up used cache regions and "stops" the cache provider.
 	 * <li>close the JDBC connection
 	 * <li>remove the JNDI binding
 	 * </ol>
 	 *
 	 * Note: Be aware that the sessionFactory instance still can
 	 * be a "heavy" object memory wise after close() has been called.  Thus
 	 * it is important to not keep referencing the instance to let the garbage
 	 * collector release the memory.
 	 * @throws HibernateException
 	 */
 	public void close() throws HibernateException {
 
 		if ( isClosed ) {
 			LOG.trace( "Already closed" );
 			return;
 		}
 
 		LOG.closing();
 
 		isClosed = true;
 
 		settings.getMultiTableBulkIdStrategy().release( jdbcServices, buildLocalConnectionAccess() );
 
 		Iterator iter = entityPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			EntityPersister p = (EntityPersister) iter.next();
 			if ( p.hasCache() ) {
 				p.getCacheAccessStrategy().getRegion().destroy();
 			}
 		}
 
 		iter = collectionPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			CollectionPersister p = (CollectionPersister) iter.next();
 			if ( p.hasCache() ) {
 				p.getCacheAccessStrategy().getRegion().destroy();
 			}
 		}
 
 		cacheAccess.close();
 
 		queryPlanCache.cleanup();
 
 		if ( settings.isAutoDropSchema() ) {
 			schemaExport.drop( false, true );
 		}
 
 		SessionFactoryRegistry.INSTANCE.removeSessionFactory(
 				uuid,
 				name,
 				settings.isSessionFactoryNameAlsoJndiName(),
 				serviceRegistry.getService( JndiService.class )
 		);
 
 		observer.sessionFactoryClosed( this );
 		serviceRegistry.destroy();
 	}
 
 	public Cache getCache() {
 		return cacheAccess;
 	}
 
 	public void evictEntity(String entityName, Serializable id) throws HibernateException {
 		getCache().evictEntity( entityName, id );
 	}
 
 	public void evictEntity(String entityName) throws HibernateException {
 		getCache().evictEntityRegion( entityName );
 	}
 
 	public void evict(Class persistentClass, Serializable id) throws HibernateException {
 		getCache().evictEntity( persistentClass, id );
 	}
 
 	public void evict(Class persistentClass) throws HibernateException {
 		getCache().evictEntityRegion( persistentClass );
 	}
 
 	public void evictCollection(String roleName, Serializable id) throws HibernateException {
 		getCache().evictCollection( roleName, id );
 	}
 
 	public void evictCollection(String roleName) throws HibernateException {
 		getCache().evictCollectionRegion( roleName );
 	}
 
 	public void evictQueries() throws HibernateException {
 		cacheAccess.evictQueries();
 	}
 
 	public void evictQueries(String regionName) throws HibernateException {
 		getCache().evictQueryRegion( regionName );
 	}
 
 	public UpdateTimestampsCache getUpdateTimestampsCache() {
 		return cacheAccess.getUpdateTimestampsCache();
 	}
 
 	public QueryCache getQueryCache() {
 		return cacheAccess.getQueryCache();
 	}
 
 	public QueryCache getQueryCache(String regionName) throws HibernateException {
 		return cacheAccess.getQueryCache( regionName );
 	}
 
 	public Region getSecondLevelCacheRegion(String regionName) {
 		return cacheAccess.getSecondLevelCacheRegion( regionName );
 	}
 
 	public Region getNaturalIdCacheRegion(String regionName) {
 		return cacheAccess.getNaturalIdCacheRegion( regionName );
 	}
 
 	@SuppressWarnings( {"unchecked"})
 	public Map getAllSecondLevelCacheRegions() {
 		return cacheAccess.getAllSecondLevelCacheRegions();
 	}
 
 	public boolean isClosed() {
 		return isClosed;
 	}
 
 	public Statistics getStatistics() {
 		return getStatisticsImplementor();
 	}
 
 	public StatisticsImplementor getStatisticsImplementor() {
 		return serviceRegistry.getService( StatisticsImplementor.class );
 	}
 
 	public FilterDefinition getFilterDefinition(String filterName) throws HibernateException {
 		FilterDefinition def = filters.get( filterName );
 		if ( def == null ) {
 			throw new HibernateException( "No such filter configured [" + filterName + "]" );
 		}
 		return def;
 	}
 
 	public boolean containsFetchProfileDefinition(String name) {
 		return fetchProfiles.containsKey( name );
 	}
 
 	public Set getDefinedFilterNames() {
 		return filters.keySet();
 	}
 
 	public IdentifierGenerator getIdentifierGenerator(String rootEntityName) {
 		return identifierGenerators.get(rootEntityName);
 	}
 
 	private TransactionFactory transactionFactory() {
 		return serviceRegistry.getService( TransactionFactory.class );
 	}
 
 	private boolean canAccessTransactionManager() {
 		try {
 			return serviceRegistry.getService( JtaPlatform.class ).retrieveTransactionManager() != null;
 		}
 		catch (Exception e) {
 			return false;
 		}
 	}
 
 	private CurrentSessionContext buildCurrentSessionContext() {
 		String impl = properties.getProperty( Environment.CURRENT_SESSION_CONTEXT_CLASS );
 		// for backward-compatibility
 		if ( impl == null ) {
 			if ( canAccessTransactionManager() ) {
 				impl = "jta";
 			}
 			else {
 				return null;
 			}
 		}
 
 		if ( "jta".equals( impl ) ) {
 			if ( ! transactionFactory().compatibleWithJtaSynchronization() ) {
 				LOG.autoFlushWillNotWork();
 			}
 			return new JTASessionContext( this );
 		}
 		else if ( "thread".equals( impl ) ) {
 			return new ThreadLocalSessionContext( this );
 		}
 		else if ( "managed".equals( impl ) ) {
 			return new ManagedSessionContext( this );
 		}
 		else {
 			try {
 				Class implClass = serviceRegistry.getService( ClassLoaderService.class ).classForName( impl );
 				return ( CurrentSessionContext ) implClass
 						.getConstructor( new Class[] { SessionFactoryImplementor.class } )
 						.newInstance( this );
 			}
 			catch( Throwable t ) {
 				LOG.unableToConstructCurrentSessionContext( impl, t );
 				return null;
 			}
 		}
 	}
 
 	@Override
 	public ServiceRegistryImplementor getServiceRegistry() {
 		return serviceRegistry;
 	}
 
 	@Override
 	public EntityNotFoundDelegate getEntityNotFoundDelegate() {
 		return sessionFactoryOptions.getEntityNotFoundDelegate();
 	}
 
 	public SQLFunctionRegistry getSqlFunctionRegistry() {
 		return sqlFunctionRegistry;
 	}
 
 	public FetchProfile getFetchProfile(String name) {
 		return fetchProfiles.get( name );
 	}
 
 	public TypeHelper getTypeHelper() {
 		return typeHelper;
 	}
 
 	static class SessionBuilderImpl implements SessionBuilderImplementor {
 		private static final Logger log = CoreLogging.logger( SessionBuilderImpl.class );
 
 		private final SessionFactoryImpl sessionFactory;
 		private SessionOwner sessionOwner;
 		private Interceptor interceptor;
 		private Connection connection;
 		private ConnectionReleaseMode connectionReleaseMode;
 		private boolean autoClose;
 		private boolean autoJoinTransactions = true;
 		private boolean flushBeforeCompletion;
 		private String tenantIdentifier;
 
 		SessionBuilderImpl(SessionFactoryImpl sessionFactory) {
 			this.sessionFactory = sessionFactory;
 			this.sessionOwner = null;
 			final Settings settings = sessionFactory.settings;
 
 			// set up default builder values...
 			this.interceptor = sessionFactory.getInterceptor();
 			this.connectionReleaseMode = settings.getConnectionReleaseMode();
 			this.autoClose = settings.isAutoCloseSessionEnabled();
 			this.flushBeforeCompletion = settings.isFlushBeforeCompletionEnabled();
 
 			if ( sessionFactory.getCurrentTenantIdentifierResolver() != null ) {
 				tenantIdentifier = sessionFactory.getCurrentTenantIdentifierResolver().resolveCurrentTenantIdentifier();
 			}
 		}
 
 		protected TransactionCoordinatorImpl getTransactionCoordinator() {
 			return null;
 		}
 
 		@Override
 		public Session openSession() {
 			log.tracef( "Opening Hibernate Session.  tenant=%s, owner=%s", tenantIdentifier, sessionOwner );
 			return new SessionImpl(
 					connection,
 					sessionFactory,
 					sessionOwner,
 					getTransactionCoordinator(),
 					autoJoinTransactions,
 					sessionFactory.settings.getRegionFactory().nextTimestamp(),
 					interceptor,
 					flushBeforeCompletion,
 					autoClose,
 					connectionReleaseMode,
 					tenantIdentifier
 			);
 		}
 
 		@Override
 		public SessionBuilder owner(SessionOwner sessionOwner) {
 			this.sessionOwner = sessionOwner;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder interceptor(Interceptor interceptor) {
 			this.interceptor = interceptor;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder noInterceptor() {
 			this.interceptor = EmptyInterceptor.INSTANCE;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder connection(Connection connection) {
 			this.connection = connection;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder connectionReleaseMode(ConnectionReleaseMode connectionReleaseMode) {
 			this.connectionReleaseMode = connectionReleaseMode;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder autoJoinTransactions(boolean autoJoinTransactions) {
 			this.autoJoinTransactions = autoJoinTransactions;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder autoClose(boolean autoClose) {
 			this.autoClose = autoClose;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder flushBeforeCompletion(boolean flushBeforeCompletion) {
 			this.flushBeforeCompletion = flushBeforeCompletion;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder tenantIdentifier(String tenantIdentifier) {
 			this.tenantIdentifier = tenantIdentifier;
 			return this;
 		}
 	}
 
 	public static class StatelessSessionBuilderImpl implements StatelessSessionBuilder {
 		private final SessionFactoryImpl sessionFactory;
 		private Connection connection;
 		private String tenantIdentifier;
 
 		public StatelessSessionBuilderImpl(SessionFactoryImpl sessionFactory) {
 			this.sessionFactory = sessionFactory;
 
 			if ( sessionFactory.getCurrentTenantIdentifierResolver() != null ) {
 				tenantIdentifier = sessionFactory.getCurrentTenantIdentifierResolver().resolveCurrentTenantIdentifier();
 			}
 		}
 
 		@Override
 		public StatelessSession openStatelessSession() {
 			return new StatelessSessionImpl( connection, tenantIdentifier, sessionFactory );
 		}
 
 		@Override
 		public StatelessSessionBuilder connection(Connection connection) {
 			this.connection = connection;
 			return this;
 		}
 
 		@Override
 		public StatelessSessionBuilder tenantIdentifier(String tenantIdentifier) {
 			this.tenantIdentifier = tenantIdentifier;
 			return this;
 		}
 	}
 
 	@Override
 	public CustomEntityDirtinessStrategy getCustomEntityDirtinessStrategy() {
 		return customEntityDirtinessStrategy;
 	}
 
 	@Override
 	public CurrentTenantIdentifierResolver getCurrentTenantIdentifierResolver() {
 		return currentTenantIdentifierResolver;
 	}
 
 
 	// Serialization handling ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Custom serialization hook defined by Java spec.  Used when the factory is directly serialized
 	 *
 	 * @param out The stream into which the object is being serialized.
 	 *
 	 * @throws IOException Can be thrown by the stream
 	 */
 	private void writeObject(ObjectOutputStream out) throws IOException {
 		LOG.debugf( "Serializing: %s", uuid );
 		out.defaultWriteObject();
 		LOG.trace( "Serialized" );
 	}
 
 	/**
 	 * Custom serialization hook defined by Java spec.  Used when the factory is directly deserialized
 	 *
 	 * @param in The stream from which the object is being deserialized.
 	 *
 	 * @throws IOException Can be thrown by the stream
 	 * @throws ClassNotFoundException Again, can be thrown by the stream
 	 */
 	private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException {
 		LOG.trace( "Deserializing" );
 		in.defaultReadObject();
 		LOG.debugf( "Deserialized: %s", uuid );
 	}
 
 	/**
 	 * Custom serialization hook defined by Java spec.  Used when the factory is directly deserialized.
 	 * Here we resolve the uuid/name read from the stream previously to resolve the SessionFactory
 	 * instance to use based on the registrations with the {@link SessionFactoryRegistry}
 	 *
 	 * @return The resolved factory to use.
 	 *
 	 * @throws InvalidObjectException Thrown if we could not resolve the factory by uuid/name.
 	 */
 	private Object readResolve() throws InvalidObjectException {
 		LOG.trace( "Resolving serialized SessionFactory" );
 		return locateSessionFactoryOnDeserialization( uuid, name );
 	}
 
 	private static SessionFactory locateSessionFactoryOnDeserialization(String uuid, String name) throws InvalidObjectException{
 		final SessionFactory uuidResult = SessionFactoryRegistry.INSTANCE.getSessionFactory( uuid );
 		if ( uuidResult != null ) {
 			LOG.debugf( "Resolved SessionFactory by UUID [%s]", uuid );
 			return uuidResult;
 		}
 
 		// in case we were deserialized in a different JVM, look for an instance with the same name
 		// (provided we were given a name)
 		if ( name != null ) {
 			final SessionFactory namedResult = SessionFactoryRegistry.INSTANCE.getNamedSessionFactory( name );
 			if ( namedResult != null ) {
 				LOG.debugf( "Resolved SessionFactory by name [%s]", name );
 				return namedResult;
 			}
 		}
 
 		throw new InvalidObjectException( "Could not find a SessionFactory [uuid=" + uuid + ",name=" + name + "]" );
 	}
 
 	/**
 	 * Custom serialization hook used during Session serialization.
 	 *
 	 * @param oos The stream to which to write the factory
 	 * @throws IOException Indicates problems writing out the serial data stream
 	 */
 	void serialize(ObjectOutputStream oos) throws IOException {
 		oos.writeUTF( uuid );
 		oos.writeBoolean( name != null );
 		if ( name != null ) {
 			oos.writeUTF( name );
 		}
 	}
 
 	/**
 	 * Custom deserialization hook used during Session deserialization.
 	 *
 	 * @param ois The stream from which to "read" the factory
 	 * @return The deserialized factory
 	 * @throws IOException indicates problems reading back serial data stream
 	 * @throws ClassNotFoundException indicates problems reading back serial data stream
 	 */
 	static SessionFactoryImpl deserialize(ObjectInputStream ois) throws IOException, ClassNotFoundException {
 		LOG.trace( "Deserializing SessionFactory from Session" );
 		final String uuid = ois.readUTF();
 		boolean isNamed = ois.readBoolean();
 		final String name = isNamed ? ois.readUTF() : null;
 		return (SessionFactoryImpl) locateSessionFactoryOnDeserialization( uuid, name );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/GeneratedCollectionAliases.java b/hibernate-core/src/main/java/org/hibernate/loader/GeneratedCollectionAliases.java
index 0780587831..dafb0837c0 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/GeneratedCollectionAliases.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/GeneratedCollectionAliases.java
@@ -1,155 +1,157 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader;
 import java.util.Collections;
 import java.util.Map;
 
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.persister.collection.CollectionPersister;
 
 /**
  * CollectionAliases which handles the logic of selecting user provided aliases (via return-property),
  * before using the default aliases. 
  *
  * @author Steve Ebersole
  * @author Max Rydahl Andersen
  */
 public class GeneratedCollectionAliases implements CollectionAliases {
 	private final String suffix;
 	private final String[] keyAliases;
 	private final String[] indexAliases;
 	private final String[] elementAliases;
 	private final String identifierAlias;
 	private Map userProvidedAliases;
 	
 	public GeneratedCollectionAliases(Map userProvidedAliases, CollectionPersister persister, String suffix) {
 		this.suffix = suffix;
 		this.userProvidedAliases = userProvidedAliases;
 
 		this.keyAliases = getUserProvidedAliases(
 				"key", 
 				persister.getKeyColumnAliases( suffix )
-			);
+		);
 
 		this.indexAliases = getUserProvidedAliases(
 				"index",
 				persister.getIndexColumnAliases( suffix )
-				);
+		);
 		
-		this.elementAliases = getUserProvidedAliases( "element", 
+		this.elementAliases = getUserProvidedAliases(
+				"element",
 				persister.getElementColumnAliases( suffix )
-				);
+		);
 				
-		this.identifierAlias = getUserProvidedAlias( "id", 
+		this.identifierAlias = getUserProvidedAlias(
+				"id",
 				persister.getIdentifierColumnAlias( suffix )
-				);
+		);
 	}
 
 	public GeneratedCollectionAliases(CollectionPersister persister, String string) {
 		this( Collections.EMPTY_MAP, persister, string);
 	}
 
 	/**
 	 * Returns the suffixed result-set column-aliases for columns making up the key for this collection (i.e., its FK to
 	 * its owner).
 	 *
 	 * @return The key result-set column aliases.
 	 */
 	public String[] getSuffixedKeyAliases() {
 		return keyAliases;
 	}
 
 	/**
 	 * Returns the suffixed result-set column-aliases for the collumns making up the collection's index (map or list).
 	 *
 	 * @return The index result-set column aliases.
 	 */
 	public String[] getSuffixedIndexAliases() {
 		return indexAliases;
 	}
 
 	/**
 	 * Returns the suffixed result-set column-aliases for the columns making up the collection's elements.
 	 *
 	 * @return The element result-set column aliases.
 	 */
 	public String[] getSuffixedElementAliases() {
 		return elementAliases;
 	}
 
 	/**
 	 * Returns the suffixed result-set column-aliases for the column defining the collection's identifier (if any).
 	 *
 	 * @return The identifier result-set column aliases.
 	 */
 	public String getSuffixedIdentifierAlias() {
 		return identifierAlias;
 	}
 
 	/**
 	 * Returns the suffix used to unique the column aliases for this particular alias set.
 	 *
 	 * @return The uniqued column alias suffix.
 	 */
 	public String getSuffix() {
 		return suffix;
 	}
 
 	@Override
     public String toString() {
 		return super.toString() + " [suffix=" + suffix +
 		        ", suffixedKeyAliases=[" + join( keyAliases ) +
 		        "], suffixedIndexAliases=[" + join( indexAliases ) +
 		        "], suffixedElementAliases=[" + join( elementAliases ) +
 		        "], suffixedIdentifierAlias=[" + identifierAlias + "]]";
 	}
 
 	private String join(String[] aliases) {
 		if ( aliases == null) return null;
 
 		return StringHelper.join( ", ", aliases );
 	}
 	
 	private String[] getUserProvidedAliases(String propertyPath, String[] defaultAliases) {
 		String[] result = (String[]) userProvidedAliases.get(propertyPath);
 		if (result==null) {
 			return defaultAliases;			
 		} 
 		else {
 			return result;
 		}
 	}
 
 	private String getUserProvidedAlias(String propertyPath, String defaultAlias) {
 		String[] columns = (String[]) userProvidedAliases.get(propertyPath);
 		if (columns==null) {
 			return defaultAlias;
 		} 
 		else {
 			return columns[0];
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/JoinWalker.java b/hibernate-core/src/main/java/org/hibernate/loader/JoinWalker.java
index affb387682..c415c6e7a4 100755
--- a/hibernate-core/src/main/java/org/hibernate/loader/JoinWalker.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/JoinWalker.java
@@ -1,1093 +1,1097 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader;
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collections;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Set;
 
 import org.hibernate.FetchMode;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.internal.JoinHelper;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.sql.ConditionFragment;
 import org.hibernate.sql.DisjunctionFragment;
 import org.hibernate.sql.InFragment;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.JoinType;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.ForeignKeyDirection;
 import org.hibernate.type.Type;
 
 /**
  * Walks the metamodel, searching for joins, and collecting
  * together information needed by <tt>OuterJoinLoader</tt>.
  * 
  * @see OuterJoinLoader
  * @author Gavin King, Jon Lipsky
  */
 public class JoinWalker {
 	
 	private final SessionFactoryImplementor factory;
 	protected final List associations = new ArrayList();
 	private final Set visitedAssociationKeys = new HashSet();
 	private final LoadQueryInfluencers loadQueryInfluencers;
 
 	protected String[] suffixes;
 	protected String[] collectionSuffixes;
 	protected Loadable[] persisters;
 	protected int[] owners;
 	protected EntityType[] ownerAssociationTypes;
 	protected CollectionPersister[] collectionPersisters;
 	protected int[] collectionOwners;
 	protected String[] aliases;
 	protected LockOptions lockOptions;
 	protected LockMode[] lockModeArray;
 	protected String sql;
 
 	protected JoinWalker(
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers loadQueryInfluencers) {
 		this.factory = factory;
 		this.loadQueryInfluencers = loadQueryInfluencers;
 
 	}
 
+	public List getAssociations() {
+		return Collections.unmodifiableList( associations );
+	}
 
 	public String[] getCollectionSuffixes() {
 		return collectionSuffixes;
 	}
 
 	public void setCollectionSuffixes(String[] collectionSuffixes) {
 		this.collectionSuffixes = collectionSuffixes;
 	}
 
 	public LockOptions getLockModeOptions() {
 		return lockOptions;
 	}
 
 	public LockMode[] getLockModeArray() {
 		return lockModeArray;
 	}
 
 	public String[] getSuffixes() {
 		return suffixes;
 	}
 
 	public void setSuffixes(String[] suffixes) {
 		this.suffixes = suffixes;
 	}
 
 	public String[] getAliases() {
 		return aliases;
 	}
 
 	public void setAliases(String[] aliases) {
 		this.aliases = aliases;
 	}
 
 	public int[] getCollectionOwners() {
 		return collectionOwners;
 	}
 
 	public void setCollectionOwners(int[] collectionOwners) {
 		this.collectionOwners = collectionOwners;
 	}
 
 	public CollectionPersister[] getCollectionPersisters() {
 		return collectionPersisters;
 	}
 
 	public void setCollectionPersisters(CollectionPersister[] collectionPersisters) {
 		this.collectionPersisters = collectionPersisters;
 	}
 
 	public EntityType[] getOwnerAssociationTypes() {
 		return ownerAssociationTypes;
 	}
 
 	public void setOwnerAssociationTypes(EntityType[] ownerAssociationType) {
 		this.ownerAssociationTypes = ownerAssociationType;
 	}
 
 	public int[] getOwners() {
 		return owners;
 	}
 
 	public void setOwners(int[] owners) {
 		this.owners = owners;
 	}
 
 	public Loadable[] getPersisters() {
 		return persisters;
 	}
 
 	public void setPersisters(Loadable[] persisters) {
 		this.persisters = persisters;
 	}
 
 	public String getSQLString() {
 		return sql;
 	}
 
 	public void setSql(String sql) {
 		this.sql = sql;
 	}
 
 	protected SessionFactoryImplementor getFactory() {
 		return factory;
 	}
 
 	protected Dialect getDialect() {
 		return factory.getDialect();
 	}
 
 	public LoadQueryInfluencers getLoadQueryInfluencers() {
 		return loadQueryInfluencers;
 	}
 
 	/**
 	 * Add on association (one-to-one, many-to-one, or a collection) to a list 
 	 * of associations to be fetched by outerjoin (if necessary)
 	 */
 	private void addAssociationToJoinTreeIfNecessary(
 			final AssociationType type,
 			final String[] aliasedLhsColumns,
 			final String alias,
 			final PropertyPath path,
 			int currentDepth,
 			final JoinType joinType) throws MappingException {
 		if ( joinType != JoinType.NONE ) {
 			addAssociationToJoinTree(
 					type, 
 					aliasedLhsColumns, 
 					alias, 
 					path,
 					currentDepth,
 					joinType
 			);
 		}
 	}
 
 	protected boolean hasRestriction(PropertyPath path)	{
 		return false;
 	}
 
 	protected String getWithClause(PropertyPath path)	{
 		return "";
 	}
 	
 	/**
 	 * Add on association (one-to-one, many-to-one, or a collection) to a list 
 	 * of associations to be fetched by outerjoin 
 	 */
 	private void addAssociationToJoinTree(
 			final AssociationType type,
 			final String[] aliasedLhsColumns,
 			final String alias,
 			final PropertyPath path,
 			final int currentDepth,
 			final JoinType joinType) throws MappingException {
 
 		Joinable joinable = type.getAssociatedJoinable( getFactory() );
 
 		// important to generate alias based on size of association collection
 		// *before* adding this join to that collection
 		String subalias = generateTableAlias( associations.size() + 1, path, joinable );
 
 		// NOTE : it should be fine to continue to pass only filters below
 		// (instead of LoadQueryInfluencers) since "from that point on" we
 		// only need to worry about restrictions (and not say adding more
 		// joins)
 		OuterJoinableAssociation assoc = new OuterJoinableAssociation(
 				path,
 				type, 
 				alias, 
 				aliasedLhsColumns, 
 				subalias, 
 				joinType, 
 				getWithClause(path),
 				hasRestriction( path ),
 				getFactory(),
 				loadQueryInfluencers.getEnabledFilters()
 		);
 		assoc.validateJoin( path.getFullPath() );
 		associations.add( assoc );
 
 		int nextDepth = currentDepth + 1;
 //		path = "";
 		if ( !joinable.isCollection() ) {
 			if (joinable instanceof OuterJoinLoadable) {
 				walkEntityTree(
 					(OuterJoinLoadable) joinable, 
 					subalias,
 					path, 
 					nextDepth
 				);
 			}
 		}
 		else {
 			if (joinable instanceof QueryableCollection) {
 				walkCollectionTree(
 					(QueryableCollection) joinable, 
 					subalias, 
 					path, 
 					nextDepth
 				);
 			}
 		}
 
 	}
 
 	/**
 	 * Walk the association tree for an entity, adding associations which should
 	 * be join fetched to the {@link #associations} inst var.  This form is the
 	 * entry point into the walking for a given entity, starting the recursive
 	 * calls into {@link #walkEntityTree(org.hibernate.persister.entity.OuterJoinLoadable, String, PropertyPath ,int)}.
 	 *
 	 * @param persister The persister representing the entity to be walked.
 	 * @param alias The (root) alias to use for this entity/persister.
 	 * @throws org.hibernate.MappingException ???
 	 */
 	protected final void walkEntityTree(
 			OuterJoinLoadable persister,
 			String alias) throws MappingException {
 		walkEntityTree( persister, alias, new PropertyPath(), 0 );
 	}
 
 	/**
 	 * For a collection role, return a list of associations to be fetched by outerjoin
 	 */
 	protected final void walkCollectionTree(QueryableCollection persister, String alias) throws MappingException {
 		walkCollectionTree( persister, alias, new PropertyPath(), 0 );
 		//TODO: when this is the entry point, we should use an INNER_JOIN for fetching the many-to-many elements!
 	}
 
 	/**
 	 * For a collection role, return a list of associations to be fetched by outerjoin
 	 */
 	private void walkCollectionTree(
 			final QueryableCollection persister,
 			final String alias,
 			final PropertyPath path,
 			final int currentDepth)	throws MappingException {
 
 		if ( persister.isOneToMany() ) {
 			walkEntityTree(
 					(OuterJoinLoadable) persister.getElementPersister(),
 					alias,
 					path,
 					currentDepth
 				);
 		}
 		else {
 			Type type = persister.getElementType();
 			if ( type.isAssociationType() ) {
 				// a many-to-many;
 				// decrement currentDepth here to allow join across the association table
 				// without exceeding MAX_FETCH_DEPTH (i.e. the "currentDepth - 1" bit)
 				AssociationType associationType = (AssociationType) type;
 				String[] aliasedLhsColumns = persister.getElementColumnNames(alias);
 				String[] lhsColumns = persister.getElementColumnNames();
 				// if the current depth is 0, the root thing being loaded is the
 				// many-to-many collection itself.  Here, it is alright to use
 				// an inner join...
 				boolean useInnerJoin = currentDepth == 0;
 				final JoinType joinType = getJoinType(
 						associationType,
 						persister.getFetchMode(),
 						path,
 						persister.getTableName(),
 						lhsColumns,
 						!useInnerJoin,
 						currentDepth - 1, 
 						null //operations which cascade as far as the collection also cascade to collection elements
 				);
 				addAssociationToJoinTreeIfNecessary(
 						associationType,
 						aliasedLhsColumns,
 						alias,
 						path,
 						currentDepth - 1,
 						joinType
 					);
 			}
 			else if ( type.isComponentType() ) {
 				walkCompositeElementTree(
 						(CompositeType) type,
 						persister.getElementColumnNames(),
 						persister,
 						alias,
 						path,
 						currentDepth
 					);
 			}
 		}
 
 	}
 	
 	/**
 	 * Process a particular association owned by the entity
 	 *
 	 * @param associationType The type representing the association to be
 	 * processed.
 	 * @param persister The owner of the association to be processed.
 	 * @param propertyNumber The property number for the association
 	 * (relative to the persister).
 	 * @param alias The entity alias
 	 * @param path The path to the association
 	 * @param nullable is the association nullable (which I think is supposed
 	 * to indicate inner/outer join semantics).
 	 * @param currentDepth The current join depth
 	 * @throws org.hibernate.MappingException ???
 	 */
 	private void walkEntityAssociationTree(
 			final AssociationType associationType,
 			final OuterJoinLoadable persister,
 			final int propertyNumber,
 			final String alias,
 			final PropertyPath path,
 			final boolean nullable,
 			final int currentDepth) throws MappingException {
 		String[] aliasedLhsColumns = JoinHelper.getAliasedLHSColumnNames(
 				associationType, alias, propertyNumber, persister, getFactory()
 		);
 		String[] lhsColumns = JoinHelper.getLHSColumnNames(
 				associationType, propertyNumber, persister, getFactory()
 		);
 		String lhsTable = JoinHelper.getLHSTableName(associationType, propertyNumber, persister);
 
 		PropertyPath subPath = path.append( persister.getSubclassPropertyName(propertyNumber) );
 		JoinType joinType = getJoinType(
 				persister,
 				subPath,
 				propertyNumber,
 				associationType,
 				persister.getFetchMode( propertyNumber ),
 				persister.getCascadeStyle( propertyNumber ),
 				lhsTable,
 				lhsColumns,
 				nullable,
 				currentDepth
 		);
 		addAssociationToJoinTreeIfNecessary(
 				associationType,
 				aliasedLhsColumns,
 				alias,
 				subPath,
 				currentDepth,
 				joinType
 		);
 	}
 
 	/**
 	 * Determine the appropriate type of join (if any) to use to fetch the
 	 * given association.
 	 *
 	 * @param persister The owner of the association.
 	 * @param path The path to the association
 	 * @param propertyNumber The property number representing the association.
 	 * @param associationType The association type.
 	 * @param metadataFetchMode The metadata-defined fetch mode.
 	 * @param metadataCascadeStyle The metadata-defined cascade style.
 	 * @param lhsTable The owner table
 	 * @param lhsColumns The owner join columns
 	 * @param nullable Is the association nullable.
 	 * @param currentDepth Current join depth
 	 * @return type of join to use ({@link org.hibernate.sql.JoinType#INNER_JOIN},
 	 * {@link org.hibernate.sql.JoinType#LEFT_OUTER_JOIN}, or -1 to indicate no joining.
 	 * @throws MappingException ??
 	 */
 	protected JoinType getJoinType(
 			OuterJoinLoadable persister,
 			final PropertyPath path,
 			int propertyNumber,
 			AssociationType associationType,
 			FetchMode metadataFetchMode,
 			CascadeStyle metadataCascadeStyle,
 			String lhsTable,
 			String[] lhsColumns,
 			final boolean nullable,
 			final int currentDepth) throws MappingException {
 		return getJoinType(
 				associationType,
 				metadataFetchMode,
 				path,
 				lhsTable,
 				lhsColumns,
 				nullable,
 				currentDepth,
 				metadataCascadeStyle
 		);
 	}
 
 	/**
 	 * Determine the appropriate associationType of join (if any) to use to fetch the
 	 * given association.
 	 *
 	 * @param associationType The association associationType.
 	 * @param config The metadata-defined fetch mode.
 	 * @param path The path to the association
 	 * @param lhsTable The owner table
 	 * @param lhsColumns The owner join columns
 	 * @param nullable Is the association nullable.
 	 * @param currentDepth Current join depth
 	 * @param cascadeStyle The metadata-defined cascade style.
 	 * @return type of join to use ({@link org.hibernate.sql.JoinType#INNER_JOIN},
 	 * {@link org.hibernate.sql.JoinType#LEFT_OUTER_JOIN}, or -1 to indicate no joining.
 	 * @throws MappingException ??
 	 */
 	protected JoinType getJoinType(
 			AssociationType associationType,
 			FetchMode config,
 			PropertyPath path,
 			String lhsTable,
 			String[] lhsColumns,
 			boolean nullable,
 			int currentDepth,
 			CascadeStyle cascadeStyle) throws MappingException {
 		if  ( !isJoinedFetchEnabled( associationType, config, cascadeStyle ) ) {
 			return JoinType.NONE;
 		}
 		if ( isTooDeep(currentDepth) || ( associationType.isCollectionType() && isTooManyCollections() ) ) {
 			return JoinType.NONE;
 		}
 		if ( isDuplicateAssociation( lhsTable, lhsColumns, associationType ) ) {
 			return JoinType.NONE;
 		}
 		return getJoinType( nullable, currentDepth );
 	}
 
 	/**
 	 * Walk the association tree for an entity, adding associations which should
 	 * be join fetched to the {@link #associations} inst var.  This form is the
 	 * entry point into the walking for a given entity, starting the recursive
 	 * calls into {@link #walkEntityTree(org.hibernate.persister.entity.OuterJoinLoadable, String, PropertyPath ,int)}.
 	 *
 	 * @param persister The persister representing the entity to be walked.
 	 * @param alias The (root) alias to use for this entity/persister.
 	 * @param path The property path to the entity being walked
 	 * @param currentDepth The current join depth
 	 * @throws org.hibernate.MappingException ???
 	 */
 	private void walkEntityTree(
 			final OuterJoinLoadable persister,
 			final String alias,
 			final PropertyPath path,
 			final int currentDepth) throws MappingException {
 		int n = persister.countSubclassProperties();
 		for ( int i = 0; i < n; i++ ) {
 			Type type = persister.getSubclassPropertyType(i);
 			if ( type.isAssociationType() ) {
 				walkEntityAssociationTree(
 					( AssociationType ) type,
 					persister,
 					i,
 					alias,
 					path,
 					persister.isSubclassPropertyNullable(i),
 					currentDepth
 				);
 			}
 			else if ( type.isComponentType() ) {
 				walkComponentTree(
 						( CompositeType ) type,
 						i,
 						0,
 						persister,
 						alias,
 						path.append( persister.getSubclassPropertyName(i) ),
 						currentDepth
 				);
 			}
 		}
 
 		// if the entity has a composite identifier, see if we need to handle
 		// its sub-properties separately
 		final Type idType = persister.getIdentifierType();
 		if ( idType.isComponentType() ) {
 			final CompositeType cidType = (CompositeType) idType;
 			if ( cidType.isEmbedded() ) {
 				// we have an embedded composite identifier.  Most likely we need to process the composite
 				// properties separately, although there is an edge case where the identifier is really
 				// a simple identifier (single value) wrapped in a JPA @IdClass or even in the case of a
 				// a simple identifier (single value) wrapped in a Hibernate composite type.
 				//
 				// We really do not have a built-in method to determine that.  However, generally the
 				// persister would report that there is single, physical identifier property which is
 				// explicitly at odds with the notion of "embedded composite".  So we use that for now
 				if ( persister.getEntityMetamodel().getIdentifierProperty().isEmbedded() ) {
 					walkComponentTree(
 							cidType,
 							-1,
 							0,
 							persister,
 							alias,
 							path,
 							currentDepth
 					);
 				}
 			}
 		}
 	}
 
 	/**
 	 * For a component, add to a list of associations to be fetched by outerjoin
 	 *
 	 *
 	 * @param componentType The component type to be walked.
 	 * @param propertyNumber The property number for the component property (relative to
 	 * persister).
 	 * @param begin todo unknowm
 	 * @param persister The owner of the component property
 	 * @param alias The root alias
 	 * @param path The property access path
 	 * @param currentDepth The current join depth
 	 * @throws org.hibernate.MappingException ???
 	 */
 	private void walkComponentTree(
 			final CompositeType componentType,
 			final int propertyNumber,
 			int begin,
 			final OuterJoinLoadable persister,
 			final String alias,
 			final PropertyPath path,
 			final int currentDepth) throws MappingException {
 		Type[] types = componentType.getSubtypes();
 		String[] propertyNames = componentType.getPropertyNames();
 		for ( int i = 0; i < types.length; i++ ) {
 			if ( types[i].isAssociationType() ) {
 				AssociationType associationType = (AssociationType) types[i];
 				String[] aliasedLhsColumns = JoinHelper.getAliasedLHSColumnNames(
 					associationType, alias, propertyNumber, begin, persister, getFactory()
 				);
 				String[] lhsColumns = JoinHelper.getLHSColumnNames(
 					associationType, propertyNumber, begin, persister, getFactory()
 				);
 				String lhsTable = JoinHelper.getLHSTableName(associationType, propertyNumber, persister);
 
 				final PropertyPath subPath = path.append( propertyNames[i] );
 				final boolean[] propertyNullability = componentType.getPropertyNullability();
 				final JoinType joinType = getJoinType(
 						persister,
 						subPath,
 						propertyNumber,
 						associationType,
 						componentType.getFetchMode(i),
 						componentType.getCascadeStyle(i),
 						lhsTable,
 						lhsColumns,
 						propertyNullability==null || propertyNullability[i],
 						currentDepth
 				);
 				addAssociationToJoinTreeIfNecessary(			
 						associationType,
 						aliasedLhsColumns,
 						alias,
 						subPath,
 						currentDepth,
 						joinType
 				);
 
 			}
 			else if ( types[i].isComponentType() ) {
 				final PropertyPath subPath = path.append( propertyNames[i] );
 				walkComponentTree(
 						( CompositeType ) types[i],
 						propertyNumber,
 						begin,
 						persister,
 						alias,
 						subPath,
 						currentDepth
 				);
 			}
 			begin += types[i].getColumnSpan( getFactory() );
 		}
 
 	}
 
 	/**
 	 * For a composite element, add to a list of associations to be fetched by outerjoin
 	 */
 	private void walkCompositeElementTree(
 			final CompositeType compositeType,
 			final String[] cols,
 			final QueryableCollection persister,
 			final String alias,
 			final PropertyPath path,
 			final int currentDepth) throws MappingException {
 
 		Type[] types = compositeType.getSubtypes();
 		String[] propertyNames = compositeType.getPropertyNames();
 		int begin = 0;
 		for ( int i=0; i <types.length; i++ ) {
 			int length = types[i].getColumnSpan( getFactory() );
 			String[] lhsColumns = ArrayHelper.slice(cols, begin, length);
 
 			if ( types[i].isAssociationType() ) {
 				AssociationType associationType = (AssociationType) types[i];
 
 				// simple, because we can't have a one-to-one or a collection 
 				// (or even a property-ref) in a composite-element:
 				String[] aliasedLhsColumns = StringHelper.qualify(alias, lhsColumns);
 
 				final PropertyPath subPath = path.append( propertyNames[i] );
 				final boolean[] propertyNullability = compositeType.getPropertyNullability();
 				final JoinType joinType = getJoinType(
 						associationType,
 						compositeType.getFetchMode(i),
 						subPath,
 						persister.getTableName(),
 						lhsColumns,
 						propertyNullability==null || propertyNullability[i],
 						currentDepth, 
 						compositeType.getCascadeStyle(i)
 					);
 				addAssociationToJoinTreeIfNecessary(
 						associationType,
 						aliasedLhsColumns,
 						alias,
 						subPath,
 						currentDepth,
 						joinType
 					);
 			}
 			else if ( types[i].isComponentType() ) {
 				final PropertyPath subPath = path.append( propertyNames[i] );
 				walkCompositeElementTree(
 						(CompositeType) types[i],
 						lhsColumns,
 						persister,
 						alias,
 						subPath,
 						currentDepth
 					);
 			}
 			begin+=length;
 		}
 
 	}
 
 	/**
 	 * Use an inner join if it is a non-null association and this
 	 * is the "first" join in a series
 	 */
 	protected JoinType getJoinType(boolean nullable, int currentDepth) {
 		//TODO: this is too conservative; if all preceding joins were 
 		//      also inner joins, we could use an inner join here
 		//
 		// IMPL NOTE : currentDepth might be less-than zero if this is the
 		// 		root of a many-to-many collection initializer 
 		return !nullable && currentDepth <= 0
 				? JoinType.INNER_JOIN
 				: JoinType.LEFT_OUTER_JOIN;
 	}
 
 	protected boolean isTooDeep(int currentDepth) {
 		Integer maxFetchDepth = getFactory().getSettings().getMaximumFetchDepth();
 		return maxFetchDepth!=null && currentDepth >= maxFetchDepth;
 	}
 	
 	protected boolean isTooManyCollections() {
 		return false;
 	}
 	
 	/**
 	 * Does the mapping, and Hibernate default semantics, specify that
 	 * this association should be fetched by outer joining
 	 */
 	protected boolean isJoinedFetchEnabledInMapping(FetchMode config, AssociationType type) 
 	throws MappingException {
 		if ( !type.isEntityType() && !type.isCollectionType() ) {
 			return false;
 		}
 		else {
 			if (config==FetchMode.JOIN) return true;
 			if (config==FetchMode.SELECT) return false;
 			if ( type.isEntityType() ) {
 				//TODO: look at the owning property and check that it 
 				//      isn't lazy (by instrumentation)
 				EntityType entityType =(EntityType) type;
 				EntityPersister persister = getFactory().getEntityPersister( entityType.getAssociatedEntityName() );
 				return !persister.hasProxy();
 			}
 			else {
 				return false;
 			}
 		}
 	}
 
 	/**
 	 * Override on subclasses to enable or suppress joining 
 	 * of certain association types
 	 */
 	protected boolean isJoinedFetchEnabled(AssociationType type, FetchMode config, CascadeStyle cascadeStyle) {
 		return type.isEntityType() && isJoinedFetchEnabledInMapping(config, type) ;
 	}
 	
 	protected String generateTableAlias(final int n, final PropertyPath path, final Joinable joinable) {
 		return StringHelper.generateAlias( joinable.getName(), n );
 	}
 
 	protected String generateRootAlias(final String description) {
 		return StringHelper.generateAlias(description, 0);
 	}
 
 	/**
 	 * Used to detect circularities in the joined graph, note that 
 	 * this method is side-effecty
 	 */
 	protected boolean isDuplicateAssociation(final String foreignKeyTable, final String[] foreignKeyColumns) {
 		AssociationKey associationKey = new AssociationKey(foreignKeyColumns, foreignKeyTable);
 		return !visitedAssociationKeys.add( associationKey );
 	}
 	
 	/**
 	 * Used to detect circularities in the joined graph, note that 
 	 * this method is side-effecty
 	 */
 	protected boolean isDuplicateAssociation(final String lhsTable, final String[] lhsColumnNames, final AssociationType type) {
 		final String foreignKeyTable;
 		final String[] foreignKeyColumns;
 		if ( type.getForeignKeyDirection()==ForeignKeyDirection.FOREIGN_KEY_FROM_PARENT ) {
 			foreignKeyTable = lhsTable;
 			foreignKeyColumns = lhsColumnNames;
 		}
 		else {
 			foreignKeyTable = type.getAssociatedJoinable( getFactory() ).getTableName();
 			foreignKeyColumns = JoinHelper.getRHSColumnNames( type, getFactory() );
 		}
 		return isDuplicateAssociation(foreignKeyTable, foreignKeyColumns);
 	}
 	
 	/**
 	 * Uniquely identifier a foreign key, so that we don't
 	 * join it more than once, and create circularities
 	 */
 	private static final class AssociationKey {
 		private String[] columns;
 		private String table;
 		private AssociationKey(String[] columns, String table) {
 			this.columns = columns;
 			this.table = table;
 		}
 		@Override
         public boolean equals(Object other) {
 			AssociationKey that = (AssociationKey) other;
 			return that.table.equals(table) && Arrays.equals(columns, that.columns);
 		}
 		@Override
         public int hashCode() {
 			return table.hashCode(); //TODO: inefficient
 		}
 	}
 	
 	/**
 	 * Should we join this association?
 	 */
 	protected boolean isJoinable(
 			final JoinType joinType,
 			final Set visitedAssociationKeys,
 			final String lhsTable,
 			final String[] lhsColumnNames,
 			final AssociationType type,
 			final int depth) {
 
 		if ( joinType == JoinType.NONE ) {
 			return false;
 		}
 		
 		if ( joinType == JoinType.INNER_JOIN ) {
 			return true;
 		}
 
 		Integer maxFetchDepth = getFactory().getSettings().getMaximumFetchDepth();
 		final boolean tooDeep = maxFetchDepth!=null && depth >= maxFetchDepth;
 		
 		return !tooDeep && !isDuplicateAssociation(lhsTable, lhsColumnNames, type);
 	}
 	
 	protected String orderBy(final List associations, final String orderBy) {
 		return mergeOrderings( orderBy( associations ), orderBy );
 	}
 
 	protected static String mergeOrderings(String ordering1, String ordering2) {
 		if ( ordering1.length() == 0 ) {
 			return ordering2;
 		}
 		else if ( ordering2.length() == 0 ) {
 			return ordering1;
 		}
 		else {
 			return ordering1 + ", " + ordering2;
 		}
 	}
 	
 	/**
 	 * Generate a sequence of <tt>LEFT OUTER JOIN</tt> clauses for the given associations.
 	 */
 	protected final JoinFragment mergeOuterJoins(List associations)
 	throws MappingException {
 		JoinFragment outerjoin = getDialect().createOuterJoinFragment();
 		Iterator iter = associations.iterator();
 		OuterJoinableAssociation last = null;
 		while ( iter.hasNext() ) {
 			OuterJoinableAssociation oj = (OuterJoinableAssociation) iter.next();
 			if ( last != null && last.isManyToManyWith( oj ) ) {
 				oj.addManyToManyJoin( outerjoin, ( QueryableCollection ) last.getJoinable() );
 			}
 			else {
 				oj.addJoins(outerjoin);
 			}
 			last = oj;
 		}
 		last = null;
 		return outerjoin;
 	}
 
 	/**
 	 * Count the number of instances of Joinable which are actually
 	 * also instances of Loadable, or are one-to-many associations
 	 */
 	protected static final int countEntityPersisters(List associations)
 	throws MappingException {
 		int result = 0;
 		Iterator iter = associations.iterator();
 		while ( iter.hasNext() ) {
 			OuterJoinableAssociation oj = (OuterJoinableAssociation) iter.next();
 			if ( oj.getJoinable().consumesEntityAlias() ) {
 				result++;
 			}
 		}
 		return result;
 	}
 	
 	/**
 	 * Count the number of instances of Joinable which are actually
 	 * also instances of PersistentCollection which are being fetched
 	 * by outer join
 	 */
 	protected static final int countCollectionPersisters(List associations)
 	throws MappingException {
 		int result = 0;
 		Iterator iter = associations.iterator();
 		while ( iter.hasNext() ) {
 			OuterJoinableAssociation oj = (OuterJoinableAssociation) iter.next();
 			if ( oj.getJoinType()==JoinType.LEFT_OUTER_JOIN &&
 					oj.getJoinable().isCollection() &&
 					! oj.hasRestriction() ) {
 				result++;
 			}
 		}
 		return result;
 	}
 	
 	/**
 	 * Get the order by string required for collection fetching
 	 */
 	protected static final String orderBy(List associations)
 	throws MappingException {
 		StringBuilder buf = new StringBuilder();
 		Iterator iter = associations.iterator();
 		OuterJoinableAssociation last = null;
 		while ( iter.hasNext() ) {
 			OuterJoinableAssociation oj = (OuterJoinableAssociation) iter.next();
 			if ( oj.getJoinType() == JoinType.LEFT_OUTER_JOIN ) { // why does this matter?
 				if ( oj.getJoinable().isCollection() ) {
 					final QueryableCollection queryableCollection = (QueryableCollection) oj.getJoinable();
 					if ( queryableCollection.hasOrdering() ) {
 						final String orderByString = queryableCollection.getSQLOrderByString( oj.getRHSAlias() );
 						buf.append( orderByString ).append(", ");
 					}
 				}
 				else {
 					// it might still need to apply a collection ordering based on a
 					// many-to-many defined order-by...
 					if ( last != null && last.getJoinable().isCollection() ) {
 						final QueryableCollection queryableCollection = (QueryableCollection) last.getJoinable();
 						if ( queryableCollection.isManyToMany() && last.isManyToManyWith( oj ) ) {
 							if ( queryableCollection.hasManyToManyOrdering() ) {
 								final String orderByString = queryableCollection.getManyToManyOrderByString( oj.getRHSAlias() );
 								buf.append( orderByString ).append(", ");
 							}
 						}
 					}
 				}
 			}
 			last = oj;
 		}
 		if ( buf.length()>0 ) buf.setLength( buf.length()-2 );
 		return buf.toString();
 	}
 
 	/**
 	 * Render the where condition for a (batch) load by identifier / collection key
 	 */
 	protected StringBuilder whereString(String alias, String[] columnNames, int batchSize) {
 		if ( columnNames.length==1 ) {
 			// if not a composite key, use "foo in (?, ?, ?)" for batching
 			// if no batch, and not a composite key, use "foo = ?"
 			InFragment in = new InFragment().setColumn( alias, columnNames[0] );
 			for ( int i=0; i<batchSize; i++ ) in.addValue("?");
 			return new StringBuilder( in.toFragmentString() );
 		}
 		else {
 			//a composite key
 			ConditionFragment byId = new ConditionFragment()
 					.setTableAlias(alias)
 					.setCondition( columnNames, "?" );
 	
 			StringBuilder whereString = new StringBuilder();
 			if ( batchSize==1 ) {
 				// if no batch, use "foo = ? and bar = ?"
 				whereString.append( byId.toFragmentString() );
 			}
 			else {
 				// if a composite key, use "( (foo = ? and bar = ?) or (foo = ? and bar = ?) )" for batching
 				whereString.append('('); //TODO: unnecessary for databases with ANSI-style joins
 				DisjunctionFragment df = new DisjunctionFragment();
 				for ( int i=0; i<batchSize; i++ ) {
 					df.addCondition(byId);
 				}
 				whereString.append( df.toFragmentString() );
 				whereString.append(')'); //TODO: unnecessary for databases with ANSI-style joins
 			}
 			return whereString;
 		}
 	}
 
 
 	protected void initPersisters(final List associations, final LockMode lockMode) throws MappingException {
 		initPersisters( associations, new LockOptions(lockMode));
 	}
 
 	protected static interface AssociationInitCallback {
 		public static final AssociationInitCallback NO_CALLBACK = new AssociationInitCallback() {
 			public void associationProcessed(OuterJoinableAssociation oja, int position) {
 			}
 		};
 
 		public void associationProcessed(OuterJoinableAssociation oja, int position);
 	}
 	protected void initPersisters(final List associations, final LockOptions lockOptions) throws MappingException {
 		initPersisters( associations, lockOptions, AssociationInitCallback.NO_CALLBACK );
 	}
 
 	protected void initPersisters(
 			final List associations,
 			final LockOptions lockOptions,
 			final AssociationInitCallback callback) throws MappingException {
 		final int joins = countEntityPersisters(associations);
 		final int collections = countCollectionPersisters(associations);
 
 		collectionOwners = collections==0 ? null : new int[collections];
 		collectionPersisters = collections==0 ? null : new CollectionPersister[collections];
 		collectionSuffixes = BasicLoader.generateSuffixes( joins + 1, collections );
 
 		this.lockOptions = lockOptions;
 
 		persisters = new Loadable[joins];
 		aliases = new String[joins];
 		owners = new int[joins];
 		ownerAssociationTypes = new EntityType[joins];
 		lockModeArray = ArrayHelper.fillArray( lockOptions.getLockMode(), joins );
 
 		int i=0;
 		int j=0;
 		Iterator iter = associations.iterator();
 		while ( iter.hasNext() ) {
 			final OuterJoinableAssociation oj = (OuterJoinableAssociation) iter.next();
 			if ( !oj.isCollection() ) {
 				
 				persisters[i] = (Loadable) oj.getJoinable();
 				aliases[i] = oj.getRHSAlias();
 				owners[i] = oj.getOwner(associations);
 				ownerAssociationTypes[i] = (EntityType) oj.getJoinableType();
 				callback.associationProcessed( oj, i );
 				i++;
 				
 			}
 			else {
 				
 				QueryableCollection collPersister = (QueryableCollection) oj.getJoinable();
 				if ( oj.getJoinType()==JoinType.LEFT_OUTER_JOIN && ! oj.hasRestriction() ) {
 					//it must be a collection fetch
 					collectionPersisters[j] = collPersister;
 					collectionOwners[j] = oj.getOwner(associations);
 					j++;
 				}
 	
 				if ( collPersister.isOneToMany() ) {
 					persisters[i] = (Loadable) collPersister.getElementPersister();
 					aliases[i] = oj.getRHSAlias();
 					callback.associationProcessed( oj, i );
 					i++;
 				}
 			}
 		}
 
 		if ( ArrayHelper.isAllNegative(owners) ) owners = null;
 		if ( collectionOwners!=null && ArrayHelper.isAllNegative(collectionOwners) ) {
 			collectionOwners = null;
 		}
 	}
 
 	/**
 	 * Generate a select list of columns containing all properties of the entity classes
 	 */
 	protected final String selectString(List associations)
 	throws MappingException {
 
 		if ( associations.size()==0 ) {
 			return "";
 		}
 		else {
 			StringBuilder buf = new StringBuilder( associations.size() * 100 );
 			int entityAliasCount=0;
 			int collectionAliasCount=0;
 			for ( int i=0; i<associations.size(); i++ ) {
 				OuterJoinableAssociation join = (OuterJoinableAssociation) associations.get(i);
 				OuterJoinableAssociation next = (i == associations.size() - 1)
 				        ? null
 				        : ( OuterJoinableAssociation ) associations.get( i + 1 );
 				final Joinable joinable = join.getJoinable();
 				final String entitySuffix = ( suffixes == null || entityAliasCount >= suffixes.length )
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/entity/BatchingEntityLoaderBuilder.java b/hibernate-core/src/main/java/org/hibernate/loader/entity/BatchingEntityLoaderBuilder.java
index e2a9c247f1..116716903a 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/entity/BatchingEntityLoaderBuilder.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/entity/BatchingEntityLoaderBuilder.java
@@ -1,117 +1,133 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.entity;
 
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 
 /**
  * The contract for building {@link UniqueEntityLoader} capable of performing batch-fetch loading.  Intention
  * is to build these instances, by first calling the static {@link #getBuilder}, and then calling the appropriate
  * {@link #buildLoader} method.
  *
  * @author Steve Ebersole
  *
  * @see org.hibernate.loader.BatchFetchStyle
  */
 public abstract class BatchingEntityLoaderBuilder {
 	public static BatchingEntityLoaderBuilder getBuilder(SessionFactoryImplementor factory) {
 		switch ( factory.getSettings().getBatchFetchStyle() ) {
 			case PADDED: {
 				return PaddedBatchingEntityLoaderBuilder.INSTANCE;
 			}
 			case DYNAMIC: {
 				return DynamicBatchingEntityLoaderBuilder.INSTANCE;
 			}
 			default: {
 				return org.hibernate.loader.entity.plan.LegacyBatchingEntityLoaderBuilder.INSTANCE;
 			}
 		}
 	}
 
 	/**
 	 * Builds a batch-fetch capable loader based on the given persister, lock-mode, etc.
 	 *
 	 * @param persister The entity persister
 	 * @param batchSize The maximum number of ids to batch-fetch at once
 	 * @param lockMode The lock mode
 	 * @param factory The SessionFactory
 	 * @param influencers Any influencers that should affect the built query
 	 *
 	 * @return The loader.
 	 */
 	public UniqueEntityLoader buildLoader(
 			OuterJoinLoadable persister,
 			int batchSize,
 			LockMode lockMode,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers influencers) {
 		if ( batchSize <= 1 ) {
 			// no batching
-			return new EntityLoader( persister, lockMode, factory, influencers );
+			return buildNonBatchingLoader( persister, lockMode, factory, influencers );
 		}
 		return buildBatchingLoader( persister, batchSize, lockMode, factory, influencers );
 	}
 
+	protected UniqueEntityLoader buildNonBatchingLoader(
+			OuterJoinLoadable persister,
+			LockMode lockMode,
+			SessionFactoryImplementor factory,
+			LoadQueryInfluencers influencers) {
+		return new EntityLoader( persister, lockMode, factory, influencers );
+	}
+
 	protected abstract UniqueEntityLoader buildBatchingLoader(
 			OuterJoinLoadable persister,
 			int batchSize,
 			LockMode lockMode,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers influencers);
 
 	/**
 	 * Builds a batch-fetch capable loader based on the given persister, lock-options, etc.
 	 *
 	 * @param persister The entity persister
 	 * @param batchSize The maximum number of ids to batch-fetch at once
 	 * @param lockOptions The lock options
 	 * @param factory The SessionFactory
 	 * @param influencers Any influencers that should affect the built query
 	 *
 	 * @return The loader.
 	 */
 	public UniqueEntityLoader buildLoader(
 			OuterJoinLoadable persister,
 			int batchSize,
 			LockOptions lockOptions,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers influencers) {
 		if ( batchSize <= 1 ) {
 			// no batching
-			return new EntityLoader( persister, lockOptions, factory, influencers );
+			return buildNonBatchingLoader( persister, lockOptions, factory, influencers );
 		}
 		return buildBatchingLoader( persister, batchSize, lockOptions, factory, influencers );
 	}
 
+	protected UniqueEntityLoader buildNonBatchingLoader(
+			OuterJoinLoadable persister,
+			LockOptions lockOptions,
+			SessionFactoryImplementor factory,
+			LoadQueryInfluencers influencers) {
+		return new EntityLoader( persister, lockOptions, factory, influencers );
+	}
+
 	protected abstract UniqueEntityLoader buildBatchingLoader(
 			OuterJoinLoadable persister,
 			int batchSize,
 			LockOptions lockOptions,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers influencers);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/AbstractBatchingEntityLoaderBuilder.java b/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/AbstractBatchingEntityLoaderBuilder.java
new file mode 100644
index 0000000000..657743d6d5
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/AbstractBatchingEntityLoaderBuilder.java
@@ -0,0 +1,58 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.entity.plan;
+
+import org.hibernate.LockMode;
+import org.hibernate.LockOptions;
+import org.hibernate.engine.spi.LoadQueryInfluencers;
+import org.hibernate.engine.spi.SessionFactoryImplementor;
+import org.hibernate.loader.entity.BatchingEntityLoaderBuilder;
+import org.hibernate.loader.entity.UniqueEntityLoader;
+import org.hibernate.persister.entity.OuterJoinLoadable;
+
+/**
+ * Base class for LoadPlan-based BatchingEntityLoaderBuilder implementations.  Mainly we handle the common
+ * "no batching" case here to use the LoadPlan-based EntityLoader
+ *
+ * @author Steve Ebersole
+ */
+public abstract class AbstractBatchingEntityLoaderBuilder extends BatchingEntityLoaderBuilder {
+	@Override
+	protected UniqueEntityLoader buildNonBatchingLoader(
+			OuterJoinLoadable persister,
+			LockMode lockMode,
+			SessionFactoryImplementor factory,
+			LoadQueryInfluencers influencers) {
+		return EntityLoader.forEntity( persister ).withLockMode( lockMode ).withInfluencers( influencers ).byPrimaryKey();
+	}
+
+	@Override
+	protected UniqueEntityLoader buildNonBatchingLoader(
+			OuterJoinLoadable persister,
+			LockOptions lockOptions,
+			SessionFactoryImplementor factory,
+			LoadQueryInfluencers influencers) {
+		return EntityLoader.forEntity( persister ).withLockOptions( lockOptions ).withInfluencers( influencers ).byPrimaryKey();
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/AbstractLoadPlanBasedEntityLoader.java b/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/AbstractLoadPlanBasedEntityLoader.java
index 48661de5d5..9f66629638 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/AbstractLoadPlanBasedEntityLoader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/AbstractLoadPlanBasedEntityLoader.java
@@ -1,769 +1,728 @@
 package org.hibernate.loader.entity.plan;
 
 import java.io.Serializable;
 import java.sql.CallableStatement;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.util.ArrayList;
 import java.util.Arrays;
-import java.util.Collections;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
 import org.hibernate.LockOptions;
 import org.hibernate.ScrollMode;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.pagination.LimitHandler;
 import org.hibernate.dialect.pagination.LimitHelper;
 import org.hibernate.dialect.pagination.NoopLimitHandler;
 import org.hibernate.engine.jdbc.ColumnNameCache;
-import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.TypedValue;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.loader.entity.UniqueEntityLoader;
-import org.hibernate.loader.internal.EntityLoadQueryBuilderImpl;
-import org.hibernate.loader.internal.LoadQueryAliasResolutionContextImpl;
-import org.hibernate.loader.internal.ResultSetProcessorImpl;
+import org.hibernate.loader.plan.exec.query.spi.NamedParameterContext;
+import org.hibernate.loader.plan.exec.query.spi.QueryBuildingParameters;
+import org.hibernate.loader.plan.exec.spi.LoadQueryDetails;
 import org.hibernate.loader.plan.internal.SingleRootReturnLoadPlanBuilderStrategy;
 import org.hibernate.loader.plan.spi.LoadPlan;
 import org.hibernate.loader.plan.spi.build.LoadPlanBuilder;
 import org.hibernate.loader.spi.AfterLoadAction;
-import org.hibernate.loader.spi.LoadQueryAliasResolutionContext;
-import org.hibernate.loader.spi.NamedParameterContext;
 import org.hibernate.loader.spi.NoOpLoadPlanAdvisor;
-import org.hibernate.loader.spi.ResultSetProcessor;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.Type;
 
 /**
  * A UniqueEntityLoader implementation based on using LoadPlans
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractLoadPlanBasedEntityLoader implements UniqueEntityLoader {
 	private static final CoreMessageLogger log = CoreLogging.messageLogger( AbstractLoadPlanBasedEntityLoader.class );
 
 	private final SessionFactoryImplementor factory;
 	private final OuterJoinLoadable entityPersister;
 	private final Type uniqueKeyType;
 	private final String entityName;
 
 	private final LoadPlan plan;
-	private final String staticSql;
-	private final LoadQueryAliasResolutionContext staticAliasResolutionContext;
-	private final ResultSetProcessor staticResultSetProcessor;
+	private final LoadQueryDetails staticLoadQuery;
 
 	private ColumnNameCache columnNameCache;
 
 	public AbstractLoadPlanBasedEntityLoader(
 			OuterJoinLoadable entityPersister,
-			Type uniqueKeyType,
 			SessionFactoryImplementor factory,
-			LoadQueryInfluencers loadQueryInfluencers) {
+			String[] uniqueKeyColumnNames,
+			Type uniqueKeyType,
+			QueryBuildingParameters buildingParameters) {
+		this.entityPersister = entityPersister;
 		this.factory = factory;
 		this.uniqueKeyType = uniqueKeyType;
 		this.entityName = entityPersister.getEntityName();
-		this.entityPersister = entityPersister;
 
 		final SingleRootReturnLoadPlanBuilderStrategy strategy = new SingleRootReturnLoadPlanBuilderStrategy(
 				factory,
-				loadQueryInfluencers
+				buildingParameters.getQueryInfluencers()
 		);
 
 		this.plan = LoadPlanBuilder.buildRootEntityLoadPlan( strategy, entityPersister );
-		this.staticAliasResolutionContext = buildAliasResolutionContext( plan, factory );
-		this.staticSql = generateStaticSql( plan, staticAliasResolutionContext, factory, loadQueryInfluencers );
-		this.staticResultSetProcessor = generateStaticResultSetProcessor( plan );
-	}
-
-	protected LoadQueryAliasResolutionContext buildAliasResolutionContext(LoadPlan plan, SessionFactoryImplementor factory) {
-		return new LoadQueryAliasResolutionContextImpl(
+		this.staticLoadQuery = LoadQueryDetails.makeForBatching(
+				uniqueKeyColumnNames,
+				plan,
 				factory,
-				0,
-				Collections.singletonMap( plan.getReturns().get( 0 ), new String[] {"abc"} )
+				buildingParameters
 		);
 	}
 
-	protected String generateStaticSql(
-			LoadPlan plan,
-			LoadQueryAliasResolutionContext aliasResolutionContext,
-			SessionFactoryImplementor factory,
-			LoadQueryInfluencers loadQueryInfluencers) {
-		return new EntityLoadQueryBuilderImpl( loadQueryInfluencers, plan ).generateSql(
-				1,
-				factory,
-				aliasResolutionContext
-		);
-	}
-
-	protected ResultSetProcessor generateStaticResultSetProcessor(LoadPlan plan) {
-		return new ResultSetProcessorImpl( plan );
-	}
-
 	protected SessionFactoryImplementor getFactory() {
 		return factory;
 	}
 
-	protected String getSqlStatement() {
-		return staticSql;
+	protected LoadQueryDetails getStaticLoadQuery() {
+		return staticLoadQuery;
 	}
 
 	protected String getEntityName() {
 		return entityName;
 	}
 
 	/**
 	 * Called by wrappers that batch load entities
 	 * @param persister only needed for logging
 	 * @param lockOptions
 	 */
 	public final List loadEntityBatch(
 			final SessionImplementor session,
 			final Serializable[] ids,
 			final Type idType,
 			final Object optionalObject,
 			final String optionalEntityName,
 			final Serializable optionalId,
 			final EntityPersister persister,
 			LockOptions lockOptions) throws HibernateException {
 
 		if ( log.isDebugEnabled() ) {
 			log.debugf( "Batch loading entity: %s", MessageHelper.infoString( persister, ids, getFactory() ) );
 		}
 
 		final Type[] types = new Type[ids.length];
 		Arrays.fill( types, idType );
 		List result;
 		try {
 			final QueryParameters qp = new QueryParameters();
 			qp.setPositionalParameterTypes( types );
 			qp.setPositionalParameterValues( ids );
-			qp.setOptionalObject( optionalObject );
-			qp.setOptionalEntityName( optionalEntityName );
-			qp.setOptionalId( optionalId );
 			qp.setLockOptions( lockOptions );
 
 			result = executeLoad(
 					session,
 					qp,
-					staticSql,
-					staticResultSetProcessor,
-					staticAliasResolutionContext,
+					staticLoadQuery,
 					false,
 					null
 			);
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not load an entity batch: " + MessageHelper.infoString( entityPersister, ids, getFactory() ),
-					getSqlStatement()
+					staticLoadQuery.getSqlStatement()
 			);
 		}
 
 		log.debug( "Done entity batch load" );
 
 		return result;
 
 	}
 
 	@Override
 	@Deprecated
 	public Object load(Serializable id, Object optionalObject, SessionImplementor session) throws HibernateException {
 		return load( id, optionalObject, session, LockOptions.NONE );
 	}
 
 	@Override
 	public Object load(Serializable id, Object optionalObject, SessionImplementor session, LockOptions lockOptions) {
 		Object result = null;
 
 		try {
 			final QueryParameters qp = new QueryParameters();
 			qp.setPositionalParameterTypes( new Type[] { entityPersister.getIdentifierType() } );
 			qp.setPositionalParameterValues( new Object[] { id } );
 			qp.setOptionalObject( optionalObject );
 			qp.setOptionalEntityName( entityPersister.getEntityName() );
 			qp.setOptionalId( id );
 			qp.setLockOptions( lockOptions );
 
 			final List results = executeLoad(
 					session,
 					qp,
-					staticSql,
-					staticResultSetProcessor,
-					staticAliasResolutionContext,
+					staticLoadQuery,
 					false,
 					null
 			);
 			result = extractEntityResult( results );
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not load an entity: " + MessageHelper.infoString(
 							entityPersister,
 							id,
 							entityPersister.getIdentifierType(),
 							factory
 					),
-					getSqlStatement()
+					staticLoadQuery.getSqlStatement()
 			);
 		}
 
 		log.debugf( "Done entity load : %s#%s", getEntityName(), id );
 		return result;
 	}
 
 	protected List executeLoad(
 			SessionImplementor session,
 			QueryParameters queryParameters,
-			String sql,
-			ResultSetProcessor resultSetProcessor,
-			LoadQueryAliasResolutionContext aliasResolutionContext,
+			LoadQueryDetails loadQueryDetails,
 			boolean returnProxies,
 			ResultTransformer forcedResultTransformer) throws SQLException {
 		final List<AfterLoadAction> afterLoadActions = new ArrayList<AfterLoadAction>();
 		return executeLoad(
 				session,
 				queryParameters,
-				sql,
-				resultSetProcessor,
-				aliasResolutionContext,
+				loadQueryDetails,
 				returnProxies,
 				forcedResultTransformer,
 				afterLoadActions
 		);
 	}
 
 	protected List executeLoad(
 			SessionImplementor session,
 			QueryParameters queryParameters,
-			String sql,
-			ResultSetProcessor resultSetProcessor,
-			LoadQueryAliasResolutionContext aliasResolutionContext,
+			LoadQueryDetails loadQueryDetails,
 			boolean returnProxies,
 			ResultTransformer forcedResultTransformer,
 			List<AfterLoadAction> afterLoadActions) throws SQLException {
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		final boolean defaultReadOnlyOrig = persistenceContext.isDefaultReadOnly();
 		if ( queryParameters.isReadOnlyInitialized() ) {
 			// The read-only/modifiable mode for the query was explicitly set.
 			// Temporarily set the default read-only/modifiable setting to the query's setting.
 			persistenceContext.setDefaultReadOnly( queryParameters.isReadOnly() );
 		}
 		else {
 			// The read-only/modifiable setting for the query was not initialized.
 			// Use the default read-only/modifiable from the persistence context instead.
 			queryParameters.setReadOnly( persistenceContext.isDefaultReadOnly() );
 		}
 		persistenceContext.beforeLoad();
 		try {
 			List results;
+			final String sql = loadQueryDetails.getSqlStatement();
 			try {
 				final SqlStatementWrapper wrapper = executeQueryStatement( sql, queryParameters, false, afterLoadActions, session );
-				results = resultSetProcessor.extractResults(
+				results = loadQueryDetails.getResultSetProcessor().extractResults(
 						// todo : hook in the JPA 2.1 entity graph advisor
 						NoOpLoadPlanAdvisor.INSTANCE,
 						wrapper.getResultSet(),
 						session,
 						queryParameters,
 						new NamedParameterContext() {
 							@Override
 							public int[] getNamedParameterLocations(String name) {
 								return AbstractLoadPlanBasedEntityLoader.this.getNamedParameterLocs( name );
 							}
 						},
-						aliasResolutionContext,
+						loadQueryDetails.getAliasResolutionContext(),
 						returnProxies,
 						queryParameters.isReadOnly(),
 						forcedResultTransformer,
 						afterLoadActions
 				);
 			}
 			finally {
 				persistenceContext.afterLoad();
 			}
 			persistenceContext.initializeNonLazyCollections();
 			return results;
 		}
 		finally {
 			// Restore the original default
 			persistenceContext.setDefaultReadOnly( defaultReadOnlyOrig );
 		}
 	}
 
 	protected Object extractEntityResult(List results) {
 		if ( results.size() == 0 ) {
 			return null;
 		}
 		else if ( results.size() == 1 ) {
 			return results.get( 0 );
 		}
 		else {
 			final Object row = results.get( 0 );
 			if ( row.getClass().isArray() ) {
 				// the logical type of the result list is List<Object[]>.  See if the contained
 				// array contains just one element, and return that if so
 				final Object[] rowArray = (Object[]) row;
 				if ( rowArray.length == 1 ) {
 					return rowArray[0];
 				}
 			}
 			else {
 				return row;
 			}
 		}
 
 		throw new HibernateException( "Unable to interpret given query results in terms of a load-entity query" );
 	}
 
 	protected Object doQueryAndLoadEntity(
 			SessionImplementor session,
 			QueryParameters queryParameters,
-			String sql,
-			ResultSetProcessor resultSetProcessor,
-			LoadQueryAliasResolutionContext aliasResolutionContext,
+			LoadQueryDetails loadQueryDetails,
 			boolean returnProxies,
 			ResultTransformer forcedResultTransformer) throws SQLException {
 
 		final List<AfterLoadAction> afterLoadActions = new ArrayList<AfterLoadAction>();
 
 		final SqlStatementWrapper wrapper = executeQueryStatement( queryParameters, false, afterLoadActions, session );
 
 		try {
-			final List results = resultSetProcessor.extractResults(
+			final List results = loadQueryDetails.getResultSetProcessor().extractResults(
 					NoOpLoadPlanAdvisor.INSTANCE,
 					wrapper.getResultSet(),
 					session,
 					queryParameters,
 					new NamedParameterContext() {
 						@Override
 						public int[] getNamedParameterLocations(String name) {
 							return AbstractLoadPlanBasedEntityLoader.this.getNamedParameterLocs( name );
 						}
 					},
-					staticAliasResolutionContext,
+					loadQueryDetails.getAliasResolutionContext(),
 					returnProxies,
 					queryParameters.isReadOnly(),
 					forcedResultTransformer,
 					afterLoadActions
 			);
 
 
 			if ( results.size() == 0 ) {
 				return null;
 			}
 			else if ( results.size() == 1 ) {
 				return results.get( 0 );
 			}
 			else {
 				final Object row = results.get( 0 );
 				if ( row.getClass().isArray() ) {
 					// the logical type of the result list is List<Object[]>.  See if the contained
 					// array contains just one element, and return that if so
 					final Object[] rowArray = (Object[]) row;
 					if ( rowArray.length == 1 ) {
 						return rowArray[0];
 					}
 				}
 				else {
 					return row;
 				}
 			}
 
 			throw new HibernateException( "Unable to interpret given query results in terms of a load-entity query" );
 		}
 		finally {
 			session.getTransactionCoordinator().getJdbcCoordinator().release( wrapper.getStatement() );
 		}
 	}
 
 
 	protected SqlStatementWrapper executeQueryStatement(
 			final QueryParameters queryParameters,
 			final boolean scroll,
 			List<AfterLoadAction> afterLoadActions,
 			final SessionImplementor session) throws SQLException {
-		return executeQueryStatement( getSqlStatement(), queryParameters, scroll, afterLoadActions, session );
+		return executeQueryStatement( staticLoadQuery.getSqlStatement(), queryParameters, scroll, afterLoadActions, session );
 	}
 
 	protected SqlStatementWrapper executeQueryStatement(
 			String sqlStatement,
 			QueryParameters queryParameters,
 			boolean scroll,
 			List<AfterLoadAction> afterLoadActions,
 			SessionImplementor session) throws SQLException {
 
 		// Processing query filters.
 		queryParameters.processFilters( sqlStatement, session );
 
 		// Applying LIMIT clause.
 		final LimitHandler limitHandler = getLimitHandler(
 				queryParameters.getFilteredSQL(),
 				queryParameters.getRowSelection()
 		);
 		String sql = limitHandler.getProcessedSql();
 
 		// Adding locks and comments.
 		sql = preprocessSQL( sql, queryParameters, getFactory().getDialect(), afterLoadActions );
 
 		final PreparedStatement st = prepareQueryStatement( sql, queryParameters, limitHandler, scroll, session );
 		return new SqlStatementWrapper( st, getResultSet( st, queryParameters.getRowSelection(), limitHandler, queryParameters.hasAutoDiscoverScalarTypes(), session ) );
 	}
 
 	/**
 	 * Build LIMIT clause handler applicable for given selection criteria. Returns {@link org.hibernate.dialect.pagination.NoopLimitHandler} delegate
 	 * if dialect does not support LIMIT expression or processed query does not use pagination.
 	 *
 	 * @param sql Query string.
 	 * @param selection Selection criteria.
 	 * @return LIMIT clause delegate.
 	 */
 	protected LimitHandler getLimitHandler(String sql, RowSelection selection) {
 		final LimitHandler limitHandler = getFactory().getDialect().buildLimitHandler( sql, selection );
 		return LimitHelper.useLimit( limitHandler, selection ) ? limitHandler : new NoopLimitHandler( sql, selection );
 	}
 
 	private String preprocessSQL(
 			String sql,
 			QueryParameters queryParameters,
 			Dialect dialect,
 			List<AfterLoadAction> afterLoadActions) {
 		return getFactory().getSettings().isCommentsEnabled()
 				? prependComment( sql, queryParameters )
 				: sql;
 	}
 
 	private String prependComment(String sql, QueryParameters parameters) {
 		final String comment = parameters.getComment();
 		if ( comment == null ) {
 			return sql;
 		}
 		else {
 			return "/* " + comment + " */ " + sql;
 		}
 	}
 
 	/**
 	 * Obtain a <tt>PreparedStatement</tt> with all parameters pre-bound.
 	 * Bind JDBC-style <tt>?</tt> parameters, named parameters, and
 	 * limit parameters.
 	 */
 	protected final PreparedStatement prepareQueryStatement(
 			final String sql,
 			final QueryParameters queryParameters,
 			final LimitHandler limitHandler,
 			final boolean scroll,
 			final SessionImplementor session) throws SQLException, HibernateException {
 		final Dialect dialect = getFactory().getDialect();
 		final RowSelection selection = queryParameters.getRowSelection();
 		final boolean useLimit = LimitHelper.useLimit( limitHandler, selection );
 		final boolean hasFirstRow = LimitHelper.hasFirstRow( selection );
 		final boolean useLimitOffset = hasFirstRow && useLimit && limitHandler.supportsLimitOffset();
 		final boolean callable = queryParameters.isCallable();
 		final ScrollMode scrollMode = getScrollMode( scroll, hasFirstRow, useLimitOffset, queryParameters );
 
 		final PreparedStatement st = session.getTransactionCoordinator().getJdbcCoordinator()
 				.getStatementPreparer().prepareQueryStatement( sql, callable, scrollMode );
 
 		try {
 
 			int col = 1;
 			//TODO: can we limit stored procedures ?!
 			col += limitHandler.bindLimitParametersAtStartOfQuery( st, col );
 
 			if (callable) {
 				col = dialect.registerResultSetOutParameter( (CallableStatement)st, col );
 			}
 
 			col += bindParameterValues( st, queryParameters, col, session );
 
 			col += limitHandler.bindLimitParametersAtEndOfQuery( st, col );
 
 			limitHandler.setMaxRows( st );
 
 			if ( selection != null ) {
 				if ( selection.getTimeout() != null ) {
 					st.setQueryTimeout( selection.getTimeout() );
 				}
 				if ( selection.getFetchSize() != null ) {
 					st.setFetchSize( selection.getFetchSize() );
 				}
 			}
 
 			// handle lock timeout...
 			final LockOptions lockOptions = queryParameters.getLockOptions();
 			if ( lockOptions != null ) {
 				if ( lockOptions.getTimeOut() != LockOptions.WAIT_FOREVER ) {
 					if ( !dialect.supportsLockTimeouts() ) {
 						if ( log.isDebugEnabled() ) {
 							log.debugf(
 									"Lock timeout [%s] requested but dialect reported to not support lock timeouts",
 									lockOptions.getTimeOut()
 							);
 						}
 					}
 					else if ( dialect.isLockTimeoutParameterized() ) {
 						st.setInt( col++, lockOptions.getTimeOut() );
 					}
 				}
 			}
 
 			if ( log.isTraceEnabled() ) {
 				log.tracev( "Bound [{0}] parameters total", col );
 			}
 		}
 		catch ( SQLException sqle ) {
 			session.getTransactionCoordinator().getJdbcCoordinator().release( st );
 			throw sqle;
 		}
 		catch ( HibernateException he ) {
 			session.getTransactionCoordinator().getJdbcCoordinator().release( st );
 			throw he;
 		}
 
 		return st;
 	}
 
 	protected ScrollMode getScrollMode(boolean scroll, boolean hasFirstRow, boolean useLimitOffSet, QueryParameters queryParameters) {
 		final boolean canScroll = getFactory().getSettings().isScrollableResultSetsEnabled();
 		if ( canScroll ) {
 			if ( scroll ) {
 				return queryParameters.getScrollMode();
 			}
 			if ( hasFirstRow && !useLimitOffSet ) {
 				return ScrollMode.SCROLL_INSENSITIVE;
 			}
 		}
 		return null;
 	}
 
 	/**
 	 * Bind all parameter values into the prepared statement in preparation
 	 * for execution.
 	 *
 	 * @param statement The JDBC prepared statement
 	 * @param queryParameters The encapsulation of the parameter values to be bound.
 	 * @param startIndex The position from which to start binding parameter values.
 	 * @param session The originating session.
 	 * @return The number of JDBC bind positions actually bound during this method execution.
 	 * @throws SQLException Indicates problems performing the binding.
 	 */
 	protected int bindParameterValues(
 			PreparedStatement statement,
 			QueryParameters queryParameters,
 			int startIndex,
 			SessionImplementor session) throws SQLException {
 		int span = 0;
 		span += bindPositionalParameters( statement, queryParameters, startIndex, session );
 		span += bindNamedParameters( statement, queryParameters.getNamedParameters(), startIndex + span, session );
 		return span;
 	}
 
 	/**
 	 * Bind positional parameter values to the JDBC prepared statement.
 	 * <p/>
 	 * Positional parameters are those specified by JDBC-style ? parameters
 	 * in the source query.  It is (currently) expected that these come
 	 * before any named parameters in the source query.
 	 *
 	 * @param statement The JDBC prepared statement
 	 * @param queryParameters The encapsulation of the parameter values to be bound.
 	 * @param startIndex The position from which to start binding parameter values.
 	 * @param session The originating session.
 	 * @return The number of JDBC bind positions actually bound during this method execution.
 	 * @throws SQLException Indicates problems performing the binding.
 	 * @throws org.hibernate.HibernateException Indicates problems delegating binding to the types.
 	 */
 	protected int bindPositionalParameters(
 			final PreparedStatement statement,
 			final QueryParameters queryParameters,
 			final int startIndex,
 			final SessionImplementor session) throws SQLException, HibernateException {
 		final Object[] values = queryParameters.getFilteredPositionalParameterValues();
 		final Type[] types = queryParameters.getFilteredPositionalParameterTypes();
 		int span = 0;
 		for ( int i = 0; i < values.length; i++ ) {
 			types[i].nullSafeSet( statement, values[i], startIndex + span, session );
 			span += types[i].getColumnSpan( getFactory() );
 		}
 		return span;
 	}
 
 	/**
 	 * Bind named parameters to the JDBC prepared statement.
 	 * <p/>
 	 * This is a generic implementation, the problem being that in the
 	 * general case we do not know enough information about the named
 	 * parameters to perform this in a complete manner here.  Thus this
 	 * is generally overridden on subclasses allowing named parameters to
 	 * apply the specific behavior.  The most usual limitation here is that
 	 * we need to assume the type span is always one...
 	 *
 	 * @param statement The JDBC prepared statement
 	 * @param namedParams A map of parameter names to values
 	 * @param startIndex The position from which to start binding parameter values.
 	 * @param session The originating session.
 	 * @return The number of JDBC bind positions actually bound during this method execution.
 	 * @throws SQLException Indicates problems performing the binding.
 	 * @throws org.hibernate.HibernateException Indicates problems delegating binding to the types.
 	 */
 	protected int bindNamedParameters(
 			final PreparedStatement statement,
 			final Map namedParams,
 			final int startIndex,
 			final SessionImplementor session) throws SQLException, HibernateException {
 		if ( namedParams != null ) {
 			// assumes that types are all of span 1
 			final Iterator itr = namedParams.entrySet().iterator();
 			final boolean debugEnabled = log.isDebugEnabled();
 			int result = 0;
 			while ( itr.hasNext() ) {
 				final Map.Entry e = (Map.Entry) itr.next();
 				final String name = (String) e.getKey();
 				final TypedValue typedval = (TypedValue) e.getValue();
 				final int[] locs = getNamedParameterLocs( name );
 				for ( int loc : locs ) {
 					if ( debugEnabled ) {
 						log.debugf(
 								"bindNamedParameters() %s -> %s [%s]",
 								typedval.getValue(),
 								name,
 								loc + startIndex
 						);
 					}
 					typedval.getType().nullSafeSet( statement, typedval.getValue(), loc + startIndex, session );
 				}
 				result += locs.length;
 			}
 			return result;
 		}
 		else {
 			return 0;
 		}
 	}
 
 	public int[] getNamedParameterLocs(String name) {
 		throw new AssertionFailure("no named parameters");
 	}
 
 	/**
 	 * Execute given <tt>PreparedStatement</tt>, advance to the first result and return SQL <tt>ResultSet</tt>.
 	 */
 	protected final ResultSet getResultSet(
 			final PreparedStatement st,
 			final RowSelection selection,
 			final LimitHandler limitHandler,
 			final boolean autodiscovertypes,
 			final SessionImplementor session)
 			throws SQLException, HibernateException {
 
 		try {
 			ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st );
 			rs = wrapResultSetIfEnabled( rs , session );
 
 			if ( !limitHandler.supportsLimitOffset() || !LimitHelper.useLimit( limitHandler, selection ) ) {
 				advance( rs, selection );
 			}
 
 			if ( autodiscovertypes ) {
 				autoDiscoverTypes( rs );
 			}
 			return rs;
 		}
 		catch ( SQLException sqle ) {
 			session.getTransactionCoordinator().getJdbcCoordinator().release( st );
 			throw sqle;
 		}
 	}
 
 	/**
 	 * Advance the cursor to the first required row of the <tt>ResultSet</tt>
 	 */
 	protected void advance(final ResultSet rs, final RowSelection selection) throws SQLException {
 		final int firstRow = LimitHelper.getFirstRow( selection );
 		if ( firstRow != 0 ) {
 			if ( getFactory().getSettings().isScrollableResultSetsEnabled() ) {
 				// we can go straight to the first required row
 				rs.absolute( firstRow );
 			}
 			else {
 				// we need to step through the rows one row at a time (slow)
 				for ( int m = 0; m < firstRow; m++ ) {
 					rs.next();
 				}
 			}
 		}
 	}
 
 	protected void autoDiscoverTypes(ResultSet rs) {
 		throw new AssertionFailure("Auto discover types not supported in this loader");
 
 	}
 
 	private synchronized ResultSet wrapResultSetIfEnabled(final ResultSet rs, final SessionImplementor session) {
 		// synchronized to avoid multi-thread access issues; defined as method synch to avoid
 		// potential deadlock issues due to nature of code.
 		if ( session.getFactory().getSettings().isWrapResultSetsEnabled() ) {
 			try {
 				if ( log.isDebugEnabled() ) {
 					log.debugf( "Wrapping result set [%s]", rs );
 				}
 				return session.getFactory()
 						.getJdbcServices()
 						.getResultSetWrapper().wrap( rs, retreiveColumnNameToIndexCache( rs ) );
 			}
 			catch(SQLException e) {
 				log.unableToWrapResultSet( e );
 				return rs;
 			}
 		}
 		else {
 			return rs;
 		}
 	}
 
 	private ColumnNameCache retreiveColumnNameToIndexCache(ResultSet rs) throws SQLException {
 		if ( columnNameCache == null ) {
 			log.trace( "Building columnName->columnIndex cache" );
 			columnNameCache = new ColumnNameCache( rs.getMetaData().getColumnCount() );
 		}
 
 		return columnNameCache;
 	}
 
 	/**
 	 * Wrapper class for {@link java.sql.Statement} and associated {@link ResultSet}.
 	 */
 	protected static class SqlStatementWrapper {
 		private final Statement statement;
 		private final ResultSet resultSet;
 
 		private SqlStatementWrapper(Statement statement, ResultSet resultSet) {
 			this.resultSet = resultSet;
 			this.statement = statement;
 		}
 
 		public ResultSet getResultSet() {
 			return resultSet;
 		}
 
 		public Statement getStatement() {
 			return statement;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/BatchingEntityLoader.java b/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/BatchingEntityLoader.java
index 5bf03ec81a..b8e9d5f820 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/BatchingEntityLoader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/BatchingEntityLoader.java
@@ -1,130 +1,132 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.entity.plan;
 
 import java.io.Serializable;
 import java.sql.SQLException;
 import java.util.Arrays;
 import java.util.List;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.LockOptions;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.loader.Loader;
 import org.hibernate.loader.entity.UniqueEntityLoader;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.Type;
 
 /**
- * The base contract for loaders capable of performing batch-fetch loading of entities using multiple primary key
- * values in the SQL <tt>WHERE</tt> clause.
+ * The base contract for UniqueEntityLoader implementations capable of performing batch-fetch loading of entities
+ * using multiple primary key values in the SQL <tt>WHERE</tt> clause.
+ * <p/>
+ * Typically these are
  *
  * @author Gavin King
  * @author Steve Ebersole
  *
  * @see org.hibernate.loader.entity.BatchingEntityLoaderBuilder
  * @see org.hibernate.loader.entity.UniqueEntityLoader
  */
 public abstract class BatchingEntityLoader implements UniqueEntityLoader {
 	private static final Logger log = Logger.getLogger( BatchingEntityLoader.class );
 
 	private final EntityPersister persister;
 
 	public BatchingEntityLoader(EntityPersister persister) {
 		this.persister = persister;
 	}
 
 	public EntityPersister persister() {
 		return persister;
 	}
 
 	@Override
 	@Deprecated
 	public Object load(Serializable id, Object optionalObject, SessionImplementor session) {
 		return load( id, optionalObject, session, LockOptions.NONE );
 	}
 
 	protected QueryParameters buildQueryParameters(
 			Serializable id,
 			Serializable[] ids,
 			Object optionalObject,
 			LockOptions lockOptions) {
 		Type[] types = new Type[ids.length];
 		Arrays.fill( types, persister().getIdentifierType() );
 
 		QueryParameters qp = new QueryParameters();
 		qp.setPositionalParameterTypes( types );
 		qp.setPositionalParameterValues( ids );
 		qp.setOptionalObject( optionalObject );
 		qp.setOptionalEntityName( persister().getEntityName() );
 		qp.setOptionalId( id );
 		qp.setLockOptions( lockOptions );
 		return qp;
 	}
 
 	protected Object getObjectFromList(List results, Serializable id, SessionImplementor session) {
 		for ( Object obj : results ) {
 			final boolean equal = persister.getIdentifierType().isEqual(
 					id,
 					session.getContextEntityIdentifier( obj ),
 					session.getFactory()
 			);
 			if ( equal ) {
 				return obj;
 			}
 		}
 		return null;
 	}
 
 	protected Object doBatchLoad(
 			Serializable id,
 			Loader loaderToUse,
 			SessionImplementor session,
 			Serializable[] ids,
 			Object optionalObject,
 			LockOptions lockOptions) {
 		if ( log.isDebugEnabled() ) {
 			log.debugf( "Batch loading entity: %s", MessageHelper.infoString( persister, ids, session.getFactory() ) );
 		}
 
 		QueryParameters qp = buildQueryParameters( id, ids, optionalObject, lockOptions );
 
 		try {
 			final List results = loaderToUse.doQueryAndInitializeNonLazyCollections( session, qp, false );
 			log.debug( "Done entity batch load" );
 			return getObjectFromList(results, id, session);
 		}
 		catch ( SQLException sqle ) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not load an entity batch: " + MessageHelper.infoString( persister(), ids, session.getFactory() ),
 					loaderToUse.getSQLString()
 			);
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/EntityLoader.java b/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/EntityLoader.java
index 14068c13e6..4b7a3f3bfc 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/EntityLoader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/EntityLoader.java
@@ -1,179 +1,156 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader.entity.plan;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.CoreLogging;
+import org.hibernate.loader.plan.exec.query.spi.QueryBuildingParameters;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.type.Type;
 
 /**
+ * UniqueEntityLoader implementation that is the main functionality for LoadPlan-based Entity loading.
+ * <p/>
+ * Can handle batch-loading as well as non-pk, unique-key loading,
+ * <p/>
+ * Much is ultimately delegated to its superclass, AbstractLoadPlanBasedEntityLoader.  However:
+ * todo How much of AbstractLoadPlanBasedEntityLoader is actually needed?
+ *
  * Loads an entity instance using outerjoin fetching to fetch associated entities.
  * <br>
  * The <tt>EntityPersister</tt> must implement <tt>Loadable</tt>. For other entities,
  * create a customized subclass of <tt>Loader</tt>.
  *
  * @author Gavin King
+ * @author Steve Ebersole
+ * @author Gail Badner
  */
 public class EntityLoader extends AbstractLoadPlanBasedEntityLoader  {
 	private static final Logger log = CoreLogging.logger( EntityLoader.class );
 
-//	private final boolean batchLoader;
-//	private final int[][] compositeKeyManyToOneTargetIndices;
-//
-//	public EntityLoader(
-//			OuterJoinLoadable persister,
-//			LockMode lockMode,
-//			SessionFactoryImplementor factory,
-//			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
-//		this( persister, 1, lockMode, factory, loadQueryInfluencers );
-//	}
-//
-//	public EntityLoader(
-//			OuterJoinLoadable persister,
-//			LockOptions lockOptions,
-//			SessionFactoryImplementor factory,
-//			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
-//		this( persister, 1, lockOptions, factory, loadQueryInfluencers );
-//	}
-
-	public EntityLoader(
-			OuterJoinLoadable persister,
-			int batchSize,
-			LockMode lockMode,
-			SessionFactoryImplementor factory,
-			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
-		this(
-				persister,
-				persister.getIdentifierColumnNames(),
-				persister.getIdentifierType(),
-				batchSize,
-				lockMode,
-				factory,
-				loadQueryInfluencers
-			);
+	public static Builder forEntity(OuterJoinLoadable persister) {
+		return new Builder( persister );
 	}
 
-	public EntityLoader(
-			OuterJoinLoadable persister,
-			int batchSize,
-			LockOptions lockOptions,
-			SessionFactoryImplementor factory,
-			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
-		this(
-				persister,
-				persister.getIdentifierColumnNames(),
-				persister.getIdentifierType(),
-				batchSize,
-				lockOptions,
-				factory,
-				loadQueryInfluencers
-			);
-	}
+	public static class Builder {
+		private final OuterJoinLoadable persister;
+		private int batchSize = 1;
+		private LoadQueryInfluencers influencers = LoadQueryInfluencers.NONE;
+		private LockMode lockMode = LockMode.NONE;
+		private LockOptions lockOptions;
 
-	public EntityLoader(
-			OuterJoinLoadable persister,
-			String[] uniqueKey,
-			Type uniqueKeyType,
-			int batchSize,
-			LockMode lockMode,
-			SessionFactoryImplementor factory,
-			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
-		super( persister, uniqueKeyType, factory, loadQueryInfluencers );
-
-//		EntityJoinWalker walker = new EntityJoinWalker(
-//				persister,
-//				uniqueKey,
-//				batchSize,
-//				lockMode,
-//				factory,
-//				loadQueryInfluencers
-//		);
-//		initFromWalker( walker );
-//		this.compositeKeyManyToOneTargetIndices = walker.getCompositeKeyManyToOneTargetIndices();
-//		postInstantiate();
-//
-//		batchLoader = batchSize > 1;
-//
-		if ( log.isDebugEnabled() ) {
-			log.debugf( "Static select for entity %s [%s]: %s", getEntityName(), lockMode, getSqlStatement() );
+		public Builder(OuterJoinLoadable persister) {
+			this.persister = persister;
+		}
+
+		public Builder withBatchSize(int batchSize) {
+			this.batchSize = batchSize;
+			return this;
+		}
+
+		public Builder withInfluencers(LoadQueryInfluencers influencers) {
+			this.influencers = influencers;
+			return this;
+		}
+
+		public Builder withLockMode(LockMode lockMode) {
+			this.lockMode = lockMode;
+			return this;
+		}
+
+		public Builder withLockOptions(LockOptions lockOptions) {
+			this.lockOptions = lockOptions;
+			return this;
+		}
+
+		public EntityLoader byPrimaryKey() {
+			return byUniqueKey( persister.getIdentifierColumnNames(), persister.getIdentifierType() );
+		}
+
+		public EntityLoader byUniqueKey(String[] keyColumnNames, Type keyType) {
+			return new EntityLoader(
+					persister.getFactory(),
+					persister,
+					keyColumnNames,
+					keyType,
+					new QueryBuildingParameters() {
+						@Override
+						public LoadQueryInfluencers getQueryInfluencers() {
+							return influencers;
+						}
+
+						@Override
+						public int getBatchSize() {
+							return batchSize;
+						}
+
+						@Override
+						public LockMode getLockMode() {
+							return lockMode;
+						}
+
+						@Override
+						public LockOptions getLockOptions() {
+							return lockOptions;
+						}
+					}
+			);
 		}
 	}
 
-	public EntityLoader(
+	private EntityLoader(
+			SessionFactoryImplementor factory,
 			OuterJoinLoadable persister,
-			String[] uniqueKey,
+			String[] uniqueKeyColumnNames,
 			Type uniqueKeyType,
-			int batchSize,
-			LockOptions lockOptions,
-			SessionFactoryImplementor factory,
-			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
-		super( persister, uniqueKeyType, factory, loadQueryInfluencers );
-//
-//		EntityJoinWalker walker = new EntityJoinWalker(
-//				persister,
-//				uniqueKey,
-//				batchSize,
-//				lockOptions,
-//				factory,
-//				loadQueryInfluencers
-//		);
-//		initFromWalker( walker );
-//		this.compositeKeyManyToOneTargetIndices = walker.getCompositeKeyManyToOneTargetIndices();
-//		postInstantiate();
-//
-//		batchLoader = batchSize > 1;
-//
+			QueryBuildingParameters buildingParameters) throws MappingException {
+		super( persister, factory, uniqueKeyColumnNames, uniqueKeyType, buildingParameters );
 		if ( log.isDebugEnabled() ) {
-			log.debugf(
-					"Static select for entity %s [%s:%s]: %s",
-					getEntityName(),
-					lockOptions.getLockMode(),
-					lockOptions.getTimeOut(),
-					getSqlStatement()
-			);
+			if ( buildingParameters.getLockOptions() != null ) {
+				log.debugf(
+						"Static select for entity %s [%s:%s]: %s",
+						getEntityName(),
+						buildingParameters.getLockOptions().getLockMode(),
+						buildingParameters.getLockOptions().getTimeOut(),
+						getStaticLoadQuery().getSqlStatement()
+				);
+			}
+			else if ( buildingParameters.getLockMode() != null ) {
+				log.debugf(
+						"Static select for entity %s [%s]: %s",
+						getEntityName(),
+						buildingParameters.getLockMode(),
+						getStaticLoadQuery().getSqlStatement()
+				);
+			}
 		}
 	}
-
-//	public Object loadByUniqueKey(SessionImplementor session,Object key) {
-//		return load( session, key, null, null, LockOptions.NONE );
-//	}
-//
-//	@Override
-//    protected boolean isSingleRowLoader() {
-//		return !batchLoader;
-//	}
-//
-//	@Override
-//    public int[][] getCompositeKeyManyToOneTargetIndices() {
-//		return compositeKeyManyToOneTargetIndices;
-//	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/LegacyBatchingEntityLoaderBuilder.java b/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/LegacyBatchingEntityLoaderBuilder.java
index d3239f042b..474364e5f0 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/LegacyBatchingEntityLoaderBuilder.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/LegacyBatchingEntityLoaderBuilder.java
@@ -1,129 +1,134 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.entity.plan;
 
 import java.io.Serializable;
 import java.util.List;
 
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.util.collections.ArrayHelper;
-import org.hibernate.loader.Loader;
-import org.hibernate.loader.entity.BatchingEntityLoader;
-import org.hibernate.loader.entity.BatchingEntityLoaderBuilder;
 import org.hibernate.loader.entity.UniqueEntityLoader;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 
 /**
+ * LoadPlan-based implementation of the the legacy batch loading strategy
+ *
  * @author Steve Ebersole
  */
-public class LegacyBatchingEntityLoaderBuilder extends BatchingEntityLoaderBuilder {
+public class LegacyBatchingEntityLoaderBuilder extends AbstractBatchingEntityLoaderBuilder {
 	public static final LegacyBatchingEntityLoaderBuilder INSTANCE = new LegacyBatchingEntityLoaderBuilder();
 
 	@Override
 	protected UniqueEntityLoader buildBatchingLoader(
 			OuterJoinLoadable persister,
 			int batchSize,
 			LockMode lockMode,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers influencers) {
 		return new LegacyBatchingEntityLoader( persister, batchSize, lockMode, factory, influencers );
 	}
 
 	@Override
 	protected UniqueEntityLoader buildBatchingLoader(
 			OuterJoinLoadable persister,
 			int batchSize,
 			LockOptions lockOptions,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers influencers) {
 		return new LegacyBatchingEntityLoader( persister, batchSize, lockOptions, factory, influencers );
 	}
 
 	public static class LegacyBatchingEntityLoader extends BatchingEntityLoader implements UniqueEntityLoader {
 		private final int[] batchSizes;
 		private final EntityLoader[] loaders;
 
 		public LegacyBatchingEntityLoader(
 				OuterJoinLoadable persister,
 				int maxBatchSize,
 				LockMode lockMode,
 				SessionFactoryImplementor factory,
 				LoadQueryInfluencers loadQueryInfluencers) {
 			super( persister );
 			this.batchSizes = ArrayHelper.getBatchSizes( maxBatchSize );
 			this.loaders = new EntityLoader[ batchSizes.length ];
+			final EntityLoader.Builder entityLoaderBuilder = EntityLoader.forEntity( persister )
+					.withInfluencers( loadQueryInfluencers )
+					.withLockMode( lockMode );
 			for ( int i = 0; i < batchSizes.length; i++ ) {
-				this.loaders[i] = new EntityLoader( persister, batchSizes[i], lockMode, factory, loadQueryInfluencers);
+				this.loaders[i] = entityLoaderBuilder.withBatchSize( batchSizes[i] ).byPrimaryKey();
 			}
 		}
 
 		public LegacyBatchingEntityLoader(
 				OuterJoinLoadable persister,
 				int maxBatchSize,
 				LockOptions lockOptions,
 				SessionFactoryImplementor factory,
 				LoadQueryInfluencers loadQueryInfluencers) {
 			super( persister );
 			this.batchSizes = ArrayHelper.getBatchSizes( maxBatchSize );
 			this.loaders = new EntityLoader[ batchSizes.length ];
+			final EntityLoader.Builder entityLoaderBuilder = EntityLoader.forEntity( persister )
+					.withInfluencers( loadQueryInfluencers )
+					.withLockOptions( lockOptions );
 			for ( int i = 0; i < batchSizes.length; i++ ) {
-				this.loaders[i] = new EntityLoader( persister, batchSizes[i], lockOptions, factory, loadQueryInfluencers);
+				this.loaders[i] = entityLoaderBuilder.withBatchSize( batchSizes[i] ).byPrimaryKey();
 			}
 		}
 
 		@Override
 		public Object load(Serializable id, Object optionalObject, SessionImplementor session, LockOptions lockOptions) {
 			final Serializable[] batch = session.getPersistenceContext()
 					.getBatchFetchQueue()
 					.getEntityBatch( persister(), id, batchSizes[0], persister().getEntityMode() );
 
 			for ( int i = 0; i < batchSizes.length-1; i++) {
 				final int smallBatchSize = batchSizes[i];
 				if ( batch[smallBatchSize-1] != null ) {
 					Serializable[] smallBatch = new Serializable[smallBatchSize];
 					System.arraycopy(batch, 0, smallBatch, 0, smallBatchSize);
 					// for now...
 					final List results = loaders[i].loadEntityBatch(
 							session,
 							smallBatch,
 							persister().getIdentifierType(),
 							optionalObject,
 							persister().getEntityName(),
 							id,
 							persister(),
 							lockOptions
 					);
 					//EARLY EXIT
 					return getObjectFromList( results, id, session );
 				}
 			}
 			return ( loaders[batchSizes.length-1] ).load( id, optionalObject, session );
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/internal/AbstractEntityLoadQueryImpl.java b/hibernate-core/src/main/java/org/hibernate/loader/internal/AbstractEntityLoadQueryImpl.java
deleted file mode 100755
index e9745d860f..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/loader/internal/AbstractEntityLoadQueryImpl.java
+++ /dev/null
@@ -1,128 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.loader.internal;
-import java.util.List;
-
-import org.hibernate.LockOptions;
-import org.hibernate.MappingException;
-import org.hibernate.engine.spi.SessionFactoryImplementor;
-import org.hibernate.loader.plan.spi.EntityReturn;
-import org.hibernate.loader.spi.JoinableAssociation;
-import org.hibernate.loader.spi.LoadQueryAliasResolutionContext;
-import org.hibernate.persister.entity.OuterJoinLoadable;
-import org.hibernate.sql.JoinFragment;
-import org.hibernate.sql.Select;
-
-/**
- * Represents an entity load query for criteria
- * queries and entity loaders, used for generating SQL.
- *
- * This code is based on the SQL generation code originally in
- * org.hibernate.loader.AbstractEntityJoinWalker.
- *
- * @author Gavin King
- * @author Gail Badner
- */
-public abstract class AbstractEntityLoadQueryImpl extends AbstractLoadQueryImpl {
-
-	private final EntityReturn entityReturn;
-
-	public AbstractEntityLoadQueryImpl(EntityReturn entityReturn, List<JoinableAssociation> associations) {
-		super( associations );
-		this.entityReturn = entityReturn;
-	}
-
-	protected final String generateSql(
-			final String whereString,
-			final String orderByString,
-			final LockOptions lockOptions,
-			final SessionFactoryImplementor factory,
-			final LoadQueryAliasResolutionContext aliasResolutionContext) throws MappingException {
-		return generateSql( null, whereString, orderByString, "", lockOptions, factory, aliasResolutionContext );
-	}
-
-	private String generateSql(
-			final String projection,
-			final String condition,
-			final String orderBy,
-			final String groupBy,
-			final LockOptions lockOptions,
-			final SessionFactoryImplementor factory,
-			final LoadQueryAliasResolutionContext aliasResolutionContext) throws MappingException {
-
-		JoinFragment ojf = mergeOuterJoins( factory, aliasResolutionContext );
-
-		// If no projection, then the last suffix should be for the entity return.
-		// TODO: simplify how suffixes are generated/processed.
-
-		final String entityReturnAlias = resolveEntityReturnAlias( aliasResolutionContext );
-		Select select = new Select( factory.getDialect() )
-				.setLockOptions( lockOptions )
-				.setSelectClause(
-						projection == null ?
-								getPersister().selectFragment(
-										entityReturnAlias,
-										aliasResolutionContext.resolveEntityColumnAliases( entityReturn ).getSuffix()
-								) + associationSelectString( aliasResolutionContext ) :
-								projection
-				)
-				.setFromClause(
-						factory.getDialect().appendLockHint(
-								lockOptions,
-								getPersister().fromTableFragment( entityReturnAlias )
-						) + getPersister().fromJoinFragment( entityReturnAlias, true, true )
-				)
-				.setWhereClause( condition )
-				.setOuterJoins(
-						ojf.toFromFragmentString(),
-						ojf.toWhereFragmentString() + getWhereFragment( aliasResolutionContext )
-				)
-				.setOrderByClause( orderBy( orderBy, aliasResolutionContext ) )
-				.setGroupByClause( groupBy );
-
-		if ( factory.getSettings().isCommentsEnabled() ) {
-			select.setComment( getComment() );
-		}
-		return select.toStatementString();
-	}
-
-	protected String getWhereFragment(LoadQueryAliasResolutionContext aliasResolutionContext) throws MappingException {
-		// here we do not bother with the discriminator.
-		return getPersister().whereJoinFragment( resolveEntityReturnAlias( aliasResolutionContext ), true, true );
-	}
-
-	protected abstract String getComment();
-
-	protected final OuterJoinLoadable getPersister() {
-		return (OuterJoinLoadable) entityReturn.getEntityPersister();
-	}
-
-	protected final String resolveEntityReturnAlias(LoadQueryAliasResolutionContext aliasResolutionContext) {
-		return aliasResolutionContext.resolveEntityTableAlias( entityReturn );
-	}
-
-	public String toString() {
-		return getClass().getName() + '(' + getPersister().getEntityName() + ')';
-	}
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/internal/AbstractLoadQueryImpl.java b/hibernate-core/src/main/java/org/hibernate/loader/internal/AbstractLoadQueryImpl.java
index 15ba337255..9e75c62e9e 100755
--- a/hibernate-core/src/main/java/org/hibernate/loader/internal/AbstractLoadQueryImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/internal/AbstractLoadQueryImpl.java
@@ -1,313 +1,323 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.internal;
 import java.util.List;
 
 import org.hibernate.MappingException;
 import org.hibernate.engine.internal.JoinHelper;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.loader.CollectionAliases;
 import org.hibernate.loader.EntityAliases;
+import org.hibernate.loader.plan.exec.spi.AliasResolutionContext;
+import org.hibernate.loader.plan.spi.Fetch;
 import org.hibernate.loader.spi.JoinableAssociation;
-import org.hibernate.loader.spi.LoadQueryAliasResolutionContext;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.Joinable;
+import org.hibernate.persister.walking.internal.FetchStrategyHelper;
 import org.hibernate.sql.ConditionFragment;
 import org.hibernate.sql.DisjunctionFragment;
 import org.hibernate.sql.InFragment;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.JoinType;
 
 /**
  * Represents a generic load query used for generating SQL.
  *
  * This code is based on the SQL generation code originally in
  * org.hibernate.loader.JoinWalker.
  *
  * @author Gavin King
  * @author Jon Lipsky
  * @author Gail Badner
  */
 public abstract class AbstractLoadQueryImpl {
 
 	private final List<JoinableAssociation> associations;
 
 	protected AbstractLoadQueryImpl(List<JoinableAssociation> associations) {
 		this.associations = associations;
 	}
 
-	protected String orderBy(final String orderBy, LoadQueryAliasResolutionContext aliasResolutionContext) {
+	protected String orderBy(final String orderBy, AliasResolutionContext aliasResolutionContext) {
 		return mergeOrderings( orderBy( associations, aliasResolutionContext ), orderBy );
 	}
 
 	protected static String mergeOrderings(String ordering1, String ordering2) {
 		if ( ordering1.length() == 0 ) {
 			return ordering2;
 		}
 		else if ( ordering2.length() == 0 ) {
 			return ordering1;
 		}
 		else {
 			return ordering1 + ", " + ordering2;
 		}
 	}
 
 	/**
 	 * Generate a sequence of <tt>LEFT OUTER JOIN</tt> clauses for the given associations.
 	 */
-	protected final JoinFragment mergeOuterJoins(SessionFactoryImplementor factory, LoadQueryAliasResolutionContext aliasResolutionContext)
+	protected final JoinFragment mergeOuterJoins(SessionFactoryImplementor factory, AliasResolutionContext aliasResolutionContext)
 	throws MappingException {
 		JoinFragment joinFragment = factory.getDialect().createOuterJoinFragment();
 		JoinableAssociation previous = null;
 		for ( JoinableAssociation association : associations ) {
 			final String rhsAlias = aliasResolutionContext.resolveAssociationRhsTableAlias( association );
 			final String[] aliasedLhsColumnNames = aliasResolutionContext.resolveAssociationAliasedLhsColumnNames(
 					association
 			);
 			final String[] rhsColumnNames = JoinHelper.getRHSColumnNames( association.getAssociationType(), factory );
 			final String on = resolveOnCondition( factory, association, aliasResolutionContext );
 			if ( previous != null && previous.isManyToManyWith( association ) ) {
 				addManyToManyJoin(
 						joinFragment,
 						association,
 						( QueryableCollection ) previous.getJoinable(),
 						rhsAlias,
 						aliasedLhsColumnNames,
 						rhsColumnNames,
 						on
 				);
 			}
 			else {
 				addJoins(
 						joinFragment,
 						association,
 						rhsAlias,
 						aliasedLhsColumnNames,
 						rhsColumnNames,
 						on
 				);
 			}
 			previous = association;
 		}
 		return joinFragment;
 	}
 
 	/**
 	 * Get the order by string required for collection fetching
 	 */
 	// TODO: why is this static?
 	protected static String orderBy(
 			List<JoinableAssociation> associations,
-			LoadQueryAliasResolutionContext aliasResolutionContext)
+			AliasResolutionContext aliasResolutionContext)
 	throws MappingException {
 		StringBuilder buf = new StringBuilder();
 		JoinableAssociation previous = null;
 		for ( JoinableAssociation association : associations ) {
 			final String rhsAlias = aliasResolutionContext.resolveAssociationRhsTableAlias( association );
 			if ( association.getJoinType() == JoinType.LEFT_OUTER_JOIN ) { // why does this matter?
 				if ( association.getJoinable().isCollection() ) {
 					final QueryableCollection queryableCollection = (QueryableCollection) association.getJoinable();
 					if ( queryableCollection.hasOrdering() ) {
 						final String orderByString = queryableCollection.getSQLOrderByString( rhsAlias );
 						buf.append( orderByString ).append(", ");
 					}
 				}
 				else {
 					// it might still need to apply a collection ordering based on a
 					// many-to-many defined order-by...
 					if ( previous != null && previous.getJoinable().isCollection() ) {
 						final QueryableCollection queryableCollection = (QueryableCollection) previous.getJoinable();
 						if ( queryableCollection.isManyToMany() && previous.isManyToManyWith( association ) ) {
 							if ( queryableCollection.hasManyToManyOrdering() ) {
 								final String orderByString = queryableCollection.getManyToManyOrderByString( rhsAlias );
 								buf.append( orderByString ).append(", ");
 							}
 						}
 					}
 				}
 			}
 			previous = association;
 		}
 		if ( buf.length() > 0 ) {
 			buf.setLength( buf.length() - 2 );
 		}
 		return buf.toString();
 	}
 
 	/**
 	 * Render the where condition for a (batch) load by identifier / collection key
 	 */
 	protected StringBuilder whereString(String alias, String[] columnNames, int batchSize) {
 		if ( columnNames.length==1 ) {
 			// if not a composite key, use "foo in (?, ?, ?)" for batching
 			// if no batch, and not a composite key, use "foo = ?"
 			InFragment in = new InFragment().setColumn( alias, columnNames[0] );
 			for ( int i = 0; i < batchSize; i++ ) {
 				in.addValue( "?" );
 			}
 			return new StringBuilder( in.toFragmentString() );
 		}
 		else {
 			//a composite key
 			ConditionFragment byId = new ConditionFragment()
 					.setTableAlias(alias)
 					.setCondition( columnNames, "?" );
 	
 			StringBuilder whereString = new StringBuilder();
 			if ( batchSize==1 ) {
 				// if no batch, use "foo = ? and bar = ?"
 				whereString.append( byId.toFragmentString() );
 			}
 			else {
 				// if a composite key, use "( (foo = ? and bar = ?) or (foo = ? and bar = ?) )" for batching
 				whereString.append('('); //TODO: unnecessary for databases with ANSI-style joins
 				DisjunctionFragment df = new DisjunctionFragment();
 				for ( int i=0; i<batchSize; i++ ) {
 					df.addCondition(byId);
 				}
 				whereString.append( df.toFragmentString() );
 				whereString.append(')'); //TODO: unnecessary for databases with ANSI-style joins
 			}
 			return whereString;
 		}
 	}
 
 	/**
 	 * Generate a select list of columns containing all properties of the entity classes
 	 */
-	protected final String associationSelectString(LoadQueryAliasResolutionContext aliasResolutionContext)
+	protected final String associationSelectString(AliasResolutionContext aliasResolutionContext)
 	throws MappingException {
 
 		if ( associations.size() == 0 ) {
 			return "";
 		}
 		else {
 			StringBuilder buf = new StringBuilder( associations.size() * 100 );
 			for ( int i=0; i<associations.size(); i++ ) {
 				JoinableAssociation association = associations.get( i );
 				JoinableAssociation next = ( i == associations.size() - 1 )
 				        ? null
 				        : associations.get( i + 1 );
+				if ( !shouldAddToSql( association.getCurrentFetch() ) ) {
+					continue;
+				}
+
 				final Joinable joinable = association.getJoinable();
 				final EntityAliases currentEntityAliases =
 						association.getCurrentEntityReference() == null ?
 								null :
-								aliasResolutionContext.resolveEntityColumnAliases( association.getCurrentEntityReference() );
+								aliasResolutionContext.resolveAliases( association.getCurrentEntityReference() ).getColumnAliases();
 				final CollectionAliases currentCollectionAliases =
 						association.getCurrentCollectionReference() == null ?
 								null :
-								aliasResolutionContext.resolveCollectionColumnAliases( association.getCurrentCollectionReference() );
+								aliasResolutionContext.resolveAliases( association.getCurrentCollectionReference() ).getCollectionColumnAliases();
 				final String selectFragment = joinable.selectFragment(
 						next == null ? null : next.getJoinable(),
 						next == null ? null : aliasResolutionContext.resolveAssociationRhsTableAlias( next ),
 						aliasResolutionContext.resolveAssociationRhsTableAlias( association ),
 						currentEntityAliases == null ? null : currentEntityAliases.getSuffix(),
 						currentCollectionAliases == null ? null : currentCollectionAliases.getSuffix(),
 						association.getJoinType()==JoinType.LEFT_OUTER_JOIN
 				);
 				if (selectFragment.trim().length() > 0) {
 					// TODO: shouldn't the append of selectFragment be outside this if statement???
 					buf.append(", ").append( selectFragment );
 				}
 			}
 			return buf.toString();
 		}
 	}
 
+	private boolean shouldAddToSql(Fetch fetch) {
+		return FetchStrategyHelper.isJoinFetched( fetch.getFetchStrategy() );
+	}
+
 	private void addJoins(
 			JoinFragment joinFragment,
 			JoinableAssociation association,
 			String rhsAlias,
 			String[] aliasedLhsColumnNames,
 			String[] rhsColumnNames,
 			String on) throws MappingException {
 		joinFragment.addJoin(
 				association.getJoinable().getTableName(),
 				rhsAlias,
 				aliasedLhsColumnNames,
 				rhsColumnNames,
 				association.getJoinType(),
 				on
 		);
 		joinFragment.addJoins(
 				association.getJoinable().fromJoinFragment( rhsAlias, false, true ),
 				association.getJoinable().whereJoinFragment( rhsAlias, false, true )
 		);
 	}
 
 	private String resolveOnCondition(
 			SessionFactoryImplementor factory,
 			JoinableAssociation joinableAssociation,
-			LoadQueryAliasResolutionContext aliasResolutionContext) {
+			AliasResolutionContext aliasResolutionContext) {
 		final String withClause = StringHelper.isEmpty( joinableAssociation.getWithClause() ) ?
 				"" :
 				" and ( " + joinableAssociation.getWithClause() + " )";
 		return joinableAssociation.getAssociationType().getOnCondition(
 				aliasResolutionContext.resolveAssociationRhsTableAlias( joinableAssociation ),
 				factory,
 				joinableAssociation.getEnabledFilters()
 		) + withClause;
 	}
 
 	/*
 	public void validateJoin(String path) throws MappingException {
 		if ( rhsColumns==null || lhsColumns==null
 				|| lhsColumns.length!=rhsColumns.length || lhsColumns.length==0 ) {
 			throw new MappingException("invalid join columns for association: " + path);
 		}
 	}
 	*/
 
 	private void addManyToManyJoin(
 			JoinFragment outerjoin,
 			JoinableAssociation association,
 			QueryableCollection collection,
 			String rhsAlias,
 			String[] aliasedLhsColumnNames,
 			String[] rhsColumnNames,
 			String on) throws MappingException {
 		final String manyToManyFilter = collection.getManyToManyFilterFragment(
 				rhsAlias,
 				association.getEnabledFilters()
 		);
 		String condition = "".equals( manyToManyFilter )
 				? on
 				: "".equals( on )
 				? manyToManyFilter
 				: on + " and " + manyToManyFilter;
 		outerjoin.addJoin(
 				association.getJoinable().getTableName(),
 				rhsAlias,
 				aliasedLhsColumnNames,
 				rhsColumnNames,
 				association.getJoinType(),
 				condition
 		);
 		outerjoin.addJoins(
 				association.getJoinable().fromJoinFragment( rhsAlias, false, true ),
 				association.getJoinable().whereJoinFragment( rhsAlias, false, true )
 		);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/internal/EntityJoinableAssociationImpl.java b/hibernate-core/src/main/java/org/hibernate/loader/internal/EntityJoinableAssociationImpl.java
index 1f6b5aaa32..02b1c9cba4 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/internal/EntityJoinableAssociationImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/internal/EntityJoinableAssociationImpl.java
@@ -1,89 +1,89 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.internal;
 
 import java.util.Map;
 
 import org.hibernate.Filter;
 import org.hibernate.MappingException;
 import org.hibernate.loader.plan.spi.CollectionReference;
 import org.hibernate.loader.plan.spi.EntityFetch;
 import org.hibernate.loader.spi.JoinableAssociation;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.EntityType;
 
 /**
  * This class represents a joinable entity association.
  *
  * @author Gavin King
  */
 public class EntityJoinableAssociationImpl extends AbstractJoinableAssociationImpl {
 
 	private final AssociationType joinableType;
 	private final Joinable joinable;
 
 	public EntityJoinableAssociationImpl(
 			EntityFetch entityFetch,
 			CollectionReference currentCollectionReference,
 			String withClause,
 			boolean hasRestriction,
 			Map<String, Filter> enabledFilters) throws MappingException {
 		super(
 				entityFetch,
 				entityFetch,
 				currentCollectionReference,
 				withClause,
 				hasRestriction,
 				enabledFilters
 		);
-		this.joinableType = entityFetch.getEntityType();
+		this.joinableType = entityFetch.getFetchedType();
 		this.joinable = (Joinable) entityFetch.getEntityPersister();
 	}
 
 	@Override
 	public AssociationType getAssociationType() {
 		return joinableType;
 	}
 
 	@Override
 	public Joinable getJoinable() {
 		return joinable;
 	}
 
 	@Override
 	public boolean isCollection() {
 		return false;
 	}
 
 	@Override
 	public boolean isManyToManyWith(JoinableAssociation other) {
 		return false;
 	}
 
 	protected boolean isOneToOne() {
 		EntityType entityType = (EntityType) joinableType;
 		return entityType.isOneToOne() /*&& entityType.isReferenceToPrimaryKey()*/;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/internal/EntityLoadQueryBuilderImpl.java b/hibernate-core/src/main/java/org/hibernate/loader/internal/EntityLoadQueryBuilderImpl.java
deleted file mode 100644
index aef90267f1..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/loader/internal/EntityLoadQueryBuilderImpl.java
+++ /dev/null
@@ -1,227 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.loader.internal;
-
-import java.util.ArrayDeque;
-import java.util.ArrayList;
-import java.util.Deque;
-import java.util.List;
-
-import org.hibernate.engine.spi.LoadQueryInfluencers;
-import org.hibernate.engine.spi.SessionFactoryImplementor;
-import org.hibernate.loader.plan.spi.CollectionFetch;
-import org.hibernate.loader.plan.spi.CollectionReference;
-import org.hibernate.loader.plan.spi.CompositeFetch;
-import org.hibernate.loader.plan.spi.EntityFetch;
-import org.hibernate.loader.plan.spi.EntityReference;
-import org.hibernate.loader.plan.spi.EntityReturn;
-import org.hibernate.loader.plan.spi.LoadPlan;
-import org.hibernate.loader.plan.spi.visit.LoadPlanVisitationStrategyAdapter;
-import org.hibernate.loader.plan.spi.visit.LoadPlanVisitor;
-import org.hibernate.loader.plan.spi.Return;
-import org.hibernate.loader.spi.JoinableAssociation;
-import org.hibernate.loader.spi.LoadQueryAliasResolutionContext;
-import org.hibernate.loader.spi.LoadQueryBuilder;
-import org.hibernate.persister.entity.OuterJoinLoadable;
-import org.hibernate.persister.walking.spi.WalkingException;
-
-/**
- * @author Gail Badner
- */
-public class EntityLoadQueryBuilderImpl implements LoadQueryBuilder {
-	private final LoadQueryInfluencers loadQueryInfluencers;
-	private final LoadPlan loadPlan;
-	private final List<JoinableAssociation> associations;
-
-	public EntityLoadQueryBuilderImpl(
-			LoadQueryInfluencers loadQueryInfluencers,
-			LoadPlan loadPlan) {
-		this.loadQueryInfluencers = loadQueryInfluencers;
-		this.loadPlan = loadPlan;
-
-	    // TODO: the whole point of the following is to build associations.
-		// this could be done while building loadPlan (and be a part of the LoadPlan).
-		// Should it be?
-		LocalVisitationStrategy strategy = new LocalVisitationStrategy();
-		LoadPlanVisitor.visit( loadPlan, strategy );
-		this.associations = strategy.associations;
-	}
-
-	@Override
-	public String generateSql(
-			int batchSize,
-			SessionFactoryImplementor sessionFactory,
-			LoadQueryAliasResolutionContext aliasResolutionContext) {
-		return generateSql(
-				batchSize,
-				getOuterJoinLoadable().getKeyColumnNames(),
-				sessionFactory,
-				aliasResolutionContext
-		);
-	}
-
-	public String generateSql(
-			int batchSize,
-			String[] uniqueKey,
-			SessionFactoryImplementor sessionFactory,
-			LoadQueryAliasResolutionContext aliasResolutionContext) {
-		final EntityLoadQueryImpl loadQuery = new EntityLoadQueryImpl(
-				getRootEntityReturn(),
-				associations
-		);
-		return loadQuery.generateSql(
-				uniqueKey,
-				batchSize,
-				getRootEntityReturn().getLockMode(),
-				sessionFactory,
-				aliasResolutionContext );
-	}
-
-	private EntityReturn getRootEntityReturn() {
-		return (EntityReturn) loadPlan.getReturns().get( 0 );
-	}
-
-	private OuterJoinLoadable getOuterJoinLoadable() {
-		return (OuterJoinLoadable) getRootEntityReturn().getEntityPersister();
-	}
-
-	private class LocalVisitationStrategy extends LoadPlanVisitationStrategyAdapter {
-		private final List<JoinableAssociation> associations = new ArrayList<JoinableAssociation>();
-		private Deque<EntityReference> entityReferenceStack = new ArrayDeque<EntityReference>();
-		private Deque<CollectionReference> collectionReferenceStack = new ArrayDeque<CollectionReference>();
-
-		private EntityReturn entityRootReturn;
-
-		@Override
-		public void handleEntityReturn(EntityReturn rootEntityReturn) {
-			this.entityRootReturn = rootEntityReturn;
-		}
-
-		@Override
-		public void startingRootReturn(Return rootReturn) {
-			if ( !EntityReturn.class.isInstance( rootReturn ) ) {
-				throw new WalkingException(
-						String.format(
-								"Unexpected type of return; expected [%s]; instead it was [%s]",
-								EntityReturn.class.getName(),
-								rootReturn.getClass().getName()
-						)
-				);
-			}
-			this.entityRootReturn = (EntityReturn) rootReturn;
-			pushToStack( entityReferenceStack, entityRootReturn );
-		}
-
-		@Override
-		public void finishingRootReturn(Return rootReturn) {
-			if ( !EntityReturn.class.isInstance( rootReturn ) ) {
-				throw new WalkingException(
-						String.format(
-								"Unexpected type of return; expected [%s]; instead it was [%s]",
-								EntityReturn.class.getName(),
-								rootReturn.getClass().getName()
-						)
-				);
-			}
-			popFromStack( entityReferenceStack, entityRootReturn );
-		}
-
-		@Override
-		public void startingEntityFetch(EntityFetch entityFetch) {
-			EntityJoinableAssociationImpl assoc = new EntityJoinableAssociationImpl(
-					entityFetch,
-					getCurrentCollectionReference(),
-					"",    // getWithClause( entityFetch.getPropertyPath() )
-					false, // hasRestriction( entityFetch.getPropertyPath() )
-					loadQueryInfluencers.getEnabledFilters()
-			);
-			associations.add( assoc );
-			pushToStack( entityReferenceStack, entityFetch );
-		}
-
-		@Override
-		public void finishingEntityFetch(EntityFetch entityFetch) {
-			popFromStack( entityReferenceStack, entityFetch );
-		}
-
-		@Override
-		public void startingCollectionFetch(CollectionFetch collectionFetch) {
-			CollectionJoinableAssociationImpl assoc = new CollectionJoinableAssociationImpl(
-					collectionFetch,
-					getCurrentEntityReference(),
-					"",    // getWithClause( entityFetch.getPropertyPath() )
-					false, // hasRestriction( entityFetch.getPropertyPath() )
-					loadQueryInfluencers.getEnabledFilters()
-			);
-			associations.add( assoc );
-			pushToStack( collectionReferenceStack, collectionFetch );
-		}
-
-		@Override
-		public void finishingCollectionFetch(CollectionFetch collectionFetch) {
-			popFromStack( collectionReferenceStack, collectionFetch );
-		}
-
-		@Override
-		public void startingCompositeFetch(CompositeFetch fetch) {
-			//To change body of implemented methods use File | Settings | File Templates.
-		}
-
-		@Override
-		public void finishingCompositeFetch(CompositeFetch fetch) {
-			//To change body of implemented methods use File | Settings | File Templates.
-		}
-
-		@Override
-		public void finish(LoadPlan loadPlan) {
-			entityReferenceStack.clear();
-			collectionReferenceStack.clear();
-		}
-
-		private EntityReference getCurrentEntityReference() {
-			return entityReferenceStack.peekFirst() == null ? null : entityReferenceStack.peekFirst();
-		}
-
-		private CollectionReference getCurrentCollectionReference() {
-			return collectionReferenceStack.peekFirst() == null ? null : collectionReferenceStack.peekFirst();
-		}
-
-		private <T> void pushToStack(Deque<T> stack, T value) {
-			stack.push( value );
-		}
-
-		private <T> void popFromStack(Deque<T> stack, T expectedValue) {
-			T poppedValue = stack.pop();
-			if ( poppedValue != expectedValue ) {
-				throw new WalkingException(
-						String.format(
-								"Unexpected value from stack. Expected=[%s]; instead it was [%s].",
-								expectedValue,
-								poppedValue
-						)
-				);
-			}
-		}
-	}
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/internal/EntityLoadQueryImpl.java b/hibernate-core/src/main/java/org/hibernate/loader/internal/EntityLoadQueryImpl.java
deleted file mode 100755
index eb1612a68d..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/loader/internal/EntityLoadQueryImpl.java
+++ /dev/null
@@ -1,68 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.loader.internal;
-import java.util.Collections;
-import java.util.List;
-
-import org.hibernate.LockMode;
-import org.hibernate.LockOptions;
-import org.hibernate.MappingException;
-import org.hibernate.engine.spi.SessionFactoryImplementor;
-import org.hibernate.loader.plan.spi.EntityReturn;
-import org.hibernate.loader.spi.JoinableAssociation;
-import org.hibernate.loader.spi.LoadQueryAliasResolutionContext;
-
-/**
- * Represents an load query for fetching an entity, used for generating SQL.
- *
- * This code is based on the SQL generation code originally in
- * org.hibernate.loader.EntityJoinWalker.
- *
- * @author Gavin King
- * @author Gail Badner
- */
-public class EntityLoadQueryImpl extends AbstractEntityLoadQueryImpl {
-
-	public EntityLoadQueryImpl(
-			EntityReturn entityReturn,
-			List<JoinableAssociation> associations) throws MappingException {
-		super( entityReturn, associations );
-	}
-
-	public String generateSql(
-			String[] uniqueKey,
-			int batchSize,
-			LockMode lockMode,
-			SessionFactoryImplementor factory,
-			LoadQueryAliasResolutionContext aliasResolutionContext) {
-		StringBuilder whereCondition = whereString( resolveEntityReturnAlias( aliasResolutionContext ), uniqueKey, batchSize )
-				//include the discriminator and class-level where, but not filters
-				.append( getPersister().filterFragment( resolveEntityReturnAlias( aliasResolutionContext ), Collections.EMPTY_MAP ) );
-		return generateSql( whereCondition.toString(), "",  new LockOptions().setLockMode( lockMode ), factory, aliasResolutionContext );
-	}
-
-	protected String getComment() {
-		return "load " + getPersister().getEntityName();
-	}
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/internal/ResultSetProcessorImpl.java b/hibernate-core/src/main/java/org/hibernate/loader/internal/ResultSetProcessorImpl.java
deleted file mode 100644
index 64dedf44fc..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/loader/internal/ResultSetProcessorImpl.java
+++ /dev/null
@@ -1,223 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.loader.internal;
-
-import java.io.Serializable;
-import java.sql.ResultSet;
-import java.sql.SQLException;
-import java.util.ArrayList;
-import java.util.List;
-
-import org.jboss.logging.Logger;
-
-import org.hibernate.cfg.NotYetImplementedException;
-import org.hibernate.dialect.pagination.LimitHelper;
-import org.hibernate.engine.FetchStyle;
-import org.hibernate.engine.spi.QueryParameters;
-import org.hibernate.engine.spi.RowSelection;
-import org.hibernate.engine.spi.SessionImplementor;
-import org.hibernate.loader.plan.spi.CollectionFetch;
-import org.hibernate.loader.plan.spi.CollectionReturn;
-import org.hibernate.loader.plan.spi.EntityFetch;
-import org.hibernate.loader.plan.spi.LoadPlan;
-import org.hibernate.loader.plan.spi.visit.LoadPlanVisitationStrategyAdapter;
-import org.hibernate.loader.plan.spi.visit.LoadPlanVisitor;
-import org.hibernate.loader.plan.spi.Return;
-import org.hibernate.loader.spi.AfterLoadAction;
-import org.hibernate.loader.spi.LoadPlanAdvisor;
-import org.hibernate.loader.spi.LoadQueryAliasResolutionContext;
-import org.hibernate.loader.spi.NamedParameterContext;
-import org.hibernate.loader.spi.ScrollableResultSetProcessor;
-import org.hibernate.loader.spi.ResultSetProcessor;
-import org.hibernate.persister.collection.CollectionPersister;
-import org.hibernate.pretty.MessageHelper;
-import org.hibernate.transform.ResultTransformer;
-
-/**
- * @author Steve Ebersole
- */
-public class ResultSetProcessorImpl implements ResultSetProcessor {
-	private static final Logger LOG = Logger.getLogger( ResultSetProcessorImpl.class );
-
-	private final LoadPlan baseLoadPlan;
-
-	private final boolean hadSubselectFetches;
-
-	public ResultSetProcessorImpl(LoadPlan loadPlan) {
-		this.baseLoadPlan = loadPlan;
-
-		LocalVisitationStrategy strategy = new LocalVisitationStrategy();
-		LoadPlanVisitor.visit( loadPlan, strategy );
-		this.hadSubselectFetches = strategy.hadSubselectFetches;
-	}
-
-	@Override
-	public ScrollableResultSetProcessor toOnDemandForm() {
-		// todo : implement
-		throw new NotYetImplementedException();
-	}
-
-	@Override
-	public List extractResults(
-			LoadPlanAdvisor loadPlanAdvisor,
-			ResultSet resultSet,
-			final SessionImplementor session,
-			QueryParameters queryParameters,
-			NamedParameterContext namedParameterContext,
-			LoadQueryAliasResolutionContext aliasResolutionContext,
-			boolean returnProxies,
-			boolean readOnly,
-			ResultTransformer forcedResultTransformer,
-			List<AfterLoadAction> afterLoadActionList) throws SQLException {
-
-		final LoadPlan loadPlan = loadPlanAdvisor.advise( this.baseLoadPlan );
-		if ( loadPlan == null ) {
-			throw new IllegalStateException( "LoadPlanAdvisor returned null" );
-		}
-
-		handlePotentiallyEmptyCollectionRootReturns( loadPlan, queryParameters.getCollectionKeys(), resultSet, session );
-
-		final int maxRows;
-		final RowSelection selection = queryParameters.getRowSelection();
-		if ( LimitHelper.hasMaxRows( selection ) ) {
-			maxRows = selection.getMaxRows();
-			LOG.tracef( "Limiting ResultSet processing to just %s rows", maxRows );
-		}
-		else {
-			maxRows = Integer.MAX_VALUE;
-		}
-
-		final ResultSetProcessingContextImpl context = new ResultSetProcessingContextImpl(
-				resultSet,
-				session,
-				loadPlan,
-				readOnly,
-//				true, // use optional entity key?  for now, always say yes
-				false, // use optional entity key?  actually for now always say no since in the simple test cases true causes failures because there is no optional key
-				queryParameters,
-				namedParameterContext,
-				aliasResolutionContext,
-				hadSubselectFetches
-		);
-
-		final List loadResults = new ArrayList();
-
-		final int rootReturnCount = loadPlan.getReturns().size();
-
-		LOG.trace( "Processing result set" );
-		int count;
-		for ( count = 0; count < maxRows && resultSet.next(); count++ ) {
-			LOG.debugf( "Starting ResultSet row #%s", count );
-
-			Object logicalRow;
-			if ( rootReturnCount == 1 ) {
-				loadPlan.getReturns().get( 0 ).hydrate( resultSet, context );
-				loadPlan.getReturns().get( 0 ).resolve( resultSet, context );
-
-				logicalRow = loadPlan.getReturns().get( 0 ).read( resultSet, context );
-				context.readCollectionElements( new Object[] { logicalRow } );
-			}
-			else {
-				for ( Return rootReturn : loadPlan.getReturns() ) {
-					rootReturn.hydrate( resultSet, context );
-				}
-				for ( Return rootReturn : loadPlan.getReturns() ) {
-					rootReturn.resolve( resultSet, context );
-				}
-
-				logicalRow = new Object[ rootReturnCount ];
-				int pos = 0;
-				for ( Return rootReturn : loadPlan.getReturns() ) {
-					( (Object[]) logicalRow )[pos] = rootReturn.read( resultSet, context );
-					pos++;
-				}
-				context.readCollectionElements( (Object[]) logicalRow );
-			}
-
-			// todo : apply transformers here?
-
-			loadResults.add( logicalRow );
-
-			context.finishUpRow();
-		}
-
-		LOG.tracev( "Done processing result set ({0} rows)", count );
-
-		context.finishUp( afterLoadActionList );
-
-		session.getPersistenceContext().initializeNonLazyCollections();
-
-		return loadResults;
-	}
-
-
-	private void handlePotentiallyEmptyCollectionRootReturns(
-			LoadPlan loadPlan,
-			Serializable[] collectionKeys,
-			ResultSet resultSet,
-			SessionImplementor session) {
-		if ( collectionKeys == null ) {
-			// this is not a collection initializer (and empty collections will be detected by looking for
-			// the owner's identifier in the result set)
-			return;
-		}
-
-		// this is a collection initializer, so we must create a collection
-		// for each of the passed-in keys, to account for the possibility
-		// that the collection is empty and has no rows in the result set
-		//
-		// todo : move this inside CollectionReturn ?
-		CollectionPersister persister = ( (CollectionReturn) loadPlan.getReturns().get( 0 ) ).getCollectionPersister();
-		for ( Serializable key : collectionKeys ) {
-			if ( LOG.isDebugEnabled() ) {
-				LOG.debugf(
-						"Preparing collection intializer : %s",
-							MessageHelper.collectionInfoString( persister, key, session.getFactory() )
-				);
-				session.getPersistenceContext()
-						.getLoadContexts()
-						.getCollectionLoadContext( resultSet )
-						.getLoadingCollection( persister, key );
-			}
-		}
-	}
-
-
-	private class LocalVisitationStrategy extends LoadPlanVisitationStrategyAdapter {
-		private boolean hadSubselectFetches = false;
-
-		@Override
-		public void startingEntityFetch(EntityFetch entityFetch) {
-// only collections are currently supported for subselect fetching.
-//			hadSubselectFetches = hadSubselectFetches
-//					| entityFetch.getFetchStrategy().getStyle() == FetchStyle.SUBSELECT;
-		}
-
-		@Override
-		public void startingCollectionFetch(CollectionFetch collectionFetch) {
-			hadSubselectFetches = hadSubselectFetches
-					| collectionFetch.getFetchStrategy().getStyle() == FetchStyle.SUBSELECT;
-		}
-	}
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/internal/LoadQueryAliasResolutionContextImpl.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/internal/AliasResolutionContextImpl.java
similarity index 53%
rename from hibernate-core/src/main/java/org/hibernate/loader/internal/LoadQueryAliasResolutionContextImpl.java
rename to hibernate-core/src/main/java/org/hibernate/loader/plan/exec/internal/AliasResolutionContextImpl.java
index cd6f42ae80..6f514622dc 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/internal/LoadQueryAliasResolutionContextImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/internal/AliasResolutionContextImpl.java
@@ -1,314 +1,361 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.loader.internal;
+package org.hibernate.loader.plan.exec.internal;
 
+import java.util.Collections;
 import java.util.HashMap;
 import java.util.Map;
 
 import org.hibernate.cfg.NotYetImplementedException;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
+import org.hibernate.hql.internal.NameGenerator;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.loader.CollectionAliases;
 import org.hibernate.loader.DefaultEntityAliases;
 import org.hibernate.loader.EntityAliases;
 import org.hibernate.loader.GeneratedCollectionAliases;
+import org.hibernate.loader.plan.spi.BidirectionalEntityFetch;
+import org.hibernate.loader.plan.exec.spi.AliasResolutionContext;
+import org.hibernate.loader.plan.exec.spi.CollectionReferenceAliases;
+import org.hibernate.loader.plan.exec.spi.EntityReferenceAliases;
+import org.hibernate.loader.plan.spi.AnyFetch;
 import org.hibernate.loader.plan.spi.CollectionReference;
-import org.hibernate.loader.plan.spi.CollectionReturn;
 import org.hibernate.loader.plan.spi.CompositeElementGraph;
+import org.hibernate.loader.plan.spi.CompositeFetch;
 import org.hibernate.loader.plan.spi.CompositeIndexGraph;
 import org.hibernate.loader.plan.spi.EntityReference;
-import org.hibernate.loader.plan.spi.EntityReturn;
 import org.hibernate.loader.plan.spi.Fetch;
+import org.hibernate.loader.plan.spi.FetchOwner;
 import org.hibernate.loader.plan.spi.Return;
 import org.hibernate.loader.plan.spi.ScalarReturn;
+import org.hibernate.loader.plan.spi.SourceQualifiable;
 import org.hibernate.loader.spi.JoinableAssociation;
-import org.hibernate.loader.spi.LoadQueryAliasResolutionContext;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Loadable;
+import org.hibernate.persister.walking.spi.WalkingException;
 import org.hibernate.type.EntityType;
 
 /**
  * Provides aliases that are used by load queries and ResultSet processors.
  *
  * @author Gail Badner
+ * @author Steve Ebersole
  */
-public class LoadQueryAliasResolutionContextImpl implements LoadQueryAliasResolutionContext {
-	private final Map<Return,String[]> aliasesByReturn;
-	private final Map<EntityReference,LoadQueryEntityAliasesImpl> aliasesByEntityReference =
-			new HashMap<EntityReference,LoadQueryEntityAliasesImpl>();
+public class AliasResolutionContextImpl implements AliasResolutionContext {
+	private final SessionFactoryImplementor sessionFactory;
+
+	private final Map<Return,String> sourceAliasByReturnMap;
+	private final Map<SourceQualifiable,String> sourceQualifiersByReturnMap;
+
+	private final Map<EntityReference,EntityReferenceAliasesImpl> aliasesByEntityReference =
+			new HashMap<EntityReference,EntityReferenceAliasesImpl>();
 	private final Map<CollectionReference,LoadQueryCollectionAliasesImpl> aliasesByCollectionReference =
 			new HashMap<CollectionReference,LoadQueryCollectionAliasesImpl>();
 	private final Map<JoinableAssociation,JoinableAssociationAliasesImpl> aliasesByJoinableAssociation =
 			new HashMap<JoinableAssociation, JoinableAssociationAliasesImpl>();
-	private final SessionFactoryImplementor sessionFactory;
 
-	private int currentAliasSuffix = 0;
+	private int currentAliasSuffix;
+	private int currentTableAliasUniqueness;
+
+	/**
+	 * Constructs a AliasResolutionContextImpl without any source aliases.  This form is used in
+	 * non-query (HQL, criteria, etc) contexts.
+	 *
+	 * @param sessionFactory The session factory
+	 */
+	public AliasResolutionContextImpl(SessionFactoryImplementor sessionFactory) {
+		this( sessionFactory, 0 );
+	}
+
+	/**
+	 * Constructs a AliasResolutionContextImpl without any source aliases.  This form is used in
+	 * non-query (HQL, criteria, etc) contexts.
+	 *
+	 * @param sessionFactory The session factory
+	 * @param suffixSeed The seed value to use for generating the suffix used when generating SQL aliases.
+	 */
+	public AliasResolutionContextImpl(SessionFactoryImplementor sessionFactory, int suffixSeed) {
+		this(
+				sessionFactory,
+				suffixSeed,
+				Collections.<Return,String>emptyMap(),
+				Collections.<SourceQualifiable,String>emptyMap()
+		);
+	}
 
-	public LoadQueryAliasResolutionContextImpl(
+	/**
+	 * Constructs a AliasResolutionContextImpl with source aliases.  See the notes on
+	 * {@link org.hibernate.loader.plan.exec.spi.AliasResolutionContext#getSourceAlias(Return)} for discussion of "source aliases".
+	 *
+	 * @param sessionFactory The session factory
+	 * @param suffixSeed The seed value to use for generating the suffix used when generating SQL aliases.
+	 * @param sourceAliasByReturnMap Mapping of the source alias for each return (select-clause assigned alias).
+	 * @param sourceQualifiersByReturnMap Mapping of source query qualifiers (from-clause assigned alias).
+	 */
+	public AliasResolutionContextImpl(
 			SessionFactoryImplementor sessionFactory,
 			int suffixSeed,
-			Map<Return,String[]> aliasesByReturn) {
+			Map<Return, String> sourceAliasByReturnMap,
+			Map<SourceQualifiable, String> sourceQualifiersByReturnMap) {
 		this.sessionFactory = sessionFactory;
 		this.currentAliasSuffix = suffixSeed;
-
-		checkAliasesByReturn( aliasesByReturn );
-		this.aliasesByReturn = new HashMap<Return, String[]>( aliasesByReturn );
-	}
-
-	private static void checkAliasesByReturn(Map<Return, String[]> aliasesByReturn) {
-		if ( aliasesByReturn == null || aliasesByReturn.size() == 0 ) {
-			throw new IllegalArgumentException( "No return aliases defined" );
-		}
-		for ( Map.Entry<Return,String[]> entry : aliasesByReturn.entrySet() ) {
-			final Return aReturn = entry.getKey();
-			final String[] aliases = entry.getValue();
-			if ( aReturn == null ) {
-				throw new IllegalArgumentException( "null key found in aliasesByReturn" );
-			}
-			if ( aliases == null || aliases.length == 0 ) {
-				throw new IllegalArgumentException(
-						String.format( "No alias defined for [%s]", aReturn )
-				);
-			}
-			if ( ( aliases.length > 1 ) &&
-					( aReturn instanceof EntityReturn || aReturn instanceof CollectionReturn ) ) {
-				throw new IllegalArgumentException( String.format( "More than 1 alias defined for [%s]", aReturn ) );
-			}
-			for ( String alias : aliases ) {
-				if ( StringHelper.isEmpty( alias ) ) {
-					throw new IllegalArgumentException( String.format( "An alias for [%s] is null or empty.", aReturn ) );
-				}
-			}
-		}
+		this.sourceAliasByReturnMap = new HashMap<Return, String>( sourceAliasByReturnMap );
+		this.sourceQualifiersByReturnMap = new HashMap<SourceQualifiable, String>( sourceQualifiersByReturnMap );
 	}
 
 	@Override
-	public String resolveEntityReturnAlias(EntityReturn entityReturn) {
-		return getAndCheckReturnAliasExists( entityReturn )[ 0 ];
+	public String getSourceAlias(Return theReturn) {
+		return sourceAliasByReturnMap.get( theReturn );
 	}
 
 	@Override
-	public String resolveCollectionReturnAlias(CollectionReturn collectionReturn) {
-		return getAndCheckReturnAliasExists( collectionReturn )[ 0 ];
+	public String[] resolveScalarColumnAliases(ScalarReturn scalarReturn) {
+		final int numberOfColumns = scalarReturn.getType().getColumnSpan( sessionFactory );
+
+		// if the scalar return was assigned an alias in the source query, use that as the basis for generating
+		// the SQL aliases
+		final String sourceAlias = getSourceAlias( scalarReturn );
+		if ( sourceAlias != null ) {
+			// generate one based on the source alias
+			// todo : to do this properly requires dialect involvement ++
+			// 		due to needing uniqueness even across identifier length based truncation; just truncating is
+			//		*not* enough since truncated names might clash
+			//
+			// for now, don't even truncate...
+			return NameGenerator.scalarNames( sourceAlias, numberOfColumns );
+		}
+		else {
+			// generate one from scratch
+			return NameGenerator.scalarNames( currentAliasSuffix++, numberOfColumns );
+		}
 	}
 
 	@Override
-	public String[] resolveScalarReturnAliases(ScalarReturn scalarReturn) {
-		throw new NotYetImplementedException( "Cannot resolve scalar column aliases yet." );
-	}
-
-	private String[] getAndCheckReturnAliasExists(Return aReturn) {
-		// There is already a check for the appropriate number of aliases stored in aliasesByReturn,
-		// so just check for existence here.
-		final String[] aliases = aliasesByReturn.get( aReturn );
+	public EntityReferenceAliases resolveAliases(EntityReference entityReference) {
+		EntityReferenceAliasesImpl aliases = aliasesByEntityReference.get( entityReference );
 		if ( aliases == null ) {
-			throw new IllegalStateException(
-					String.format( "No alias is defined for [%s]", aReturn )
+			if ( BidirectionalEntityFetch.class.isInstance( entityReference ) ) {
+				return resolveAliases(
+						( (BidirectionalEntityFetch) entityReference ).getTargetEntityReference()
+				);
+			}
+			final EntityPersister entityPersister = entityReference.getEntityPersister();
+			aliases = new EntityReferenceAliasesImpl(
+					createTableAlias( entityPersister ),
+					createEntityAliases( entityPersister )
 			);
+			aliasesByEntityReference.put( entityReference, aliases );
 		}
 		return aliases;
 	}
 
 	@Override
-	public String resolveEntityTableAlias(EntityReference entityReference) {
-		return getOrGenerateLoadQueryEntityAliases( entityReference ).tableAlias;
+	public CollectionReferenceAliases resolveAliases(CollectionReference collectionReference) {
+		LoadQueryCollectionAliasesImpl aliases = aliasesByCollectionReference.get( collectionReference );
+		if ( aliases == null ) {
+			final CollectionPersister collectionPersister = collectionReference.getCollectionPersister();
+			aliases = new LoadQueryCollectionAliasesImpl(
+					createTableAlias( collectionPersister.getRole() ),
+					collectionPersister.isManyToMany()
+							? createTableAlias( collectionPersister.getRole() )
+							: null,
+					createCollectionAliases( collectionPersister ),
+					createCollectionElementAliases( collectionPersister )
+			);
+			aliasesByCollectionReference.put( collectionReference, aliases );
+		}
+		return aliases;
 	}
 
-	@Override
-	public EntityAliases resolveEntityColumnAliases(EntityReference entityReference) {
-		return getOrGenerateLoadQueryEntityAliases( entityReference ).columnAliases;
-	}
 
-	@Override
-	public String resolveCollectionTableAlias(CollectionReference collectionReference) {
-		return getOrGenerateLoadQueryCollectionAliases( collectionReference ).tableAlias;
-	}
 
-	@Override
-	public CollectionAliases resolveCollectionColumnAliases(CollectionReference collectionReference) {
-		return getOrGenerateLoadQueryCollectionAliases( collectionReference ).collectionAliases;
-	}
 
-	@Override
-	public EntityAliases resolveCollectionElementColumnAliases(CollectionReference collectionReference) {
-		return getOrGenerateLoadQueryCollectionAliases( collectionReference ).collectionElementAliases;
-	}
+
+
 
 	@Override
 	public String resolveAssociationRhsTableAlias(JoinableAssociation joinableAssociation) {
 		return getOrGenerateJoinAssocationAliases( joinableAssociation ).rhsAlias;
 	}
 
 	@Override
 	public String resolveAssociationLhsTableAlias(JoinableAssociation joinableAssociation) {
 		return getOrGenerateJoinAssocationAliases( joinableAssociation ).lhsAlias;
 	}
 
 	@Override
 	public String[] resolveAssociationAliasedLhsColumnNames(JoinableAssociation joinableAssociation) {
 		return getOrGenerateJoinAssocationAliases( joinableAssociation ).aliasedLhsColumnNames;
 	}
 
 	protected SessionFactoryImplementor sessionFactory() {
 		return sessionFactory;
 	}
 
 	private String createSuffix() {
 		return Integer.toString( currentAliasSuffix++ ) + '_';
 	}
 
-	private LoadQueryEntityAliasesImpl getOrGenerateLoadQueryEntityAliases(EntityReference entityReference) {
-		LoadQueryEntityAliasesImpl aliases = aliasesByEntityReference.get( entityReference );
-		if ( aliases == null ) {
-			final EntityPersister entityPersister = entityReference.getEntityPersister();
-			aliases = new LoadQueryEntityAliasesImpl(
-					createTableAlias( entityPersister ),
-					createEntityAliases( entityPersister )
-			);
-			aliasesByEntityReference.put( entityReference, aliases );
-		}
-		return aliases;
-	}
-
-	private LoadQueryCollectionAliasesImpl getOrGenerateLoadQueryCollectionAliases(CollectionReference collectionReference) {
-		LoadQueryCollectionAliasesImpl aliases = aliasesByCollectionReference.get( collectionReference );
-		if ( aliases == null ) {
-			final CollectionPersister collectionPersister = collectionReference.getCollectionPersister();
-			aliases = new LoadQueryCollectionAliasesImpl(
-					createTableAlias( collectionPersister.getRole() ),
-					createCollectionAliases( collectionPersister ),
-					createCollectionElementAliases( collectionPersister )
-			);
-			aliasesByCollectionReference.put( collectionReference, aliases );
-		}
-		return aliases;
-	}
-
 	private JoinableAssociationAliasesImpl getOrGenerateJoinAssocationAliases(JoinableAssociation joinableAssociation) {
 		JoinableAssociationAliasesImpl aliases = aliasesByJoinableAssociation.get( joinableAssociation );
 		if ( aliases == null ) {
 			final Fetch currentFetch = joinableAssociation.getCurrentFetch();
 			final String lhsAlias;
-			if ( EntityReference.class.isInstance( currentFetch.getOwner() ) ) {
-				lhsAlias = resolveEntityTableAlias( (EntityReference) currentFetch.getOwner() );
+			if ( AnyFetch.class.isInstance( currentFetch ) ) {
+				throw new WalkingException( "Any type should never be joined!" );
+			}
+			else if ( EntityReference.class.isInstance( currentFetch.getOwner() ) ) {
+				lhsAlias = resolveAliases( (EntityReference) currentFetch.getOwner() ).getTableAlias();
+			}
+			else if ( CompositeFetch.class.isInstance( currentFetch.getOwner() ) ) {
+				lhsAlias = resolveAliases(
+						locateCompositeFetchEntityReferenceSource( (CompositeFetch) currentFetch.getOwner() )
+				).getTableAlias();
 			}
 			else if ( CompositeElementGraph.class.isInstance( currentFetch.getOwner() ) ) {
 				CompositeElementGraph compositeElementGraph = (CompositeElementGraph) currentFetch.getOwner();
-				lhsAlias = resolveCollectionTableAlias( compositeElementGraph.getCollectionReference() );
+				lhsAlias = resolveAliases( compositeElementGraph.getCollectionReference() ).getElementTableAlias();
 			}
 			else if ( CompositeIndexGraph.class.isInstance( currentFetch.getOwner() ) ) {
 				CompositeIndexGraph compositeIndexGraph = (CompositeIndexGraph) currentFetch.getOwner();
-				lhsAlias = resolveCollectionTableAlias( compositeIndexGraph.getCollectionReference() );
+				lhsAlias = resolveAliases( compositeIndexGraph.getCollectionReference() ).getElementTableAlias();
 			}
 			else {
 				throw new NotYetImplementedException( "Cannot determine LHS alias for FetchOwner." );
 			}
 
 			final String[] aliasedLhsColumnNames = currentFetch.toSqlSelectFragments( lhsAlias );
 			final String rhsAlias;
 			if ( EntityReference.class.isInstance( currentFetch ) ) {
-				rhsAlias = resolveEntityTableAlias( (EntityReference) currentFetch );
+				rhsAlias = resolveAliases( (EntityReference) currentFetch ).getTableAlias();
 			}
 			else if ( CollectionReference.class.isInstance( joinableAssociation.getCurrentFetch() ) ) {
-				rhsAlias = resolveCollectionTableAlias( (CollectionReference) currentFetch );
+				rhsAlias = resolveAliases( (CollectionReference) currentFetch ).getCollectionTableAlias();
 			}
 			else {
 				throw new NotYetImplementedException( "Cannot determine RHS alis for a fetch that is not an EntityReference or CollectionReference." );
 			}
 
-			// TODO: can't this be found in CollectionAliases or EntityAliases? should be moved to LoadQueryAliasResolutionContextImpl
+			// TODO: can't this be found in CollectionAliases or EntityAliases? should be moved to AliasResolutionContextImpl
 
 			aliases = new JoinableAssociationAliasesImpl( lhsAlias, aliasedLhsColumnNames, rhsAlias );
 			aliasesByJoinableAssociation.put( joinableAssociation, aliases );
 		}
 		return aliases;
 	}
 
+	private EntityReference locateCompositeFetchEntityReferenceSource(CompositeFetch composite) {
+		final FetchOwner owner = composite.getOwner();
+		if ( EntityReference.class.isInstance( owner ) ) {
+			return (EntityReference) owner;
+		}
+		if ( CompositeFetch.class.isInstance( owner ) ) {
+			return locateCompositeFetchEntityReferenceSource( (CompositeFetch) owner );
+		}
+
+		throw new WalkingException( "Cannot resolve entity source for a CompositeFetch" );
+	}
+
 	private String createTableAlias(EntityPersister entityPersister) {
 		return createTableAlias( StringHelper.unqualifyEntityName( entityPersister.getEntityName() ) );
 	}
 
 	private String createTableAlias(String name) {
-		return StringHelper.generateAlias( name ) + createSuffix();
+		return StringHelper.generateAlias( name, currentTableAliasUniqueness++ );
 	}
 
 	private EntityAliases createEntityAliases(EntityPersister entityPersister) {
 		return new DefaultEntityAliases( (Loadable) entityPersister, createSuffix() );
 	}
 
 	private CollectionAliases createCollectionAliases(CollectionPersister collectionPersister) {
 		return new GeneratedCollectionAliases( collectionPersister, createSuffix() );
 	}
 
 	private EntityAliases createCollectionElementAliases(CollectionPersister collectionPersister) {
 		if ( !collectionPersister.getElementType().isEntityType() ) {
 			return null;
 		}
 		else {
 			final EntityType entityElementType = (EntityType) collectionPersister.getElementType();
 			return createEntityAliases( (EntityPersister) entityElementType.getAssociatedJoinable( sessionFactory() ) );
 		}
 	}
 
-	private static class LoadQueryEntityAliasesImpl {
-		private final String tableAlias;
-		private final EntityAliases columnAliases;
-
-		public LoadQueryEntityAliasesImpl(String tableAlias, EntityAliases columnAliases) {
-			this.tableAlias = tableAlias;
-			this.columnAliases = columnAliases;
-		}
-	}
-
-	private static class LoadQueryCollectionAliasesImpl {
+	private static class LoadQueryCollectionAliasesImpl implements CollectionReferenceAliases {
 		private final String tableAlias;
+		private final String manyToManyAssociationTableAlias;
 		private final CollectionAliases collectionAliases;
-		private final EntityAliases collectionElementAliases;
+		private final EntityAliases entityElementAliases;
 
 		public LoadQueryCollectionAliasesImpl(
 				String tableAlias,
+				String manyToManyAssociationTableAlias,
 				CollectionAliases collectionAliases,
-				EntityAliases collectionElementAliases) {
+				EntityAliases entityElementAliases) {
 			this.tableAlias = tableAlias;
+			this.manyToManyAssociationTableAlias = manyToManyAssociationTableAlias;
 			this.collectionAliases = collectionAliases;
-			this.collectionElementAliases = collectionElementAliases;
+			this.entityElementAliases = entityElementAliases;
+		}
+
+		@Override
+		public String getCollectionTableAlias() {
+			return StringHelper.isNotEmpty( manyToManyAssociationTableAlias )
+					? manyToManyAssociationTableAlias
+					: tableAlias;
+		}
+
+		@Override
+		public String getElementTableAlias() {
+			return tableAlias;
+		}
+
+		@Override
+		public CollectionAliases getCollectionColumnAliases() {
+			return collectionAliases;
+		}
+
+		@Override
+		public EntityAliases getEntityElementColumnAliases() {
+			return entityElementAliases;
 		}
 	}
 
 	private static class JoinableAssociationAliasesImpl {
 		private final String lhsAlias;
 		private final String[] aliasedLhsColumnNames;
 		private final String rhsAlias;
 
 		public JoinableAssociationAliasesImpl(
 				String lhsAlias,
 				String[] aliasedLhsColumnNames,
 				String rhsAlias) {
 			this.lhsAlias = lhsAlias;
 			this.aliasedLhsColumnNames = aliasedLhsColumnNames;
 			this.rhsAlias = rhsAlias;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/internal/EntityReferenceAliasesImpl.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/internal/EntityReferenceAliasesImpl.java
new file mode 100644
index 0000000000..985f6a2976
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/internal/EntityReferenceAliasesImpl.java
@@ -0,0 +1,51 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.exec.internal;
+
+import org.hibernate.loader.EntityAliases;
+import org.hibernate.loader.plan.exec.spi.EntityReferenceAliases;
+
+/**
+ * @author Gail Badner
+ * @author Steve Ebersole
+ */
+class EntityReferenceAliasesImpl implements EntityReferenceAliases {
+	private final String tableAlias;
+	private final EntityAliases columnAliases;
+
+	public EntityReferenceAliasesImpl(String tableAlias, EntityAliases columnAliases) {
+		this.tableAlias = tableAlias;
+		this.columnAliases = columnAliases;
+	}
+
+	@Override
+	public String getTableAlias() {
+		return tableAlias;
+	}
+
+	@Override
+	public EntityAliases getColumnAliases() {
+		return columnAliases;
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/CollectionReferenceReader.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/CollectionReferenceReader.java
new file mode 100644
index 0000000000..bf340f853f
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/CollectionReferenceReader.java
@@ -0,0 +1,155 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.exec.process.internal;
+
+import java.io.Serializable;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+
+import org.jboss.logging.Logger;
+
+import org.hibernate.collection.spi.PersistentCollection;
+import org.hibernate.engine.spi.PersistenceContext;
+import org.hibernate.internal.CoreLogging;
+import org.hibernate.loader.plan.exec.process.spi.ResultSetProcessingContext;
+import org.hibernate.loader.plan.exec.spi.CollectionReferenceAliases;
+import org.hibernate.loader.plan.spi.CollectionReference;
+import org.hibernate.pretty.MessageHelper;
+
+/**
+ * @author Steve Ebersole
+ */
+public class CollectionReferenceReader {
+	private static final Logger log = CoreLogging.logger( CollectionReferenceReader.class );
+
+	private final CollectionReference collectionReference;
+
+	public CollectionReferenceReader(CollectionReference collectionReference) {
+		this.collectionReference = collectionReference;
+	}
+
+	public void finishUpRow(ResultSet resultSet, ResultSetProcessingContextImpl context) {
+		final CollectionReferenceAliases aliases = context.getAliasResolutionContext().resolveAliases(
+				collectionReference
+		);
+
+		try {
+			// read the collection key for this reference for the current row.
+			final PersistenceContext persistenceContext = context.getSession().getPersistenceContext();
+			final Serializable collectionRowKey = (Serializable) collectionReference.getCollectionPersister().readKey(
+					resultSet,
+					aliases.getCollectionColumnAliases().getSuffixedKeyAliases(),
+					context.getSession()
+			);
+
+			if ( collectionRowKey != null ) {
+				// we found a collection element in the result set
+
+				if ( log.isDebugEnabled() ) {
+					log.debugf(
+							"Found row of collection: %s",
+							MessageHelper.collectionInfoString(
+									collectionReference.getCollectionPersister(),
+									collectionRowKey,
+									context.getSession().getFactory()
+							)
+					);
+				}
+
+				Object collectionOwner = findCollectionOwner( collectionRowKey, resultSet, context );
+
+				PersistentCollection rowCollection = persistenceContext.getLoadContexts()
+						.getCollectionLoadContext( resultSet )
+						.getLoadingCollection( collectionReference.getCollectionPersister(), collectionRowKey );
+
+				if ( rowCollection != null ) {
+					rowCollection.readFrom(
+							resultSet,
+							collectionReference.getCollectionPersister(),
+							aliases.getCollectionColumnAliases(),
+							collectionOwner
+					);
+				}
+
+			}
+			else {
+				final Serializable optionalKey = findCollectionOwnerKey( context );
+				if ( optionalKey != null ) {
+					// we did not find a collection element in the result set, so we
+					// ensure that a collection is created with the owner's identifier,
+					// since what we have is an empty collection
+					if ( log.isDebugEnabled() ) {
+						log.debugf(
+								"Result set contains (possibly empty) collection: %s",
+								MessageHelper.collectionInfoString(
+										collectionReference.getCollectionPersister(),
+										optionalKey,
+										context.getSession().getFactory()
+								)
+						);
+					}
+					// handle empty collection
+					persistenceContext.getLoadContexts()
+							.getCollectionLoadContext( resultSet )
+							.getLoadingCollection( collectionReference.getCollectionPersister(), optionalKey );
+
+				}
+			}
+			// else no collection element, but also no owner
+		}
+		catch ( SQLException sqle ) {
+			// TODO: would be nice to have the SQL string that failed...
+			throw context.getSession().getFactory().getSQLExceptionHelper().convert(
+					sqle,
+					"could not read next row of results"
+			);
+		}
+
+	}
+
+	protected Object findCollectionOwner(
+			Serializable collectionRowKey,
+			ResultSet resultSet,
+			ResultSetProcessingContextImpl context) {
+		final Object collectionOwner = context.getSession().getPersistenceContext().getCollectionOwner(
+				collectionRowKey,
+				collectionReference.getCollectionPersister()
+		);
+		// todo : try org.hibernate.loader.plan.exec.process.spi.ResultSetProcessingContext.getOwnerProcessingState() ??
+		//			-- specifically to return its ResultSetProcessingContext.EntityReferenceProcessingState#getEntityInstance()
+		if ( collectionOwner == null ) {
+			//TODO: This is assertion is disabled because there is a bug that means the
+			//	  original owner of a transient, uninitialized collection is not known
+			//	  if the collection is re-referenced by a different object associated
+			//	  with the current Session
+			//throw new AssertionFailure("bug loading unowned collection");
+		}
+		return collectionOwner;
+	}
+
+	protected Serializable findCollectionOwnerKey(ResultSetProcessingContext context) {
+		return null;
+	}
+
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/CollectionReturnReader.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/CollectionReturnReader.java
new file mode 100644
index 0000000000..c71bfbec54
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/CollectionReturnReader.java
@@ -0,0 +1,74 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.exec.process.internal;
+
+import java.io.Serializable;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+
+import org.hibernate.engine.spi.EntityKey;
+import org.hibernate.loader.plan.exec.process.spi.ResultSetProcessingContext;
+import org.hibernate.loader.plan.exec.process.spi.ReturnReader;
+import org.hibernate.loader.plan.spi.CollectionReturn;
+
+/**
+ * @author Steve Ebersole
+ */
+public class CollectionReturnReader extends CollectionReferenceReader implements ReturnReader {
+	private final CollectionReturn collectionReturn;
+
+	public CollectionReturnReader(CollectionReturn collectionReturn) {
+		super( collectionReturn );
+		this.collectionReturn = collectionReturn;
+	}
+
+	@Override
+	protected Object findCollectionOwner(
+			Serializable collectionRowKey,
+			ResultSet resultSet,
+			ResultSetProcessingContextImpl context) {
+		if ( context.shouldUseOptionalEntityInformation() ) {
+			final Object optionalEntityInstance = context.getQueryParameters().getOptionalObject();
+			if ( optionalEntityInstance != null ) {
+				return optionalEntityInstance;
+			}
+		}
+		return super.findCollectionOwner( collectionRowKey, resultSet, context );
+	}
+
+	@Override
+	protected Serializable findCollectionOwnerKey(ResultSetProcessingContext context) {
+		final EntityKey entityKey = context.shouldUseOptionalEntityInformation()
+				? ResultSetProcessorHelper.getOptionalObjectKey( context.getQueryParameters(), context.getSession() )
+				: null;
+		return entityKey == null
+				? super.findCollectionOwnerKey( context )
+				: entityKey;
+	}
+
+	@Override
+	public Object read(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
+		return null;  //To change body of implemented methods use File | Settings | File Templates.
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/EntityIdentifierReader.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/EntityIdentifierReader.java
new file mode 100644
index 0000000000..5000b10e34
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/EntityIdentifierReader.java
@@ -0,0 +1,88 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.exec.process.internal;
+
+import java.sql.ResultSet;
+import java.sql.SQLException;
+
+import org.hibernate.loader.plan.exec.process.spi.ResultSetProcessingContext;
+
+/**
+ * Identifiers are read from the ResultSet in 2 distinct phases:
+ * <ol>
+ *     <li>
+ *         First we hydrate the identifier values (see {@link #hydrate}).  During this "phase" 2 things happen:
+ *         <ol>
+ *             <li>
+ *                 Any "optional identifier" specified on QueryParameters is considered.  If the "optional identifier"
+ *                 is to be used for this identifier read, it is used to build an EntityKey which is associated with
+ *                 the {@link ResultSetProcessingContext.EntityReferenceProcessingState} for the EntityReference under
+ *                 {@link ResultSetProcessingContext.EntityReferenceProcessingState#registerEntityKey}
+ *             </li>
+ *             <li>
+ *                 All other id values are hydrated from the ResultSet.  Those hydrated values are then registered
+ *                 with the {@link ResultSetProcessingContext.EntityReferenceProcessingState} for the EntityReference
+ *                 under {@link ResultSetProcessingContext.EntityReferenceProcessingState#registerIdentifierHydratedForm}
+ *             </li>
+ *         </ol>
+ *     </li>
+ *     <li>
+ *         Then we resolve the identifier.  This is again a 2 step process:
+ *         <ol>
+ *             <li>
+ *                 For all fetches that "come from" an identifier (key-many-to-ones), we fully hydrate those entities
+ *             </li>
+ *             <li>
+ *                 We then call resolve on root identifier type, and use that to build an EntityKey,which is then
+ *                 registered with the {@link ResultSetProcessingContext.EntityReferenceProcessingState} for the
+ *                 EntityReference whose identifier we are reading under
+ *                 {@link ResultSetProcessingContext.EntityReferenceProcessingState#registerEntityKey}
+ *             </li>
+ *         </ol>
+ *     </li>
+ * </ol>
+ *
+ * @author Steve Ebersole
+ */
+public interface EntityIdentifierReader {
+	/**
+	 * Hydrate the entity identifier.  Perform the first phase outlined above.
+	 *
+	 * @param resultSet The ResultSet
+	 * @param context The processing context
+	 *
+	 * @throws java.sql.SQLException Problem accessing ResultSet
+	 */
+	public void hydrate(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException;
+
+	/**
+	 * Resolve the entity identifier.  Perform the second phase outlined above.
+	 *
+	 * @param resultSet The ResultSet
+	 * @param context The processing context
+	 *
+	 * @throws java.sql.SQLException Problem accessing ResultSet
+	 */
+	public void resolve(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException;
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/EntityIdentifierReaderImpl.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/EntityIdentifierReaderImpl.java
new file mode 100644
index 0000000000..254612bebf
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/EntityIdentifierReaderImpl.java
@@ -0,0 +1,326 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.exec.process.internal;
+
+import java.io.Serializable;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+
+import org.jboss.logging.Logger;
+
+import org.hibernate.HibernateException;
+import org.hibernate.JDBCException;
+import org.hibernate.cfg.NotYetImplementedException;
+import org.hibernate.engine.spi.EntityKey;
+import org.hibernate.internal.CoreLogging;
+import org.hibernate.loader.plan.exec.process.spi.ResultSetProcessingContext;
+import org.hibernate.loader.plan.spi.CompositeFetch;
+import org.hibernate.loader.plan.spi.EntityFetch;
+import org.hibernate.loader.plan.spi.EntityReference;
+import org.hibernate.loader.plan.spi.EntityReturn;
+import org.hibernate.loader.plan.spi.Fetch;
+import org.hibernate.loader.plan.spi.FetchOwner;
+import org.hibernate.persister.spi.HydratedCompoundValueHandler;
+import org.hibernate.persister.walking.internal.FetchStrategyHelper;
+import org.hibernate.persister.walking.spi.WalkingException;
+import org.hibernate.type.Type;
+
+import static org.hibernate.loader.plan.exec.process.spi.ResultSetProcessingContext.*;
+
+/**
+ * Encapsulates the logic for reading a single entity identifier from a JDBC ResultSet, including support for fetches
+ * that are part of the identifier.
+ *
+ * @author Steve Ebersole
+ */
+class EntityIdentifierReaderImpl implements EntityIdentifierReader {
+	private static final Logger log = CoreLogging.logger( EntityIdentifierReaderImpl.class );
+
+	private final EntityReference entityReference;
+
+	private List<EntityReferenceReader> identifierFetchReaders;
+
+	private final boolean isReturn;
+	private final Type identifierType;
+
+	/**
+	 * Creates a delegate capable of performing the reading of an entity identifier
+	 *
+	 * @param entityReference The entity reference for which we will be reading the identifier.
+	 */
+	EntityIdentifierReaderImpl(EntityReference entityReference) {
+		this.entityReference = entityReference;
+		this.isReturn = EntityReturn.class.isInstance( entityReference );
+		this.identifierType = entityReference.getEntityPersister().getIdentifierType();
+
+		identifierFetchReaders = collectIdentifierFetchReaders();
+	}
+
+	private List<EntityReferenceReader> collectIdentifierFetchReaders() {
+		if ( ! identifierType.isComponentType() ) {
+			return Collections.emptyList();
+		}
+		final Fetch[] fetches = entityReference.getIdentifierDescription().getFetches();
+		if ( fetches == null || fetches.length == 0 ) {
+			return Collections.emptyList();
+		}
+
+		final List<EntityReferenceReader> readers = new ArrayList<EntityReferenceReader>();
+		for ( Fetch fetch : fetches ) {
+			collectIdentifierFetchReaders( readers, fetch );
+		}
+		return readers;
+	}
+
+	private void collectIdentifierFetchReaders(List<EntityReferenceReader> readers, Fetch fetch) {
+		if ( CompositeFetch.class.isInstance( fetch ) ) {
+			for ( Fetch subFetch : ( (CompositeFetch) fetch).getFetches() ) {
+				collectIdentifierFetchReaders( readers, subFetch );
+			}
+		}
+		else if ( ! EntityFetch.class.isInstance( fetch ) ) {
+			throw new IllegalStateException(
+					String.format(
+							"non-entity (and non-composite) fetch [%s] was found as part of entity identifier : %s",
+							fetch,
+							entityReference.getEntityPersister().getEntityName()
+					)
+			);
+		}
+		else {
+			final EntityReference fetchedEntityReference = (EntityReference) fetch;
+			readers.add( new EntityReferenceReader( fetchedEntityReference ) );
+		}
+	}
+
+	@Override
+	public void hydrate(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
+		final EntityReferenceProcessingState processingState = context.getProcessingState( entityReference );
+
+		// if the entity reference we are hydrating is a Return, it is possible that its EntityKey is
+		// supplied by the QueryParameter optional entity information
+		if ( context.shouldUseOptionalEntityInformation() ) {
+			if ( isReturn ) {
+				final EntityKey entityKey = ResultSetProcessorHelper.getOptionalObjectKey(
+						context.getQueryParameters(),
+						context.getSession()
+				);
+
+				if ( entityKey != null ) {
+					processingState.registerEntityKey( entityKey );
+					return;
+				}
+			}
+		}
+
+		// get any previously registered identifier hydrated-state
+		Object identifierHydratedForm = processingState.getIdentifierHydratedForm();
+		if ( identifierHydratedForm == null ) {
+			// if there is none, read it from the result set
+			identifierHydratedForm = readIdentifierHydratedState( resultSet, context );
+
+			// broadcast the fact that a hydrated identifier value just became associated with
+			// this entity reference
+			processingState.registerIdentifierHydratedForm( identifierHydratedForm );
+//			hydrateIdentifierFetchIdentifiers( resultSet, context, identifierHydratedForm );
+			for ( EntityReferenceReader reader : identifierFetchReaders ) {
+				reader.hydrateIdentifier( resultSet, context );
+			}
+		}
+	}
+
+	/**
+	 * Read the identifier state for the entity reference for the currently processing row in the ResultSet
+	 *
+	 * @param resultSet The ResultSet being processed
+	 * @param context The processing context
+	 *
+	 * @return The hydrated state
+	 *
+	 * @throws java.sql.SQLException Indicates a problem accessing the ResultSet
+	 */
+	private Object readIdentifierHydratedState(ResultSet resultSet, ResultSetProcessingContext context)
+			throws SQLException {
+//		if ( EntityReturn.class.isInstance( entityReference ) ) {
+//			// if there is a "optional entity key" associated with the context it would pertain to this
+//			// entity reference, because it is the root return.
+//			final EntityKey suppliedEntityKey = context.getSuppliedOptionalEntityKey();
+//			if ( suppliedEntityKey != null ) {
+//				return suppliedEntityKey.getIdentifier();
+//			}
+//		}
+
+		// Otherwise, read it from the ResultSet
+		final String[] columnNames;
+		if ( EntityFetch.class.isInstance( entityReference )
+				&& !FetchStrategyHelper.isJoinFetched( ((EntityFetch) entityReference).getFetchStrategy() ) ) {
+			final EntityFetch fetch = (EntityFetch) entityReference;
+			final FetchOwner fetchOwner = fetch.getOwner();
+			if ( EntityReference.class.isInstance( fetchOwner ) ) {
+				throw new NotYetImplementedException();
+//					final EntityReference ownerEntityReference = (EntityReference) fetchOwner;
+//					final EntityAliases ownerEntityAliases = context.getAliasResolutionContext()
+//							.resolveEntityColumnAliases( ownerEntityReference );
+//					final int propertyIndex = ownerEntityReference.getEntityPersister()
+//							.getEntityMetamodel()
+//							.getPropertyIndex( fetch.getOwnerPropertyName() );
+//					columnNames = ownerEntityAliases.getSuffixedPropertyAliases()[ propertyIndex ];
+			}
+			else {
+				// todo : better message here...
+				throw new WalkingException( "Cannot locate association column names" );
+			}
+		}
+		else {
+			columnNames = context.getAliasResolutionContext()
+					.resolveAliases( entityReference )
+					.getColumnAliases()
+					.getSuffixedKeyAliases();
+		}
+
+		try {
+			return entityReference.getEntityPersister().getIdentifierType().hydrate(
+					resultSet,
+					columnNames,
+					context.getSession(),
+					null
+			);
+		}
+		catch (Exception e) {
+			throw new HibernateException(
+					"Encountered problem trying to hydrate identifier for entity ["
+							+ entityReference.getEntityPersister() + "]",
+					e
+
+			);
+		}
+	}
+
+//	/**
+//	 * Hydrate the identifiers of all fetches that are part of this entity reference's identifier (key-many-to-one).
+//	 *
+//	 * @param resultSet The ResultSet
+//	 * @param context The processing context
+//	 * @param hydratedIdentifierState The hydrated identifier state of the entity reference.  We can extract the
+//	 * fetch identifier's hydrated state from there if available, without having to read the Result (which can
+//	 * be a performance problem on some drivers).
+//	 */
+//	private void hydrateIdentifierFetchIdentifiers(
+//			ResultSet resultSet,
+//			ResultSetProcessingContext context,
+//			Object hydratedIdentifierState) throws SQLException {
+//		// for all fetches that are part of our identifier...
+//		for ( Fetch fetch : entityReference.getIdentifierDescription().getFetches() ) {
+//			hydrateIdentifierFetchIdentifier( resultSet, context, fetch, hydratedIdentifierState );
+//		}
+//	}
+//
+//	private void hydrateIdentifierFetchIdentifier(
+//			ResultSet resultSet,
+//			ResultSetProcessingContext context,
+//			Fetch fetch,
+//			Object hydratedIdentifierState) throws SQLException {
+//		if ( CompositeFetch.class.isInstance( fetch ) ) {
+//			for ( Fetch subFetch : ( (CompositeFetch) fetch).getFetches() ) {
+//				hydrateIdentifierFetchIdentifier( resultSet, context, subFetch, hydratedIdentifierState );
+//			}
+//		}
+//		else if ( ! EntityFetch.class.isInstance( fetch ) ) {
+//			throw new NotYetImplementedException( "Cannot hydrate identifier Fetch that is not an EntityFetch" );
+//		}
+//		else {
+//			final EntityFetch entityFetch = (EntityFetch) fetch;
+//			final EntityReferenceProcessingState fetchProcessingState = context.getProcessingState( entityFetch );
+//
+//			// if the identifier for the fetch was already hydrated, nothing to do
+//			if ( fetchProcessingState.getIdentifierHydratedForm() != null ) {
+//				return;
+//			}
+//
+//			// we can either hydrate the fetch's identifier from the incoming 'hydratedIdentifierState' (by
+//			// extracting the relevant portion using HydratedCompoundValueHandler) or we can
+//			// read it from the ResultSet
+//			if ( hydratedIdentifierState != null ) {
+//				final HydratedCompoundValueHandler hydratedStateHandler = entityReference.getIdentifierDescription().getHydratedStateHandler( fetch );
+//				if ( hydratedStateHandler != null ) {
+//					final Serializable extracted = (Serializable) hydratedStateHandler.extract( hydratedIdentifierState );
+//					fetchProcessingState.registerIdentifierHydratedForm( extracted );
+//				}
+//			}
+//			else {
+//				// Use a reader to hydrate the fetched entity.
+//				//
+//				// todo : Ideally these should be kept around
+//				new EntityReferenceReader( entityFetch ).hydrateIdentifier( resultSet, context );
+//			}
+//		}
+//	}
+
+
+	public void resolve(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
+		// resolve fetched state from the identifier first
+		for ( EntityReferenceReader reader : identifierFetchReaders ) {
+			reader.resolveEntityKey( resultSet, context );
+		}
+		for ( EntityReferenceReader reader : identifierFetchReaders ) {
+			reader.hydrateEntityState( resultSet, context );
+		}
+
+		final EntityReferenceProcessingState processingState = context.getProcessingState( entityReference );
+
+		// see if we already have an EntityKey associated with this EntityReference in the processing state.
+		// if we do, this should have come from the optional entity identifier...
+		final EntityKey entityKey = processingState.getEntityKey();
+		if ( entityKey != null ) {
+			log.debugf(
+					"On call to EntityIdentifierReaderImpl#resolve [for %s], EntityKey was already known; " +
+							"should only happen on root returns with an optional identifier specified"
+			);
+			return;
+		}
+
+		// Look for the hydrated form
+		final Object identifierHydratedForm = processingState.getIdentifierHydratedForm();
+		if ( identifierHydratedForm == null ) {
+			// we need to register the missing identifier, but that happens later after all readers have had a chance
+			// to resolve its EntityKey
+			return;
+		}
+
+		final Type identifierType = entityReference.getEntityPersister().getIdentifierType();
+		final Serializable resolvedId = (Serializable) identifierType.resolve(
+				identifierHydratedForm,
+				context.getSession(),
+				null
+		);
+		if ( resolvedId != null ) {
+			processingState.registerEntityKey(
+					context.getSession().generateEntityKey( resolvedId, entityReference.getEntityPersister() )
+			);
+		}
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/EntityReferenceReader.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/EntityReferenceReader.java
new file mode 100644
index 0000000000..1fe9c8daf3
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/EntityReferenceReader.java
@@ -0,0 +1,436 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.exec.process.internal;
+
+import java.io.Serializable;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+
+import org.jboss.logging.Logger;
+
+import org.hibernate.LockMode;
+import org.hibernate.StaleObjectStateException;
+import org.hibernate.WrongClassException;
+import org.hibernate.engine.internal.TwoPhaseLoad;
+import org.hibernate.engine.spi.EntityKey;
+import org.hibernate.engine.spi.EntityUniqueKey;
+import org.hibernate.engine.spi.SessionImplementor;
+import org.hibernate.internal.CoreLogging;
+import org.hibernate.loader.EntityAliases;
+import org.hibernate.loader.plan.exec.process.spi.ResultSetProcessingContext;
+import org.hibernate.loader.plan.exec.spi.EntityReferenceAliases;
+import org.hibernate.loader.plan.spi.EntityFetch;
+import org.hibernate.loader.plan.spi.EntityReference;
+import org.hibernate.loader.plan.spi.EntityReturn;
+import org.hibernate.persister.entity.EntityPersister;
+import org.hibernate.persister.entity.Loadable;
+import org.hibernate.persister.entity.UniqueKeyLoadable;
+import org.hibernate.pretty.MessageHelper;
+import org.hibernate.type.CompositeType;
+import org.hibernate.type.EntityType;
+import org.hibernate.type.Type;
+import org.hibernate.type.VersionType;
+
+import static org.hibernate.loader.plan.exec.process.spi.ResultSetProcessingContext.EntityReferenceProcessingState;
+
+/**
+ * @author Steve Ebersole
+ */
+public class EntityReferenceReader {
+	private static final Logger log = CoreLogging.logger( EntityReferenceReader.class );
+
+	private final EntityReference entityReference;
+	private final EntityIdentifierReader identifierReader;
+
+	private final boolean isReturn;
+
+
+	protected EntityReferenceReader(EntityReference entityReference, EntityIdentifierReader identifierReader) {
+		this.entityReference = entityReference;
+		this.identifierReader = identifierReader;
+
+		this.isReturn = EntityReturn.class.isInstance( entityReference );
+	}
+
+	public EntityReferenceReader(EntityReference entityReference) {
+		this( entityReference, new EntityIdentifierReaderImpl( entityReference ) );
+	}
+
+	public EntityReference getEntityReference() {
+		return entityReference;
+	}
+
+	public void hydrateIdentifier(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
+		identifierReader.hydrate( resultSet, context );
+	}
+
+	public void resolveEntityKey(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
+		identifierReader.resolve( resultSet, context );
+	}
+
+	public void hydrateEntityState(ResultSet resultSet, ResultSetProcessingContext context) {
+		// hydrate the entity reference.  at this point it is expected that
+
+		final EntityReferenceProcessingState processingState = context.getProcessingState( entityReference );
+
+		// If there is no identifier for this entity reference for this row, nothing to do
+		if ( processingState.isMissingIdentifier() ) {
+			handleMissingIdentifier( context );
+			return;
+		}
+
+		// make sure we have the EntityKey
+		final EntityKey entityKey = processingState.getEntityKey();
+		if ( entityKey == null ) {
+			handleMissingIdentifier( context );
+			return;
+		}
+
+		// Have we already hydrated this entity's state?
+		if ( processingState.getEntityInstance() != null ) {
+			return;
+		}
+
+
+		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+		// In getting here, we know that:
+		// 		1) We need to hydrate the entity state
+		//		2) We have a valid EntityKey for the entity
+
+		// see if we have an existing entry in the session for this EntityKey
+		final Object existing = context.getSession().getEntityUsingInterceptor( entityKey );
+		if ( existing != null ) {
+			// It is previously associated with the Session, perform some checks
+			if ( ! entityReference.getEntityPersister().isInstance( existing ) ) {
+				throw new WrongClassException(
+						"loaded object was of wrong class " + existing.getClass(),
+						entityKey.getIdentifier(),
+						entityReference.getEntityPersister().getEntityName()
+				);
+			}
+			checkVersion( resultSet, context, entityKey, existing );
+
+			// use the existing association as the hydrated state
+			processingState.registerEntityInstance( existing );
+			return;
+		}
+
+		// Otherwise, we need to load it from the ResultSet...
+
+		// determine which entity instance to use.  Either the supplied one, or instantiate one
+		Object optionalEntityInstance = null;
+		if ( isReturn && context.shouldUseOptionalEntityInformation() ) {
+			final EntityKey optionalEntityKey = ResultSetProcessorHelper.getOptionalObjectKey(
+					context.getQueryParameters(),
+					context.getSession()
+			);
+			if ( optionalEntityKey != null ) {
+				if ( optionalEntityKey.equals( entityKey ) ) {
+					optionalEntityInstance = context.getQueryParameters().getOptionalObject();
+				}
+			}
+		}
+
+		final String concreteEntityTypeName = getConcreteEntityTypeName( resultSet, context, entityKey );
+
+		final Object entityInstance = optionalEntityInstance != null
+				? optionalEntityInstance
+				: context.getSession().instantiate( concreteEntityTypeName, entityKey.getIdentifier() );
+
+		processingState.registerEntityInstance( entityInstance );
+
+		// need to hydrate it.
+		// grab its state from the ResultSet and keep it in the Session
+		// (but don't yet initialize the object itself)
+		// note that we acquire LockMode.READ even if it was not requested
+		log.trace( "hydrating entity state" );
+		final LockMode requestedLockMode = context.resolveLockMode( entityReference );
+		final LockMode lockModeToAcquire = requestedLockMode == LockMode.NONE
+				? LockMode.READ
+				: requestedLockMode;
+
+		loadFromResultSet(
+				resultSet,
+				context,
+				entityInstance,
+				concreteEntityTypeName,
+				entityKey,
+				lockModeToAcquire
+		);
+	}
+
+	private void handleMissingIdentifier(ResultSetProcessingContext context) {
+		if ( EntityFetch.class.isInstance( entityReference ) ) {
+			final EntityFetch fetch = (EntityFetch) entityReference;
+			final EntityType fetchedType = fetch.getFetchedType();
+			if ( ! fetchedType.isOneToOne() ) {
+				return;
+			}
+
+			final EntityReferenceProcessingState fetchOwnerState = context.getOwnerProcessingState( fetch );
+			if ( fetchOwnerState == null ) {
+				throw new IllegalStateException( "Could not locate fetch owner state" );
+			}
+
+			final EntityKey ownerEntityKey = fetchOwnerState.getEntityKey();
+			if ( ownerEntityKey == null ) {
+				throw new IllegalStateException( "Could not locate fetch owner EntityKey" );
+			}
+
+			context.getSession().getPersistenceContext().addNullProperty(
+					ownerEntityKey,
+					fetchedType.getPropertyName()
+			);
+		}
+	}
+
+	private void loadFromResultSet(
+			ResultSet resultSet,
+			ResultSetProcessingContext context,
+			Object entityInstance,
+			String concreteEntityTypeName,
+			EntityKey entityKey,
+			LockMode lockModeToAcquire) {
+		final Serializable id = entityKey.getIdentifier();
+
+		// Get the persister for the _subclass_
+		final Loadable concreteEntityPersister = (Loadable) context.getSession().getFactory().getEntityPersister( concreteEntityTypeName );
+
+		if ( log.isTraceEnabled() ) {
+			log.tracev(
+					"Initializing object from ResultSet: {0}",
+					MessageHelper.infoString(
+							concreteEntityPersister,
+							id,
+							context.getSession().getFactory()
+					)
+			);
+		}
+
+		// add temp entry so that the next step is circular-reference
+		// safe - only needed because some types don't take proper
+		// advantage of two-phase-load (esp. components)
+		TwoPhaseLoad.addUninitializedEntity(
+				entityKey,
+				entityInstance,
+				concreteEntityPersister,
+				lockModeToAcquire,
+				!context.getLoadPlan().areLazyAttributesForceFetched(),
+				context.getSession()
+		);
+
+		final EntityPersister rootEntityPersister = context.getSession().getFactory().getEntityPersister(
+				concreteEntityPersister.getRootEntityName()
+		);
+		final EntityReferenceAliases aliases = context.getAliasResolutionContext().resolveAliases( entityReference );
+		final Object[] values;
+		try {
+			values = concreteEntityPersister.hydrate(
+					resultSet,
+					id,
+					entityInstance,
+					(Loadable) entityReference.getEntityPersister(),
+					concreteEntityPersister == rootEntityPersister
+							? aliases.getColumnAliases().getSuffixedPropertyAliases()
+							: aliases.getColumnAliases().getSuffixedPropertyAliases( concreteEntityPersister ),
+					context.getLoadPlan().areLazyAttributesForceFetched(),
+					context.getSession()
+			);
+
+			context.getProcessingState( entityReference ).registerHydratedState( values );
+		}
+		catch (SQLException e) {
+			throw context.getSession().getFactory().getJdbcServices().getSqlExceptionHelper().convert(
+					e,
+					"Could not read entity state from ResultSet : " + entityKey
+			);
+		}
+
+		final Object rowId;
+		try {
+			rowId = concreteEntityPersister.hasRowId() ? resultSet.getObject( aliases.getColumnAliases().getRowIdAlias() ) : null;
+		}
+		catch (SQLException e) {
+			throw context.getSession().getFactory().getJdbcServices().getSqlExceptionHelper().convert(
+					e,
+					"Could not read entity row-id from ResultSet : " + entityKey
+			);
+		}
+
+		final EntityType entityType = EntityFetch.class.isInstance( entityReference )
+				? ( (EntityFetch) entityReference ).getFetchedType()
+				: entityReference.getEntityPersister().getEntityMetamodel().getEntityType();
+
+		if ( entityType != null ) {
+			String ukName = entityType.getRHSUniqueKeyPropertyName();
+			if ( ukName != null ) {
+				final int index = ( (UniqueKeyLoadable) concreteEntityPersister ).getPropertyIndex( ukName );
+				final Type type = concreteEntityPersister.getPropertyTypes()[index];
+
+				// polymorphism not really handled completely correctly,
+				// perhaps...well, actually its ok, assuming that the
+				// entity name used in the lookup is the same as the
+				// the one used here, which it will be
+
+				EntityUniqueKey euk = new EntityUniqueKey(
+						entityReference.getEntityPersister().getEntityName(),
+						ukName,
+						type.semiResolve( values[index], context.getSession(), entityInstance ),
+						type,
+						concreteEntityPersister.getEntityMode(),
+						context.getSession().getFactory()
+				);
+				context.getSession().getPersistenceContext().addEntity( euk, entityInstance );
+			}
+		}
+
+		TwoPhaseLoad.postHydrate(
+				concreteEntityPersister,
+				id,
+				values,
+				rowId,
+				entityInstance,
+				lockModeToAcquire,
+				!context.getLoadPlan().areLazyAttributesForceFetched(),
+				context.getSession()
+		);
+
+		context.registerHydratedEntity( entityReference, entityKey, entityInstance );
+	}
+
+	private String getConcreteEntityTypeName(
+			ResultSet resultSet,
+			ResultSetProcessingContext context,
+			EntityKey entityKey) {
+		final Loadable loadable = (Loadable) entityReference.getEntityPersister();
+		if ( ! loadable.hasSubclasses() ) {
+			return entityReference.getEntityPersister().getEntityName();
+		}
+
+		final Object discriminatorValue;
+		try {
+			discriminatorValue = loadable.getDiscriminatorType().nullSafeGet(
+					resultSet,
+					context.getAliasResolutionContext().resolveAliases( entityReference ).getColumnAliases().getSuffixedDiscriminatorAlias(),
+					context.getSession(),
+					null
+			);
+		}
+		catch (SQLException e) {
+			throw context.getSession().getFactory().getJdbcServices().getSqlExceptionHelper().convert(
+					e,
+					"Could not read discriminator value from ResultSet"
+			);
+		}
+
+		final String result = loadable.getSubclassForDiscriminatorValue( discriminatorValue );
+
+		if ( result == null ) {
+			// whoops! we got an instance of another class hierarchy branch
+			throw new WrongClassException(
+					"Discriminator: " + discriminatorValue,
+					entityKey.getIdentifier(),
+					entityReference.getEntityPersister().getEntityName()
+			);
+		}
+
+		return result;
+	}
+
+	private void checkVersion(
+			ResultSet resultSet,
+			ResultSetProcessingContext context,
+			EntityKey entityKey,
+			Object existing) {
+		final LockMode requestedLockMode = context.resolveLockMode( entityReference );
+		if ( requestedLockMode != LockMode.NONE ) {
+			final LockMode currentLockMode = context.getSession().getPersistenceContext().getEntry( existing ).getLockMode();
+			final boolean isVersionCheckNeeded = entityReference.getEntityPersister().isVersioned()
+					&& currentLockMode.lessThan( requestedLockMode );
+
+			// we don't need to worry about existing version being uninitialized because this block isn't called
+			// by a re-entrant load (re-entrant loads *always* have lock mode NONE)
+			if ( isVersionCheckNeeded ) {
+				//we only check the version when *upgrading* lock modes
+				checkVersion(
+						context.getSession(),
+						resultSet,
+						entityReference.getEntityPersister(),
+						context.getAliasResolutionContext().resolveAliases( entityReference ).getColumnAliases(),
+						entityKey,
+						existing
+				);
+				//we need to upgrade the lock mode to the mode requested
+				context.getSession().getPersistenceContext().getEntry( existing ).setLockMode( requestedLockMode );
+			}
+		}
+	}
+
+	private void checkVersion(
+			SessionImplementor session,
+			ResultSet resultSet,
+			EntityPersister persister,
+			EntityAliases entityAliases,
+			EntityKey entityKey,
+			Object entityInstance) {
+		final Object version = session.getPersistenceContext().getEntry( entityInstance ).getVersion();
+
+		if ( version != null ) {
+			//null version means the object is in the process of being loaded somewhere else in the ResultSet
+			VersionType versionType = persister.getVersionType();
+			final Object currentVersion;
+			try {
+				currentVersion = versionType.nullSafeGet(
+						resultSet,
+						entityAliases.getSuffixedVersionAliases(),
+						session,
+						null
+				);
+			}
+			catch (SQLException e) {
+				throw session.getFactory().getJdbcServices().getSqlExceptionHelper().convert(
+						e,
+						"Could not read version value from result set"
+				);
+			}
+
+			if ( !versionType.isEqual( version, currentVersion ) ) {
+				if ( session.getFactory().getStatistics().isStatisticsEnabled() ) {
+					session.getFactory().getStatisticsImplementor().optimisticFailure( persister.getEntityName() );
+				}
+				throw new StaleObjectStateException( persister.getEntityName(), entityKey.getIdentifier() );
+			}
+		}
+	}
+
+	public void resolve(ResultSet resultSet, ResultSetProcessingContext context) {
+		//To change body of created methods use File | Settings | File Templates.
+	}
+
+	public void finishUpRow(ResultSet resultSet, ResultSetProcessingContextImpl context) {
+		//To change body of created methods use File | Settings | File Templates.
+	}
+
+
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/EntityReturnReader.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/EntityReturnReader.java
new file mode 100644
index 0000000000..0d5edb86af
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/EntityReturnReader.java
@@ -0,0 +1,123 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.exec.process.internal;
+
+import java.sql.ResultSet;
+import java.sql.SQLException;
+
+import org.hibernate.AssertionFailure;
+import org.hibernate.engine.spi.EntityKey;
+import org.hibernate.loader.plan.exec.process.spi.ResultSetProcessingContext;
+import org.hibernate.loader.plan.exec.process.spi.ReturnReader;
+import org.hibernate.loader.plan.spi.EntityReturn;
+import org.hibernate.proxy.HibernateProxy;
+
+import static org.hibernate.loader.plan.exec.process.spi.ResultSetProcessingContext.EntityReferenceProcessingState;
+
+/**
+ * @author Steve Ebersole
+ */
+public class EntityReturnReader extends EntityReferenceReader implements ReturnReader {
+	private final EntityReturn entityReturn;
+
+	public EntityReturnReader(EntityReturn entityReturn) {
+		super( entityReturn );
+		this.entityReturn = entityReturn;
+	}
+
+//	@Override
+//	public void hydrate(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
+//		final EntityKey entityKey = getEntityKeyFromContext( context );
+//		if ( entityKey != null ) {
+//			getIdentifierResolutionContext( context ).registerEntityKey( entityKey );
+//			return;
+//		}
+//
+//		entityReturn.getIdentifierDescription().hydrate( resultSet, context );
+//
+//		for ( Fetch fetch : entityReturn.getFetches() ) {
+//			if ( FetchStrategyHelper.isJoinFetched( fetch.getFetchStrategy() ) ) {
+//				fetch.hydrate( resultSet, context );
+//			}
+//		}
+//	}
+
+	private EntityReferenceProcessingState getIdentifierResolutionContext(ResultSetProcessingContext context) {
+		final ResultSetProcessingContext.EntityReferenceProcessingState entityReferenceProcessingState = context.getProcessingState(
+				entityReturn
+		);
+
+		if ( entityReferenceProcessingState == null ) {
+			throw new AssertionFailure(
+					String.format(
+							"Could not locate EntityReferenceProcessingState for root entity return [%s (%s)]",
+							entityReturn.getPropertyPath().getFullPath(),
+							entityReturn.getEntityPersister().getEntityName()
+					)
+			);
+		}
+
+		return entityReferenceProcessingState;
+	}
+
+//	@Override
+//	public void resolve(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
+//		final EntityReferenceProcessingState entityReferenceProcessingState = getIdentifierResolutionContext( context );
+//		EntityKey entityKey = entityReferenceProcessingState.getEntityKey();
+//		if ( entityKey != null ) {
+//			return;
+//		}
+//
+//		entityKey = entityReturn.getIdentifierDescription().resolve( resultSet, context );
+//		entityReferenceProcessingState.registerEntityKey( entityKey );
+//
+//		for ( Fetch fetch : entityReturn.getFetches() ) {
+//			if ( FetchStrategyHelper.isJoinFetched( fetch.getFetchStrategy() ) ) {
+//				fetch.resolve( resultSet, context );
+//			}
+//		}
+//	}
+
+	@Override
+	public Object read(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
+		final EntityReferenceProcessingState processingState = getIdentifierResolutionContext( context );
+
+		final EntityKey entityKey = processingState.getEntityKey();
+		final Object entityInstance = context.getProcessingState( entityReturn ).getEntityInstance();
+
+		if ( context.shouldReturnProxies() ) {
+			final Object proxy = context.getSession().getPersistenceContext().proxyFor(
+					entityReturn.getEntityPersister(),
+					entityKey,
+					entityInstance
+			);
+			if ( proxy != entityInstance ) {
+				( (HibernateProxy) proxy ).getHibernateLazyInitializer().setImplementation( proxy );
+				return proxy;
+			}
+		}
+
+		return entityInstance;
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/Helper.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/Helper.java
new file mode 100644
index 0000000000..84da32cadd
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/Helper.java
@@ -0,0 +1,58 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.exec.process.internal;
+
+import org.hibernate.loader.plan.spi.CompositeFetch;
+import org.hibernate.loader.plan.spi.EntityElementGraph;
+import org.hibernate.loader.plan.spi.EntityReference;
+import org.hibernate.loader.plan.spi.FetchOwner;
+
+/**
+ * @author Steve Ebersole
+ */
+public class Helper {
+	/**
+	 * Singleton access
+	 */
+	public static final Helper INSTANCE = new Helper();
+
+	private Helper() {
+	}
+
+	public EntityReference findOwnerEntityReference(FetchOwner owner) {
+		if ( EntityReference.class.isInstance( owner ) ) {
+			return (EntityReference) owner;
+		}
+		else if ( CompositeFetch.class.isInstance( owner ) ) {
+			return findOwnerEntityReference( ( (CompositeFetch) owner).getOwner() );
+		}
+		else if ( EntityElementGraph.class.isInstance( owner ) ) {
+			return ( (EntityElementGraph) owner ).getEntityReference();
+		}
+
+		throw new IllegalStateException(
+				"Could not locate owner's EntityReference : " + owner.getPropertyPath().getFullPath()
+		);
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/OneToOneFetchReader.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/OneToOneFetchReader.java
new file mode 100644
index 0000000000..82bad7b476
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/OneToOneFetchReader.java
@@ -0,0 +1,46 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.exec.process.internal;
+
+import org.hibernate.loader.plan.spi.EntityFetch;
+import org.hibernate.loader.plan.spi.EntityReference;
+
+/**
+ * @author Steve Ebersole
+ */
+public class OneToOneFetchReader extends EntityReferenceReader {
+	private final EntityReference ownerEntityReference;
+
+	public OneToOneFetchReader(EntityFetch entityFetch, EntityReference ownerEntityReference) {
+		super( entityFetch, new OneToOneFetchIdentifierReader( entityFetch, ownerEntityReference ) );
+		this.ownerEntityReference = ownerEntityReference;
+	}
+
+	private static class OneToOneFetchIdentifierReader extends EntityIdentifierReaderImpl {
+		public OneToOneFetchIdentifierReader(EntityFetch oneToOne, EntityReference ownerEntityReference) {
+			super( oneToOne );
+		}
+
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/internal/ResultSetProcessingContextImpl.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/ResultSetProcessingContextImpl.java
similarity index 74%
rename from hibernate-core/src/main/java/org/hibernate/loader/internal/ResultSetProcessingContextImpl.java
rename to hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/ResultSetProcessingContextImpl.java
index 940dab925d..30fad0710d 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/internal/ResultSetProcessingContextImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/ResultSetProcessingContextImpl.java
@@ -1,803 +1,947 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.loader.internal;
+package org.hibernate.loader.plan.exec.process.internal;
 
 import java.io.Serializable;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
-import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
+import java.util.IdentityHashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
-import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.WrongClassException;
 import org.hibernate.collection.spi.PersistentCollection;
+import org.hibernate.engine.FetchStrategy;
 import org.hibernate.engine.internal.TwoPhaseLoad;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.EntityUniqueKey;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.SubselectFetch;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.event.spi.PostLoadEvent;
 import org.hibernate.event.spi.PreLoadEvent;
 import org.hibernate.loader.CollectionAliases;
 import org.hibernate.loader.EntityAliases;
+import org.hibernate.loader.plan.exec.process.spi.ResultSetProcessingContext;
+import org.hibernate.loader.plan.exec.query.spi.NamedParameterContext;
+import org.hibernate.loader.plan.exec.spi.AliasResolutionContext;
+import org.hibernate.loader.plan.exec.spi.LockModeResolver;
 import org.hibernate.loader.plan.spi.CollectionFetch;
 import org.hibernate.loader.plan.spi.CollectionReturn;
+import org.hibernate.loader.plan.spi.CompositeFetch;
+import org.hibernate.loader.plan.spi.EntityFetch;
 import org.hibernate.loader.plan.spi.EntityReference;
+import org.hibernate.loader.plan.spi.Fetch;
+import org.hibernate.loader.plan.spi.FetchOwner;
 import org.hibernate.loader.plan.spi.LoadPlan;
 import org.hibernate.loader.plan.spi.visit.LoadPlanVisitationStrategyAdapter;
 import org.hibernate.loader.plan.spi.visit.LoadPlanVisitor;
 import org.hibernate.loader.spi.AfterLoadAction;
-import org.hibernate.loader.spi.LoadQueryAliasResolutionContext;
-import org.hibernate.loader.spi.NamedParameterContext;
-import org.hibernate.loader.spi.ResultSetProcessingContext;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.UniqueKeyLoadable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.hibernate.type.VersionType;
 
 /**
  * @author Steve Ebersole
  */
 public class ResultSetProcessingContextImpl implements ResultSetProcessingContext {
 	private static final Logger LOG = Logger.getLogger( ResultSetProcessingContextImpl.class );
 
 	private final ResultSet resultSet;
 	private final SessionImplementor session;
 	private final LoadPlan loadPlan;
 	private final boolean readOnly;
+	private final boolean shouldUseOptionalEntityInformation;
+	private final boolean forceFetchLazyAttributes;
+	private final boolean shouldReturnProxies;
 	private final QueryParameters queryParameters;
 	private final NamedParameterContext namedParameterContext;
-	private final LoadQueryAliasResolutionContext aliasResolutionContext;
+	private final AliasResolutionContext aliasResolutionContext;
 	private final boolean hadSubselectFetches;
 
-	private final EntityKey dictatedRootEntityKey;
-
 	private List<HydratedEntityRegistration> currentRowHydratedEntityRegistrationList;
 
 	private Map<EntityPersister,Set<EntityKey>> subselectLoadableEntityKeyMap;
 	private List<HydratedEntityRegistration> hydratedEntityRegistrationList;
 
+	private LockModeResolver lockModeResolverDelegate = new LockModeResolver() {
+		@Override
+		public LockMode resolveLockMode(EntityReference entityReference) {
+			return LockMode.NONE;
+		}
+	};
+
+	/**
+	 * Builds a ResultSetProcessingContextImpl
+	 *
+	 * @param resultSet
+	 * @param session
+	 * @param loadPlan
+	 * @param readOnly
+	 * @param shouldUseOptionalEntityInformation There are times when the "optional entity information" on
+	 * QueryParameters should be used and times when they should not.  Collection initializers, batch loaders, etc
+	 * are times when it should NOT be used.
+	 * @param forceFetchLazyAttributes
+	 * @param shouldReturnProxies
+	 * @param queryParameters
+	 * @param namedParameterContext
+	 * @param aliasResolutionContext
+	 * @param hadSubselectFetches
+	 */
 	public ResultSetProcessingContextImpl(
 			ResultSet resultSet,
 			SessionImplementor session,
 			LoadPlan loadPlan,
 			boolean readOnly,
-			boolean useOptionalEntityKey,
+			boolean shouldUseOptionalEntityInformation,
+			boolean forceFetchLazyAttributes,
+			boolean shouldReturnProxies,
 			QueryParameters queryParameters,
 			NamedParameterContext namedParameterContext,
-			LoadQueryAliasResolutionContext aliasResolutionContext,
+			AliasResolutionContext aliasResolutionContext,
 			boolean hadSubselectFetches) {
 		this.resultSet = resultSet;
 		this.session = session;
 		this.loadPlan = loadPlan;
 		this.readOnly = readOnly;
+		this.shouldUseOptionalEntityInformation = shouldUseOptionalEntityInformation;
+		this.forceFetchLazyAttributes = forceFetchLazyAttributes;
+		this.shouldReturnProxies = shouldReturnProxies;
 		this.queryParameters = queryParameters;
 		this.namedParameterContext = namedParameterContext;
 		this.aliasResolutionContext = aliasResolutionContext;
 		this.hadSubselectFetches = hadSubselectFetches;
 
-		if ( useOptionalEntityKey ) {
-			this.dictatedRootEntityKey = ResultSetProcessorHelper.getOptionalObjectKey( queryParameters, session );
-			if ( this.dictatedRootEntityKey == null ) {
-				throw new HibernateException( "Unable to resolve optional entity-key" );
+		if ( shouldUseOptionalEntityInformation ) {
+			if ( queryParameters.getOptionalId() != null ) {
+				// make sure we have only one return
+				if ( loadPlan.getReturns().size() > 1 ) {
+					throw new IllegalStateException( "Cannot specify 'optional entity' values with multi-return load plans" );
+				}
 			}
 		}
-		else {
-			this.dictatedRootEntityKey = null;
-		}
 	}
 
 	@Override
 	public SessionImplementor getSession() {
 		return session;
 	}
 
 	@Override
+	public boolean shouldUseOptionalEntityInformation() {
+		return shouldUseOptionalEntityInformation;
+	}
+
+	@Override
 	public QueryParameters getQueryParameters() {
 		return queryParameters;
 	}
 
 	@Override
-	public EntityKey getDictatedRootEntityKey() {
-		return dictatedRootEntityKey;
+	public boolean shouldReturnProxies() {
+		return shouldReturnProxies;
+	}
+
+	@Override
+	public LoadPlan getLoadPlan() {
+		return loadPlan;
 	}
 
-	private Map<EntityReference,IdentifierResolutionContext> identifierResolutionContextMap;
+	@Override
+	public LockMode resolveLockMode(EntityReference entityReference) {
+		final LockMode lockMode = lockModeResolverDelegate.resolveLockMode( entityReference );
+		return LockMode.NONE == lockMode ? LockMode.NONE : lockMode;
+	}
+
+	private Map<EntityReference,EntityReferenceProcessingState> identifierResolutionContextMap;
 
 	@Override
-	public IdentifierResolutionContext getIdentifierResolutionContext(final EntityReference entityReference) {
+	public EntityReferenceProcessingState getProcessingState(final EntityReference entityReference) {
 		if ( identifierResolutionContextMap == null ) {
-			identifierResolutionContextMap = new HashMap<EntityReference, IdentifierResolutionContext>();
+			identifierResolutionContextMap = new IdentityHashMap<EntityReference, EntityReferenceProcessingState>();
 		}
-		IdentifierResolutionContext context = identifierResolutionContextMap.get( entityReference );
+
+		EntityReferenceProcessingState context = identifierResolutionContextMap.get( entityReference );
 		if ( context == null ) {
-			context = new IdentifierResolutionContext() {
-				private Object hydratedForm;
+			context = new EntityReferenceProcessingState() {
+				private boolean wasMissingIdentifier;
+				private Object identifierHydratedForm;
 				private EntityKey entityKey;
+				private Object[] hydratedState;
+				private Object entityInstance;
 
 				@Override
 				public EntityReference getEntityReference() {
 					return entityReference;
 				}
 
 				@Override
-				public void registerHydratedForm(Object hydratedForm) {
-					if ( this.hydratedForm != null ) {
-						// this could be bad...
+				public void registerMissingIdentifier() {
+					if ( !EntityFetch.class.isInstance( entityReference ) ) {
+						throw new IllegalStateException( "Missing return row identifier" );
 					}
-					this.hydratedForm = hydratedForm;
+					ResultSetProcessingContextImpl.this.registerNonExists( (EntityFetch) entityReference );
+					wasMissingIdentifier = true;
 				}
 
 				@Override
-				public Object getHydratedForm() {
-					return hydratedForm;
+				public boolean isMissingIdentifier() {
+					return wasMissingIdentifier;
+				}
+
+				@Override
+				public void registerIdentifierHydratedForm(Object identifierHydratedForm) {
+					this.identifierHydratedForm = identifierHydratedForm;
+				}
+
+				@Override
+				public Object getIdentifierHydratedForm() {
+					return identifierHydratedForm;
 				}
 
 				@Override
 				public void registerEntityKey(EntityKey entityKey) {
-					if ( this.entityKey != null ) {
-						// again, could be trouble...
-					}
 					this.entityKey = entityKey;
 				}
 
 				@Override
 				public EntityKey getEntityKey() {
 					return entityKey;
 				}
+
+				@Override
+				public void registerHydratedState(Object[] hydratedState) {
+					this.hydratedState = hydratedState;
+				}
+
+				@Override
+				public Object[] getHydratedState() {
+					return hydratedState;
+				}
+
+				@Override
+				public void registerEntityInstance(Object entityInstance) {
+					this.entityInstance = entityInstance;
+				}
+
+				@Override
+				public Object getEntityInstance() {
+					return entityInstance;
+				}
 			};
 			identifierResolutionContextMap.put( entityReference, context );
 		}
 
 		return context;
 	}
 
+	private void registerNonExists(EntityFetch fetch) {
+		final EntityType fetchedType = fetch.getFetchedType();
+		if ( ! fetchedType.isOneToOne() ) {
+			return;
+		}
+
+		final EntityReferenceProcessingState fetchOwnerState = getOwnerProcessingState( fetch );
+		if ( fetchOwnerState == null ) {
+			throw new IllegalStateException( "Could not locate fetch owner state" );
+		}
+
+		final EntityKey ownerEntityKey = fetchOwnerState.getEntityKey();
+		if ( ownerEntityKey == null ) {
+			throw new IllegalStateException( "Could not locate fetch owner EntityKey" );
+		}
+
+		session.getPersistenceContext().addNullProperty(
+				ownerEntityKey,
+				fetchedType.getPropertyName()
+		);
+	}
+
 	@Override
-	public Set<IdentifierResolutionContext> getIdentifierResolutionContexts() {
-		return Collections.unmodifiableSet(
-				new HashSet<IdentifierResolutionContext>( identifierResolutionContextMap.values() )
+	public EntityReferenceProcessingState getOwnerProcessingState(Fetch fetch) {
+		return getProcessingState( resolveFetchOwnerEntityReference( fetch ) );
+	}
+
+	private EntityReference resolveFetchOwnerEntityReference(Fetch fetch) {
+		final FetchOwner fetchOwner = fetch.getOwner();
+
+		if ( EntityReference.class.isInstance( fetchOwner ) ) {
+			return (EntityReference) fetchOwner;
+		}
+		else if ( CompositeFetch.class.isInstance( fetchOwner ) ) {
+			return resolveFetchOwnerEntityReference( (CompositeFetch) fetchOwner );
+		}
+
+		throw new IllegalStateException(
+				String.format(
+						"Cannot resolve FetchOwner [%s] of Fetch [%s (%s)] to an EntityReference",
+						fetchOwner,
+						fetch,
+						fetch.getPropertyPath()
+				)
 		);
 	}
 
 	@Override
-	public LoadQueryAliasResolutionContext getLoadQueryAliasResolutionContext() {
+	public AliasResolutionContext getAliasResolutionContext() {
 		return aliasResolutionContext;
 	}
 
 	@Override
 	public void checkVersion(
 			ResultSet resultSet,
 			EntityPersister persister,
 			EntityAliases entityAliases,
 			EntityKey entityKey,
 			Object entityInstance) {
 		final Object version = session.getPersistenceContext().getEntry( entityInstance ).getVersion();
 
 		if ( version != null ) {
 			//null version means the object is in the process of being loaded somewhere else in the ResultSet
 			VersionType versionType = persister.getVersionType();
 			final Object currentVersion;
 			try {
 				currentVersion = versionType.nullSafeGet(
 						resultSet,
 						entityAliases.getSuffixedVersionAliases(),
 						session,
 						null
 				);
 			}
 			catch (SQLException e) {
 				throw getSession().getFactory().getJdbcServices().getSqlExceptionHelper().convert(
 						e,
 						"Could not read version value from result set"
 				);
 			}
 
 			if ( !versionType.isEqual( version, currentVersion ) ) {
 				if ( session.getFactory().getStatistics().isStatisticsEnabled() ) {
 					session.getFactory().getStatisticsImplementor().optimisticFailure( persister.getEntityName() );
 				}
 				throw new StaleObjectStateException( persister.getEntityName(), entityKey.getIdentifier() );
 			}
 		}
 	}
 
 	@Override
 	public String getConcreteEntityTypeName(
 			final ResultSet rs,
 			final EntityPersister persister,
 			final EntityAliases entityAliases,
 			final EntityKey entityKey) {
 
 		final Loadable loadable = (Loadable) persister;
 		if ( ! loadable.hasSubclasses() ) {
 			return persister.getEntityName();
 		}
 
 		final Object discriminatorValue;
 		try {
 			discriminatorValue = loadable.getDiscriminatorType().nullSafeGet(
 					rs,
 					entityAliases.getSuffixedDiscriminatorAlias(),
 					session,
 					null
 			);
 		}
 		catch (SQLException e) {
 			throw getSession().getFactory().getJdbcServices().getSqlExceptionHelper().convert(
 					e,
 					"Could not read discriminator value from ResultSet"
 			);
 		}
 
 		final String result = loadable.getSubclassForDiscriminatorValue( discriminatorValue );
 
 		if ( result == null ) {
 			// whoops! we got an instance of another class hierarchy branch
 			throw new WrongClassException(
 					"Discriminator: " + discriminatorValue,
 					entityKey.getIdentifier(),
 					persister.getEntityName()
 			);
 		}
 
 		return result;
 	}
 
 	@Override
 	public Object resolveEntityKey(EntityKey entityKey, EntityKeyResolutionContext entityKeyContext) {
 		final Object existing = getSession().getEntityUsingInterceptor( entityKey );
 
 		if ( existing != null ) {
 			if ( !entityKeyContext.getEntityPersister().isInstance( existing ) ) {
 				throw new WrongClassException(
 						"loaded object was of wrong class " + existing.getClass(),
 						entityKey.getIdentifier(),
 						entityKeyContext.getEntityPersister().getEntityName()
 				);
 			}
 
 			final LockMode requestedLockMode = entityKeyContext.getLockMode() == null
 					? LockMode.NONE
 					: entityKeyContext.getLockMode();
 
 			if ( requestedLockMode != LockMode.NONE ) {
 				final LockMode currentLockMode = getSession().getPersistenceContext().getEntry( existing ).getLockMode();
 				final boolean isVersionCheckNeeded = entityKeyContext.getEntityPersister().isVersioned()
 						&& currentLockMode.lessThan( requestedLockMode );
 
 				// we don't need to worry about existing version being uninitialized because this block isn't called
 				// by a re-entrant load (re-entrant loads *always* have lock mode NONE)
 				if ( isVersionCheckNeeded ) {
 					//we only check the version when *upgrading* lock modes
 					checkVersion(
 							resultSet,
 							entityKeyContext.getEntityPersister(),
-							aliasResolutionContext.resolveEntityColumnAliases( entityKeyContext.getEntityReference() ),
+							aliasResolutionContext.resolveAliases( entityKeyContext.getEntityReference() ).getColumnAliases(),
 							entityKey,
 							existing
 					);
 					//we need to upgrade the lock mode to the mode requested
 					getSession().getPersistenceContext().getEntry( existing ).setLockMode( requestedLockMode );
 				}
 			}
 
 			return existing;
 		}
 		else {
 			final String concreteEntityTypeName = getConcreteEntityTypeName(
 					resultSet,
 					entityKeyContext.getEntityPersister(),
-					aliasResolutionContext.resolveEntityColumnAliases( entityKeyContext.getEntityReference() ),
+					aliasResolutionContext.resolveAliases( entityKeyContext.getEntityReference() ).getColumnAliases(),
 					entityKey
 			);
 
-			final Object entityInstance = getSession().instantiate(
-					concreteEntityTypeName,
-					entityKey.getIdentifier()
-			);
+			final Object entityInstance;
+//			if ( suppliedOptionalEntityKey != null && entityKey.equals( suppliedOptionalEntityKey ) ) {
+//				// its the given optional object
+//				entityInstance = queryParameters.getOptionalObject();
+//			}
+//			else {
+				// instantiate a new instance
+				entityInstance = session.instantiate( concreteEntityTypeName, entityKey.getIdentifier() );
+//			}
+
+			FetchStrategy fetchStrategy = null;
+			final EntityReference entityReference = entityKeyContext.getEntityReference();
+			if ( EntityFetch.class.isInstance( entityReference ) ) {
+				final EntityFetch fetch = (EntityFetch) entityReference;
+				fetchStrategy = fetch.getFetchStrategy();
+			}
 
 			//need to hydrate it.
 
 			// grab its state from the ResultSet and keep it in the Session
 			// (but don't yet initialize the object itself)
 			// note that we acquire LockMode.READ even if it was not requested
 			final LockMode requestedLockMode = entityKeyContext.getLockMode() == null
 					? LockMode.NONE
 					: entityKeyContext.getLockMode();
 			final LockMode acquiredLockMode = requestedLockMode == LockMode.NONE
 					? LockMode.READ
 					: requestedLockMode;
 
 			loadFromResultSet(
 					resultSet,
 					entityInstance,
 					concreteEntityTypeName,
 					entityKey,
-					aliasResolutionContext.resolveEntityColumnAliases( entityKeyContext.getEntityReference() ),
+					aliasResolutionContext.resolveAliases( entityKeyContext.getEntityReference() ).getColumnAliases(),
 					acquiredLockMode,
 					entityKeyContext.getEntityPersister(),
+					fetchStrategy,
 					true,
 					entityKeyContext.getEntityPersister().getEntityMetamodel().getEntityType()
 			);
 
 			// materialize associations (and initialize the object) later
-			registerHydratedEntity( entityKeyContext.getEntityPersister(), entityKey, entityInstance );
+			registerHydratedEntity( entityKeyContext.getEntityReference(), entityKey, entityInstance );
 
 			return entityInstance;
 		}
 	}
 
 	@Override
 	public void loadFromResultSet(
 			ResultSet resultSet,
 			Object entityInstance,
 			String concreteEntityTypeName,
 			EntityKey entityKey,
 			EntityAliases entityAliases,
 			LockMode acquiredLockMode,
 			EntityPersister rootPersister,
+			FetchStrategy fetchStrategy,
 			boolean eagerFetch,
 			EntityType associationType) {
 
 		final Serializable id = entityKey.getIdentifier();
 
 		// Get the persister for the _subclass_
 		final Loadable persister = (Loadable) getSession().getFactory().getEntityPersister( concreteEntityTypeName );
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev(
 					"Initializing object from ResultSet: {0}",
 					MessageHelper.infoString(
 							persister,
 							id,
 							getSession().getFactory()
 					)
 			);
 		}
 
 		// add temp entry so that the next step is circular-reference
 		// safe - only needed because some types don't take proper
 		// advantage of two-phase-load (esp. components)
 		TwoPhaseLoad.addUninitializedEntity(
 				entityKey,
 				entityInstance,
 				persister,
 				acquiredLockMode,
-				!eagerFetch,
+				!forceFetchLazyAttributes,
 				session
 		);
 
 		// This is not very nice (and quite slow):
 		final String[][] cols = persister == rootPersister ?
 				entityAliases.getSuffixedPropertyAliases() :
 				entityAliases.getSuffixedPropertyAliases(persister);
 
 		final Object[] values;
 		try {
 			values = persister.hydrate(
 					resultSet,
 					id,
 					entityInstance,
 					(Loadable) rootPersister,
 					cols,
-					eagerFetch,
+					loadPlan.areLazyAttributesForceFetched(),
 					session
 			);
 		}
 		catch (SQLException e) {
 			throw getSession().getFactory().getJdbcServices().getSqlExceptionHelper().convert(
 					e,
 					"Could not read entity state from ResultSet : " + entityKey
 			);
 		}
 
 		final Object rowId;
 		try {
 			rowId = persister.hasRowId() ? resultSet.getObject( entityAliases.getRowIdAlias() ) : null;
 		}
 		catch (SQLException e) {
 			throw getSession().getFactory().getJdbcServices().getSqlExceptionHelper().convert(
 					e,
 					"Could not read entity row-id from ResultSet : " + entityKey
 			);
 		}
 
 		if ( associationType != null ) {
 			String ukName = associationType.getRHSUniqueKeyPropertyName();
 			if ( ukName != null ) {
 				final int index = ( (UniqueKeyLoadable) persister ).getPropertyIndex( ukName );
 				final Type type = persister.getPropertyTypes()[index];
 
 				// polymorphism not really handled completely correctly,
 				// perhaps...well, actually its ok, assuming that the
 				// entity name used in the lookup is the same as the
 				// the one used here, which it will be
 
 				EntityUniqueKey euk = new EntityUniqueKey(
 						rootPersister.getEntityName(), //polymorphism comment above
 						ukName,
 						type.semiResolve( values[index], session, entityInstance ),
 						type,
 						persister.getEntityMode(),
 						session.getFactory()
 				);
 				session.getPersistenceContext().addEntity( euk, entityInstance );
 			}
 		}
 
 		TwoPhaseLoad.postHydrate(
 				persister,
 				id,
 				values,
 				rowId,
 				entityInstance,
 				acquiredLockMode,
-				!eagerFetch,
+				!loadPlan.areLazyAttributesForceFetched(),
 				session
 		);
 
 	}
 
 	public void readCollectionElements(final Object[] row) {
 			LoadPlanVisitor.visit(
 					loadPlan,
 					new LoadPlanVisitationStrategyAdapter() {
 						@Override
 						public void handleCollectionReturn(CollectionReturn rootCollectionReturn) {
 							readCollectionElement(
 									null,
 									null,
 									rootCollectionReturn.getCollectionPersister(),
-									aliasResolutionContext.resolveCollectionColumnAliases( rootCollectionReturn ),
+									aliasResolutionContext.resolveAliases( rootCollectionReturn ).getCollectionColumnAliases(),
 									resultSet,
 									session
 							);
 						}
 
 						@Override
 						public void startingCollectionFetch(CollectionFetch collectionFetch) {
 							// TODO: determine which element is the owner.
 							final Object owner = row[ 0 ];
 							readCollectionElement(
 									owner,
 									collectionFetch.getCollectionPersister().getCollectionType().getKeyOfOwner( owner, session ),
 									collectionFetch.getCollectionPersister(),
-									aliasResolutionContext.resolveCollectionColumnAliases( collectionFetch ),
+									aliasResolutionContext.resolveAliases( collectionFetch ).getCollectionColumnAliases(),
 									resultSet,
 									session
 							);
 						}
 
 						private void readCollectionElement(
 								final Object optionalOwner,
 								final Serializable optionalKey,
 								final CollectionPersister persister,
 								final CollectionAliases descriptor,
 								final ResultSet rs,
 								final SessionImplementor session) {
 
 							try {
 								final PersistenceContext persistenceContext = session.getPersistenceContext();
 
 								final Serializable collectionRowKey = (Serializable) persister.readKey(
 										rs,
 										descriptor.getSuffixedKeyAliases(),
 										session
 								);
 
 								if ( collectionRowKey != null ) {
 									// we found a collection element in the result set
 
 									if ( LOG.isDebugEnabled() ) {
 										LOG.debugf( "Found row of collection: %s",
 												MessageHelper.collectionInfoString( persister, collectionRowKey, session.getFactory() ) );
 									}
 
 									Object owner = optionalOwner;
 									if ( owner == null ) {
 										owner = persistenceContext.getCollectionOwner( collectionRowKey, persister );
 										if ( owner == null ) {
 											//TODO: This is assertion is disabled because there is a bug that means the
 											//	  original owner of a transient, uninitialized collection is not known
 											//	  if the collection is re-referenced by a different object associated
 											//	  with the current Session
 											//throw new AssertionFailure("bug loading unowned collection");
 										}
 									}
 
 									PersistentCollection rowCollection = persistenceContext.getLoadContexts()
 											.getCollectionLoadContext( rs )
 											.getLoadingCollection( persister, collectionRowKey );
 
 									if ( rowCollection != null ) {
 										rowCollection.readFrom( rs, persister, descriptor, owner );
 									}
 
 								}
 								else if ( optionalKey != null ) {
 									// we did not find a collection element in the result set, so we
 									// ensure that a collection is created with the owner's identifier,
 									// since what we have is an empty collection
 
 									if ( LOG.isDebugEnabled() ) {
 										LOG.debugf( "Result set contains (possibly empty) collection: %s",
 												MessageHelper.collectionInfoString( persister, optionalKey, session.getFactory() ) );
 									}
 
 									persistenceContext.getLoadContexts()
 											.getCollectionLoadContext( rs )
 											.getLoadingCollection( persister, optionalKey ); // handle empty collection
 
 								}
 
 								// else no collection element, but also no owner
 							}
 							catch ( SQLException sqle ) {
 								// TODO: would be nice to have the SQL string that failed...
 								throw session.getFactory().getSQLExceptionHelper().convert(
 										sqle,
 										"could not read next row of results"
 								);
 							}
 						}
 
 					}
 			);
 	}
 
 	@Override
-	public void registerHydratedEntity(EntityPersister persister, EntityKey entityKey, Object entityInstance) {
+	public void registerHydratedEntity(EntityReference entityReference, EntityKey entityKey, Object entityInstance) {
 		if ( currentRowHydratedEntityRegistrationList == null ) {
 			currentRowHydratedEntityRegistrationList = new ArrayList<HydratedEntityRegistration>();
 		}
-		currentRowHydratedEntityRegistrationList.add( new HydratedEntityRegistration( persister, entityKey, entityInstance ) );
+		currentRowHydratedEntityRegistrationList.add(
+				new HydratedEntityRegistration(
+						entityReference,
+						entityKey,
+						entityInstance
+				)
+		);
 	}
 
 	/**
 	 * Package-protected
 	 */
 	void finishUpRow() {
 		if ( currentRowHydratedEntityRegistrationList == null ) {
 			return;
 		}
 
 
 		// managing the running list of registrations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		if ( hydratedEntityRegistrationList == null ) {
 			hydratedEntityRegistrationList = new ArrayList<HydratedEntityRegistration>();
 		}
 		hydratedEntityRegistrationList.addAll( currentRowHydratedEntityRegistrationList );
 
 
 		// managing the map forms needed for subselect fetch generation ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		if ( hadSubselectFetches ) {
 			if ( subselectLoadableEntityKeyMap == null ) {
 				subselectLoadableEntityKeyMap = new HashMap<EntityPersister, Set<EntityKey>>();
 			}
 			for ( HydratedEntityRegistration registration : currentRowHydratedEntityRegistrationList ) {
-				Set<EntityKey> entityKeys = subselectLoadableEntityKeyMap.get( registration.persister );
+				Set<EntityKey> entityKeys = subselectLoadableEntityKeyMap.get( registration.entityReference.getEntityPersister() );
 				if ( entityKeys == null ) {
 					entityKeys = new HashSet<EntityKey>();
-					subselectLoadableEntityKeyMap.put( registration.persister, entityKeys );
+					subselectLoadableEntityKeyMap.put( registration.entityReference.getEntityPersister(), entityKeys );
 				}
 				entityKeys.add( registration.key );
 			}
 		}
 
 		// release the currentRowHydratedEntityRegistrationList entries
 		currentRowHydratedEntityRegistrationList.clear();
+
+		identifierResolutionContextMap.clear();
 	}
 
 	/**
 	 * Package-protected
 	 *
 	 * @param afterLoadActionList List of after-load actions to perform
 	 */
 	void finishUp(List<AfterLoadAction> afterLoadActionList) {
 		initializeEntitiesAndCollections( afterLoadActionList );
 		createSubselects();
 
 		if ( hydratedEntityRegistrationList != null ) {
 			hydratedEntityRegistrationList.clear();
 			hydratedEntityRegistrationList = null;
 		}
 
 		if ( subselectLoadableEntityKeyMap != null ) {
 			subselectLoadableEntityKeyMap.clear();
 			subselectLoadableEntityKeyMap = null;
 		}
 	}
 
 	private void initializeEntitiesAndCollections(List<AfterLoadAction> afterLoadActionList) {
 		// for arrays, we should end the collection load before resolving the entities, since the
 		// actual array instances are not instantiated during loading
 		finishLoadingArrays();
 
 
 		// IMPORTANT: reuse the same event instances for performance!
 		final PreLoadEvent preLoadEvent;
 		final PostLoadEvent postLoadEvent;
 		if ( session.isEventSource() ) {
 			preLoadEvent = new PreLoadEvent( (EventSource) session );
 			postLoadEvent = new PostLoadEvent( (EventSource) session );
 		}
 		else {
 			preLoadEvent = null;
 			postLoadEvent = null;
 		}
 
 		// now finish loading the entities (2-phase load)
 		performTwoPhaseLoad( preLoadEvent );
 
 		// now we can finalize loading collections
 		finishLoadingCollections();
 
 		// finally, perform post-load operations
 		postLoad( postLoadEvent, afterLoadActionList );
 	}
 
 	private void finishLoadingArrays() {
 		LoadPlanVisitor.visit(
 				loadPlan,
 				new LoadPlanVisitationStrategyAdapter() {
 					@Override
 					public void handleCollectionReturn(CollectionReturn rootCollectionReturn) {
 						endLoadingArray( rootCollectionReturn.getCollectionPersister() );
 					}
 
 					@Override
 					public void startingCollectionFetch(CollectionFetch collectionFetch) {
 						endLoadingArray( collectionFetch.getCollectionPersister() );
 					}
 
 					private void endLoadingArray(CollectionPersister persister) {
 						if ( persister.isArray() ) {
 							session.getPersistenceContext()
 									.getLoadContexts()
 									.getCollectionLoadContext( resultSet )
 									.endLoadingCollections( persister );
 						}
 					}
 				}
 		);
 	}
 
 	private void performTwoPhaseLoad(PreLoadEvent preLoadEvent) {
 		final int numberOfHydratedObjects = hydratedEntityRegistrationList == null
 				? 0
 				: hydratedEntityRegistrationList.size();
 		LOG.tracev( "Total objects hydrated: {0}", numberOfHydratedObjects );
 
 		if ( hydratedEntityRegistrationList == null ) {
 			return;
 		}
 
 		for ( HydratedEntityRegistration registration : hydratedEntityRegistrationList ) {
 			TwoPhaseLoad.initializeEntity( registration.instance, readOnly, session, preLoadEvent );
 		}
 	}
 
 	private void finishLoadingCollections() {
 		LoadPlanVisitor.visit(
 				loadPlan,
 				new LoadPlanVisitationStrategyAdapter() {
 					@Override
 					public void handleCollectionReturn(CollectionReturn rootCollectionReturn) {
 						endLoadingCollection( rootCollectionReturn.getCollectionPersister() );
 					}
 
 					@Override
 					public void startingCollectionFetch(CollectionFetch collectionFetch) {
 						endLoadingCollection( collectionFetch.getCollectionPersister() );
 					}
 
 					private void endLoadingCollection(CollectionPersister persister) {
 						if ( ! persister.isArray() ) {
 							session.getPersistenceContext()
 									.getLoadContexts()
 									.getCollectionLoadContext( resultSet )
 									.endLoadingCollections( persister );
 						}
 					}
 				}
 		);
 	}
 
 	private void postLoad(PostLoadEvent postLoadEvent, List<AfterLoadAction> afterLoadActionList) {
 		// Until this entire method is refactored w/ polymorphism, postLoad was
 		// split off from initializeEntity.  It *must* occur after
 		// endCollectionLoad to ensure the collection is in the
 		// persistence context.
 		if ( hydratedEntityRegistrationList == null ) {
 			return;
 		}
 
 		for ( HydratedEntityRegistration registration : hydratedEntityRegistrationList ) {
 			TwoPhaseLoad.postLoad( registration.instance, session, postLoadEvent );
 			if ( afterLoadActionList != null ) {
 				for ( AfterLoadAction afterLoadAction : afterLoadActionList ) {
-					afterLoadAction.afterLoad( session, registration.instance, (Loadable) registration.persister );
+					afterLoadAction.afterLoad( session, registration.instance, (Loadable) registration.entityReference.getEntityPersister() );
 				}
 			}
 		}
 	}
 
 	private void createSubselects() {
 		if ( subselectLoadableEntityKeyMap == null || subselectLoadableEntityKeyMap.size() <= 1 ) {
 			// if we only returned one entity, query by key is more efficient; so do nothing here
 			return;
 		}
 
 		final Map<String, int[]> namedParameterLocMap =
 				ResultSetProcessorHelper.buildNamedParameterLocMap( queryParameters, namedParameterContext );
 
 		for ( Map.Entry<EntityPersister, Set<EntityKey>> entry : subselectLoadableEntityKeyMap.entrySet() ) {
 			if ( ! entry.getKey().hasSubselectLoadableCollections() ) {
 				continue;
 			}
 
 			SubselectFetch subselectFetch = new SubselectFetch(
 					//getSQLString(),
 					null, // aliases[i],
 					(Loadable) entry.getKey(),
 					queryParameters,
 					entry.getValue(),
 					namedParameterLocMap
 			);
 
 			for ( EntityKey key : entry.getValue() ) {
 				session.getPersistenceContext().getBatchFetchQueue().addSubselect( key, subselectFetch );
 			}
 
 		}
 	}
 
 	private static class HydratedEntityRegistration {
-		private final EntityPersister persister;
+		private final EntityReference entityReference;
 		private final EntityKey key;
-		private final Object instance;
+		private Object instance;
 
-		private HydratedEntityRegistration(EntityPersister persister, EntityKey key, Object instance) {
-			this.persister = persister;
+		private HydratedEntityRegistration(EntityReference entityReference, EntityKey key, Object instance) {
+			this.entityReference = entityReference;
 			this.key = key;
 			this.instance = instance;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/internal/ResultSetProcessorHelper.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/ResultSetProcessorHelper.java
similarity index 65%
rename from hibernate-core/src/main/java/org/hibernate/loader/internal/ResultSetProcessorHelper.java
rename to hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/ResultSetProcessorHelper.java
index 8401218694..06f5a003ff 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/internal/ResultSetProcessorHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/ResultSetProcessorHelper.java
@@ -1,77 +1,98 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.loader.internal;
+package org.hibernate.loader.plan.exec.process.internal;
 
 import java.io.Serializable;
-import java.sql.ResultSet;
-import java.sql.SQLException;
 import java.util.HashMap;
 import java.util.Map;
 
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
-import org.hibernate.loader.EntityAliases;
-import org.hibernate.loader.plan.spi.EntityReference;
-import org.hibernate.loader.plan.spi.Fetch;
-import org.hibernate.loader.spi.NamedParameterContext;
-import org.hibernate.loader.spi.ResultSetProcessingContext;
+import org.hibernate.loader.plan.exec.query.spi.NamedParameterContext;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.type.CompositeType;
-import org.hibernate.type.Type;
 
 /**
  * @author Steve Ebersole
  */
 public class ResultSetProcessorHelper {
+	/**
+	 * Singleton access
+	 */
+	public static final ResultSetProcessorHelper INSTANCE = new ResultSetProcessorHelper();
+
 	public static EntityKey getOptionalObjectKey(QueryParameters queryParameters, SessionImplementor session) {
 		final Object optionalObject = queryParameters.getOptionalObject();
 		final Serializable optionalId = queryParameters.getOptionalId();
 		final String optionalEntityName = queryParameters.getOptionalEntityName();
 
-		if ( optionalObject != null && optionalEntityName != null ) {
-			return session.generateEntityKey( optionalId, session.getEntityPersister( optionalEntityName, optionalObject ) );
+		return INSTANCE.interpretEntityKey( session, optionalEntityName, optionalId, optionalObject );
+	}
+
+	public EntityKey interpretEntityKey(
+			SessionImplementor session,
+			String optionalEntityName,
+			Serializable optionalId,
+			Object optionalObject) {
+		if ( optionalEntityName != null ) {
+			final EntityPersister entityPersister;
+			if ( optionalObject != null ) {
+				entityPersister = session.getEntityPersister( optionalEntityName, optionalObject );
+			}
+			else {
+				entityPersister = session.getFactory().getEntityPersister( optionalEntityName );
+			}
+			if ( entityPersister.isInstance( optionalId ) ) {
+				// embedded (non-encapsulated) composite identifier
+				final Serializable identifierState = ( (CompositeType) entityPersister.getIdentifierType() ).getPropertyValues( optionalId, session );
+				return session.generateEntityKey( identifierState, entityPersister );
+			}
+			else {
+				return session.generateEntityKey( optionalId, entityPersister );
+			}
 		}
 		else {
 			return null;
 		}
 	}
 
 	public static Map<String, int[]> buildNamedParameterLocMap(
 			QueryParameters queryParameters,
 			NamedParameterContext namedParameterContext) {
 		if ( queryParameters.getNamedParameters() == null || queryParameters.getNamedParameters().isEmpty() ) {
 			return null;
 		}
 
 		final Map<String, int[]> namedParameterLocMap = new HashMap<String, int[]>();
 		for ( String name : queryParameters.getNamedParameters().keySet() ) {
 			namedParameterLocMap.put(
 					name,
 					namedParameterContext.getNamedParameterLocations( name )
 			);
 		}
 		return namedParameterLocMap;
 	}
+
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/ResultSetProcessorImpl.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/ResultSetProcessorImpl.java
new file mode 100644
index 0000000000..60a77179be
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/ResultSetProcessorImpl.java
@@ -0,0 +1,543 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.exec.process.internal;
+
+import java.io.Serializable;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.jboss.logging.Logger;
+
+import org.hibernate.cfg.NotYetImplementedException;
+import org.hibernate.dialect.pagination.LimitHelper;
+import org.hibernate.engine.FetchStyle;
+import org.hibernate.engine.spi.QueryParameters;
+import org.hibernate.engine.spi.RowSelection;
+import org.hibernate.engine.spi.SessionImplementor;
+import org.hibernate.loader.plan.exec.process.spi.ReturnReader;
+import org.hibernate.loader.plan.spi.CollectionFetch;
+import org.hibernate.loader.plan.spi.CollectionReference;
+import org.hibernate.loader.plan.spi.CollectionReturn;
+import org.hibernate.loader.plan.spi.CompositeFetch;
+import org.hibernate.loader.plan.spi.EntityFetch;
+import org.hibernate.loader.plan.spi.EntityReference;
+import org.hibernate.loader.plan.spi.EntityReturn;
+import org.hibernate.loader.plan.spi.Fetch;
+import org.hibernate.loader.plan.spi.FetchOwner;
+import org.hibernate.loader.plan.spi.LoadPlan;
+import org.hibernate.loader.plan.spi.ScalarReturn;
+import org.hibernate.loader.plan.spi.visit.LoadPlanVisitationStrategyAdapter;
+import org.hibernate.loader.plan.spi.visit.LoadPlanVisitor;
+import org.hibernate.loader.plan.spi.Return;
+import org.hibernate.loader.spi.AfterLoadAction;
+import org.hibernate.loader.spi.LoadPlanAdvisor;
+import org.hibernate.loader.plan.exec.spi.AliasResolutionContext;
+import org.hibernate.loader.plan.exec.query.spi.NamedParameterContext;
+import org.hibernate.loader.plan.exec.process.spi.ScrollableResultSetProcessor;
+import org.hibernate.loader.plan.exec.process.spi.ResultSetProcessor;
+import org.hibernate.persister.collection.CollectionPersister;
+import org.hibernate.pretty.MessageHelper;
+import org.hibernate.transform.ResultTransformer;
+
+/**
+ * @author Steve Ebersole
+ */
+public class ResultSetProcessorImpl implements ResultSetProcessor {
+	private static final Logger LOG = Logger.getLogger( ResultSetProcessorImpl.class );
+
+	private final LoadPlan baseLoadPlan;
+	private final RowReader rowReader;
+
+	private final boolean shouldUseOptionalEntityInstance;
+
+	private final boolean hadSubselectFetches;
+
+	public ResultSetProcessorImpl(
+			LoadPlan loadPlan,
+			boolean shouldUseOptionalEntityInstance) {
+		this.baseLoadPlan = loadPlan;
+		this.rowReader = buildRowReader( loadPlan );
+		this.shouldUseOptionalEntityInstance = shouldUseOptionalEntityInstance;
+
+		LocalVisitationStrategy strategy = new LocalVisitationStrategy();
+		LoadPlanVisitor.visit( loadPlan, strategy );
+		this.hadSubselectFetches = strategy.hadSubselectFetches;
+	}
+
+	private RowReader buildRowReader(LoadPlan loadPlan) {
+		switch ( loadPlan.getDisposition() ) {
+			case MIXED: {
+				return new MixedReturnRowReader( loadPlan );
+			}
+			case ENTITY_LOADER: {
+				return new EntityLoaderRowReader( loadPlan );
+			}
+			case COLLECTION_INITIALIZER: {
+				return new CollectionInitializerRowReader( loadPlan );
+			}
+			default: {
+				throw new IllegalStateException( "Unrecognized LoadPlan Return dispostion : " + loadPlan.getDisposition() );
+			}
+		}
+	}
+
+	@Override
+	public ScrollableResultSetProcessor toOnDemandForm() {
+		// todo : implement
+		throw new NotYetImplementedException();
+	}
+
+	@Override
+	public List extractResults(
+			LoadPlanAdvisor loadPlanAdvisor,
+			ResultSet resultSet,
+			final SessionImplementor session,
+			QueryParameters queryParameters,
+			NamedParameterContext namedParameterContext,
+			AliasResolutionContext aliasResolutionContext,
+			boolean returnProxies,
+			boolean readOnly,
+			ResultTransformer forcedResultTransformer,
+			List<AfterLoadAction> afterLoadActionList) throws SQLException {
+
+		final LoadPlan loadPlan = loadPlanAdvisor.advise( this.baseLoadPlan );
+		if ( loadPlan == null ) {
+			throw new IllegalStateException( "LoadPlanAdvisor returned null" );
+		}
+
+		handlePotentiallyEmptyCollectionRootReturns( loadPlan, queryParameters.getCollectionKeys(), resultSet, session );
+
+		final int maxRows;
+		final RowSelection selection = queryParameters.getRowSelection();
+		if ( LimitHelper.hasMaxRows( selection ) ) {
+			maxRows = selection.getMaxRows();
+			LOG.tracef( "Limiting ResultSet processing to just %s rows", maxRows );
+		}
+		else {
+			maxRows = Integer.MAX_VALUE;
+		}
+
+		// There are times when the "optional entity information" on QueryParameters should be used and
+		// times when they should be ignored.  Loader uses its isSingleRowLoader method to allow
+		// subclasses to override that.  Collection initializers, batch loaders, e.g. override that
+		// it to be false.  The 'shouldUseOptionalEntityInstance' setting is meant to fill that same role.
+		final boolean shouldUseOptionalEntityInstance = true;
+
+		// Handles the "FETCH ALL PROPERTIES" directive in HQL
+		final boolean forceFetchLazyAttributes = false;
+
+		final ResultSetProcessingContextImpl context = new ResultSetProcessingContextImpl(
+				resultSet,
+				session,
+				loadPlan,
+				readOnly,
+				shouldUseOptionalEntityInstance,
+				forceFetchLazyAttributes,
+				returnProxies,
+				queryParameters,
+				namedParameterContext,
+				aliasResolutionContext,
+				hadSubselectFetches
+		);
+
+		final List loadResults = new ArrayList();
+
+		LOG.trace( "Processing result set" );
+		int count;
+		for ( count = 0; count < maxRows && resultSet.next(); count++ ) {
+			LOG.debugf( "Starting ResultSet row #%s", count );
+
+			Object logicalRow = rowReader.readRow( resultSet, context );
+
+			// todo : apply transformers here?
+
+			loadResults.add( logicalRow );
+
+			context.finishUpRow();
+		}
+
+		LOG.tracev( "Done processing result set ({0} rows)", count );
+
+		context.finishUp( afterLoadActionList );
+
+		session.getPersistenceContext().initializeNonLazyCollections();
+
+		return loadResults;
+	}
+
+
+	private void handlePotentiallyEmptyCollectionRootReturns(
+			LoadPlan loadPlan,
+			Serializable[] collectionKeys,
+			ResultSet resultSet,
+			SessionImplementor session) {
+		if ( collectionKeys == null ) {
+			// this is not a collection initializer (and empty collections will be detected by looking for
+			// the owner's identifier in the result set)
+			return;
+		}
+
+		// this is a collection initializer, so we must create a collection
+		// for each of the passed-in keys, to account for the possibility
+		// that the collection is empty and has no rows in the result set
+		//
+		// todo : move this inside CollectionReturn ?
+		CollectionPersister persister = ( (CollectionReturn) loadPlan.getReturns().get( 0 ) ).getCollectionPersister();
+		for ( Serializable key : collectionKeys ) {
+			if ( LOG.isDebugEnabled() ) {
+				LOG.debugf(
+						"Preparing collection intializer : %s",
+							MessageHelper.collectionInfoString( persister, key, session.getFactory() )
+				);
+				session.getPersistenceContext()
+						.getLoadContexts()
+						.getCollectionLoadContext( resultSet )
+						.getLoadingCollection( persister, key );
+			}
+		}
+	}
+
+
+	private class LocalVisitationStrategy extends LoadPlanVisitationStrategyAdapter {
+		private boolean hadSubselectFetches = false;
+
+		@Override
+		public void startingEntityFetch(EntityFetch entityFetch) {
+		// only collections are currently supported for subselect fetching.
+		//			hadSubselectFetches = hadSubselectFetches
+		//					|| entityFetch.getFetchStrategy().getStyle() == FetchStyle.SUBSELECT;
+		}
+
+		@Override
+		public void startingCollectionFetch(CollectionFetch collectionFetch) {
+			hadSubselectFetches = hadSubselectFetches
+					|| collectionFetch.getFetchStrategy().getStyle() == FetchStyle.SUBSELECT;
+		}
+	}
+
+	private static interface RowReader {
+		Object readRow(ResultSet resultSet, ResultSetProcessingContextImpl context) throws SQLException;
+	}
+
+	private static abstract class AbstractRowReader implements RowReader {
+
+		@Override
+		public Object readRow(ResultSet resultSet, ResultSetProcessingContextImpl context) throws SQLException {
+			final List<EntityReferenceReader> entityReferenceReaders = getEntityReferenceReaders();
+			final List<CollectionReferenceReader> collectionReferenceReaders = getCollectionReferenceReaders();
+
+			final boolean hasEntityReferenceReaders = entityReferenceReaders != null && entityReferenceReaders.size() > 0;
+			final boolean hasCollectionReferenceReaders = collectionReferenceReaders != null && collectionReferenceReaders.size() > 0;
+
+			if ( hasEntityReferenceReaders ) {
+				// 	1) allow entity references to resolve identifiers (in 2 steps)
+				for ( EntityReferenceReader entityReferenceReader : entityReferenceReaders ) {
+					entityReferenceReader.hydrateIdentifier( resultSet, context );
+				}
+				for ( EntityReferenceReader entityReferenceReader : entityReferenceReaders ) {
+					entityReferenceReader.resolveEntityKey( resultSet, context );
+				}
+
+
+				// 2) allow entity references to resolve their hydrated state and entity instance
+				for ( EntityReferenceReader entityReferenceReader : entityReferenceReaders ) {
+					entityReferenceReader.hydrateEntityState( resultSet, context );
+				}
+			}
+
+
+			// 3) read the logical row
+
+			Object logicalRow = readLogicalRow( resultSet, context );
+
+
+			// 4) allow entities and collection to read their elements
+			if ( hasEntityReferenceReaders ) {
+				for ( EntityReferenceReader entityReferenceReader : entityReferenceReaders ) {
+					entityReferenceReader.finishUpRow( resultSet, context );
+				}
+			}
+			if ( hasCollectionReferenceReaders ) {
+				for ( CollectionReferenceReader collectionReferenceReader : collectionReferenceReaders ) {
+					collectionReferenceReader.finishUpRow( resultSet, context );
+				}
+			}
+
+			return logicalRow;
+		}
+
+		protected abstract List<EntityReferenceReader> getEntityReferenceReaders();
+		protected abstract List<CollectionReferenceReader> getCollectionReferenceReaders();
+
+		protected abstract Object readLogicalRow(ResultSet resultSet, ResultSetProcessingContextImpl context)
+				throws SQLException;
+
+	}
+
+	private class MixedReturnRowReader extends AbstractRowReader implements RowReader {
+		private final List<ReturnReader> returnReaders;
+		private List<EntityReferenceReader> entityReferenceReaders = new ArrayList<EntityReferenceReader>();
+		private List<CollectionReferenceReader> collectionReferenceReaders = new ArrayList<CollectionReferenceReader>();
+
+		private final int numberOfReturns;
+
+		public MixedReturnRowReader(LoadPlan loadPlan) {
+			LoadPlanVisitor.visit(
+					loadPlan,
+					new LoadPlanVisitationStrategyAdapter() {
+						@Override
+						public void startingEntityFetch(EntityFetch entityFetch) {
+							entityReferenceReaders.add( new EntityReferenceReader( entityFetch ) );
+						}
+
+						@Override
+						public void startingCollectionFetch(CollectionFetch collectionFetch) {
+							collectionReferenceReaders.add( new CollectionReferenceReader( collectionFetch ) );
+						}
+					}
+			);
+
+			final List<ReturnReader> readers = new ArrayList<ReturnReader>();
+
+			for ( Return rtn : loadPlan.getReturns() ) {
+				final ReturnReader returnReader = buildReturnReader( rtn );
+				if ( EntityReferenceReader.class.isInstance( returnReader ) ) {
+					entityReferenceReaders.add( (EntityReferenceReader) returnReader );
+				}
+				readers.add( returnReader );
+			}
+
+			this.returnReaders = readers;
+			this.numberOfReturns = readers.size();
+		}
+
+		@Override
+		protected List<EntityReferenceReader> getEntityReferenceReaders() {
+			return entityReferenceReaders;
+		}
+
+		@Override
+		protected List<CollectionReferenceReader> getCollectionReferenceReaders() {
+			return collectionReferenceReaders;
+		}
+
+		@Override
+		protected Object readLogicalRow(ResultSet resultSet, ResultSetProcessingContextImpl context) throws SQLException {
+			Object[] logicalRow = new Object[ numberOfReturns ];
+			int pos = 0;
+			for ( ReturnReader reader : returnReaders ) {
+				logicalRow[pos] = reader.read( resultSet, context );
+				pos++;
+			}
+			return logicalRow;
+		}
+	}
+
+	private static ReturnReader buildReturnReader(Return rtn) {
+		if ( ScalarReturn.class.isInstance( rtn ) ) {
+			return new ScalarReturnReader( (ScalarReturn) rtn );
+		}
+		else if ( EntityReturn.class.isInstance( rtn ) ) {
+			return new EntityReturnReader( (EntityReturn) rtn );
+		}
+		else if ( CollectionReturn.class.isInstance( rtn ) ) {
+			return new CollectionReturnReader( (CollectionReturn) rtn );
+		}
+		else {
+			throw new IllegalStateException( "Unknown Return type : " + rtn );
+		}
+	}
+
+	private static interface EntityReferenceReaderListBuildingAccess {
+		public void add(EntityReferenceReader reader);
+	}
+
+	private static interface CollectionReferenceReaderListBuildingAccess {
+		public void add(CollectionReferenceReader reader);
+	}
+
+
+	private class EntityLoaderRowReader extends AbstractRowReader implements RowReader {
+		private final EntityReturnReader returnReader;
+		private final List<EntityReferenceReader> entityReferenceReaders = new ArrayList<EntityReferenceReader>();
+		private List<CollectionReferenceReader> collectionReferenceReaders = null;
+
+		public EntityLoaderRowReader(LoadPlan loadPlan) {
+			final EntityReturn entityReturn = (EntityReturn) loadPlan.getReturns().get( 0 );
+			this.returnReader = (EntityReturnReader) buildReturnReader( entityReturn );
+
+//			final EntityReferenceReaderListBuildingAccess entityReaders = new EntityReferenceReaderListBuildingAccess() {
+//				@Override
+//				public void add(EntityReferenceReader reader) {
+//					entityReferenceReaders.add( reader );
+//				}
+//			};
+//
+//			final CollectionReferenceReaderListBuildingAccess collectionReaders = new CollectionReferenceReaderListBuildingAccess() {
+//				@Override
+//				public void add(CollectionReferenceReader reader) {
+//					if ( collectionReferenceReaders == null ) {
+//						collectionReferenceReaders = new ArrayList<CollectionReferenceReader>();
+//					}
+//					collectionReferenceReaders.add( reader );
+//				}
+//			};
+//
+//			buildFetchReaders( entityReaders, collectionReaders, entityReturn, returnReader );
+
+			LoadPlanVisitor.visit(
+					loadPlan,
+					new LoadPlanVisitationStrategyAdapter() {
+						@Override
+						public void startingEntityFetch(EntityFetch entityFetch) {
+							entityReferenceReaders.add( new EntityReferenceReader( entityFetch ) );
+						}
+
+						@Override
+						public void startingCollectionFetch(CollectionFetch collectionFetch) {
+							if ( collectionReferenceReaders == null ) {
+								collectionReferenceReaders = new ArrayList<CollectionReferenceReader>();
+							}
+							collectionReferenceReaders.add( new CollectionReferenceReader( collectionFetch ) );
+						}
+					}
+			);
+
+			entityReferenceReaders.add( returnReader );
+		}
+
+//		private void buildFetchReaders(
+//				EntityReferenceReaderListBuildingAccess entityReaders,
+//				CollectionReferenceReaderListBuildingAccess collectionReaders,
+//				FetchOwner fetchOwner,
+//				EntityReferenceReader entityReferenceReader) {
+//			for ( Fetch fetch : fetchOwner.getFetches() ) {
+//				if ( CollectionFetch.class.isInstance( fetch ) ) {
+//					final CollectionFetch collectionFetch = (CollectionFetch) fetch;
+//					buildFetchReaders(
+//							entityReaders,
+//							collectionReaders,
+//							collectionFetch.getIndexGraph(),
+//							null
+//					);
+//					buildFetchReaders(
+//							entityReaders,
+//							collectionReaders,
+//							collectionFetch.getElementGraph(),
+//							null
+//					);
+//					collectionReaders.add( new CollectionReferenceReader( collectionFetch ) );
+//				}
+//				else if ( CompositeFetch.class.isInstance( fetch ) ) {
+//					buildFetchReaders(
+//							entityReaders,
+//							collectionReaders,
+//							(CompositeFetch) fetch,
+//							entityReferenceReader
+//					);
+//				}
+//				else {
+//					final EntityFetch entityFetch = (EntityFetch) fetch;
+//					if ( entityFetch.getFetchedType().isOneToOne() ) {
+//						// entityReferenceReader should reference the owner still...
+//						if ( entityReferenceReader == null ) {
+//							throw new IllegalStateException( "Entity reader for one-to-one fetch owner not known" );
+//						}
+//						final EntityReferenceReader fetchReader = new OneToOneFetchReader(
+//								entityFetch,
+//								entityReferenceReader.getEntityReference()
+//						);
+//					}
+//					else {
+//
+//					}
+//				}
+//			}
+//			//To change body of created methods use File | Settings | File Templates.
+//		}
+
+		@Override
+		protected List<EntityReferenceReader> getEntityReferenceReaders() {
+			return entityReferenceReaders;
+		}
+
+		@Override
+		protected List<CollectionReferenceReader> getCollectionReferenceReaders() {
+			return collectionReferenceReaders;
+		}
+
+		@Override
+		protected Object readLogicalRow(ResultSet resultSet, ResultSetProcessingContextImpl context) throws SQLException {
+			return returnReader.read( resultSet, context );
+		}
+	}
+
+	private class CollectionInitializerRowReader extends AbstractRowReader implements RowReader {
+		private final CollectionReturnReader returnReader;
+
+		private List<EntityReferenceReader> entityReferenceReaders = null;
+		private final List<CollectionReferenceReader> collectionReferenceReaders = new ArrayList<CollectionReferenceReader>();
+
+		public CollectionInitializerRowReader(LoadPlan loadPlan) {
+			returnReader = (CollectionReturnReader) buildReturnReader( loadPlan.getReturns().get( 0 ) );
+
+			LoadPlanVisitor.visit(
+					loadPlan,
+					new LoadPlanVisitationStrategyAdapter() {
+						@Override
+						public void startingEntityFetch(EntityFetch entityFetch) {
+							if ( entityReferenceReaders == null ) {
+								entityReferenceReaders = new ArrayList<EntityReferenceReader>();
+							}
+							entityReferenceReaders.add( new EntityReferenceReader( entityFetch ) );
+						}
+
+						@Override
+						public void startingCollectionFetch(CollectionFetch collectionFetch) {
+							collectionReferenceReaders.add( new CollectionReferenceReader( collectionFetch ) );
+						}
+					}
+			);
+
+			collectionReferenceReaders.add( returnReader );
+		}
+
+		@Override
+		protected List<EntityReferenceReader> getEntityReferenceReaders() {
+			return entityReferenceReaders;
+		}
+
+		@Override
+		protected List<CollectionReferenceReader> getCollectionReferenceReaders() {
+			return collectionReferenceReaders;
+		}
+
+		@Override
+		protected Object readLogicalRow(ResultSet resultSet, ResultSetProcessingContextImpl context) throws SQLException {
+			return returnReader.read( resultSet, context );
+		}
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/ScalarReturnReader.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/ScalarReturnReader.java
new file mode 100644
index 0000000000..e36347f0b0
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/ScalarReturnReader.java
@@ -0,0 +1,52 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.exec.process.internal;
+
+import java.sql.ResultSet;
+import java.sql.SQLException;
+
+import org.hibernate.loader.plan.exec.process.spi.ResultSetProcessingContext;
+import org.hibernate.loader.plan.exec.process.spi.ReturnReader;
+import org.hibernate.loader.plan.spi.ScalarReturn;
+
+/**
+ * @author Steve Ebersole
+ */
+public class ScalarReturnReader implements ReturnReader {
+	private final ScalarReturn scalarReturn;
+
+	public ScalarReturnReader(ScalarReturn scalarReturn) {
+		this.scalarReturn = scalarReturn;
+	}
+
+	@Override
+	public Object read(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
+		return scalarReturn.getType().nullSafeGet(
+				resultSet,
+				context.getAliasResolutionContext().resolveScalarColumnAliases( scalarReturn ),
+				context.getSession(),
+				null
+		);
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/internal/ScrollableResultSetProcessorImpl.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/ScrollableResultSetProcessorImpl.java
similarity index 93%
rename from hibernate-core/src/main/java/org/hibernate/loader/internal/ScrollableResultSetProcessorImpl.java
rename to hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/ScrollableResultSetProcessorImpl.java
index 5e2d06104e..309d8cde04 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/internal/ScrollableResultSetProcessorImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/ScrollableResultSetProcessorImpl.java
@@ -1,58 +1,58 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.loader.internal;
+package org.hibernate.loader.plan.exec.process.internal;
 
 import java.sql.ResultSet;
 
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
-import org.hibernate.loader.spi.ScrollableResultSetProcessor;
+import org.hibernate.loader.plan.exec.process.spi.ScrollableResultSetProcessor;
 
 /**
  * @author Steve Ebersole
  */
 public class ScrollableResultSetProcessorImpl implements ScrollableResultSetProcessor {
 	@Override
 	public Object extractSingleRow(
 			ResultSet resultSet,
 			SessionImplementor session,
 			QueryParameters queryParameters) {
 		return null;
 	}
 
 	@Override
 	public Object extractLogicalRowForward(
 			ResultSet resultSet, SessionImplementor session, QueryParameters queryParameters) {
 		return null;  //To change body of implemented methods use File | Settings | File Templates.
 	}
 
 	@Override
 	public Object extractLogicalRowReverse(
 			ResultSet resultSet,
 			SessionImplementor session,
 			QueryParameters queryParameters,
 			boolean isLogicallyAfterLast) {
 		return null;  //To change body of implemented methods use File | Settings | File Templates.
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/package-info.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/package-info.java
new file mode 100644
index 0000000000..028443e4af
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/package-info.java
@@ -0,0 +1,4 @@
+/**
+ * Defines support for processing ResultSet values as defined by a LoadPlan
+ */
+package org.hibernate.loader.plan.exec.process;
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/spi/ResultSetProcessingContext.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/spi/ResultSetProcessingContext.java
new file mode 100644
index 0000000000..43249d2ed8
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/spi/ResultSetProcessingContext.java
@@ -0,0 +1,171 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.exec.process.spi;
+
+import java.sql.ResultSet;
+import java.sql.SQLException;
+
+import org.hibernate.LockMode;
+import org.hibernate.engine.FetchStrategy;
+import org.hibernate.engine.spi.EntityKey;
+import org.hibernate.engine.spi.QueryParameters;
+import org.hibernate.engine.spi.SessionImplementor;
+import org.hibernate.loader.EntityAliases;
+import org.hibernate.loader.plan.exec.spi.AliasResolutionContext;
+import org.hibernate.loader.plan.exec.spi.LockModeResolver;
+import org.hibernate.loader.plan.spi.EntityReference;
+import org.hibernate.loader.plan.spi.Fetch;
+import org.hibernate.loader.plan.spi.LoadPlan;
+import org.hibernate.persister.entity.EntityPersister;
+import org.hibernate.type.EntityType;
+
+/**
+ * @author Steve Ebersole
+ */
+public interface ResultSetProcessingContext extends LockModeResolver {
+	public SessionImplementor getSession();
+
+	public QueryParameters getQueryParameters();
+
+	public boolean shouldUseOptionalEntityInformation();
+
+	public boolean shouldReturnProxies();
+
+	public LoadPlan getLoadPlan();
+
+	/**
+	 * Holds all pieces of information known about an entity reference in relation to each row as we process the
+	 * result set.  Caches these values and makes it easy for access while processing Fetches.
+	 */
+	public static interface EntityReferenceProcessingState {
+		/**
+		 * The EntityReference for which this is collecting process state
+		 *
+		 * @return The EntityReference
+		 */
+		public EntityReference getEntityReference();
+
+		/**
+		 * Register the fact that no identifier was found on attempt to hydrate it from ResultSet
+		 */
+		public void registerMissingIdentifier();
+
+		/**
+		 *
+		 * @return
+		 */
+		public boolean isMissingIdentifier();
+
+		/**
+		 * Register the hydrated form (raw Type-read ResultSet values) of the entity's identifier for the row
+		 * currently being processed.
+		 *
+		 * @param hydratedForm The entity identifier hydrated state
+		 */
+		public void registerIdentifierHydratedForm(Object hydratedForm);
+
+		/**
+		 * Obtain the hydrated form (the raw Type-read ResultSet values) of the entity's identifier
+		 *
+		 * @return The entity identifier hydrated state
+		 */
+		public Object getIdentifierHydratedForm();
+
+		/**
+		 * Register the processed EntityKey for this Entity for the row currently being processed.
+		 *
+		 * @param entityKey The processed EntityKey for this EntityReference
+		 */
+		public void registerEntityKey(EntityKey entityKey);
+
+		/**
+		 * Obtain the registered EntityKey for this EntityReference for the row currently being processed.
+		 *
+		 * @return The registered EntityKey for this EntityReference
+		 */
+		public EntityKey getEntityKey();
+
+		public void registerHydratedState(Object[] hydratedState);
+		public Object[] getHydratedState();
+
+		// usually uninitialized at this point
+		public void registerEntityInstance(Object instance);
+
+		// may be uninitialized
+		public Object getEntityInstance();
+
+	}
+
+	public EntityReferenceProcessingState getProcessingState(EntityReference entityReference);
+
+	/**
+	 * Find the EntityReferenceProcessingState for the FetchOwner of the given Fetch.
+	 *
+	 * @param fetch The Fetch for which to find the EntityReferenceProcessingState of its FetchOwner.
+	 *
+	 * @return The FetchOwner's EntityReferenceProcessingState
+	 */
+	public EntityReferenceProcessingState getOwnerProcessingState(Fetch fetch);
+
+
+	public AliasResolutionContext getAliasResolutionContext();
+
+	public void registerHydratedEntity(EntityReference entityReference, EntityKey entityKey, Object entityInstance);
+
+	public static interface EntityKeyResolutionContext {
+		public EntityPersister getEntityPersister();
+		public LockMode getLockMode();
+		public EntityReference getEntityReference();
+	}
+
+	public Object resolveEntityKey(EntityKey entityKey, EntityKeyResolutionContext entityKeyContext);
+
+
+	// should be able to get rid of the methods below here from the interface ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+	public void checkVersion(
+			ResultSet resultSet,
+			EntityPersister persister,
+			EntityAliases entityAliases,
+			EntityKey entityKey,
+			Object entityInstance) throws SQLException;
+
+	public String getConcreteEntityTypeName(
+			ResultSet resultSet,
+			EntityPersister persister,
+			EntityAliases entityAliases,
+			EntityKey entityKey) throws SQLException;
+
+	public void loadFromResultSet(
+			ResultSet resultSet,
+			Object entityInstance,
+			String concreteEntityTypeName,
+			EntityKey entityKey,
+			EntityAliases entityAliases,
+			LockMode acquiredLockMode,
+			EntityPersister persister,
+			FetchStrategy fetchStrategy,
+			boolean eagerFetch,
+			EntityType associationType) throws SQLException;
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/spi/ResultSetProcessor.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/spi/ResultSetProcessor.java
similarity index 89%
rename from hibernate-core/src/main/java/org/hibernate/loader/spi/ResultSetProcessor.java
rename to hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/spi/ResultSetProcessor.java
index df733dc16c..211d48d83a 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/spi/ResultSetProcessor.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/spi/ResultSetProcessor.java
@@ -1,74 +1,78 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.loader.spi;
+package org.hibernate.loader.plan.exec.process.spi;
 
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.List;
 
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
+import org.hibernate.loader.plan.exec.query.spi.NamedParameterContext;
+import org.hibernate.loader.plan.exec.spi.AliasResolutionContext;
+import org.hibernate.loader.spi.AfterLoadAction;
+import org.hibernate.loader.spi.LoadPlanAdvisor;
 import org.hibernate.transform.ResultTransformer;
 
 /**
  * Contract for processing JDBC ResultSets.  Separated because ResultSets can be chained and we'd really like to
  * reuse this logic across all result sets.
  * <p/>
  * todo : investigate having this work with non-JDBC results; maybe just typed as Object? or a special Result contract?
  *
  * @author Steve Ebersole
  */
 public interface ResultSetProcessor {
 
 	public ScrollableResultSetProcessor toOnDemandForm();
 
 	/**
 	 * Process an entire ResultSet, performing all extractions.
 	 *
 	 * Semi-copy of {@link org.hibernate.loader.Loader#doQuery}, with focus on just the ResultSet processing bit.
 	 *
 	 * @param loadPlanAdvisor A dynamic advisor on the load plan.
 	 * @param resultSet The result set being processed.
 	 * @param session The originating session
 	 * @param queryParameters The "parameters" used to build the query
 	 * @param returnProxies Can proxies be returned (not the same as can they be created!)
 	 * @param forcedResultTransformer My old "friend" ResultTransformer...
 	 * @param afterLoadActions Actions to be performed after loading an entity.
 	 *
 	 * @return The extracted results list.
 	 *
 	 * @throws java.sql.SQLException Indicates a problem access the JDBC ResultSet
 	 */
 	public List extractResults(
 			LoadPlanAdvisor loadPlanAdvisor,
 			ResultSet resultSet,
 			SessionImplementor session,
 			QueryParameters queryParameters,
 			NamedParameterContext namedParameterContext,
-			LoadQueryAliasResolutionContext aliasResolutionContext,
+			AliasResolutionContext aliasResolutionContext,
 			boolean returnProxies,
 			boolean readOnly,
 			ResultTransformer forcedResultTransformer,
 			List<AfterLoadAction> afterLoadActions) throws SQLException;
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/spi/ReturnReader.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/spi/ReturnReader.java
new file mode 100644
index 0000000000..a674d8ebd6
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/spi/ReturnReader.java
@@ -0,0 +1,46 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.exec.process.spi;
+
+import java.sql.ResultSet;
+import java.sql.SQLException;
+
+/**
+ * Handles reading results from a JDBC ResultSet relating to a single Return object.
+ *
+ * @author Steve Ebersole
+ */
+public interface ReturnReader {
+	/**
+	 * Essentially performs the second phase of two-phase loading.
+	 *
+	 * @param resultSet The result set being processed
+	 * @param context The context for the processing
+	 *
+	 * @return The read object
+	 *
+	 * @throws SQLException Indicates a problem access the JDBC result set
+	 */
+	public Object read(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException;
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/spi/ScrollableResultSetProcessor.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/spi/ScrollableResultSetProcessor.java
similarity index 98%
rename from hibernate-core/src/main/java/org/hibernate/loader/spi/ScrollableResultSetProcessor.java
rename to hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/spi/ScrollableResultSetProcessor.java
index 3892bba3f5..1d425e62ab 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/spi/ScrollableResultSetProcessor.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/spi/ScrollableResultSetProcessor.java
@@ -1,107 +1,107 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.loader.spi;
+package org.hibernate.loader.plan.exec.process.spi;
 
 import java.sql.ResultSet;
 
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 
 /**
  * Contract for processing JDBC ResultSets a single logical row at a time.  These are intended for use by
  * {@link org.hibernate.ScrollableResults} implementations.
  *
  * NOTE : these methods initially taken directly from {@link org.hibernate.loader.Loader} counterparts in an effort
  * to break Loader into manageable pieces, especially in regards to the processing of result sets.
  *
  * @author Steve Ebersole
  */
 public interface ScrollableResultSetProcessor {
 
 	/**
 	 * Give a ResultSet, extract just a single result row.
 	 *
 	 * Copy of {@link org.hibernate.loader.Loader#loadSingleRow(ResultSet, SessionImplementor, QueryParameters, boolean)}
 	 * but dropping the 'returnProxies' (that method has only one use in the entire codebase and it always passes in
 	 * false...)
 	 *
 	 * @param resultSet The result set being processed.
 	 * @param session The originating session
 	 * @param queryParameters The "parameters" used to build the query
 	 *
 	 * @return The extracted result row
 	 *
 	 * @throws org.hibernate.HibernateException Indicates a problem extracting values from the result set.
 	 */
 	public Object extractSingleRow(
 			ResultSet resultSet,
 			SessionImplementor session,
 			QueryParameters queryParameters);
 
 	/**
 	 * Given a scrollable ResultSet, extract a logical row.  The assumption here is that the ResultSet is already
 	 * properly ordered to account for any to-many fetches.  Multiple ResultSet rows are read into a single query
 	 * result "row".
 	 *
 	 * Copy of {@link org.hibernate.loader.Loader#loadSequentialRowsForward(ResultSet, SessionImplementor, QueryParameters, boolean)}
 	 * but dropping the 'returnProxies' (that method has only one use in the entire codebase and it always passes in
 	 * false...)
 	 *
 	 * @param resultSet The result set being processed.
 	 * @param session The originating session
 	 * @param queryParameters The "parameters" used to build the query
 	 *
 	 * @return The extracted result row
 	 *
 	 * @throws org.hibernate.HibernateException Indicates a problem extracting values from the result set.
 	 */
 	public Object extractLogicalRowForward(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters);
 
 	/**
 	 * Like {@link #extractLogicalRowForward} but here moving through the ResultSet in reverse.
 	 *
 	 * Copy of {@link org.hibernate.loader.Loader#loadSequentialRowsReverse(ResultSet, SessionImplementor, QueryParameters, boolean, boolean)}
 	 * but dropping the 'returnProxies' (that method has only one use in the entire codebase and it always passes in
 	 * false...).
 	 *
 	 * todo : is 'logicallyAfterLastRow really needed?  Can't that be deduced?  In fact pretty positive it is not needed.
 	 *
 	 * @param resultSet The result set being processed.
 	 * @param session The originating session
 	 * @param queryParameters The "parameters" used to build the query
 	 * @param isLogicallyAfterLast Is the result set currently positioned after the last row; again, is this really needed?  How is it any diff
 	 *
 	 * @return The extracted result row
 	 *
 	 * @throws org.hibernate.HibernateException Indicates a problem extracting values from the result set.
 	 */
 	public Object extractLogicalRowReverse(
 			ResultSet resultSet,
 			SessionImplementor session,
 			QueryParameters queryParameters,
 			boolean isLogicallyAfterLast);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/query/internal/EntityLoadQueryBuilderImpl.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/query/internal/EntityLoadQueryBuilderImpl.java
new file mode 100644
index 0000000000..5db0e113e6
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/query/internal/EntityLoadQueryBuilderImpl.java
@@ -0,0 +1,213 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.exec.query.internal;
+
+import org.hibernate.LockOptions;
+import org.hibernate.engine.spi.LoadQueryInfluencers;
+import org.hibernate.engine.spi.SessionFactoryImplementor;
+import org.hibernate.loader.plan.exec.query.spi.EntityLoadQueryBuilder;
+import org.hibernate.loader.plan.exec.query.spi.QueryBuildingParameters;
+import org.hibernate.loader.plan.exec.spi.AliasResolutionContext;
+import org.hibernate.loader.plan.spi.EntityReturn;
+import org.hibernate.loader.plan.spi.LoadPlan;
+import org.hibernate.loader.plan.spi.Return;
+import org.hibernate.persister.entity.OuterJoinLoadable;
+import org.hibernate.persister.entity.Queryable;
+import org.hibernate.sql.ConditionFragment;
+import org.hibernate.sql.DisjunctionFragment;
+import org.hibernate.sql.InFragment;
+
+/**
+ * @author Steve Ebersole
+ */
+public class EntityLoadQueryBuilderImpl implements EntityLoadQueryBuilder {
+	/**
+	 * Singleton access
+	 */
+	public static final EntityLoadQueryBuilderImpl INSTANCE = new EntityLoadQueryBuilderImpl();
+
+	@Override
+	public String generateSql(
+			LoadPlan loadPlan,
+			SessionFactoryImplementor factory,
+			QueryBuildingParameters buildingParameters,
+			AliasResolutionContext aliasResolutionContext) {
+		final EntityReturn rootReturn = extractRootReturn( loadPlan );
+
+		return generateSql(
+				( (Queryable) rootReturn.getEntityPersister() ).getKeyColumnNames(),
+				rootReturn,
+				factory,
+				buildingParameters,
+				aliasResolutionContext
+		);
+	}
+
+	private static EntityReturn extractRootReturn(LoadPlan loadPlan) {
+		if ( loadPlan.getReturns().size() == 0 ) {
+			throw new IllegalStateException( "LoadPlan contained no root returns" );
+		}
+		else if ( loadPlan.getReturns().size() > 1 ) {
+			throw new IllegalStateException( "LoadPlan contained more than one root returns" );
+		}
+
+		final Return rootReturn = loadPlan.getReturns().get( 0 );
+		if ( !EntityReturn.class.isInstance( rootReturn ) ) {
+			throw new IllegalStateException(
+					String.format(
+							"Unexpected LoadPlan root return; expecting %s, but found %s",
+							EntityReturn.class.getName(),
+							rootReturn.getClass().getName()
+					)
+			);
+		}
+
+		return (EntityReturn) rootReturn;
+	}
+
+	@Override
+	public String generateSql(
+			String[] keyColumnNames,
+			LoadPlan loadPlan,
+			SessionFactoryImplementor factory,
+			QueryBuildingParameters buildingParameters,
+			AliasResolutionContext aliasResolutionContext) {
+		final EntityReturn rootReturn = extractRootReturn( loadPlan );
+
+		return generateSql(
+				keyColumnNames,
+				rootReturn,
+				factory,
+				buildingParameters,
+				aliasResolutionContext
+		);
+	}
+
+	protected String generateSql(
+			String[] keyColumnNames,
+			EntityReturn rootReturn,
+			SessionFactoryImplementor factory,
+			QueryBuildingParameters buildingParameters,
+			AliasResolutionContext aliasResolutionContext) {
+		final SelectStatementBuilder select = new SelectStatementBuilder( factory.getDialect() );
+
+		// apply root entity return specifics
+		applyRootReturnSpecifics( select, keyColumnNames, rootReturn, factory, buildingParameters, aliasResolutionContext );
+
+		LoadQueryBuilderHelper.applyJoinFetches(
+				select,
+				factory,
+				rootReturn,
+				buildingParameters,
+				aliasResolutionContext
+		);
+
+		return select.toStatementString();
+	}
+
+	protected void applyRootReturnSpecifics(
+			SelectStatementBuilder select,
+			String[] keyColumnNames,
+			EntityReturn rootReturn,
+			SessionFactoryImplementor factory,
+			QueryBuildingParameters buildingParameters,
+			AliasResolutionContext aliasResolutionContext) {
+		final String rootAlias = aliasResolutionContext.resolveAliases( rootReturn ).getTableAlias();
+		final OuterJoinLoadable rootLoadable = (OuterJoinLoadable) rootReturn.getEntityPersister();
+		final Queryable rootQueryable = (Queryable) rootReturn.getEntityPersister();
+
+		applyKeyRestriction( select, rootAlias, keyColumnNames, buildingParameters.getBatchSize() );
+		select.appendRestrictions(
+				rootQueryable.filterFragment(
+						rootAlias,
+						buildingParameters.getQueryInfluencers().getEnabledFilters()
+				)
+		);
+		select.appendRestrictions( rootLoadable.whereJoinFragment( rootAlias, true, true ) );
+		select.appendSelectClauseFragment(
+				rootLoadable.selectFragment(
+						rootAlias,
+						aliasResolutionContext.resolveAliases( rootReturn ).getColumnAliases().getSuffix()
+				)
+		);
+
+		final String fromTableFragment;
+		if ( buildingParameters.getLockOptions() != null ) {
+			fromTableFragment = factory.getDialect().appendLockHint(
+					buildingParameters.getLockOptions(),
+					rootLoadable.fromTableFragment( rootAlias )
+			);
+			select.setLockOptions( buildingParameters.getLockOptions() );
+		}
+		else if ( buildingParameters.getLockMode() != null ) {
+			fromTableFragment = factory.getDialect().appendLockHint(
+					buildingParameters.getLockMode(),
+					rootLoadable.fromTableFragment( rootAlias )
+			);
+			select.setLockMode( buildingParameters.getLockMode() );
+		}
+		else {
+			fromTableFragment = rootLoadable.fromTableFragment( rootAlias );
+		}
+		select.appendFromClauseFragment( fromTableFragment + rootLoadable.fromJoinFragment( rootAlias, true, true ) );
+	}
+
+	private void applyKeyRestriction(SelectStatementBuilder select, String alias, String[] keyColumnNames, int batchSize) {
+		if ( keyColumnNames.length==1 ) {
+			// NOT A COMPOSITE KEY
+			// 		for batching, use "foo in (?, ?, ?)" for batching
+			//		for no batching, use "foo = ?"
+			// (that distinction is handled inside InFragment)
+			final InFragment in = new InFragment().setColumn( alias, keyColumnNames[0] );
+			for ( int i = 0; i < batchSize; i++ ) {
+				in.addValue( "?" );
+			}
+			select.appendRestrictions( in.toFragmentString() );
+		}
+		else {
+			// A COMPOSITE KEY...
+			final ConditionFragment keyRestrictionBuilder = new ConditionFragment()
+					.setTableAlias( alias )
+					.setCondition( keyColumnNames, "?" );
+			final String keyRestrictionFragment = keyRestrictionBuilder.toFragmentString();
+
+			StringBuilder restrictions = new StringBuilder();
+			if ( batchSize==1 ) {
+				// for no batching, use "foo = ? and bar = ?"
+				restrictions.append( keyRestrictionFragment );
+			}
+			else {
+				// for batching, use "( (foo = ? and bar = ?) or (foo = ? and bar = ?) )"
+				restrictions.append( '(' );
+				DisjunctionFragment df = new DisjunctionFragment();
+				for ( int i=0; i<batchSize; i++ ) {
+					df.addCondition( keyRestrictionFragment );
+				}
+				restrictions.append( df.toFragmentString() );
+				restrictions.append( ')' );
+			}
+			select.appendRestrictions( restrictions.toString() );
+		}
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/query/internal/LoadQueryBuilderHelper.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/query/internal/LoadQueryBuilderHelper.java
new file mode 100644
index 0000000000..0f99cb8596
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/query/internal/LoadQueryBuilderHelper.java
@@ -0,0 +1,512 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.exec.query.internal;
+
+import org.hibernate.cfg.NotYetImplementedException;
+import org.hibernate.engine.internal.JoinHelper;
+import org.hibernate.engine.spi.LoadQueryInfluencers;
+import org.hibernate.engine.spi.SessionFactoryImplementor;
+import org.hibernate.internal.util.StringHelper;
+import org.hibernate.loader.plan.exec.query.spi.QueryBuildingParameters;
+import org.hibernate.loader.plan.exec.spi.AliasResolutionContext;
+import org.hibernate.loader.plan.exec.spi.CollectionReferenceAliases;
+import org.hibernate.loader.plan.spi.AnyFetch;
+import org.hibernate.loader.plan.spi.CollectionFetch;
+import org.hibernate.loader.plan.spi.CompositeElementGraph;
+import org.hibernate.loader.plan.spi.CompositeFetch;
+import org.hibernate.loader.plan.spi.CompositeIndexGraph;
+import org.hibernate.loader.plan.spi.EntityElementGraph;
+import org.hibernate.loader.plan.spi.EntityFetch;
+import org.hibernate.loader.plan.spi.EntityReference;
+import org.hibernate.loader.plan.spi.Fetch;
+import org.hibernate.loader.plan.spi.FetchOwner;
+import org.hibernate.persister.collection.CollectionPersister;
+import org.hibernate.persister.collection.QueryableCollection;
+import org.hibernate.persister.entity.EntityPersister;
+import org.hibernate.persister.entity.Joinable;
+import org.hibernate.persister.entity.OuterJoinLoadable;
+import org.hibernate.persister.entity.Queryable;
+import org.hibernate.persister.walking.internal.FetchStrategyHelper;
+import org.hibernate.persister.walking.spi.WalkingException;
+import org.hibernate.sql.JoinFragment;
+import org.hibernate.sql.JoinType;
+import org.hibernate.type.AssociationType;
+
+/**
+ * Helper for implementors of entity and collection based query building based on LoadPlans providing common
+ * functionality
+ *
+ * @author Steve Ebersole
+ */
+public class LoadQueryBuilderHelper {
+	private LoadQueryBuilderHelper() {
+	}
+
+	public static void applyJoinFetches(
+			SelectStatementBuilder selectStatementBuilder,
+			SessionFactoryImplementor factory,
+			FetchOwner fetchOwner,
+			QueryBuildingParameters buildingParameters,
+			AliasResolutionContext aliasResolutionContext) {
+		final JoinFragment joinFragment = factory.getDialect().createOuterJoinFragment();
+
+		processJoinFetches(
+				selectStatementBuilder,
+				factory,
+				joinFragment,
+				fetchOwner,
+				buildingParameters,
+				aliasResolutionContext
+		);
+
+		selectStatementBuilder.setOuterJoins(
+				joinFragment.toFromFragmentString(),
+				joinFragment.toWhereFragmentString()
+		);
+	}
+
+	private static void processJoinFetches(
+			SelectStatementBuilder selectStatementBuilder,
+			SessionFactoryImplementor factory,
+			JoinFragment joinFragment,
+			FetchOwner fetchOwner,
+			QueryBuildingParameters buildingParameters,
+			AliasResolutionContext aliasResolutionContext) {
+		for ( Fetch fetch : fetchOwner.getFetches() ) {
+			processFetch(
+					selectStatementBuilder,
+					factory,
+					joinFragment,
+					fetchOwner,
+					fetch,
+					buildingParameters,
+					aliasResolutionContext
+			);
+		}
+	}
+
+	private static void processFetch(
+			SelectStatementBuilder selectStatementBuilder,
+			SessionFactoryImplementor factory,
+			JoinFragment joinFragment,
+			FetchOwner fetchOwner,
+			Fetch fetch,
+			QueryBuildingParameters buildingParameters,
+			AliasResolutionContext aliasResolutionContext) {
+		if ( ! FetchStrategyHelper.isJoinFetched( fetch.getFetchStrategy() ) ) {
+			return;
+		}
+
+		if ( EntityFetch.class.isInstance( fetch ) ) {
+			processEntityFetch(
+					selectStatementBuilder,
+					factory,
+					joinFragment,
+					fetchOwner,
+					(EntityFetch) fetch,
+					buildingParameters,
+					aliasResolutionContext
+			);
+			processJoinFetches(
+					selectStatementBuilder,
+					factory,
+					joinFragment,
+					(EntityFetch) fetch,
+					buildingParameters,
+					aliasResolutionContext
+			);
+		}
+		else if ( CollectionFetch.class.isInstance( fetch ) ) {
+			processCollectionFetch(
+					selectStatementBuilder,
+					factory,
+					joinFragment,
+					fetchOwner,
+					(CollectionFetch) fetch,
+					buildingParameters,
+					aliasResolutionContext
+			);
+			final CollectionFetch collectionFetch = (CollectionFetch) fetch;
+			if ( collectionFetch.getIndexGraph() != null ) {
+				processJoinFetches(
+						selectStatementBuilder,
+						factory,
+						joinFragment,
+						collectionFetch.getIndexGraph(),
+						buildingParameters,
+						aliasResolutionContext
+				);
+			}
+			if ( collectionFetch.getElementGraph() != null ) {
+				processJoinFetches(
+						selectStatementBuilder,
+						factory,
+						joinFragment,
+						collectionFetch.getElementGraph(),
+						buildingParameters,
+						aliasResolutionContext
+				);
+			}
+		}
+		else {
+			// could also be a CompositeFetch, we ignore those here
+			// but do still need to visit their fetches...
+			if ( FetchOwner.class.isInstance( fetch ) ) {
+				processJoinFetches(
+						selectStatementBuilder,
+						factory,
+						joinFragment,
+						(FetchOwner) fetch,
+						buildingParameters,
+						aliasResolutionContext
+				);
+			}
+		}
+	}
+
+	private static void processEntityFetch(
+			SelectStatementBuilder selectStatementBuilder,
+			SessionFactoryImplementor factory,
+			JoinFragment joinFragment,
+			FetchOwner fetchOwner,
+			EntityFetch fetch,
+			QueryBuildingParameters buildingParameters,
+			AliasResolutionContext aliasResolutionContext) {
+		final String rhsAlias = aliasResolutionContext.resolveAliases( fetch ).getTableAlias();
+		final String[] rhsColumnNames = JoinHelper.getRHSColumnNames( fetch.getFetchedType(), factory );
+
+		final String lhsTableAlias = resolveLhsTableAlias( fetchOwner, fetch, aliasResolutionContext );
+		// todo : this is not exactly correct.  it assumes the join refers to the LHS PK
+		final String[] aliasedLhsColumnNames = fetch.toSqlSelectFragments( lhsTableAlias );
+
+		final String additionalJoinConditions = resolveAdditionalJoinCondition(
+				factory,
+				rhsAlias,
+				fetchOwner,
+				fetch,
+				buildingParameters.getQueryInfluencers(),
+				aliasResolutionContext
+		);
+
+		final Joinable joinable = (Joinable) fetch.getEntityPersister();
+
+		addJoins(
+				joinFragment,
+				joinable,
+				fetch.isNullable() ? JoinType.LEFT_OUTER_JOIN : JoinType.INNER_JOIN,
+				rhsAlias,
+				rhsColumnNames,
+				aliasedLhsColumnNames,
+				additionalJoinConditions
+		);
+
+		// the null arguments here relate to many-to-many fetches
+		selectStatementBuilder.appendSelectClauseFragment(
+				joinable.selectFragment(
+						null,
+						null,
+						rhsAlias,
+						aliasResolutionContext.resolveAliases( fetch ).getColumnAliases().getSuffix(),
+						null,
+						true
+				)
+		);
+	}
+
+	private static String[] resolveAliasedLhsJoinColumns(
+			FetchOwner fetchOwner,
+			Fetch fetch,
+			AliasResolutionContext aliasResolutionContext) {
+		// IMPL NOTE : the fetch-owner is the LHS; the fetch is the RHS
+		final String lhsTableAlias = resolveLhsTableAlias( fetchOwner, fetch, aliasResolutionContext );
+		return fetch.toSqlSelectFragments( lhsTableAlias );
+	}
+
+	private static String resolveLhsTableAlias(
+			FetchOwner fetchOwner,
+			Fetch fetch,
+			AliasResolutionContext aliasResolutionContext) {
+		// IMPL NOTE : the fetch-owner is the LHS; the fetch is the RHS
+
+		if ( AnyFetch.class.isInstance( fetchOwner ) ) {
+			throw new WalkingException( "Any type should never be joined!" );
+		}
+		else if ( EntityReference.class.isInstance( fetchOwner ) ) {
+			return aliasResolutionContext.resolveAliases( (EntityReference) fetchOwner ).getTableAlias();
+		}
+		else if ( CompositeFetch.class.isInstance( fetchOwner ) ) {
+			return aliasResolutionContext.resolveAliases(
+					locateCompositeFetchEntityReferenceSource( (CompositeFetch) fetchOwner )
+			).getTableAlias();
+		}
+		else if ( CompositeElementGraph.class.isInstance( fetchOwner ) ) {
+			final CompositeElementGraph compositeElementGraph = (CompositeElementGraph) fetchOwner;
+			return aliasResolutionContext.resolveAliases( compositeElementGraph.getCollectionReference() ).getCollectionTableAlias();
+		}
+		else if ( CompositeIndexGraph.class.isInstance( fetchOwner ) ) {
+			final CompositeIndexGraph compositeIndexGraph = (CompositeIndexGraph) fetchOwner;
+			return aliasResolutionContext.resolveAliases( compositeIndexGraph.getCollectionReference() ).getCollectionTableAlias();
+		}
+		else {
+			throw new NotYetImplementedException( "Cannot determine LHS alias for FetchOwner." );
+		}
+	}
+
+	private static EntityReference locateCompositeFetchEntityReferenceSource(CompositeFetch composite) {
+		final FetchOwner owner = composite.getOwner();
+		if ( EntityReference.class.isInstance( owner ) ) {
+			return (EntityReference) owner;
+		}
+		if ( CompositeFetch.class.isInstance( owner ) ) {
+			return locateCompositeFetchEntityReferenceSource( (CompositeFetch) owner );
+		}
+
+		throw new WalkingException( "Cannot resolve entity source for a CompositeFetch" );
+	}
+
+	private static String resolveAdditionalJoinCondition(
+			SessionFactoryImplementor factory,
+			String rhsTableAlias,
+			FetchOwner fetchOwner,
+			Fetch fetch,
+			LoadQueryInfluencers influencers,
+			AliasResolutionContext aliasResolutionContext) {
+		final String withClause = StringHelper.isEmpty( fetch.getAdditionalJoinConditions() )
+				? ""
+				: " and ( " + fetch.getAdditionalJoinConditions() + " )";
+		return ( (AssociationType) fetch.getFetchedType() ).getOnCondition(
+				rhsTableAlias,
+				factory,
+				influencers.getEnabledFilters()
+		) + withClause;
+	}
+
+	private static void addJoins(
+			JoinFragment joinFragment,
+			Joinable joinable,
+			JoinType joinType,
+			String rhsAlias,
+			String[] rhsColumnNames,
+			String[] aliasedLhsColumnNames,
+			String additionalJoinConditions) {
+		joinFragment.addJoin(
+				joinable.getTableName(),
+				rhsAlias,
+				aliasedLhsColumnNames,
+				rhsColumnNames,
+				joinType,
+				additionalJoinConditions
+		);
+		joinFragment.addJoins(
+				joinable.fromJoinFragment( rhsAlias, false, true ),
+				joinable.whereJoinFragment( rhsAlias, false, true )
+		);
+	}
+
+	private static void processCollectionFetch(
+			SelectStatementBuilder selectStatementBuilder,
+			SessionFactoryImplementor factory,
+			JoinFragment joinFragment,
+			FetchOwner fetchOwner,
+			CollectionFetch fetch,
+			QueryBuildingParameters buildingParameters,
+			AliasResolutionContext aliasResolutionContext) {
+		final QueryableCollection queryableCollection = (QueryableCollection) fetch.getCollectionPersister();
+		final Joinable joinableCollection = (Joinable) fetch.getCollectionPersister();
+
+		if ( fetch.getCollectionPersister().isManyToMany() ) {
+			// for many-to-many we have 3 table aliases.  By way of example, consider a normal m-n: User<->Role
+			// where User is the FetchOwner and Role (User.roles) is the Fetch.  We'd have:
+			//		1) the owner's table : user
+			final String ownerTableAlias = resolveLhsTableAlias( fetchOwner, fetch, aliasResolutionContext );
+			//		2) the m-n table : user_role
+			final String collectionTableAlias = aliasResolutionContext.resolveAliases( fetch ).getCollectionTableAlias();
+			//		3) the element table : role
+			final String elementTableAlias = aliasResolutionContext.resolveAliases( fetch ).getElementTableAlias();
+
+			{
+				// add join fragments from the owner table -> collection table ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+				final String filterFragment = ( (Joinable) fetch.getCollectionPersister() ).filterFragment(
+						collectionTableAlias,
+						buildingParameters.getQueryInfluencers().getEnabledFilters()
+				);
+
+				joinFragment.addJoin(
+						joinableCollection.getTableName(),
+						collectionTableAlias,
+						StringHelper.qualify( ownerTableAlias, extractJoinable( fetchOwner ).getKeyColumnNames() ),
+						queryableCollection.getKeyColumnNames(),
+						fetch.isNullable() ? JoinType.LEFT_OUTER_JOIN : JoinType.INNER_JOIN,
+						filterFragment
+				);
+				joinFragment.addJoins(
+						joinableCollection.fromJoinFragment( collectionTableAlias, false, true ),
+						joinableCollection.whereJoinFragment( collectionTableAlias, false, true )
+				);
+
+				// add select fragments from the collection table ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+				selectStatementBuilder.appendSelectClauseFragment(
+						joinableCollection.selectFragment(
+								(Joinable) queryableCollection.getElementPersister(),
+								ownerTableAlias,
+								collectionTableAlias,
+								aliasResolutionContext.resolveAliases( fetch ).getEntityElementColumnAliases().getSuffix(),
+								aliasResolutionContext.resolveAliases( fetch ).getCollectionColumnAliases().getSuffix(),
+								true
+						)
+				);
+			}
+
+			{
+				// add join fragments from the collection table -> element entity table ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+				final String additionalJoinConditions = resolveAdditionalJoinCondition(
+						factory,
+						elementTableAlias,
+						fetchOwner,
+						fetch,
+						buildingParameters.getQueryInfluencers(),
+						aliasResolutionContext
+				);
+
+				final String manyToManyFilter = fetch.getCollectionPersister().getManyToManyFilterFragment(
+						collectionTableAlias,
+						buildingParameters.getQueryInfluencers().getEnabledFilters()
+				);
+
+				final String condition;
+				if ( "".equals( manyToManyFilter ) ) {
+					condition = additionalJoinConditions;
+				}
+				else if ( "".equals( additionalJoinConditions ) ) {
+					condition = manyToManyFilter;
+				}
+				else {
+					condition = additionalJoinConditions + " and " + manyToManyFilter;
+				}
+
+				final OuterJoinLoadable elementPersister = (OuterJoinLoadable) queryableCollection.getElementPersister();
+
+				addJoins(
+						joinFragment,
+						elementPersister,
+//						JoinType.INNER_JOIN,
+						JoinType.LEFT_OUTER_JOIN,
+						elementTableAlias,
+						elementPersister.getIdentifierColumnNames(),
+						StringHelper.qualify( collectionTableAlias, queryableCollection.getElementColumnNames() ),
+						condition
+				);
+
+				// add select fragments from the element entity table ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+				final CollectionReferenceAliases aliases = aliasResolutionContext.resolveAliases( fetch );
+				selectStatementBuilder.appendSelectClauseFragment(
+						elementPersister.selectFragment(
+								aliases.getElementTableAlias(),
+								aliases.getEntityElementColumnAliases().getSuffix()
+						)
+				);
+			}
+
+			final String manyToManyOrdering = queryableCollection.getManyToManyOrderByString( collectionTableAlias );
+			if ( StringHelper.isNotEmpty( manyToManyOrdering ) ) {
+				selectStatementBuilder.appendOrderByFragment( manyToManyOrdering );
+			}
+
+			final String ordering = queryableCollection.getSQLOrderByString( collectionTableAlias );
+			if ( StringHelper.isNotEmpty( ordering ) ) {
+				selectStatementBuilder.appendOrderByFragment( ordering );
+			}
+		}
+		else {
+			final String rhsTableAlias = aliasResolutionContext.resolveAliases( fetch ).getElementTableAlias();
+			final String[] rhsColumnNames = JoinHelper.getRHSColumnNames( fetch.getFetchedType(), factory );
+
+			final String lhsTableAlias = resolveLhsTableAlias( fetchOwner, fetch, aliasResolutionContext );
+			// todo : this is not exactly correct.  it assumes the join refers to the LHS PK
+			final String[] aliasedLhsColumnNames = fetch.toSqlSelectFragments( lhsTableAlias );
+
+			final String on = resolveAdditionalJoinCondition(
+					factory,
+					rhsTableAlias,
+					fetchOwner,
+					fetch,
+					buildingParameters.getQueryInfluencers(),
+					aliasResolutionContext
+			);
+
+			addJoins(
+					joinFragment,
+					joinableCollection,
+					fetch.isNullable() ? JoinType.LEFT_OUTER_JOIN : JoinType.INNER_JOIN,
+					rhsTableAlias,
+					rhsColumnNames,
+					aliasedLhsColumnNames,
+					on
+			);
+
+			// select the "collection columns"
+			selectStatementBuilder.appendSelectClauseFragment(
+					queryableCollection.selectFragment(
+							rhsTableAlias,
+							aliasResolutionContext.resolveAliases( fetch ).getCollectionColumnAliases().getSuffix()
+					)
+			);
+
+			if ( fetch.getCollectionPersister().isOneToMany() ) {
+				// if the collection elements are entities, select the entity columns as well
+				final CollectionReferenceAliases aliases = aliasResolutionContext.resolveAliases( fetch );
+				final OuterJoinLoadable elementPersister = (OuterJoinLoadable) queryableCollection.getElementPersister();
+				selectStatementBuilder.appendSelectClauseFragment(
+						elementPersister.selectFragment(
+								aliases.getElementTableAlias(),
+								aliases.getEntityElementColumnAliases().getSuffix()
+						)
+				);
+			}
+
+			final String ordering = queryableCollection.getSQLOrderByString( rhsTableAlias );
+			if ( StringHelper.isNotEmpty( ordering ) ) {
+				selectStatementBuilder.appendOrderByFragment( ordering );
+			}
+		}
+
+	}
+
+	private static Joinable extractJoinable(FetchOwner fetchOwner) {
+		// this is used for collection fetches.  At the end of the day, a fetched collection must be owned by
+		// an entity.  Find that entity's persister and return it
+		if ( EntityReference.class.isInstance( fetchOwner ) ) {
+			return (Joinable) ( (EntityReference) fetchOwner ).getEntityPersister();
+		}
+		else if ( CompositeFetch.class.isInstance( fetchOwner ) ) {
+			return (Joinable) locateCompositeFetchEntityReferenceSource( (CompositeFetch) fetchOwner ).getEntityPersister();
+		}
+		else if ( EntityElementGraph.class.isInstance( fetchOwner ) ) {
+			return (Joinable) ( (EntityElementGraph) fetchOwner ).getEntityPersister();
+		}
+
+		throw new IllegalStateException( "Uncertain how to extract Joinable from given FetchOwner : " + fetchOwner );
+	}
+
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/query/internal/SelectStatementBuilder.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/query/internal/SelectStatementBuilder.java
new file mode 100644
index 0000000000..de3c5aa8dc
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/query/internal/SelectStatementBuilder.java
@@ -0,0 +1,232 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.exec.query.internal;
+
+import org.hibernate.LockMode;
+import org.hibernate.LockOptions;
+import org.hibernate.dialect.Dialect;
+import org.hibernate.internal.util.StringHelper;
+import org.hibernate.sql.SelectFragment;
+
+/**
+ * Largely a copy of the {@link org.hibernate.sql.Select} class, but changed up slightly to better meet needs
+ * of building a SQL SELECT statement from a LoadPlan
+ *
+ * @author Steve Ebersole
+ * @author Gavin King
+ */
+public class SelectStatementBuilder {
+	public final Dialect dialect;
+
+	private StringBuilder selectClause = new StringBuilder();
+	private StringBuilder fromClause = new StringBuilder();
+//	private StringBuilder outerJoinsAfterFrom;
+	private String outerJoinsAfterFrom;
+	private StringBuilder whereClause;
+//	private StringBuilder outerJoinsAfterWhere;
+	private String outerJoinsAfterWhere;
+	private StringBuilder orderByClause;
+	private String comment;
+	private LockOptions lockOptions = new LockOptions();
+
+	private int guesstimatedBufferSize = 20;
+
+	public SelectStatementBuilder(Dialect dialect) {
+		this.dialect = dialect;
+	}
+
+	/**
+	 * Appends a select clause fragment
+	 *
+	 * @param selection The selection fragment
+	 */
+	public void appendSelectClauseFragment(String selection) {
+		if ( this.selectClause.length() > 0 ) {
+			this.selectClause.append( ", " );
+			this.guesstimatedBufferSize += 2;
+		}
+		this.selectClause.append( selection );
+		this.guesstimatedBufferSize += selection.length();
+	}
+
+	public void appendSelectClauseFragment(SelectFragment selectFragment) {
+		appendSelectClauseFragment( selectFragment.toFragmentString().substring( 2 ) );
+	}
+
+	public void appendFromClauseFragment(String fragment) {
+		if ( this.fromClause.length() > 0 ) {
+			this.fromClause.append( ", " );
+			this.guesstimatedBufferSize += 2;
+		}
+		this.fromClause.append( fragment );
+		this.guesstimatedBufferSize += fragment.length();
+	}
+
+	public void appendFromClauseFragment(String tableName, String alias) {
+		appendFromClauseFragment( tableName + ' ' + alias );
+	}
+
+	public void appendRestrictions(String restrictions) {
+		final String cleaned = cleanRestrictions( restrictions );
+		if ( StringHelper.isEmpty( cleaned ) ) {
+			return;
+		}
+
+		this.guesstimatedBufferSize += cleaned.length();
+
+		if ( whereClause == null ) {
+			whereClause = new StringBuilder( cleaned );
+		}
+		else {
+			whereClause.append( " and " ).append( cleaned );
+			this.guesstimatedBufferSize += 5;
+		}
+	}
+
+	private String cleanRestrictions(String restrictions) {
+		restrictions = restrictions.trim();
+		if ( restrictions.startsWith( "and" ) ) {
+			restrictions = restrictions.substring( 4 );
+		}
+		if ( restrictions.endsWith( "and" ) ) {
+			restrictions = restrictions.substring( 0, restrictions.length()-4 );
+		}
+
+		return restrictions;
+	}
+
+//	public void appendOuterJoins(String outerJoinsAfterFrom, String outerJoinsAfterWhere) {
+//		appendOuterJoinsAfterFrom( outerJoinsAfterFrom );
+//		appendOuterJoinsAfterWhere( outerJoinsAfterWhere );
+//	}
+//
+//	private void appendOuterJoinsAfterFrom(String outerJoinsAfterFrom) {
+//		if ( this.outerJoinsAfterFrom == null ) {
+//			this.outerJoinsAfterFrom = new StringBuilder( outerJoinsAfterFrom );
+//		}
+//		else {
+//			this.outerJoinsAfterFrom.append( ' ' ).append( outerJoinsAfterFrom );
+//		}
+//	}
+//
+//	private void appendOuterJoinsAfterWhere(String outerJoinsAfterWhere) {
+//		final String cleaned = cleanRestrictions( outerJoinsAfterWhere );
+//
+//		if ( this.outerJoinsAfterWhere == null ) {
+//			this.outerJoinsAfterWhere = new StringBuilder( cleaned );
+//		}
+//		else {
+//			this.outerJoinsAfterWhere.append( " and " ).append( cleaned );
+//			this.guesstimatedBufferSize += 5;
+//		}
+//
+//		this.guesstimatedBufferSize += cleaned.length();
+//	}
+
+	public void setOuterJoins(String outerJoinsAfterFrom, String outerJoinsAfterWhere) {
+		this.outerJoinsAfterFrom = outerJoinsAfterFrom;
+
+		final String cleanRestrictions = cleanRestrictions( outerJoinsAfterWhere );
+		this.outerJoinsAfterWhere = cleanRestrictions;
+
+		this.guesstimatedBufferSize += outerJoinsAfterFrom.length() + cleanRestrictions.length();
+	}
+
+	public void appendOrderByFragment(String ordering) {
+		if ( this.orderByClause == null ) {
+			this.orderByClause = new StringBuilder();
+		}
+		else {
+			this.orderByClause.append( ", " );
+			this.guesstimatedBufferSize += 2;
+		}
+		this.orderByClause.append( ordering );
+	}
+
+	public void setComment(String comment) {
+		this.comment = comment;
+		this.guesstimatedBufferSize += comment.length();
+	}
+
+	public void setLockMode(LockMode lockMode) {
+		this.lockOptions.setLockMode( lockMode );
+	}
+
+	public void setLockOptions(LockOptions lockOptions) {
+		LockOptions.copy( lockOptions, this.lockOptions );
+	}
+
+	/**
+	 * Construct an SQL <tt>SELECT</tt> statement from the given clauses
+	 */
+	public String toStatementString() {
+		final StringBuilder buf = new StringBuilder( guesstimatedBufferSize );
+
+		if ( StringHelper.isNotEmpty( comment ) ) {
+			buf.append( "/* " ).append( comment ).append( " */ " );
+		}
+
+		buf.append( "select " )
+				.append( selectClause )
+				.append( " from " )
+				.append( fromClause );
+
+		if ( StringHelper.isNotEmpty( outerJoinsAfterFrom ) ) {
+			buf.append( outerJoinsAfterFrom );
+		}
+
+		if ( isNotEmpty( whereClause ) || isNotEmpty( outerJoinsAfterWhere ) ) {
+			buf.append( " where " );
+			// the outerJoinsAfterWhere needs to come before where clause to properly
+			// handle dynamic filters
+			if ( StringHelper.isNotEmpty( outerJoinsAfterWhere ) ) {
+				buf.append( outerJoinsAfterWhere );
+				if ( isNotEmpty( whereClause ) ) {
+					buf.append( " and " );
+				}
+			}
+			if ( isNotEmpty( whereClause ) ) {
+				buf.append( whereClause );
+			}
+		}
+
+		if ( orderByClause != null ) {
+			buf.append( " order by " ).append( orderByClause );
+		}
+
+		if ( lockOptions.getLockMode() != LockMode.NONE ) {
+			buf.append( dialect.getForUpdateString( lockOptions ) );
+		}
+
+		return dialect.transformSelectString( buf.toString() );
+	}
+
+	private boolean isNotEmpty(String string) {
+		return StringHelper.isNotEmpty( string );
+	}
+
+	private boolean isNotEmpty(StringBuilder builder) {
+		return builder != null && builder.length() > 0;
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/query/package-info.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/query/package-info.java
new file mode 100644
index 0000000000..732ccb6070
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/query/package-info.java
@@ -0,0 +1,4 @@
+/**
+ * Defines support for build a query (SQL string specifically for now) based on a LoadPlan.
+ */
+package org.hibernate.loader.plan.exec.query;
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/query/spi/EntityLoadQueryBuilder.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/query/spi/EntityLoadQueryBuilder.java
new file mode 100644
index 0000000000..16a9a06a26
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/query/spi/EntityLoadQueryBuilder.java
@@ -0,0 +1,73 @@
+/*
+ * jDocBook, processing of DocBook sources
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.exec.query.spi;
+
+import org.hibernate.LockOptions;
+import org.hibernate.engine.spi.LoadQueryInfluencers;
+import org.hibernate.engine.spi.SessionFactoryImplementor;
+import org.hibernate.loader.plan.exec.spi.AliasResolutionContext;
+import org.hibernate.loader.plan.spi.LoadPlan;
+
+/**
+ * Contract for generating the query (currently the SQL string specifically) based on a LoadPlan with a
+ * single root EntityReturn
+ *
+ * @author Steve Ebersole
+ * @author Gail Badner
+ */
+public interface EntityLoadQueryBuilder {
+	/**
+	 * Generates the query for the performing load.
+	 *
+	 * @param loadPlan The load
+	 * @param factory The session factory.
+	 * @param buildingParameters Parameters influencing the building of the query
+	 * @param aliasResolutionContext The alias resolution context.
+	 *
+	 * @return the SQL string for performing the load
+	 */
+	String generateSql(
+			LoadPlan loadPlan,
+			SessionFactoryImplementor factory,
+			QueryBuildingParameters buildingParameters,
+			AliasResolutionContext aliasResolutionContext);
+
+	/**
+	 * Generates the query for the performing load, based on the specified key column(s).
+	 *
+	 * @param keyColumnNames The names of the key columns to use
+	 * @param loadPlan The load
+	 * @param factory The session factory.
+	 * @param buildingParameters Parameters influencing the building of the query
+	 * @param aliasResolutionContext The alias resolution context.
+	 *
+	 * @return the SQL string for performing the load
+	 */
+	String generateSql(
+			String[] keyColumnNames,
+			LoadPlan loadPlan,
+			SessionFactoryImplementor factory,
+			QueryBuildingParameters buildingParameters,
+			AliasResolutionContext aliasResolutionContext);
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/spi/NamedParameterContext.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/query/spi/NamedParameterContext.java
similarity index 96%
rename from hibernate-core/src/main/java/org/hibernate/loader/spi/NamedParameterContext.java
rename to hibernate-core/src/main/java/org/hibernate/loader/plan/exec/query/spi/NamedParameterContext.java
index ed4412b42b..0054a35141 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/spi/NamedParameterContext.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/query/spi/NamedParameterContext.java
@@ -1,36 +1,36 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.loader.spi;
+package org.hibernate.loader.plan.exec.query.spi;
 
 /**
  * The context for named parameters.
  * <p/>
  * NOTE : the hope with the SQL-redesign stuff is that this whole concept goes away, the idea being that
  * the parameters are encoded into the query tree and "bind themselves"; see {@link org.hibernate.param.ParameterSpecification}.
  *
  * @author Steve Ebersole
  */
 public interface NamedParameterContext {
 	public int[] getNamedParameterLocations(String name);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/query/spi/QueryBuildingParameters.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/query/spi/QueryBuildingParameters.java
new file mode 100644
index 0000000000..4ad8f88cd2
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/query/spi/QueryBuildingParameters.java
@@ -0,0 +1,40 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.exec.query.spi;
+
+import org.hibernate.LockMode;
+import org.hibernate.LockOptions;
+import org.hibernate.engine.spi.LoadQueryInfluencers;
+
+/**
+ * @author Steve Ebersole
+ */
+public interface QueryBuildingParameters {
+	public LoadQueryInfluencers getQueryInfluencers();
+	public int getBatchSize();
+
+	// ultimately it would be better to have a way to resolve the LockMode for a given Return/Fetch...
+	public LockMode getLockMode();
+	public LockOptions getLockOptions();
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/spi/LoadQueryAliasResolutionContext.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/spi/AliasResolutionContext.java
similarity index 50%
rename from hibernate-core/src/main/java/org/hibernate/loader/spi/LoadQueryAliasResolutionContext.java
rename to hibernate-core/src/main/java/org/hibernate/loader/plan/exec/spi/AliasResolutionContext.java
index 20672f94e3..175e46e8dd 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/spi/LoadQueryAliasResolutionContext.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/spi/AliasResolutionContext.java
@@ -1,134 +1,114 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.loader.spi;
+package org.hibernate.loader.plan.exec.spi;
 
 import org.hibernate.loader.CollectionAliases;
 import org.hibernate.loader.EntityAliases;
-import org.hibernate.loader.plan.spi.CollectionReturn;
 import org.hibernate.loader.plan.spi.CollectionReference;
 import org.hibernate.loader.plan.spi.EntityReference;
 import org.hibernate.loader.plan.spi.EntityReturn;
+import org.hibernate.loader.plan.spi.Return;
 import org.hibernate.loader.plan.spi.ScalarReturn;
+import org.hibernate.loader.spi.JoinableAssociation;
 
 /**
  * Provides aliases that are used by load queries and ResultSet processors.
  *
  * @author Gail Badner
+ * @author Steve Ebersole
  */
-public interface LoadQueryAliasResolutionContext {
-
+public interface AliasResolutionContext {
 	/**
-	 * Resolve the alias associated with the specified {@link EntityReturn}.
-	 *
-	 * @param entityReturn - the {@link EntityReturn}.
+	 * Resolve the source alias (select-clause assigned alias) associated with the specified Return.  The source
+	 * alias is the alias associated with the Return in the source query.
+	 * <p/>
+	 * The concept of a source alias only has meaning in the case of queries (HQL, Criteria, etc).  Not sure we
+	 * really need to keep these here.  One argument for keeping them is that I always thought it would be nice to
+	 * base the SQL aliases on the source aliases.  Keeping the source aliases here would allow us to do that as
+	 * we are generating those SQL aliases internally.
+	 * <p/>
+	 * Should also consider pushing the source "from clause aliases" here if we keep pushing the select aliases
+	 *
+	 * @param theReturn The Return to locate
 	 *
 	 * @return the alias associated with the specified {@link EntityReturn}.
 	 */
-	public String resolveEntityReturnAlias(EntityReturn entityReturn);
+	public String getSourceAlias(Return theReturn);
 
 	/**
-	 * Resolve the alias associated with the specified {@link CollectionReturn}.
+	 * Resolve the SQL column aliases associated with the specified {@link ScalarReturn}.
 	 *
-	 * @param collectionReturn - the {@link CollectionReturn}.
+	 * @param scalarReturn The {@link ScalarReturn} for which we want SQL column aliases
 	 *
-	 * @return the alias associated with {@link CollectionReturn}.
+	 * @return The SQL column aliases associated with {@link ScalarReturn}.
 	 */
-	public String resolveCollectionReturnAlias(CollectionReturn collectionReturn);
+	public String[] resolveScalarColumnAliases(ScalarReturn scalarReturn);
 
 	/**
-	 * Resolve the aliases associated with the specified {@link ScalarReturn}.
+	 * Resolve the alias information related to the given entity reference.
 	 *
-	 * @param scalarReturn - the {@link ScalarReturn}.
-	 *
-	 * @return the alias associated with {@link ScalarReturn}.
-	 */
-	String[] resolveScalarReturnAliases(ScalarReturn scalarReturn);
-
-	/**
-	 * Resolve the SQL table alias for the specified {@link EntityReference}.
+	 * @param entityReference The entity reference for which to obtain alias info
 	 *
-	 * @param entityReference - the {@link EntityReference}.
-	 * @return The SQL table alias for the specified {@link EntityReference}.
+	 * @return The resolved alias info,
 	 */
-	String resolveEntityTableAlias(EntityReference entityReference);
+	public EntityReferenceAliases resolveAliases(EntityReference entityReference);
 
 	/**
-	 * Returns the description of the aliases in the JDBC ResultSet that identify values "belonging" to
-	 * an entity.
+	 * Resolve the alias information related to the given collection reference.
 	 *
-	 * @param entityReference - the {@link EntityReference} for the entity.
+	 * @param collectionReference The collection reference for which to obtain alias info
 	 *
-	 * @return The ResultSet alias descriptor for the {@link EntityReference}
+	 * @return The resolved alias info,
 	 */
-	EntityAliases resolveEntityColumnAliases(EntityReference entityReference);
+	public CollectionReferenceAliases resolveAliases(CollectionReference collectionReference);
+
 
-	/**
-	 * Resolve the SQL table alias for the specified {@link CollectionReference}.
-	 *
-	 * @param collectionReference - the {@link CollectionReference}.
-	 * @return The SQL table alias for the specified {@link CollectionReference}.
-	 */
-	String resolveCollectionTableAlias(CollectionReference collectionReference);
 
-	/**
-	 * Returns the description of the aliases in the JDBC ResultSet that identify values "belonging" to
-	 * the specified {@link CollectionReference}.
-	 *
-	 * @return The ResultSet alias descriptor for the {@link CollectionReference}
-	 */
-	CollectionAliases resolveCollectionColumnAliases(CollectionReference collectionReference);
 
-	/**
-	 * If the elements of this collection are entities, this methods returns the JDBC ResultSet alias descriptions
-	 * for that entity; {@code null} indicates a non-entity collection.
-	 *
-	 * @return The ResultSet alias descriptor for the collection's entity element, or {@code null}
-	 */
-	EntityAliases resolveCollectionElementColumnAliases(CollectionReference collectionReference);
 
 	/**
 	 * Resolve the table alias on the right-hand-side of the specified association.
 	 *
 	 * @param association - the joinable association.
 	 *
 	 * @return the table alias on the right-hand-side of the specified association.
 	 */
 	String resolveAssociationRhsTableAlias(JoinableAssociation association);
 
 	/**
 	 * Resolve the table alias on the left-hand-side of the specified association.
 	 *
 	 * @param association - the joinable association.
 	 *
 	 * @return the table alias on the left-hand-side of the specified association.
 	 */
 	String resolveAssociationLhsTableAlias(JoinableAssociation association);
 
 	/**
 	 * Resolve the column aliases on the left-hand-side of the specified association.
 	 * @param association - the joinable association
 	 * @return the column aliases on the left-hand-side of the specified association.
 	 */
 	String[] resolveAssociationAliasedLhsColumnNames(JoinableAssociation association);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/spi/CollectionReferenceAliases.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/spi/CollectionReferenceAliases.java
new file mode 100644
index 0000000000..611c7e45ad
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/spi/CollectionReferenceAliases.java
@@ -0,0 +1,69 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.exec.spi;
+
+import org.hibernate.loader.CollectionAliases;
+import org.hibernate.loader.EntityAliases;
+
+/**
+ * @author Steve Ebersole
+ */
+public interface CollectionReferenceAliases {
+	/**
+	 * Obtain the table alias used for the collection table of the CollectionReference.
+	 *
+	 * @return The collection table alias.
+	 */
+	public String getCollectionTableAlias();
+
+	/**
+	 * Obtain the alias of the table that contains the collection element values.
+	 * <p/>
+	 * Unlike in the legacy Loader case, CollectionReferences in the LoadPlan code refer to both the
+	 * collection and the elements *always*.  In Loader the elements were handled by EntityPersister associations
+	 * entries for one-to-many and many-to-many.  In LoadPlan we need to describe the collection table/columns
+	 * as well as the entity element table/columns.  For "basic collections" and one-to-many collections, the
+	 * "element table" and the "collection table" are actually the same.  For the many-to-many case this will be
+	 * different and we need to track it separately.
+	 *
+	 * @return The element table alias.  Only different from {@link #getCollectionTableAlias()} in the case of
+	 * many-to-many.
+	 */
+	public String getElementTableAlias();
+
+	/**
+	 * Obtain the aliases for the columns related to the collection structure such as the FK, index/key, or identifier
+	 * (idbag).
+	 *
+	 * @return The collection column aliases.
+	 */
+	public CollectionAliases getCollectionColumnAliases();
+
+	/**
+	 * Obtain the column aliases for the element values when the element of the collection is an entity.
+	 *
+	 * @return The column aliases for the entity element; {@code null} if the collection element is not an entity.
+	 */
+	public EntityAliases getEntityElementColumnAliases();
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/spi/EntityReferenceAliases.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/spi/EntityReferenceAliases.java
new file mode 100644
index 0000000000..e5828f9e78
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/spi/EntityReferenceAliases.java
@@ -0,0 +1,54 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.exec.spi;
+
+import org.hibernate.loader.EntityAliases;
+
+/**
+ * Aggregates the alias/suffix information in relation to an {@link org.hibernate.loader.plan.spi.EntityReference}
+ *
+ * todo : add a contract (interface) that can be shared by entity and collection alias info objects as lhs/rhs of a join ?
+ *
+ * @author Steve Ebersole
+ */
+public interface EntityReferenceAliases {
+	/**
+	 * Obtain the table alias used for referencing the table of the EntityReference.
+	 * <p/>
+	 * Note that this currently just returns the "root alias" whereas sometimes an entity reference covers
+	 * multiple tables.  todo : to help manage this, consider a solution like TableAliasRoot from the initial ANTLR re-work
+	 * see http://anonsvn.jboss.org/repos/hibernate/core/branches/antlr3/src/main/java/org/hibernate/sql/ast/alias/TableAliasGenerator.java
+	 *
+	 * @return The (root) table alias for the described entity reference.
+	 */
+	public String getTableAlias();
+
+	/**
+	 * Obtain the column aliases for the select fragment columns associated with the described entity reference.  These
+	 * are the column renames by which the values can be extracted from the SQL result set.
+	 *
+	 * @return The column aliases associated with the described entity reference.
+	 */
+	public EntityAliases getColumnAliases();
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/spi/LoadQueryDetails.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/spi/LoadQueryDetails.java
new file mode 100644
index 0000000000..a9447578c1
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/spi/LoadQueryDetails.java
@@ -0,0 +1,111 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.exec.spi;
+
+import org.hibernate.LockMode;
+import org.hibernate.LockOptions;
+import org.hibernate.engine.spi.LoadQueryInfluencers;
+import org.hibernate.engine.spi.SessionFactoryImplementor;
+import org.hibernate.loader.plan.exec.internal.AliasResolutionContextImpl;
+import org.hibernate.loader.plan.exec.process.internal.ResultSetProcessorImpl;
+import org.hibernate.loader.plan.exec.process.spi.ResultSetProcessor;
+import org.hibernate.loader.plan.exec.query.internal.EntityLoadQueryBuilderImpl;
+import org.hibernate.loader.plan.exec.query.spi.QueryBuildingParameters;
+import org.hibernate.loader.plan.spi.LoadPlan;
+
+/**
+ * Wraps a LoadPlan (for an entity load) and exposes details about the query and its execution.
+ *
+ * @author Steve Ebersole
+ */
+public class LoadQueryDetails {
+	private final SessionFactoryImplementor factory;
+	private final LoadPlan loadPlan;
+
+	private final AliasResolutionContext aliasResolutionContext;
+	private final String sqlStatement;
+	private final ResultSetProcessor resultSetProcessor;
+
+	/**
+	 * Constructs a LoadQueryDetails object from the given inputs.
+	 *
+	 *
+	 * @param uniqueKeyColumnNames
+	 * @param loadPlan The load plan
+	 * @param factory The SessionFactory
+	 * @param buildingParameters And influencers that would affect the generated SQL (mostly we are concerned with those
+	 * that add additional joins here)
+	 *
+	 * @return The LoadQueryDetails
+	 */
+	public static LoadQueryDetails makeForBatching(
+			String[] uniqueKeyColumnNames,
+			LoadPlan loadPlan,
+			SessionFactoryImplementor factory,
+			QueryBuildingParameters buildingParameters) {
+		final AliasResolutionContext aliasResolutionContext = new AliasResolutionContextImpl( factory );
+		final ResultSetProcessor resultSetProcessor = new ResultSetProcessorImpl( loadPlan, false );
+		final String sqlStatement = EntityLoadQueryBuilderImpl.INSTANCE.generateSql(
+				uniqueKeyColumnNames,
+				loadPlan,
+				factory,
+				buildingParameters,
+				aliasResolutionContext
+		);
+		return new LoadQueryDetails( factory, loadPlan, aliasResolutionContext, resultSetProcessor, sqlStatement );
+	}
+
+	private LoadQueryDetails(
+			SessionFactoryImplementor factory,
+			LoadPlan loadPlan,
+			AliasResolutionContext aliasResolutionContext,
+			ResultSetProcessor resultSetProcessor,
+			String sqlStatement) {
+		this.factory = factory;
+		this.loadPlan = loadPlan;
+		this.aliasResolutionContext = aliasResolutionContext;
+		this.resultSetProcessor = resultSetProcessor;
+		this.sqlStatement = sqlStatement;
+	}
+
+	public SessionFactoryImplementor getFactory() {
+		return factory;
+	}
+
+	public LoadPlan getLoadPlan() {
+		return loadPlan;
+	}
+
+	public AliasResolutionContext getAliasResolutionContext() {
+		return aliasResolutionContext;
+	}
+
+	public String getSqlStatement() {
+		return sqlStatement;
+	}
+
+	public ResultSetProcessor getResultSetProcessor() {
+		return resultSetProcessor;
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/spi/LockModeResolver.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/spi/LockModeResolver.java
new file mode 100644
index 0000000000..55397a2a16
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/spi/LockModeResolver.java
@@ -0,0 +1,34 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.exec.spi;
+
+import org.hibernate.LockMode;
+import org.hibernate.loader.plan.spi.EntityReference;
+
+/**
+ * @author Steve Ebersole
+ */
+public interface LockModeResolver {
+	public LockMode resolveLockMode(EntityReference entityReference);
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/internal/LoadPlanBuildingHelper.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/internal/LoadPlanBuildingHelper.java
index 1cc9e9c40c..05f1318c2a 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/internal/LoadPlanBuildingHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/internal/LoadPlanBuildingHelper.java
@@ -1,79 +1,96 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.internal;
 
 import org.hibernate.LockMode;
 import org.hibernate.engine.FetchStrategy;
+import org.hibernate.loader.plan.spi.AbstractFetchOwner;
+import org.hibernate.loader.plan.spi.AnyFetch;
 import org.hibernate.loader.plan.spi.CollectionFetch;
 import org.hibernate.loader.plan.spi.CompositeFetch;
 import org.hibernate.loader.plan.spi.EntityFetch;
 import org.hibernate.loader.plan.spi.FetchOwner;
 import org.hibernate.loader.plan.spi.build.LoadPlanBuildingContext;
+import org.hibernate.persister.walking.spi.AnyMappingDefinition;
 import org.hibernate.persister.walking.spi.AssociationAttributeDefinition;
+import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.persister.walking.spi.CompositionDefinition;
 
 /**
  * @author Steve Ebersole
  */
 public class LoadPlanBuildingHelper {
 	public static CollectionFetch buildStandardCollectionFetch(
 			FetchOwner fetchOwner,
 			AssociationAttributeDefinition attributeDefinition,
 			FetchStrategy fetchStrategy,
 			LoadPlanBuildingContext loadPlanBuildingContext) {
 		return new CollectionFetch(
 				loadPlanBuildingContext.getSessionFactory(),
 				LockMode.NONE, // todo : for now
 				fetchOwner,
 				fetchStrategy,
-				attributeDefinition.getName()
+				attributeDefinition
 		);
 	}
 
 	public static EntityFetch buildStandardEntityFetch(
 			FetchOwner fetchOwner,
 			AssociationAttributeDefinition attributeDefinition,
 			FetchStrategy fetchStrategy,
 			LoadPlanBuildingContext loadPlanBuildingContext) {
-
 		return new EntityFetch(
 				loadPlanBuildingContext.getSessionFactory(),
 				LockMode.NONE, // todo : for now
 				fetchOwner,
-				attributeDefinition.getName(),
+				attributeDefinition,
 				fetchStrategy
 		);
 	}
 
 	public static CompositeFetch buildStandardCompositeFetch(
 			FetchOwner fetchOwner,
 			CompositionDefinition attributeDefinition,
 			LoadPlanBuildingContext loadPlanBuildingContext) {
 		return new CompositeFetch(
 				loadPlanBuildingContext.getSessionFactory(),
 				fetchOwner,
-				attributeDefinition.getName()
+				attributeDefinition
+		);
+	}
+
+	public static AnyFetch buildAnyFetch(
+			FetchOwner fetchOwner,
+			AttributeDefinition attribute,
+			AnyMappingDefinition anyDefinition,
+			FetchStrategy fetchStrategy, LoadPlanBuildingContext loadPlanBuildingContext) {
+		return new AnyFetch(
+				loadPlanBuildingContext.getSessionFactory(),
+				fetchOwner,
+				attribute,
+				anyDefinition,
+				fetchStrategy
 		);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/internal/LoadPlanImpl.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/internal/LoadPlanImpl.java
index e2df73e13b..f2d190abad 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/internal/LoadPlanImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/internal/LoadPlanImpl.java
@@ -1,64 +1,81 @@
 /*
  * jDocBook, processing of DocBook sources
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.internal;
 
 import java.util.Collections;
 import java.util.List;
 
+import org.hibernate.loader.plan.spi.CollectionReturn;
 import org.hibernate.loader.plan.spi.EntityReturn;
 import org.hibernate.loader.plan.spi.LoadPlan;
 import org.hibernate.loader.plan.spi.Return;
 
 /**
  * Implementation of LoadPlan.
  *
  * @author Steve Ebersole
  */
 public class LoadPlanImpl implements LoadPlan {
-	private final boolean hasScalars;
-	private final List<Return> returns;
+	private final List<? extends Return> returns;
+	private final Disposition disposition;
+	private final boolean areLazyAttributesForceFetched;
 
-	public LoadPlanImpl(boolean hasScalars, List<Return> returns) {
-		this.hasScalars = hasScalars;
+	protected LoadPlanImpl(List<? extends Return> returns, Disposition disposition, boolean areLazyAttributesForceFetched) {
 		this.returns = returns;
+		this.disposition = disposition;
+		this.areLazyAttributesForceFetched = areLazyAttributesForceFetched;
 	}
 
-	public LoadPlanImpl(boolean hasScalars, Return rootReturn) {
-		this( hasScalars, Collections.singletonList( rootReturn ) );
+	public LoadPlanImpl(EntityReturn rootReturn) {
+		this( Collections.singletonList( rootReturn ), Disposition.ENTITY_LOADER, false );
 	}
 
-	public LoadPlanImpl(EntityReturn entityReturn) {
-		this( false, entityReturn );
+	public LoadPlanImpl(CollectionReturn rootReturn) {
+		this( Collections.singletonList( rootReturn ), Disposition.ENTITY_LOADER, false );
 	}
 
-	@Override
-	public boolean hasAnyScalarReturns() {
-		return hasScalars;
+	public LoadPlanImpl(List<? extends Return> returns, boolean areLazyAttributesForceFetched) {
+		this( returns, Disposition.MIXED, areLazyAttributesForceFetched );
 	}
 
 	@Override
-	public List<Return> getReturns() {
+	public List<? extends Return> getReturns() {
 		return returns;
 	}
+
+	@Override
+	public Disposition getDisposition() {
+		return disposition;
+	}
+
+	@Override
+	public boolean areLazyAttributesForceFetched() {
+		return areLazyAttributesForceFetched;
+	}
+
+	@Override
+	public boolean hasAnyScalarReturns() {
+		return disposition == Disposition.MIXED;
+	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/internal/SingleRootReturnLoadPlanBuilderStrategy.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/internal/SingleRootReturnLoadPlanBuilderStrategy.java
index aebb39fce7..7ff3039e54 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/internal/SingleRootReturnLoadPlanBuilderStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/internal/SingleRootReturnLoadPlanBuilderStrategy.java
@@ -1,148 +1,156 @@
 /*
  * jDocBook, processing of DocBook sources
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.internal;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.engine.FetchStrategy;
 import org.hibernate.engine.FetchStyle;
 import org.hibernate.engine.FetchTiming;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.loader.PropertyPath;
 import org.hibernate.loader.plan.spi.build.AbstractLoadPlanBuilderStrategy;
 import org.hibernate.loader.plan.spi.CollectionReturn;
 import org.hibernate.loader.plan.spi.EntityReturn;
 import org.hibernate.loader.plan.spi.LoadPlan;
 import org.hibernate.loader.plan.spi.build.LoadPlanBuilderStrategy;
 import org.hibernate.loader.plan.spi.Return;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.walking.spi.AssociationAttributeDefinition;
 import org.hibernate.persister.walking.spi.CollectionDefinition;
 import org.hibernate.persister.walking.spi.EntityDefinition;
 
 /**
  * LoadPlanBuilderStrategy implementation used for building LoadPlans with a single processing RootEntity LoadPlan building.
  *
  * Really this is a single-root LoadPlan building strategy for building LoadPlans for:<ul>
  *     <li>entity load plans</li>
  *     <li>cascade load plans</li>
  *     <li>collection initializer plans</li>
  * </ul>
  *
  * @author Steve Ebersole
  */
 public class SingleRootReturnLoadPlanBuilderStrategy
 		extends AbstractLoadPlanBuilderStrategy
 		implements LoadPlanBuilderStrategy {
 
 	private final LoadQueryInfluencers loadQueryInfluencers;
 
 	private Return rootReturn;
 
 	private PropertyPath propertyPath = new PropertyPath( "" );
 
 	public SingleRootReturnLoadPlanBuilderStrategy(
 			SessionFactoryImplementor sessionFactory,
 			LoadQueryInfluencers loadQueryInfluencers) {
 		super( sessionFactory );
 		this.loadQueryInfluencers = loadQueryInfluencers;
 	}
 
 	@Override
 	protected boolean supportsRootEntityReturns() {
 		return true;
 	}
 
 	@Override
 	protected boolean supportsRootCollectionReturns() {
 		return true;
 	}
 
 	@Override
 	protected void addRootReturn(Return rootReturn) {
 		if ( this.rootReturn != null ) {
 			throw new HibernateException( "Root return already identified" );
 		}
 		this.rootReturn = rootReturn;
 	}
 
 	@Override
 	public LoadPlan buildLoadPlan() {
-		return new LoadPlanImpl( false, rootReturn );
+		if ( EntityReturn.class.isInstance( rootReturn ) ) {
+			return new LoadPlanImpl( (EntityReturn) rootReturn );
+		}
+		else if ( CollectionReturn.class.isInstance( rootReturn ) ) {
+			return new LoadPlanImpl( (CollectionReturn) rootReturn );
+		}
+		else {
+			throw new IllegalStateException( "Unexpected root Return type : " + rootReturn );
+		}
 	}
 
 	@Override
 	protected FetchStrategy determineFetchPlan(AssociationAttributeDefinition attributeDefinition) {
 		FetchStrategy fetchStrategy = attributeDefinition.determineFetchPlan( loadQueryInfluencers, propertyPath );
 		if ( fetchStrategy.getTiming() == FetchTiming.IMMEDIATE && fetchStrategy.getStyle() == FetchStyle.JOIN ) {
 			// see if we need to alter the join fetch to another form for any reason
 			fetchStrategy = adjustJoinFetchIfNeeded( attributeDefinition, fetchStrategy );
 		}
 		return fetchStrategy;
 	}
 
 	protected FetchStrategy adjustJoinFetchIfNeeded(
 			AssociationAttributeDefinition attributeDefinition,
 			FetchStrategy fetchStrategy) {
 		if ( currentDepth() > sessionFactory().getSettings().getMaximumFetchDepth() ) {
 			return new FetchStrategy( fetchStrategy.getTiming(), FetchStyle.SELECT );
 		}
 
 		if ( attributeDefinition.getType().isCollectionType() && isTooManyCollections() ) {
 			// todo : have this revert to batch or subselect fetching once "sql gen redesign" is in place
 			return new FetchStrategy( fetchStrategy.getTiming(), FetchStyle.SELECT );
 		}
 
 		return fetchStrategy;
 	}
 
 	@Override
 	protected boolean isTooManyCollections() {
 		return false;
 	}
 
 	@Override
 	protected EntityReturn buildRootEntityReturn(EntityDefinition entityDefinition) {
 		final String entityName = entityDefinition.getEntityPersister().getEntityName();
 		return new EntityReturn(
 				sessionFactory(),
 				LockMode.NONE, // todo : for now
 				entityName
 		);
 	}
 
 	@Override
 	protected CollectionReturn buildRootCollectionReturn(CollectionDefinition collectionDefinition) {
 		final CollectionPersister persister = collectionDefinition.getCollectionPersister();
 		final String collectionRole = persister.getRole();
 		return new CollectionReturn(
 				sessionFactory(),
 				LockMode.NONE, // todo : for now
 				persister.getOwnerEntityPersister().getEntityName(),
 				StringHelper.unqualify( collectionRole )
 		);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/AbstractCollectionReference.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/AbstractCollectionReference.java
index ea1c61659d..3cf0665646 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/AbstractCollectionReference.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/AbstractCollectionReference.java
@@ -1,126 +1,162 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi;
 
 import org.hibernate.LockMode;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.loader.PropertyPath;
 import org.hibernate.persister.collection.CollectionPersister;
+import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 /**
  * @author Steve Ebersole
  */
 public abstract class AbstractCollectionReference extends AbstractPlanNode implements CollectionReference {
 	private final LockMode lockMode;
 	private final CollectionPersister collectionPersister;
 	private final PropertyPath propertyPath;
 
 	private final FetchableCollectionIndex indexGraph;
 	private final FetchableCollectionElement elementGraph;
 
 	protected AbstractCollectionReference(
 			SessionFactoryImplementor sessionFactory,
 			LockMode lockMode,
 			CollectionPersister collectionPersister,
-			PropertyPath propertyPath) {
+			PropertyPath propertyPath,
+			EntityReference ownerEntityReference) {
 		super( sessionFactory );
 		this.lockMode = lockMode;
 		this.collectionPersister = collectionPersister;
 		this.propertyPath = propertyPath;
 
 		this.indexGraph = buildIndexGraph( getCollectionPersister() );
-		this.elementGraph = buildElementGraph( getCollectionPersister() );
+		this.elementGraph = buildElementGraph( getCollectionPersister(), ownerEntityReference );
 	}
 
 	private FetchableCollectionIndex buildIndexGraph(CollectionPersister persister) {
 		if ( persister.hasIndex() ) {
 			final Type type = persister.getIndexType();
 			if ( type.isAssociationType() ) {
 				if ( type.isEntityType() ) {
 					return new EntityIndexGraph( sessionFactory(), this, getPropertyPath() );
 				}
 			}
 			else if ( type.isComponentType() ) {
 				return new CompositeIndexGraph( sessionFactory(), this, getPropertyPath() );
 			}
 		}
 
 		return null;
 	}
 
-	private FetchableCollectionElement buildElementGraph(CollectionPersister persister) {
+	private FetchableCollectionElement buildElementGraph(
+			CollectionPersister persister,
+			EntityReference ownerEntityReference) {
 		final Type type = persister.getElementType();
 		if ( type.isAssociationType() ) {
 			if ( type.isEntityType() ) {
+				final EntityType elementEntityType = (EntityType) type;
+
+				if ( ownerEntityReference != null ) {
+					// check for bi-directionality
+					final boolean sameType = elementEntityType.getAssociatedEntityName().equals(
+							ownerEntityReference.getEntityPersister().getEntityName()
+					);
+					if ( sameType ) {
+						// todo : check for columns too...
+
+						return new BidirectionalEntityElementGraph(
+								sessionFactory(),
+								this,
+								getPropertyPath(),
+								ownerEntityReference
+						);
+					}
+				}
 				return new EntityElementGraph( sessionFactory(), this, getPropertyPath() );
 			}
 		}
 		else if ( type.isComponentType() ) {
 			return new CompositeElementGraph( sessionFactory(), this, getPropertyPath() );
 		}
 
 		return null;
 	}
 
 	protected AbstractCollectionReference(AbstractCollectionReference original, CopyContext copyContext) {
 		super( original );
 		this.lockMode = original.lockMode;
 		this.collectionPersister = original.collectionPersister;
 		this.propertyPath = original.propertyPath;
 
 		this.indexGraph = original.indexGraph == null ? null : original.indexGraph.makeCopy( copyContext );
 		this.elementGraph = original.elementGraph == null ? null : original.elementGraph.makeCopy( copyContext );
 	}
 
 	@Override
 	public PropertyPath getPropertyPath() {
 		return propertyPath;
 	}
 
 	@Override
 	public LockMode getLockMode() {
 		return lockMode;
 	}
 
 	@Override
 	public CollectionPersister getCollectionPersister() {
 		return collectionPersister;
 	}
 
 	@Override
 	public FetchOwner getIndexGraph() {
 		return indexGraph;
 	}
 
 	@Override
 	public FetchOwner getElementGraph() {
 		return elementGraph;
 	}
 
-	@Override
-	public boolean hasEntityElements() {
-		return getCollectionPersister().isOneToMany() || getCollectionPersister().isManyToMany();
+
+	private class BidirectionalEntityElementGraph extends EntityElementGraph implements BidirectionalEntityFetch {
+		private final EntityReference targetEntityReference;
+
+		private BidirectionalEntityElementGraph(
+				SessionFactoryImplementor sessionFactory,
+				CollectionReference collectionReference,
+				PropertyPath propertyPath,
+				EntityReference targetEntityReference) {
+			super( sessionFactory, collectionReference, propertyPath );
+			this.targetEntityReference = targetEntityReference;
+		}
+
+		@Override
+		public EntityReference getTargetEntityReference() {
+			return targetEntityReference;
+		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/AbstractFetchOwner.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/AbstractFetchOwner.java
index b078d46cc1..fcc51e13c1 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/AbstractFetchOwner.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/AbstractFetchOwner.java
@@ -1,157 +1,168 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi;
 
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.List;
 
 import org.hibernate.engine.FetchStrategy;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.loader.plan.internal.LoadPlanBuildingHelper;
 import org.hibernate.loader.plan.spi.build.LoadPlanBuildingContext;
+import org.hibernate.persister.walking.spi.AnyMappingDefinition;
 import org.hibernate.persister.walking.spi.AssociationAttributeDefinition;
+import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.persister.walking.spi.CompositionDefinition;
 import org.hibernate.type.Type;
 
 /**
  * This is a class for fetch owners, providing functionality related to the owned
  * fetches.
  *
  * @author Steve Ebersole
  * @author Gail Badner
  */
 public abstract class AbstractFetchOwner extends AbstractPlanNode implements FetchOwner {
 
 	// TODO: I removed lockMode from this method because I *think* it only relates to EntityFetch and EntityReturn.
 	//       lockMode should be moved back here if it applies to all fetch owners.
 
 	private List<Fetch> fetches;
 
 	public AbstractFetchOwner(SessionFactoryImplementor factory) {
 		super( factory );
 		validate();
 	}
 
 	private void validate() {
 	}
 
 	/**
 	 * A "copy" constructor.  Used while making clones/copies of this.
 	 *
 	 * @param original - the original object to copy.
 	 * @param copyContext - the copy context.
 	 */
 	protected AbstractFetchOwner(AbstractFetchOwner original, CopyContext copyContext) {
 		super( original );
 		validate();
 
 		// TODO: I don't think this is correct; shouldn't the fetches from original be copied into this???
 		copyContext.getReturnGraphVisitationStrategy().startingFetches( original );
 		if ( fetches == null || fetches.size() == 0 ) {
 			this.fetches = Collections.emptyList();
 		}
 		else {
 			List<Fetch> fetchesCopy = new ArrayList<Fetch>();
 			for ( Fetch fetch : fetches ) {
 				fetchesCopy.add( fetch.makeCopy( copyContext, this ) );
 			}
 			this.fetches = fetchesCopy;
 		}
 		copyContext.getReturnGraphVisitationStrategy().finishingFetches( original );
 	}
 
 	@Override
 	public void addFetch(Fetch fetch) {
 		if ( fetch.getOwner() != this ) {
 			throw new IllegalArgumentException( "Fetch and owner did not match" );
 		}
 
 		if ( fetches == null ) {
 			fetches = new ArrayList<Fetch>();
 		}
 
 		fetches.add( fetch );
 	}
 
 	@Override
 	public Fetch[] getFetches() {
 		return fetches == null ? NO_FETCHES : fetches.toArray( new Fetch[ fetches.size() ] );
 	}
 
-	/**
-	 * Abstract method returning the delegate for obtaining details about an owned fetch.
-	 * @return the delegate
-	 */
-	protected abstract FetchOwnerDelegate getFetchOwnerDelegate();
-
 	@Override
 	public boolean isNullable(Fetch fetch) {
-		return getFetchOwnerDelegate().locateFetchMetadata( fetch ).isNullable();
+		return fetch.isNullable();
 	}
 
 	@Override
 	public Type getType(Fetch fetch) {
-		return getFetchOwnerDelegate().locateFetchMetadata( fetch ).getType();
+		return fetch.getFetchedType();
 	}
 
 	@Override
 	public String[] toSqlSelectFragments(Fetch fetch, String alias) {
-		return getFetchOwnerDelegate().locateFetchMetadata( fetch ).toSqlSelectFragments( alias );
+		return fetch.toSqlSelectFragments( alias );
+	}
+
+	@Override
+	public AnyFetch buildAnyFetch(
+			AttributeDefinition attribute,
+			AnyMappingDefinition anyDefinition,
+			FetchStrategy fetchStrategy,
+			LoadPlanBuildingContext loadPlanBuildingContext) {
+		return LoadPlanBuildingHelper.buildAnyFetch(
+				this,
+				attribute,
+				anyDefinition,
+				fetchStrategy,
+				loadPlanBuildingContext
+		);
 	}
 
 	@Override
 	public CollectionFetch buildCollectionFetch(
 			AssociationAttributeDefinition attributeDefinition,
 			FetchStrategy fetchStrategy,
 			LoadPlanBuildingContext loadPlanBuildingContext) {
 		return LoadPlanBuildingHelper.buildStandardCollectionFetch(
 				this,
 				attributeDefinition,
 				fetchStrategy,
 				loadPlanBuildingContext
 		);
 	}
 
 	@Override
 	public EntityFetch buildEntityFetch(
 			AssociationAttributeDefinition attributeDefinition,
 			FetchStrategy fetchStrategy,
 			LoadPlanBuildingContext loadPlanBuildingContext) {
 		return LoadPlanBuildingHelper.buildStandardEntityFetch(
 				this,
 				attributeDefinition,
 				fetchStrategy,
 				loadPlanBuildingContext
 		);
 	}
 
 	@Override
 	public CompositeFetch buildCompositeFetch(
 			CompositionDefinition attributeDefinition,
 			LoadPlanBuildingContext loadPlanBuildingContext) {
 		return LoadPlanBuildingHelper.buildStandardCompositeFetch( this, attributeDefinition, loadPlanBuildingContext );
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/AbstractSingularAttributeFetch.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/AbstractSingularAttributeFetch.java
index e3d07dc3ab..2f589ddeb4 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/AbstractSingularAttributeFetch.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/AbstractSingularAttributeFetch.java
@@ -1,122 +1,142 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi;
 
 import org.hibernate.HibernateException;
 import org.hibernate.engine.FetchStrategy;
 import org.hibernate.engine.FetchStyle;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.loader.PropertyPath;
+import org.hibernate.persister.walking.spi.AttributeDefinition;
+import org.hibernate.type.Type;
 
 /**
  * Represents a singular attribute that is both a {@link FetchOwner} and a {@link Fetch}.
  *
  * @author Steve Ebersole
  * @author Gail Badner
  */
 public abstract class AbstractSingularAttributeFetch extends AbstractFetchOwner implements Fetch {
 	private final FetchOwner owner;
-	private final String ownerProperty;
+	private final AttributeDefinition fetchedAttribute;
 	private final FetchStrategy fetchStrategy;
 
 	private final PropertyPath propertyPath;
 
 	/**
 	 * Constructs an {@link AbstractSingularAttributeFetch} object.
 	 *
 	 * @param factory - the session factory.
 	 * @param owner - the fetch owner for this fetch.
-	 * @param ownerProperty - the owner's property referring to this fetch.
+	 * @param fetchedAttribute - the attribute being fetched
 	 * @param fetchStrategy - the fetch strategy for this fetch.
 	 */
 	public AbstractSingularAttributeFetch(
 			SessionFactoryImplementor factory,
 			FetchOwner owner,
-			String ownerProperty,
+			AttributeDefinition fetchedAttribute,
 			FetchStrategy fetchStrategy) {
 		super( factory );
 		this.owner = owner;
-		this.ownerProperty = ownerProperty;
+		this.fetchedAttribute = fetchedAttribute;
 		this.fetchStrategy = fetchStrategy;
 
 		owner.addFetch( this );
 
-		this.propertyPath = owner.getPropertyPath().append( ownerProperty );
+		this.propertyPath = owner.getPropertyPath().append( fetchedAttribute.getName() );
 	}
 
 	public AbstractSingularAttributeFetch(
 			AbstractSingularAttributeFetch original,
 			CopyContext copyContext,
 			FetchOwner fetchOwnerCopy) {
 		super( original, copyContext );
 		this.owner = fetchOwnerCopy;
-		this.ownerProperty = original.ownerProperty;
+		this.fetchedAttribute = original.fetchedAttribute;
 		this.fetchStrategy = original.fetchStrategy;
 		this.propertyPath = original.propertyPath;
 	}
 
 	@Override
 	public FetchOwner getOwner() {
 		return owner;
 	}
 
+	public AttributeDefinition getFetchedAttribute() {
+		return fetchedAttribute;
+	}
+
 	@Override
-	public String getOwnerPropertyName() {
-		return ownerProperty;
+	public Type getFetchedType() {
+		return fetchedAttribute.getType();
 	}
 
 	@Override
 	public boolean isNullable() {
-		return owner.isNullable( this );
+		return fetchedAttribute.isNullable();
+//		return owner.isNullable( this );
 	}
 
 	@Override
 	public String[] toSqlSelectFragments(String alias) {
 		return owner.toSqlSelectFragments( this, alias );
 	}
 
 	@Override
 	public FetchStrategy getFetchStrategy() {
 		return fetchStrategy;
 	}
 
 	@Override
-	public void validateFetchPlan(FetchStrategy fetchStrategy) {
+	public String getAdditionalJoinConditions() {
+		// only pertinent for HQL...
+		return null;
+	}
+
+	@Override
+	public void validateFetchPlan(FetchStrategy fetchStrategy, AttributeDefinition attributeDefinition) {
 		if ( fetchStrategy.getStyle() == FetchStyle.JOIN ) {
 			if ( this.fetchStrategy.getStyle() != FetchStyle.JOIN ) {
-				throw new HibernateException( "Cannot specify join fetch from owner that is a non-joined fetch" );
+
+				throw new HibernateException(
+						String.format(
+								"Cannot specify join fetch from owner [%s] that is a non-joined fetch : %s",
+								getPropertyPath().getFullPath(),
+								attributeDefinition.getName()
+						)
+				);
 			}
 		}
 	}
 
 	@Override
 	public PropertyPath getPropertyPath() {
 		return propertyPath;
 	}
 
 	@Override
 	public String toString() {
 		return "Fetch(" + propertyPath.getFullPath() + ")";
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/AnyFetch.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/AnyFetch.java
new file mode 100644
index 0000000000..a26cf822da
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/AnyFetch.java
@@ -0,0 +1,141 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.spi;
+
+import java.sql.ResultSet;
+import java.sql.SQLException;
+
+import org.hibernate.cfg.NotYetImplementedException;
+import org.hibernate.engine.FetchStrategy;
+import org.hibernate.engine.spi.SessionFactoryImplementor;
+import org.hibernate.loader.PropertyPath;
+import org.hibernate.loader.plan.exec.process.spi.ResultSetProcessingContext;
+import org.hibernate.persister.walking.spi.AnyMappingDefinition;
+import org.hibernate.persister.walking.spi.AttributeDefinition;
+import org.hibernate.type.AnyType;
+
+/**
+ * @author Steve Ebersole
+ */
+public class AnyFetch extends AbstractPlanNode implements Fetch {
+	private final FetchOwner owner;
+	private final AttributeDefinition fetchedAttribute;
+	private final AnyMappingDefinition definition;
+	private final FetchStrategy fetchStrategy;
+
+	private final PropertyPath propertyPath;
+
+	public AnyFetch(
+			SessionFactoryImplementor sessionFactory,
+			FetchOwner owner,
+			AttributeDefinition ownerProperty,
+			AnyMappingDefinition definition,
+			FetchStrategy fetchStrategy) {
+		super( sessionFactory );
+
+		this.owner = owner;
+		this.fetchedAttribute = ownerProperty;
+		this.definition = definition;
+		this.fetchStrategy = fetchStrategy;
+
+		this.propertyPath = owner.getPropertyPath().append( ownerProperty.getName() );
+
+		owner.addFetch( this );
+	}
+
+	/**
+	 * Copy constructor.
+	 *
+	 * @param original The original fetch
+	 * @param copyContext Access to contextual needs for the copy operation
+	 */
+	protected AnyFetch(AnyFetch original, CopyContext copyContext, FetchOwner fetchOwnerCopy) {
+		super( original );
+		this.owner = fetchOwnerCopy;
+		this.fetchedAttribute = original.fetchedAttribute;
+		this.definition = original.definition;
+		this.fetchStrategy = original.fetchStrategy;
+		this.propertyPath = original.propertyPath;
+	}
+
+	@Override
+	public FetchOwner getOwner() {
+		return owner;
+	}
+
+	@Override
+	public AnyType getFetchedType() {
+		return (AnyType) fetchedAttribute.getType();
+	}
+
+	@Override
+	public boolean isNullable() {
+		return owner.isNullable( this );
+	}
+
+	@Override
+	public String[] toSqlSelectFragments(String alias) {
+		return owner.toSqlSelectFragments( this, alias );
+	}
+
+	@Override
+	public String getAdditionalJoinConditions() {
+		// only pertinent for HQL...
+		return null;
+	}
+
+	@Override
+	public FetchStrategy getFetchStrategy() {
+		return fetchStrategy;
+	}
+
+	@Override
+	public PropertyPath getPropertyPath() {
+		return propertyPath;
+	}
+
+	@Override
+	public void hydrate(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
+		throw new NotYetImplementedException();
+	}
+
+	@Override
+	public Object resolve(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
+		throw new NotYetImplementedException();
+	}
+
+	@Override
+	public void read(ResultSet resultSet, ResultSetProcessingContext context, Object owner) throws SQLException {
+		throw new NotYetImplementedException();
+	}
+
+	@Override
+	public AnyFetch makeCopy(CopyContext copyContext, FetchOwner fetchOwnerCopy) {
+		copyContext.getReturnGraphVisitationStrategy().startingAnyFetch( this );
+		final AnyFetch copy = new AnyFetch( this, copyContext, fetchOwnerCopy );
+		copyContext.getReturnGraphVisitationStrategy().startingAnyFetch( this );
+		return copy;
+	}
+
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/BidirectionalEntityFetch.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/BidirectionalEntityFetch.java
new file mode 100644
index 0000000000..8e00dbda3e
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/BidirectionalEntityFetch.java
@@ -0,0 +1,35 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.spi;
+
+/**
+ * Represents the circular side of a bi-directional entity fetch.  Wraps a reference to an EntityReference
+ * as an EntityFetch.  We can use the special type as a trigger in AliasResolutionContext, etc to lookup information
+ * based on the wrapped reference.
+ *
+ * @author Steve Ebersole
+ */
+public interface BidirectionalEntityFetch {
+	public EntityReference getTargetEntityReference();
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CollectionFetch.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CollectionFetch.java
index 4f8816e7d1..9c9b0f2a52 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CollectionFetch.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CollectionFetch.java
@@ -1,108 +1,207 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi;
 
+import java.io.Serializable;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 
+import org.jboss.logging.Logger;
+
 import org.hibernate.LockMode;
+import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.FetchStrategy;
+import org.hibernate.engine.spi.EntityKey;
+import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
-import org.hibernate.loader.spi.ResultSetProcessingContext;
+import org.hibernate.internal.CoreLogging;
+import org.hibernate.loader.CollectionAliases;
+import org.hibernate.loader.plan.exec.process.internal.Helper;
+import org.hibernate.loader.plan.exec.process.spi.ResultSetProcessingContext;
+import org.hibernate.persister.walking.spi.AttributeDefinition;
+import org.hibernate.pretty.MessageHelper;
+import org.hibernate.type.CollectionType;
 
 /**
  * @author Steve Ebersole
  */
 public class CollectionFetch extends AbstractCollectionReference implements Fetch {
+	private static final Logger log = CoreLogging.logger( CollectionFetch.class );
+
 	private final FetchOwner fetchOwner;
+	private final AttributeDefinition fetchedAttribute;
 	private final FetchStrategy fetchStrategy;
 
 	public CollectionFetch(
 			SessionFactoryImplementor sessionFactory,
 			LockMode lockMode,
 			FetchOwner fetchOwner,
 			FetchStrategy fetchStrategy,
-			String ownerProperty) {
+			AttributeDefinition fetchedAttribute) {
 		super(
 				sessionFactory,
 				lockMode,
-				sessionFactory.getCollectionPersister(
-						fetchOwner.retrieveFetchSourcePersister().getEntityName() + '.' + ownerProperty
-				),
-				fetchOwner.getPropertyPath().append( ownerProperty )
+				sessionFactory.getCollectionPersister( ( (CollectionType) fetchedAttribute.getType() ).getRole() ),
+				fetchOwner.getPropertyPath().append( fetchedAttribute.getName() ),
+				(EntityReference) fetchOwner
 		);
 		this.fetchOwner = fetchOwner;
+		this.fetchedAttribute = fetchedAttribute;
 		this.fetchStrategy = fetchStrategy;
 		fetchOwner.addFetch( this );
 	}
 
 	protected CollectionFetch(CollectionFetch original, CopyContext copyContext, FetchOwner fetchOwnerCopy) {
 		super( original, copyContext );
 		this.fetchOwner = fetchOwnerCopy;
+		this.fetchedAttribute = original.fetchedAttribute;
 		this.fetchStrategy = original.fetchStrategy;
 	}
 
 	@Override
 	public FetchOwner getOwner() {
 		return fetchOwner;
 	}
 
 	@Override
-	public String getOwnerPropertyName() {
-		return getPropertyPath().getProperty();
+	public CollectionType getFetchedType() {
+		return (CollectionType) fetchedAttribute.getType();
 	}
 
 	@Override
 	public boolean isNullable() {
 		return true;
 	}
 
 	@Override
+	public String getAdditionalJoinConditions() {
+		// only pertinent for HQL...
+		return null;
+	}
+
+	@Override
 	public String[] toSqlSelectFragments(String alias) {
-		return getOwner().toSqlSelectFragments( this, alias );
+		return getOwner().toSqlSelectFragmentResolver().toSqlSelectFragments( alias, fetchedAttribute );
 	}
 
 	@Override
 	public FetchStrategy getFetchStrategy() {
 		return fetchStrategy;
 	}
 
 	@Override
 	public void hydrate(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
 		//To change body of implemented methods use File | Settings | File Templates.
 	}
 
 	@Override
 	public Object resolve(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
-		return null;  //To change body of implemented methods use File | Settings | File Templates.
+		return null;
+	}
+
+	@Override
+	public void read(ResultSet resultSet, ResultSetProcessingContext context, Object owner) throws SQLException {
+		final Serializable collectionRowKey = (Serializable) getCollectionPersister().readKey(
+				resultSet,
+				context.getAliasResolutionContext().resolveAliases( this ).getCollectionColumnAliases().getSuffixedKeyAliases(),
+				context.getSession()
+		);
+
+		final PersistenceContext persistenceContext = context.getSession().getPersistenceContext();
+
+		if ( collectionRowKey == null ) {
+			// we did not find a collection element in the result set, so we
+			// ensure that a collection is created with the owner's identifier,
+			// since what we have is an empty collection
+			final EntityKey ownerEntityKey = findOwnerEntityKey( context );
+			if ( ownerEntityKey == null ) {
+				// should not happen
+				throw new IllegalStateException(
+						"Could not locate owner's EntityKey during attempt to read collection element fro JDBC row : " +
+								getPropertyPath().getFullPath()
+				);
+			}
+
+			if ( log.isDebugEnabled() ) {
+				log.debugf(
+						"Result set contains (possibly empty) collection: %s",
+						MessageHelper.collectionInfoString(
+								getCollectionPersister(),
+								ownerEntityKey,
+								context.getSession().getFactory()
+						)
+				);
+			}
+
+			persistenceContext.getLoadContexts()
+					.getCollectionLoadContext( resultSet )
+					.getLoadingCollection( getCollectionPersister(), ownerEntityKey );
+		}
+		else {
+			// we found a collection element in the result set
+			if ( log.isDebugEnabled() ) {
+				log.debugf(
+						"Found row of collection: %s",
+						MessageHelper.collectionInfoString(
+								getCollectionPersister(),
+								collectionRowKey,
+								context.getSession().getFactory()
+						)
+				);
+			}
+
+			PersistentCollection rowCollection = persistenceContext.getLoadContexts()
+					.getCollectionLoadContext( resultSet )
+					.getLoadingCollection( getCollectionPersister(), collectionRowKey );
+
+			final CollectionAliases descriptor = context.getAliasResolutionContext().resolveAliases( this ).getCollectionColumnAliases();
+
+			if ( rowCollection != null ) {
+				final Object element = rowCollection.readFrom( resultSet, getCollectionPersister(), descriptor, owner );
+
+				if ( getElementGraph() != null ) {
+					for ( Fetch fetch : getElementGraph().getFetches() ) {
+						fetch.read( resultSet, context, element );
+					}
+				}
+			}
+		}
+	}
+
+	private EntityKey findOwnerEntityKey(ResultSetProcessingContext context) {
+		return context.getProcessingState( findOwnerEntityReference( getOwner() ) ).getEntityKey();
+	}
+
+	private EntityReference findOwnerEntityReference(FetchOwner owner) {
+		return Helper.INSTANCE.findOwnerEntityReference( owner );
 	}
 
 	@Override
 	public CollectionFetch makeCopy(CopyContext copyContext, FetchOwner fetchOwnerCopy) {
 		copyContext.getReturnGraphVisitationStrategy().startingCollectionFetch( this );
 		final CollectionFetch copy = new CollectionFetch( this, copyContext, fetchOwnerCopy );
 		copyContext.getReturnGraphVisitationStrategy().finishingCollectionFetch( this );
 		return copy;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CollectionReference.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CollectionReference.java
index 83dec611cc..0311ff3b06 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CollectionReference.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CollectionReference.java
@@ -1,58 +1,56 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi;
 
 import org.hibernate.LockMode;
 import org.hibernate.loader.PropertyPath;
 import org.hibernate.persister.collection.CollectionPersister;
 
 /**
  * Represents a reference to an owned collection either as a return or as a fetch
  *
  * @author Steve Ebersole
  */
 public interface CollectionReference {
 
 	/**
 	 * Retrieve the lock mode associated with this return.
 	 *
 	 * @return The lock mode.
 	 */
 	public LockMode getLockMode();
 
 	/**
 	 * Retrieves the CollectionPersister describing the collection associated with this Return.
 	 *
 	 * @return The CollectionPersister.
 	 */
 	public CollectionPersister getCollectionPersister();
 
 	public FetchOwner getIndexGraph();
 
 	public FetchOwner getElementGraph();
 
 	public PropertyPath getPropertyPath();
-
-	public boolean hasEntityElements();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CollectionReturn.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CollectionReturn.java
index 933533ec80..4e709eb2ed 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CollectionReturn.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CollectionReturn.java
@@ -1,104 +1,88 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi;
 
-import java.sql.ResultSet;
-import java.sql.SQLException;
-
 import org.hibernate.LockMode;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.loader.PropertyPath;
-import org.hibernate.loader.spi.ResultSetProcessingContext;
 
 /**
  * @author Steve Ebersole
  */
 public class CollectionReturn extends AbstractCollectionReference implements Return, CopyableReturn {
 	private final String ownerEntityName;
 	private final String ownerProperty;
 
 	public CollectionReturn(
 			SessionFactoryImplementor sessionFactory,
 			LockMode lockMode,
 			String ownerEntityName,
 			String ownerProperty) {
 		super(
 				sessionFactory,
 				lockMode,
 				sessionFactory.getCollectionPersister( ownerEntityName + '.' + ownerProperty ),
-				new PropertyPath() // its a root
+				// its a root
+				new PropertyPath(),
+				// no owner
+				null
 		);
 		this.ownerEntityName = ownerEntityName;
 		this.ownerProperty = ownerProperty;
 	}
 
 	public CollectionReturn(CollectionReturn original, CopyContext copyContext) {
 		super( original, copyContext );
 		this.ownerEntityName = original.ownerEntityName;
 		this.ownerProperty = original.ownerProperty;
 	}
 
 	/**
 	 * Returns the class owning the collection.
 	 *
 	 * @return The class owning the collection.
 	 */
 	public String getOwnerEntityName() {
 		return ownerEntityName;
 	}
 
 	/**
 	 * Returns the name of the property representing the collection from the {@link #getOwnerEntityName}.
 	 *
 	 * @return The name of the property representing the collection on the owner class.
 	 */
 	public String getOwnerProperty() {
 		return ownerProperty;
 	}
 
 	@Override
-	public void hydrate(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
-		// todo : anything to do here?
-	}
-
-	@Override
-	public void resolve(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
-		// todo : anything to do here?
-	}
-
-	@Override
-	public Object read(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
-		return null;  //To change body of implemented methods use File | Settings | File Templates.
-	}
-
-	@Override
 	public String toString() {
 		return "CollectionReturn(" + getCollectionPersister().getRole() + ")";
 	}
 
 	@Override
 	public CollectionReturn makeCopy(CopyContext copyContext) {
 		return new CollectionReturn( this, copyContext );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CompositeBasedSqlSelectFragmentResolver.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CompositeBasedSqlSelectFragmentResolver.java
new file mode 100644
index 0000000000..5e8f6543bc
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CompositeBasedSqlSelectFragmentResolver.java
@@ -0,0 +1,88 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.spi;
+
+import java.util.Arrays;
+
+import org.hibernate.engine.spi.SessionFactoryImplementor;
+import org.hibernate.persister.walking.spi.AttributeDefinition;
+import org.hibernate.persister.walking.spi.WalkingException;
+import org.hibernate.type.CompositeType;
+import org.hibernate.type.Type;
+
+/**
+ * @author Steve Ebersole
+ */
+public class CompositeBasedSqlSelectFragmentResolver implements SqlSelectFragmentResolver {
+	protected static interface BaseSqlSelectFragmentResolver {
+		public String[] toSqlSelectFragments(String alias);
+	}
+
+	public CompositeBasedSqlSelectFragmentResolver(
+			SessionFactoryImplementor sessionFactory, CompositeType compositeType,
+			BaseSqlSelectFragmentResolver baseResolver) {
+		this.sessionFactory = sessionFactory;
+		this.compositeType = compositeType;
+		this.baseResolver = baseResolver;
+	}
+
+	private final SessionFactoryImplementor sessionFactory;
+	private final CompositeType compositeType;
+	private final BaseSqlSelectFragmentResolver baseResolver;
+
+	@Override
+	public String[] toSqlSelectFragments(String alias, AttributeDefinition attributeDefinition) {
+		int subIndex = -1;
+		int selectFragmentRangeStart = 0;
+		int selectFragmentRangeEnd = -1;
+
+		for ( int i = 0; i < compositeType.getPropertyNames().length; i++ ) {
+			final Type type = compositeType.getSubtypes()[i];
+			final int typeColSpan = type.getColumnSpan( sessionFactory );
+			if ( compositeType.getPropertyNames()[ i ].equals( attributeDefinition.getName() ) ) {
+				// fount it!
+				subIndex = i;
+				selectFragmentRangeEnd = selectFragmentRangeStart + typeColSpan;
+				break;
+			}
+			selectFragmentRangeStart += typeColSpan;
+		}
+
+		if ( subIndex < 0 ) {
+			throw new WalkingException(
+					String.format(
+							"Owner property [%s] not found in composite properties [%s]",
+							attributeDefinition.getName(),
+							Arrays.asList( compositeType.getPropertyNames() )
+					)
+			);
+		}
+
+		return Arrays.copyOfRange(
+				baseResolver.toSqlSelectFragments( alias ),
+				selectFragmentRangeStart,
+				selectFragmentRangeEnd
+		);
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CompositeElementGraph.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CompositeElementGraph.java
index c45c47ef2a..44ae6ddb35 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CompositeElementGraph.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CompositeElementGraph.java
@@ -1,98 +1,100 @@
 package org.hibernate.loader.plan.spi;
 
 import org.hibernate.HibernateException;
 import org.hibernate.engine.FetchStrategy;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.loader.PropertyPath;
 import org.hibernate.loader.plan.spi.build.LoadPlanBuildingContext;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.walking.spi.AssociationAttributeDefinition;
+import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.type.CompositeType;
 
 /**
  * Represents the {@link FetchOwner} for a composite collection element.
  *
  * @author Steve Ebersole
  * @author Gail Badner
  */
 public class CompositeElementGraph extends AbstractFetchOwner implements FetchableCollectionElement {
 	private final CollectionReference collectionReference;
 	private final PropertyPath propertyPath;
 	private final CollectionPersister collectionPersister;
-	private final FetchOwnerDelegate fetchOwnerDelegate;
+	private final CompositeBasedSqlSelectFragmentResolver sqlSelectFragmentResolver;
 
 	/**
 	 * Constructs a {@link CompositeElementGraph}.
 	 *
 	 * @param sessionFactory - the session factory.
 	 * @param collectionReference - the collection reference.
 	 * @param collectionPath - the {@link PropertyPath} for the collection.
 	 */
 	public CompositeElementGraph(
 			SessionFactoryImplementor sessionFactory,
 			CollectionReference collectionReference,
 			PropertyPath collectionPath) {
 		super( sessionFactory );
 
 		this.collectionReference = collectionReference;
 		this.collectionPersister = collectionReference.getCollectionPersister();
 		this.propertyPath = collectionPath.append( "<elements>" );
-		this.fetchOwnerDelegate = new CompositeFetchOwnerDelegate(
+		this.sqlSelectFragmentResolver = new CompositeBasedSqlSelectFragmentResolver(
 				sessionFactory,
 				(CompositeType) collectionPersister.getElementType(),
-				new CompositeFetchOwnerDelegate.PropertyMappingDelegate() {
+				new CompositeBasedSqlSelectFragmentResolver.BaseSqlSelectFragmentResolver() {
 					@Override
 					public String[] toSqlSelectFragments(String alias) {
-						return  ( (QueryableCollection) collectionPersister ).getElementColumnNames( alias );
+						return ( (QueryableCollection) collectionPersister ).getElementColumnNames( alias );
 					}
 				}
+
 		);
 	}
 
 	public CompositeElementGraph(CompositeElementGraph original, CopyContext copyContext) {
 		super( original, copyContext );
 		this.collectionReference = original.collectionReference;
 		this.collectionPersister = original.collectionPersister;
 		this.propertyPath = original.propertyPath;
-		this.fetchOwnerDelegate = original.fetchOwnerDelegate;
+		this.sqlSelectFragmentResolver = original.sqlSelectFragmentResolver;
 	}
 
 	@Override
 	public CollectionReference getCollectionReference() {
 		return collectionReference;
 	}
 
 	@Override
-	public void validateFetchPlan(FetchStrategy fetchStrategy) {
+	public void validateFetchPlan(FetchStrategy fetchStrategy, AttributeDefinition attributeDefinition) {
 	}
 
 	@Override
 	public EntityPersister retrieveFetchSourcePersister() {
 		return collectionPersister.getOwnerEntityPersister();
 	}
 
 	@Override
 	public PropertyPath getPropertyPath() {
 		return propertyPath;
 	}
 
 	@Override
 	public CompositeElementGraph makeCopy(CopyContext copyContext) {
 		return new CompositeElementGraph( this, copyContext );
 	}
 
 	@Override
-	protected FetchOwnerDelegate getFetchOwnerDelegate() {
-		return fetchOwnerDelegate;
-	}
-
-	@Override
 	public CollectionFetch buildCollectionFetch(
 			AssociationAttributeDefinition attributeDefinition,
 			FetchStrategy fetchStrategy,
 			LoadPlanBuildingContext loadPlanBuildingContext) {
 		throw new HibernateException( "Collection composite element cannot define collections" );
 	}
+
+	@Override
+	public SqlSelectFragmentResolver toSqlSelectFragmentResolver() {
+		return sqlSelectFragmentResolver;
+	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CompositeFetch.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CompositeFetch.java
index 764cc4cd21..18f16accc0 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CompositeFetch.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CompositeFetch.java
@@ -1,104 +1,140 @@
 /*
  * jDocBook, processing of DocBook sources
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi;
 
 import java.sql.ResultSet;
 import java.sql.SQLException;
+
+import org.hibernate.LockMode;
 import org.hibernate.engine.FetchStrategy;
 import org.hibernate.engine.FetchStyle;
 import org.hibernate.engine.FetchTiming;
+import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
-import org.hibernate.loader.spi.ResultSetProcessingContext;
+import org.hibernate.loader.plan.exec.process.internal.Helper;
+import org.hibernate.loader.plan.spi.build.LoadPlanBuildingContext;
+import org.hibernate.loader.plan.exec.process.spi.ResultSetProcessingContext;
 import org.hibernate.persister.entity.EntityPersister;
+import org.hibernate.persister.walking.spi.AssociationAttributeDefinition;
+import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.type.CompositeType;
 
 /**
  * Represents a {@link Fetch} for a composite attribute as well as a
  * {@link FetchOwner} for any sub-attributes fetches.
  *
  * @author Steve Ebersole
  * @author Gail Badner
  */
 public class CompositeFetch extends AbstractSingularAttributeFetch {
 	private static final FetchStrategy FETCH_PLAN = new FetchStrategy( FetchTiming.IMMEDIATE, FetchStyle.JOIN );
 
-	private final FetchOwnerDelegate delegate;
+	private final CompositeBasedSqlSelectFragmentResolver sqlSelectFragmentResolver;
 
 	/**
 	 * Constructs a {@link CompositeFetch} object.
 	 *
 	 * @param sessionFactory - the session factory.
 	 * @param owner - the fetch owner for this fetch.
-	 * @param ownerProperty - the owner's property referring to this fetch.
+	 * @param fetchedAttribute - the owner's property referring to this fetch.
 	 */
 	public CompositeFetch(
 			SessionFactoryImplementor sessionFactory,
 			final FetchOwner owner,
-			String ownerProperty) {
-		super( sessionFactory, owner, ownerProperty, FETCH_PLAN );
-		this.delegate = new CompositeFetchOwnerDelegate(
+			final AttributeDefinition fetchedAttribute) {
+		super( sessionFactory, owner, fetchedAttribute, FETCH_PLAN );
+
+		this.sqlSelectFragmentResolver = new CompositeBasedSqlSelectFragmentResolver(
 				sessionFactory,
-				(CompositeType) getOwner().getType( this ),
-				new CompositeFetchOwnerDelegate.PropertyMappingDelegate() {
+				(CompositeType) fetchedAttribute.getType(),
+				new CompositeBasedSqlSelectFragmentResolver.BaseSqlSelectFragmentResolver() {
 					@Override
 					public String[] toSqlSelectFragments(String alias) {
-						return owner.toSqlSelectFragments( CompositeFetch.this, alias );
+						return owner.toSqlSelectFragmentResolver().toSqlSelectFragments( alias, fetchedAttribute );
 					}
 				}
 		);
 	}
 
 	public CompositeFetch(CompositeFetch original, CopyContext copyContext, FetchOwner fetchOwnerCopy) {
 		super( original, copyContext, fetchOwnerCopy );
-		this.delegate = original.getFetchOwnerDelegate();
+		this.sqlSelectFragmentResolver = original.sqlSelectFragmentResolver;
 	}
 
 	@Override
-	protected FetchOwnerDelegate getFetchOwnerDelegate() {
-		return delegate;
+	public SqlSelectFragmentResolver toSqlSelectFragmentResolver() {
+		return sqlSelectFragmentResolver;
 	}
 
 	@Override
 	public EntityPersister retrieveFetchSourcePersister() {
 		return getOwner().retrieveFetchSourcePersister();
 	}
 
 	@Override
 	public void hydrate(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
-		//To change body of implemented methods use File | Settings | File Templates.
+		// anything to do?
 	}
 
 	@Override
 	public Object resolve(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
-		return null;  //To change body of implemented methods use File | Settings | File Templates.
+		// anything to do?
+		return null;
+	}
+
+	@Override
+	public void read(ResultSet resultSet, ResultSetProcessingContext context, Object owner) throws SQLException {
+		final EntityReference ownerEntityReference = Helper.INSTANCE.findOwnerEntityReference( this );
+		final ResultSetProcessingContext.EntityReferenceProcessingState entityReferenceProcessingState = context.getProcessingState(
+				ownerEntityReference
+		);
+		final EntityKey entityKey = entityReferenceProcessingState.getEntityKey();
+		final Object entity = context.resolveEntityKey( entityKey, Helper.INSTANCE.findOwnerEntityReference( (FetchOwner) ownerEntityReference ) );
+		for ( Fetch fetch : getFetches() ) {
+			fetch.read( resultSet, context, entity );
+		}
 	}
 
 	@Override
 	public CompositeFetch makeCopy(CopyContext copyContext, FetchOwner fetchOwnerCopy) {
 		copyContext.getReturnGraphVisitationStrategy().startingCompositeFetch( this );
 		final CompositeFetch copy = new CompositeFetch( this, copyContext, fetchOwnerCopy );
 		copyContext.getReturnGraphVisitationStrategy().finishingCompositeFetch( this );
 		return copy;
 	}
+
+	@Override
+	public CollectionFetch buildCollectionFetch(
+			AssociationAttributeDefinition attributeDefinition,
+			FetchStrategy fetchStrategy,
+			LoadPlanBuildingContext loadPlanBuildingContext) {
+		return new CollectionFetch(
+				loadPlanBuildingContext.getSessionFactory(),
+				LockMode.NONE, // todo : for now
+				this,
+				fetchStrategy,
+				attributeDefinition
+		);
+	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CompositeFetchOwnerDelegate.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CompositeFetchOwnerDelegate.java
deleted file mode 100644
index 2785d75c28..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CompositeFetchOwnerDelegate.java
+++ /dev/null
@@ -1,143 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.loader.plan.spi;
-
-import java.util.Arrays;
-
-import org.hibernate.engine.spi.SessionFactoryImplementor;
-import org.hibernate.persister.walking.spi.WalkingException;
-import org.hibernate.type.CompositeType;
-import org.hibernate.type.Type;
-
-/**
- * A delegate for a composite fetch owner to obtain details about an
- * owned sub-attribute fetch.
- *
- * @author Gail Badner
- * @author Steve Ebersole
- */
-public class CompositeFetchOwnerDelegate extends AbstractFetchOwnerDelegate implements FetchOwnerDelegate {
-	private final SessionFactoryImplementor sessionFactory;
-	private final CompositeType compositeType;
-	private final PropertyMappingDelegate propertyMappingDelegate;
-
-	/**
-	 * Constructs a CompositeFetchOwnerDelegate
-	 *
-	 * @param sessionFactory - the session factory.
-	 * @param compositeType - the composite type.
-	 * @param propertyMappingDelegate - delegate for handling property mapping
-	 */
-	public CompositeFetchOwnerDelegate(
-			SessionFactoryImplementor sessionFactory,
-			CompositeType compositeType,
-			PropertyMappingDelegate propertyMappingDelegate) {
-		this.sessionFactory = sessionFactory;
-		this.compositeType = compositeType;
-		this.propertyMappingDelegate = propertyMappingDelegate;
-	}
-
-	public static interface PropertyMappingDelegate {
-		public String[] toSqlSelectFragments(String alias);
-	}
-
-	@Override
-	protected FetchMetadata buildFetchMetadata(Fetch fetch) {
-		int subIndex = -1;
-		int selectFragmentRangeStart = 0;
-		int selectFragmentRangeEnd = -1;
-
-		for ( int i = 0; i < compositeType.getPropertyNames().length; i++ ) {
-			final Type type = compositeType.getSubtypes()[i];
-			final int typeColSpan = type.getColumnSpan( sessionFactory );
-			if ( compositeType.getPropertyNames()[ i ].equals( fetch.getOwnerPropertyName() ) ) {
-				// fount it!
-				subIndex = i;
-				selectFragmentRangeEnd = selectFragmentRangeStart + typeColSpan;
-				break;
-			}
-			selectFragmentRangeStart += typeColSpan;
-		}
-
-		if ( subIndex < 0 ) {
-			throw new WalkingException(
-					String.format(
-							"Owner property [%s] not found in composite properties [%s]",
-							fetch.getOwnerPropertyName(),
-							Arrays.asList( compositeType.getPropertyNames() )
-					)
-			);
-		}
-
-		return new FetchMetadataImpl(
-				compositeType,
-				subIndex,
-				propertyMappingDelegate,
-				selectFragmentRangeStart,
-				selectFragmentRangeEnd
-		);
-
-		// todo : we really need a PropertyMapping delegate which can encapsulate both the PropertyMapping and the path
-	}
-
-	private static class FetchMetadataImpl implements FetchMetadata {
-		private final CompositeType compositeType;
-		private final int index;
-		private final PropertyMappingDelegate propertyMappingDelegate;
-		private final int selectFragmentRangeStart;
-		private final int selectFragmentRangeEnd;
-
-		public FetchMetadataImpl(
-				CompositeType compositeType,
-				int index,
-				PropertyMappingDelegate propertyMappingDelegate,
-				int selectFragmentRangeStart,
-				int selectFragmentRangeEnd) {
-			this.compositeType = compositeType;
-			this.index = index;
-			this.propertyMappingDelegate = propertyMappingDelegate;
-			this.selectFragmentRangeStart = selectFragmentRangeStart;
-			this.selectFragmentRangeEnd = selectFragmentRangeEnd;
-		}
-
-		@Override
-		public boolean isNullable() {
-			return compositeType.getPropertyNullability()[ index ];
-		}
-
-		@Override
-		public Type getType() {
-			return compositeType.getSubtypes()[ index ];
-		}
-
-		@Override
-		public String[] toSqlSelectFragments(String alias) {
-			return Arrays.copyOfRange(
-					propertyMappingDelegate.toSqlSelectFragments( alias ),
-					selectFragmentRangeStart,
-					selectFragmentRangeEnd
-			);
-		}
-	}
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CompositeIndexGraph.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CompositeIndexGraph.java
index b623368988..3cf59b0aec 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CompositeIndexGraph.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CompositeIndexGraph.java
@@ -1,98 +1,99 @@
 package org.hibernate.loader.plan.spi;
 
 import org.hibernate.HibernateException;
 import org.hibernate.engine.FetchStrategy;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.loader.PropertyPath;
 import org.hibernate.loader.plan.spi.build.LoadPlanBuildingContext;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.walking.spi.AssociationAttributeDefinition;
+import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.type.CompositeType;
 
 /**
  *  Represents the {@link FetchOwner} for a composite collection index.
  *
  * @author Steve Ebersole
  * @author Gail Badner
  */
 public class CompositeIndexGraph extends AbstractFetchOwner implements FetchableCollectionIndex {
 	private final CollectionReference collectionReference;
 	private final PropertyPath propertyPath;
 	private final CollectionPersister collectionPersister;
-	private final FetchOwnerDelegate fetchOwnerDelegate;
+	private final CompositeBasedSqlSelectFragmentResolver sqlSelectFragmentResolver;
 
 	/**
 	 * Constructs a {@link CompositeElementGraph}.
 	 *
 	 * @param sessionFactory - the session factory.
 	 * @param collectionReference - the collection reference.
 	 * @param collectionPath - the {@link PropertyPath} for the collection.
 	 */
 	public CompositeIndexGraph(
 			SessionFactoryImplementor sessionFactory,
 			CollectionReference collectionReference,
 			PropertyPath collectionPath) {
 		super( sessionFactory );
 		this.collectionReference = collectionReference;
 		this.collectionPersister = collectionReference.getCollectionPersister();
 		this.propertyPath = collectionPath.append( "<index>" );
-		this.fetchOwnerDelegate = new CompositeFetchOwnerDelegate(
+		this.sqlSelectFragmentResolver = new CompositeBasedSqlSelectFragmentResolver(
 				sessionFactory,
 				(CompositeType) collectionPersister.getIndexType(),
-				new CompositeFetchOwnerDelegate.PropertyMappingDelegate() {
+				new CompositeBasedSqlSelectFragmentResolver.BaseSqlSelectFragmentResolver() {
 					@Override
 					public String[] toSqlSelectFragments(String alias) {
 						return ( (QueryableCollection) collectionPersister ).getIndexColumnNames( alias );
 					}
 				}
 		);
 	}
 
 	protected CompositeIndexGraph(CompositeIndexGraph original, CopyContext copyContext) {
 		super( original, copyContext );
 		this.collectionReference = original.collectionReference;
 		this.collectionPersister = original.collectionPersister;
 		this.propertyPath = original.propertyPath;
-		this.fetchOwnerDelegate = original.fetchOwnerDelegate;
+		this.sqlSelectFragmentResolver = original.sqlSelectFragmentResolver;
 	}
 
 	@Override
-	public void validateFetchPlan(FetchStrategy fetchStrategy) {
+	public void validateFetchPlan(FetchStrategy fetchStrategy, AttributeDefinition attributeDefinition) {
 	}
 
 	@Override
 	public EntityPersister retrieveFetchSourcePersister() {
 		return collectionPersister.getOwnerEntityPersister();
 	}
 
 	@Override
 	public CollectionReference getCollectionReference() {
 		return collectionReference;
 	}
 
 	@Override
 	public PropertyPath getPropertyPath() {
 		return propertyPath;
 	}
 
 	@Override
 	public CompositeIndexGraph makeCopy(CopyContext copyContext) {
 		return new CompositeIndexGraph( this, copyContext );
 	}
 
 	@Override
-	protected FetchOwnerDelegate getFetchOwnerDelegate() {
-		return fetchOwnerDelegate;
-	}
-
-	@Override
 	public CollectionFetch buildCollectionFetch(
 			AssociationAttributeDefinition attributeDefinition,
 			FetchStrategy fetchStrategy,
 			LoadPlanBuildingContext loadPlanBuildingContext) {
 		throw new HibernateException( "Composite index cannot define collections" );
 	}
 
+	@Override
+	public SqlSelectFragmentResolver toSqlSelectFragmentResolver() {
+		return sqlSelectFragmentResolver;
+	}
+
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityElementGraph.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityElementGraph.java
index b318efb667..840196f616 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityElementGraph.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityElementGraph.java
@@ -1,117 +1,180 @@
 package org.hibernate.loader.plan.spi;
 
 import org.hibernate.LockMode;
 import org.hibernate.engine.FetchStrategy;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.loader.PropertyPath;
+import org.hibernate.loader.plan.spi.build.LoadPlanBuildingContext;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
+import org.hibernate.persister.entity.Queryable;
+import org.hibernate.persister.walking.spi.AssociationAttributeDefinition;
+import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.type.AssociationType;
+import org.hibernate.type.EntityType;
 
 /**
  *  Represents the {@link FetchOwner} for a collection element that is
  *  an entity association type.
  *
  * @author Steve Ebersole
  */
 public class EntityElementGraph extends AbstractFetchOwner implements FetchableCollectionElement, EntityReference {
 	private final CollectionReference collectionReference;
 	private final CollectionPersister collectionPersister;
 	private final AssociationType elementType;
 	private final EntityPersister elementPersister;
 	private final PropertyPath propertyPath;
-	private final FetchOwnerDelegate fetchOwnerDelegate;
+	private final EntityPersisterBasedSqlSelectFragmentResolver sqlSelectFragmentResolver;
 
 	private IdentifierDescription identifierDescription;
 
 	/**
 	 * Constructs an {@link EntityElementGraph}.
 	 *
 	 * @param sessionFactory - the session factory.
 	 * @param collectionReference - the collection reference.
 	 * @param collectionPath - the {@link PropertyPath} for the collection.
 	 */
 	public EntityElementGraph(
 			SessionFactoryImplementor sessionFactory,
 			CollectionReference collectionReference,
 			PropertyPath collectionPath) {
 		super( sessionFactory );
 
 		this.collectionReference = collectionReference;
 		this.collectionPersister = collectionReference.getCollectionPersister();
 		this.elementType = (AssociationType) collectionPersister.getElementType();
 		this.elementPersister = (EntityPersister) this.elementType.getAssociatedJoinable( sessionFactory() );
 		this.propertyPath = collectionPath;
-		this.fetchOwnerDelegate = new EntityFetchOwnerDelegate( elementPersister );
+		this.sqlSelectFragmentResolver = new EntityPersisterBasedSqlSelectFragmentResolver( (Queryable) elementPersister );
 	}
 
 	public EntityElementGraph(EntityElementGraph original, CopyContext copyContext) {
 		super( original, copyContext );
 
 		this.collectionReference = original.collectionReference;
 		this.collectionPersister = original.collectionReference.getCollectionPersister();
 		this.elementType = original.elementType;
 		this.elementPersister = original.elementPersister;
 		this.propertyPath = original.propertyPath;
-		this.fetchOwnerDelegate = original.fetchOwnerDelegate;
+		this.sqlSelectFragmentResolver = original.sqlSelectFragmentResolver;
 	}
 
 	@Override
 	public LockMode getLockMode() {
 		return null;
 	}
 
 	@Override
 	public EntityReference getEntityReference() {
 		return this;
 	}
 
 	@Override
 	public EntityPersister getEntityPersister() {
 		return elementPersister;
 	}
 
 	@Override
 	public IdentifierDescription getIdentifierDescription() {
 		return identifierDescription;
 	}
 
 	@Override
-	public void validateFetchPlan(FetchStrategy fetchStrategy) {
+	public void validateFetchPlan(FetchStrategy fetchStrategy, AttributeDefinition attributeDefinition) {
 	}
 
 	@Override
 	public EntityPersister retrieveFetchSourcePersister() {
 		return elementPersister;
 	}
 
 	@Override
 	public PropertyPath getPropertyPath() {
 		return propertyPath;
 	}
 
 	@Override
 	public void injectIdentifierDescription(IdentifierDescription identifierDescription) {
 		this.identifierDescription = identifierDescription;
 	}
 
 	@Override
 	public EntityElementGraph makeCopy(CopyContext copyContext) {
 		return new EntityElementGraph( this, copyContext );
 	}
 
 	@Override
 	public CollectionReference getCollectionReference() {
 		return collectionReference;
 	}
 
 	@Override
 	public String toString() {
 		return "EntityElementGraph(collection=" + collectionPersister.getRole() + ", type=" + elementPersister.getEntityName() + ")";
 	}
 
 	@Override
-	protected FetchOwnerDelegate getFetchOwnerDelegate() {
-		return fetchOwnerDelegate;
+	public SqlSelectFragmentResolver toSqlSelectFragmentResolver() {
+		return sqlSelectFragmentResolver;
+	}
+
+	@Override
+	public EntityFetch buildEntityFetch(
+			AssociationAttributeDefinition attributeDefinition,
+			FetchStrategy fetchStrategy,
+			LoadPlanBuildingContext loadPlanBuildingContext) {
+		final EntityType attributeType = (EntityType) attributeDefinition.getType();
+
+		final FetchOwner collectionOwner = CollectionFetch.class.isInstance( collectionReference )
+				? ( (CollectionFetch) collectionReference ).getOwner()
+				: null;
+
+		if ( collectionOwner != null ) {
+			// check for bi-directionality
+			final boolean sameType = attributeType.getAssociatedEntityName().equals(
+					collectionOwner.retrieveFetchSourcePersister().getEntityName()
+			);
+
+			if ( sameType ) {
+				// todo : check for columns too...
+
+				return new BidirectionalEntityElementGraphFetch(
+						sessionFactory(),
+						LockMode.READ,
+						this,
+						attributeDefinition,
+						fetchStrategy,
+						collectionOwner
+				);
+			}
+		}
+
+		return super.buildEntityFetch(
+				attributeDefinition,
+				fetchStrategy,
+				loadPlanBuildingContext
+		);
+	}
+
+	private class BidirectionalEntityElementGraphFetch extends EntityFetch implements BidirectionalEntityFetch {
+		private final FetchOwner collectionOwner;
+
+		public BidirectionalEntityElementGraphFetch(
+				SessionFactoryImplementor sessionFactory,
+				LockMode lockMode,
+				FetchOwner owner,
+				AttributeDefinition fetchedAttribute,
+				FetchStrategy fetchStrategy,
+				FetchOwner collectionOwner) {
+			super( sessionFactory, lockMode, owner, fetchedAttribute, fetchStrategy );
+			this.collectionOwner = collectionOwner;
+		}
+
+		@Override
+		public EntityReference getTargetEntityReference() {
+			return (EntityReference) collectionOwner;
+		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityFetch.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityFetch.java
index ed18f21465..770f93ff9a 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityFetch.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityFetch.java
@@ -1,273 +1,299 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi;
 
 import java.sql.ResultSet;
 import java.sql.SQLException;
 
 import org.hibernate.LockMode;
 import org.hibernate.WrongClassException;
 import org.hibernate.engine.FetchStrategy;
-import org.hibernate.engine.FetchTiming;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
-import org.hibernate.loader.spi.ResultSetProcessingContext;
+import org.hibernate.loader.plan.exec.process.spi.ResultSetProcessingContext;
 import org.hibernate.persister.entity.EntityPersister;
+import org.hibernate.persister.entity.Queryable;
+import org.hibernate.persister.walking.spi.AttributeDefinition;
+import org.hibernate.persister.walking.spi.WalkingException;
 import org.hibernate.type.EntityType;
 
+import static org.hibernate.loader.plan.exec.process.spi.ResultSetProcessingContext.EntityReferenceProcessingState;
+
 /**
  * Represents a {@link Fetch} for an entity association attribute as well as a
  * {@link FetchOwner} of the entity association sub-attribute fetches.
 
  * @author Steve Ebersole
  */
 public class EntityFetch extends AbstractSingularAttributeFetch implements EntityReference, Fetch {
-
 	private final EntityPersister persister;
-	private final LockMode lockMode;
-	private final FetchOwnerDelegate fetchOwnerDelegate;
+	private final EntityPersisterBasedSqlSelectFragmentResolver sqlSelectFragmentResolver;
 
 	private IdentifierDescription identifierDescription;
 
+	// todo : remove these
+	private final LockMode lockMode;
+
 	/**
 	 * Constructs an {@link EntityFetch} object.
 	 *
 	 * @param sessionFactory - the session factory.
 	 * @param lockMode - the lock mode.
 	 * @param owner - the fetch owner for this fetch.
-	 * @param ownerProperty - the owner's property referring to this fetch.
+	 * @param fetchedAttribute - the attribute being fetched
 	 * @param fetchStrategy - the fetch strategy for this fetch.
 	 */
 	public EntityFetch(
 			SessionFactoryImplementor sessionFactory,
 			LockMode lockMode,
 			FetchOwner owner,
-			String ownerProperty,
+			AttributeDefinition fetchedAttribute,
 			FetchStrategy fetchStrategy) {
-		super( sessionFactory, owner, ownerProperty, fetchStrategy );
+		super( sessionFactory, owner, fetchedAttribute, fetchStrategy );
+
+		this.persister = sessionFactory.getEntityPersister( getFetchedType().getAssociatedEntityName() );
+		if ( persister == null ) {
+			throw new WalkingException(
+					String.format(
+							"Unable to locate EntityPersister [%s] for fetch [%s]",
+							getFetchedType().getAssociatedEntityName(),
+							fetchedAttribute.getName()
+					)
+			);
+		}
+		this.sqlSelectFragmentResolver = new EntityPersisterBasedSqlSelectFragmentResolver( (Queryable) persister );
 
-		this.persister = sessionFactory.getEntityPersister(
-				getEntityType().getAssociatedEntityName()
-		);
 		this.lockMode = lockMode;
-		this.fetchOwnerDelegate = new EntityFetchOwnerDelegate( persister );
 	}
 
 	/**
 	 * Copy constructor.
 	 *
 	 * @param original The original fetch
 	 * @param copyContext Access to contextual needs for the copy operation
 	 */
 	protected EntityFetch(EntityFetch original, CopyContext copyContext, FetchOwner fetchOwnerCopy) {
 		super( original, copyContext, fetchOwnerCopy );
 		this.persister = original.persister;
+		this.sqlSelectFragmentResolver = original.sqlSelectFragmentResolver;
+
 		this.lockMode = original.lockMode;
-		this.fetchOwnerDelegate = original.fetchOwnerDelegate;
 	}
 
-	/**
-	 * Returns the entity type for this fetch.
-	 * @return the entity type for this fetch.
-	 */
-	public final EntityType getEntityType() {
-		return (EntityType) getOwner().getType( this );
+	@Override
+	public EntityType getFetchedType() {
+		return (EntityType) super.getFetchedType();
+	}
+
+	@Override
+	public String[] toSqlSelectFragments(String alias) {
+		return getOwner().toSqlSelectFragmentResolver().toSqlSelectFragments( alias, getFetchedAttribute() );
 	}
 
 	@Override
 	public EntityReference getEntityReference() {
 		return this;
 	}
 
 	@Override
 	public EntityPersister getEntityPersister() {
 		return persister;
 	}
 
 	@Override
+	public SqlSelectFragmentResolver toSqlSelectFragmentResolver() {
+		return sqlSelectFragmentResolver;
+	}
+
+	@Override
 	public IdentifierDescription getIdentifierDescription() {
 		return identifierDescription;
 	}
 
 	@Override
 	public LockMode getLockMode() {
 		return lockMode;
 	}
 
 	@Override
 	public EntityPersister retrieveFetchSourcePersister() {
 		return persister;
 	}
 
 	@Override
 	public void injectIdentifierDescription(IdentifierDescription identifierDescription) {
 		this.identifierDescription = identifierDescription;
 	}
 
 	@Override
 	public void hydrate(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
-		EntityKey entityKey = context.getDictatedRootEntityKey();
-		if ( entityKey != null ) {
-			context.getIdentifierResolutionContext( this ).registerEntityKey( entityKey );
-			return;
-		}
-
 		identifierDescription.hydrate( resultSet, context );
 
 		for ( Fetch fetch : getFetches() ) {
 			fetch.hydrate( resultSet, context );
 		}
 	}
 
 	@Override
 	public EntityKey resolve(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
-		final ResultSetProcessingContext.IdentifierResolutionContext identifierResolutionContext = context.getIdentifierResolutionContext( this );
-		EntityKey entityKey = identifierResolutionContext.getEntityKey();
+		final ResultSetProcessingContext.EntityReferenceProcessingState entityReferenceProcessingState = context.getProcessingState(
+				this
+		);
+		EntityKey entityKey = entityReferenceProcessingState.getEntityKey();
 		if ( entityKey == null ) {
 			entityKey = identifierDescription.resolve( resultSet, context );
 			if ( entityKey == null ) {
 				// register the non-existence (though only for one-to-one associations)
-				if ( getEntityType().isOneToOne() ) {
+				if ( getFetchedType().isOneToOne() ) {
 					// first, find our owner's entity-key...
-					final EntityKey ownersEntityKey = context.getIdentifierResolutionContext( (EntityReference) getOwner() ).getEntityKey();
+					final EntityKey ownersEntityKey = context.getProcessingState( (EntityReference) getOwner() ).getEntityKey();
 					if ( ownersEntityKey != null ) {
 						context.getSession().getPersistenceContext()
-								.addNullProperty( ownersEntityKey, getEntityType().getPropertyName() );
+								.addNullProperty( ownersEntityKey, getFetchedType().getPropertyName() );
 					}
 				}
 			}
 
-			identifierResolutionContext.registerEntityKey( entityKey );
+			entityReferenceProcessingState.registerEntityKey( entityKey );
 
 			for ( Fetch fetch : getFetches() ) {
 				fetch.resolve( resultSet, context );
 			}
 		}
 
 		return entityKey;
 	}
 
+	@Override
+	public void read(ResultSet resultSet, ResultSetProcessingContext context, Object owner) throws SQLException {
+		final EntityReferenceProcessingState entityReferenceProcessingState = context.getProcessingState( this );
+		final EntityKey entityKey = entityReferenceProcessingState.getEntityKey();
+		if ( entityKey == null ) {
+			return;
+		}
+		final Object entity = context.resolveEntityKey( entityKey, this );
+		for ( Fetch fetch : getFetches() ) {
+			fetch.read( resultSet, context, entity );
+		}
+	}
+
 	/**
 	 * Resolve any fetches required to resolve the identifier as well
 	 * as the entity key for this fetch..
 	 *
 	 * @param resultSet - the result set.
 	 * @param context - the result set processing context.
 	 * @return the entity key for this fetch.
 	 *
 	 * @throws SQLException
 	 */
 	public EntityKey resolveInIdentifier(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
 		// todo : may not need to do this if entitykey is already part of the resolution context
 
 		final EntityKey entityKey = resolve( resultSet, context );
 
 		final Object existing = context.getSession().getEntityUsingInterceptor( entityKey );
 
 		if ( existing != null ) {
 			if ( !persister.isInstance( existing ) ) {
 				throw new WrongClassException(
 						"loaded object was of wrong class " + existing.getClass(),
 						entityKey.getIdentifier(),
 						persister.getEntityName()
 				);
 			}
 
 			if ( getLockMode() != null && getLockMode() != LockMode.NONE ) {
 				final boolean isVersionCheckNeeded = persister.isVersioned()
 						&& context.getSession().getPersistenceContext().getEntry( existing ).getLockMode().lessThan( getLockMode() );
 
 				// we don't need to worry about existing version being uninitialized because this block isn't called
 				// by a re-entrant load (re-entrant loads _always_ have lock mode NONE)
 				if ( isVersionCheckNeeded ) {
 					//we only check the version when _upgrading_ lock modes
 					context.checkVersion(
 							resultSet,
 							persister,
-							context.getLoadQueryAliasResolutionContext().resolveEntityColumnAliases( this ),
+							context.getAliasResolutionContext().resolveAliases( this ).getColumnAliases(),
 							entityKey,
 							existing
 					);
 					//we need to upgrade the lock mode to the mode requested
 					context.getSession().getPersistenceContext().getEntry( existing ).setLockMode( getLockMode() );
 				}
 			}
 		}
 		else {
 			final String concreteEntityTypeName = context.getConcreteEntityTypeName(
 					resultSet,
 					persister,
-					context.getLoadQueryAliasResolutionContext().resolveEntityColumnAliases( this ),
+					context.getAliasResolutionContext().resolveAliases( this ).getColumnAliases(),
 					entityKey
 			);
 
 			final Object entityInstance = context.getSession().instantiate(
 					concreteEntityTypeName,
 					entityKey.getIdentifier()
 			);
 
 			//need to hydrate it.
 
 			// grab its state from the ResultSet and keep it in the Session
 			// (but don't yet initialize the object itself)
 			// note that we acquire LockMode.READ even if it was not requested
 			LockMode acquiredLockMode = getLockMode() == LockMode.NONE ? LockMode.READ : getLockMode();
 
 			context.loadFromResultSet(
 					resultSet,
 					entityInstance,
 					concreteEntityTypeName,
 					entityKey,
-					context.getLoadQueryAliasResolutionContext().resolveEntityColumnAliases( this ),
+					context.getAliasResolutionContext().resolveAliases( this ).getColumnAliases(),
 					acquiredLockMode,
 					persister,
-					getFetchStrategy().getTiming() == FetchTiming.IMMEDIATE,
-					getEntityType()
+					getFetchStrategy(),
+					true,
+					getFetchedType()
 			);
 
 			// materialize associations (and initialize the object) later
-			context.registerHydratedEntity( persister, entityKey, entityInstance );
+			context.registerHydratedEntity( this, entityKey, entityInstance );
 		}
 
 		return entityKey;
 	}
 
 	@Override
 	public String toString() {
 		return "EntityFetch(" + getPropertyPath().getFullPath() + " -> " + persister.getEntityName() + ")";
 	}
 
 	@Override
 	public EntityFetch makeCopy(CopyContext copyContext, FetchOwner fetchOwnerCopy) {
 		copyContext.getReturnGraphVisitationStrategy().startingEntityFetch( this );
 		final EntityFetch copy = new EntityFetch( this, copyContext, fetchOwnerCopy );
 		copyContext.getReturnGraphVisitationStrategy().finishingEntityFetch( this );
 		return copy;
 	}
-
-	@Override
-	protected FetchOwnerDelegate getFetchOwnerDelegate() {
-		return fetchOwnerDelegate;
-	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityFetchOwnerDelegate.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityFetchOwnerDelegate.java
deleted file mode 100644
index 0cbc6c509d..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityFetchOwnerDelegate.java
+++ /dev/null
@@ -1,201 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.loader.plan.spi;
-
-import java.util.Arrays;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.hibernate.persister.entity.EntityPersister;
-import org.hibernate.persister.entity.Queryable;
-import org.hibernate.persister.walking.spi.WalkingException;
-import org.hibernate.type.CompositeType;
-import org.hibernate.type.Type;
-
-/**
- * A delegate for an entity fetch owner to obtain details about
- * an owned attribute fetch.
- *
- * @author Gail Badner
- * @author Steve Ebersole
- */
-public class EntityFetchOwnerDelegate extends AbstractFetchOwnerDelegate implements FetchOwnerDelegate {
-	private final EntityPersister entityPersister;
-
-	/**
-	 * Constructs an {@link EntityFetchOwnerDelegate}.
-	 *
-	 * @param entityPersister - the entity persister.
-	 */
-	public EntityFetchOwnerDelegate(EntityPersister entityPersister) {
-		this.entityPersister = entityPersister;
-	}
-
-	@Override
-	protected FetchMetadata buildFetchMetadata(Fetch fetch) {
-		final Integer propertyIndex = entityPersister.getEntityMetamodel().getPropertyIndexOrNull(
-				fetch.getOwnerPropertyName()
-		);
-		if ( propertyIndex == null ) {
-			// possibly it is part of the identifier; but that's only possible if the identifier is composite
-			final Type idType = entityPersister.getIdentifierType();
-			if ( CompositeType.class.isInstance( idType ) ) {
-				final CompositeType cidType = (CompositeType) idType;
-				if ( entityPersister.hasIdentifierProperty() ) {
-					// encapsulated composite id case; this *should have* been handled as part of building the fetch...
-					throw new WalkingException(
-							"Expecting different FetchOwnerDelegate type for encapsulated composite id case"
-					);
-				}
-				else {
-					// non-encapsulated composite id case...
-					return new NonEncapsulatedIdentifierAttributeFetchMetadata(
-							entityPersister,
-							cidType,
-							fetch.getOwnerPropertyName()
-					);
-				}
-			}
-		}
-		else {
-			return new NonIdentifierAttributeFetchMetadata(
-					entityPersister,
-					fetch.getOwnerPropertyName(),
-					propertyIndex.intValue()
-			);
-		}
-
-		throw new WalkingException(
-				"Could not locate metadata about given fetch [" + fetch + "] in its owning persister"
-		);
-	}
-
-	private class NonIdentifierAttributeFetchMetadata implements FetchMetadata {
-		private final EntityPersister entityPersister;
-		private final String attributeName;
-		private final int propertyIndex;
-
-		private Type attributeType;
-
-		public NonIdentifierAttributeFetchMetadata(
-				EntityPersister entityPersister,
-				String attributeName,
-				int propertyIndex) {
-			this.entityPersister = entityPersister;
-			this.attributeName = attributeName;
-			this.propertyIndex = propertyIndex;
-		}
-
-		@Override
-		public boolean isNullable() {
-			return entityPersister.getPropertyNullability()[ propertyIndex ];
-		}
-
-		@Override
-		public Type getType() {
-			if ( attributeType == null ) {
-				attributeType = entityPersister.getPropertyTypes()[ propertyIndex ];
-			}
-			return attributeType;
-		}
-
-		@Override
-		public String[] toSqlSelectFragments(String alias) {
-//			final Type type = getType();
-//			final OuterJoinLoadable outerJoinLoadable = (OuterJoinLoadable) entityPersister;
-			final Queryable queryable = (Queryable) entityPersister;
-
-			return queryable.toColumns( alias, attributeName );
-//			if ( type.isAssociationType() ) {
-//				return JoinHelper.getLHSColumnNames(
-//						(AssociationType) type,
-//						propertyIndex,
-//						outerJoinLoadable,
-//						outerJoinLoadable.getFactory()
-//				);
-//			}
-//			else {
-//				return outerJoinLoadable.getPropertyColumnNames( propertyIndex );
-//			}
-		}
-	}
-
-	private class NonEncapsulatedIdentifierAttributeFetchMetadata implements FetchMetadata {
-		private final EntityPersister entityPersister;
-		private final String attributeName;
-
-		// virtually final fields
-		private Type type;
-		private int selectFragmentRangeStart;
-		private int selectFragmentRangeEnd;
-
-
-		public NonEncapsulatedIdentifierAttributeFetchMetadata(
-				EntityPersister entityPersister,
-				CompositeType cidType,
-				String attributeName) {
-			this.entityPersister = entityPersister;
-			this.attributeName = attributeName;
-
-			this.selectFragmentRangeStart = 0;
-			Type subType;
-			boolean foundIt = false;
-			for ( int i = 0; i < cidType.getPropertyNames().length; i++ ) {
-				subType = cidType.getSubtypes()[i];
-				if ( cidType.getPropertyNames()[i].equals( attributeName ) ) {
-					// found it!
-					foundIt = true;
-					this.type = subType;
-					break;
-				}
-				selectFragmentRangeStart += subType.getColumnSpan( entityPersister.getFactory() );
-			}
-
-			if ( !foundIt ) {
-				throw new WalkingException( "Could not find " );
-			}
-
-			selectFragmentRangeEnd = selectFragmentRangeStart + type.getColumnSpan( entityPersister.getFactory() );
-		}
-
-		@Override
-		public boolean isNullable() {
-			return false;
-		}
-
-		@Override
-		public Type getType() {
-			return type;
-		}
-
-		@Override
-		public String[] toSqlSelectFragments(String alias) {
-			return Arrays.copyOfRange(
-					( (Queryable) entityPersister ).toColumns( alias, attributeName ),
-					selectFragmentRangeStart,
-					selectFragmentRangeEnd
-			);
-		}
-	}
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityIndexGraph.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityIndexGraph.java
index df16559c81..2c7b0d2170 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityIndexGraph.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityIndexGraph.java
@@ -1,135 +1,137 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi;
 
 import org.hibernate.LockMode;
 import org.hibernate.engine.FetchStrategy;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.loader.PropertyPath;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
+import org.hibernate.persister.entity.Queryable;
+import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.type.AssociationType;
 
 /**
  *  Represents the {@link FetchOwner} for a collection index that is an entity.
  *
  * @author Steve Ebersole
  */
 public class EntityIndexGraph extends AbstractFetchOwner implements FetchableCollectionIndex, EntityReference {
 	private final CollectionReference collectionReference;
 	private final CollectionPersister collectionPersister;
 	private final AssociationType indexType;
 	private final EntityPersister indexPersister;
 	private final PropertyPath propertyPath;
-	private final FetchOwnerDelegate fetchOwnerDelegate;
+	private final EntityPersisterBasedSqlSelectFragmentResolver sqlSelectFragmentResolver;
 
 	private IdentifierDescription identifierDescription;
 
 	/**
 	 * Constructs an {@link EntityIndexGraph}.
 	 *
 	 * @param sessionFactory - the session factory.
 	 * @param collectionReference - the collection reference.
 	 * @param collectionPath - the {@link PropertyPath} for the collection.
 	 */
 	public EntityIndexGraph(
 			SessionFactoryImplementor sessionFactory,
 			CollectionReference collectionReference,
 			PropertyPath collectionPath) {
 		super( sessionFactory );
 		this.collectionReference = collectionReference;
 		this.collectionPersister = collectionReference.getCollectionPersister();
 		this.indexType = (AssociationType) collectionPersister.getIndexType();
 		this.indexPersister = (EntityPersister) this.indexType.getAssociatedJoinable( sessionFactory() );
 		this.propertyPath = collectionPath.append( "<index>" ); // todo : do we want the <index> part?
-		this.fetchOwnerDelegate = new EntityFetchOwnerDelegate( indexPersister );
+		this.sqlSelectFragmentResolver = new EntityPersisterBasedSqlSelectFragmentResolver( (Queryable) indexPersister );
 	}
 
 	public EntityIndexGraph(EntityIndexGraph original, CopyContext copyContext) {
 		super( original, copyContext );
 		this.collectionReference = original.collectionReference;
 		this.collectionPersister = original.collectionReference.getCollectionPersister();
 		this.indexType = original.indexType;
 		this.indexPersister = original.indexPersister;
 		this.propertyPath = original.propertyPath;
-		this.fetchOwnerDelegate = original.fetchOwnerDelegate;
+		this.sqlSelectFragmentResolver = original.sqlSelectFragmentResolver;
 	}
 
 	/**
 	 * TODO: Does lock mode apply to a collection index that is an entity?
 	 */
 	@Override
 	public LockMode getLockMode() {
 		return null;
 	}
 
 	@Override
 	public EntityReference getEntityReference() {
 		return this;
 	}
 
 	@Override
 	public EntityPersister getEntityPersister() {
 		return indexPersister;
 	}
 
 	@Override
 	public IdentifierDescription getIdentifierDescription() {
 		return identifierDescription;
 	}
 
 	@Override
-	public void validateFetchPlan(FetchStrategy fetchStrategy) {
+	public void validateFetchPlan(FetchStrategy fetchStrategy, AttributeDefinition attributeDefinition) {
 	}
 
 	@Override
 	public EntityPersister retrieveFetchSourcePersister() {
 		return indexPersister;
 	}
 
 	@Override
 	public PropertyPath getPropertyPath() {
 		return propertyPath;
 	}
 
 	@Override
 	public void injectIdentifierDescription(IdentifierDescription identifierDescription) {
 		this.identifierDescription = identifierDescription;
 	}
 
 	@Override
 	public EntityIndexGraph makeCopy(CopyContext copyContext) {
 		return new EntityIndexGraph( this, copyContext );
 	}
 
 	@Override
 	public CollectionReference getCollectionReference() {
 		return collectionReference;
 	}
 
 	@Override
-	protected FetchOwnerDelegate getFetchOwnerDelegate() {
-		return fetchOwnerDelegate;
+	public SqlSelectFragmentResolver toSqlSelectFragmentResolver() {
+		return sqlSelectFragmentResolver;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/AbstractFetchOwnerDelegate.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityPersisterBasedSqlSelectFragmentResolver.java
similarity index 59%
rename from hibernate-core/src/main/java/org/hibernate/loader/plan/spi/AbstractFetchOwnerDelegate.java
rename to hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityPersisterBasedSqlSelectFragmentResolver.java
index 673ce80268..efdec15647 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/AbstractFetchOwnerDelegate.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityPersisterBasedSqlSelectFragmentResolver.java
@@ -1,51 +1,44 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi;
 
-import java.util.HashMap;
-import java.util.Map;
+import org.hibernate.persister.entity.Queryable;
+import org.hibernate.persister.walking.spi.AttributeDefinition;
 
 /**
- * Base implementation of FetchOwnerDelegate providing caching of FetchMetadata.
- *
  * @author Steve Ebersole
  */
-public abstract class AbstractFetchOwnerDelegate implements FetchOwnerDelegate {
-	private Map<String,FetchMetadata> fetchMetadataMap;
+public class EntityPersisterBasedSqlSelectFragmentResolver implements SqlSelectFragmentResolver {
+	private final Queryable entityPersister;
+
+	public EntityPersisterBasedSqlSelectFragmentResolver(Queryable entityPersister) {
+		this.entityPersister = entityPersister;
+	}
 
 	@Override
-	public FetchMetadata locateFetchMetadata(Fetch fetch) {
-		FetchMetadata metadata = fetchMetadataMap == null ? null : fetchMetadataMap.get( fetch.getOwnerPropertyName() );
-		if ( metadata == null ) {
-			if ( fetchMetadataMap == null ) {
-				fetchMetadataMap = new HashMap<String, FetchMetadata>();
-			}
-			metadata = buildFetchMetadata( fetch );
-			fetchMetadataMap.put( fetch.getOwnerPropertyName(), metadata );
-		}
-		return metadata;
+	public String[] toSqlSelectFragments(String alias, AttributeDefinition attributeDefinition) {
+		return entityPersister.toColumns( alias, attributeDefinition.getName() );
 	}
 
-	protected abstract FetchMetadata buildFetchMetadata(Fetch fetch);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityReference.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityReference.java
index 3f646cc9a7..6c2c0f46e8 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityReference.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityReference.java
@@ -1,52 +1,52 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi;
 
 import org.hibernate.LockMode;
-import org.hibernate.loader.spi.ResultSetProcessingContext;
+import org.hibernate.loader.plan.exec.process.spi.ResultSetProcessingContext;
 import org.hibernate.persister.entity.EntityPersister;
 
 /**
  * Represents a reference to an entity either as a return or as a fetch
  *
  * @author Steve Ebersole
  */
 public interface EntityReference
 		extends IdentifierDescriptionInjectable, ResultSetProcessingContext.EntityKeyResolutionContext {
 	/**
 	 * Retrieve the lock mode associated with this return.
 	 *
 	 * @return The lock mode.
 	 */
 	public LockMode getLockMode();
 
 	/**
 	 * Retrieves the EntityPersister describing the entity associated with this Return.
 	 *
 	 * @return The EntityPersister.
 	 */
 	public EntityPersister getEntityPersister();
 
 	public IdentifierDescription getIdentifierDescription();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityReturn.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityReturn.java
index db6321aa7d..d1feabac14 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityReturn.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/EntityReturn.java
@@ -1,198 +1,132 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi;
 
-import java.sql.ResultSet;
-import java.sql.SQLException;
-
-import org.hibernate.AssertionFailure;
 import org.hibernate.LockMode;
 import org.hibernate.engine.FetchStrategy;
-import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.loader.PropertyPath;
-import org.hibernate.loader.spi.ResultSetProcessingContext;
 import org.hibernate.persister.entity.EntityPersister;
-
-import static org.hibernate.loader.spi.ResultSetProcessingContext.IdentifierResolutionContext;
+import org.hibernate.persister.entity.Queryable;
+import org.hibernate.persister.walking.spi.AttributeDefinition;
 
 /**
  * Represents an entity return value in the query results.  Not the same
  * as a result (column) in the JDBC ResultSet!
  *
  * @see Return
  *
  * @author Steve Ebersole
  */
 public class EntityReturn extends AbstractFetchOwner implements Return, EntityReference, CopyableReturn {
-
 	private final EntityPersister persister;
+	private final EntityPersisterBasedSqlSelectFragmentResolver sqlSelectFragmentResolver;
+	private IdentifierDescription identifierDescription;
 
-	private final PropertyPath propertyPath = new PropertyPath(); // it's a root
+	private final PropertyPath propertyPath;
 
 	private final LockMode lockMode;
 
-	private final FetchOwnerDelegate fetchOwnerDelegate;
-
-	private IdentifierDescription identifierDescription;
-
 	/**
 	 * Construct an {@link EntityReturn}.
 	 *
 	 * @param sessionFactory - the session factory.
 	 * @param lockMode - the lock mode.
 	 * @param entityName - the entity name.
 	 */
 	public EntityReturn(
 			SessionFactoryImplementor sessionFactory,
 			LockMode lockMode,
 			String entityName) {
 		super( sessionFactory );
 		this.persister = sessionFactory.getEntityPersister( entityName );
+		this.propertyPath = new PropertyPath( entityName );
+		this.sqlSelectFragmentResolver = new EntityPersisterBasedSqlSelectFragmentResolver( (Queryable) persister );
+
 		this.lockMode = lockMode;
-		this.fetchOwnerDelegate = new EntityFetchOwnerDelegate( persister );
 	}
 
 	protected EntityReturn(EntityReturn original, CopyContext copyContext) {
 		super( original, copyContext );
 		this.persister = original.persister;
+		this.propertyPath = original.propertyPath;
+		this.sqlSelectFragmentResolver = original.sqlSelectFragmentResolver;
+
 		this.lockMode = original.lockMode;
-		this.fetchOwnerDelegate = original.fetchOwnerDelegate;
 	}
 
 	@Override
 	public LockMode getLockMode() {
 		return lockMode;
 	}
 
 	@Override
 	public EntityReference getEntityReference() {
 		return this;
 	}
 
 	@Override
 	public EntityPersister getEntityPersister() {
 		return persister;
 	}
 
 	@Override
 	public IdentifierDescription getIdentifierDescription() {
 		return identifierDescription;
 	}
 
 	@Override
-	public void validateFetchPlan(FetchStrategy fetchStrategy) {
+	public void validateFetchPlan(FetchStrategy fetchStrategy, AttributeDefinition attributeDefinition) {
 	}
 
 	@Override
 	public EntityPersister retrieveFetchSourcePersister() {
 		return getEntityPersister();
 	}
 
 	@Override
 	public PropertyPath getPropertyPath() {
 		return propertyPath;
 	}
 
 	@Override
-	public void hydrate(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
-		EntityKey entityKey = getEntityKeyFromContext( context );
-		if ( entityKey != null ) {
-			context.getIdentifierResolutionContext( this ).registerEntityKey( entityKey );
-			return;
-		}
-
-		identifierDescription.hydrate( resultSet, context );
-
-		for ( Fetch fetch : getFetches() ) {
-			fetch.hydrate( resultSet, context );
-		}
-	}
-
-	private EntityKey getEntityKeyFromContext(ResultSetProcessingContext context) {
-		if ( context.getDictatedRootEntityKey() != null ) {
-			return context.getDictatedRootEntityKey();
-		}
-		else if ( context.getQueryParameters().getOptionalId() != null ) {
-			return context.getSession().generateEntityKey( 
-					context.getQueryParameters().getOptionalId(),
-					getEntityPersister() 
-			);
-		}
-		return null;
-	}
-	
-	@Override
-	public void resolve(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
-		final IdentifierResolutionContext identifierResolutionContext = context.getIdentifierResolutionContext( this );
-		EntityKey entityKey = identifierResolutionContext.getEntityKey();
-		if ( entityKey != null ) {
-			return;
-		}
-
-		entityKey = identifierDescription.resolve( resultSet, context );
-		identifierResolutionContext.registerEntityKey( entityKey );
-
-		for ( Fetch fetch : getFetches() ) {
-			fetch.resolve( resultSet, context );
-		}
-	}
-
-	@Override
-	public Object read(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
-		Object objectForThisEntityReturn = null;
-		for ( IdentifierResolutionContext identifierResolutionContext : context.getIdentifierResolutionContexts() ) {
-			final EntityReference entityReference = identifierResolutionContext.getEntityReference();
-			final EntityKey entityKey = identifierResolutionContext.getEntityKey();
-			if ( entityKey == null ) {
-				throw new AssertionFailure( "Could not locate resolved EntityKey");
-			}
-			final Object object =  context.resolveEntityKey( entityKey, entityReference );
-			if ( this == entityReference ) {
-				objectForThisEntityReturn = object;
-			}
-		}
-		return objectForThisEntityReturn;
-	}
-
-	@Override
 	public void injectIdentifierDescription(IdentifierDescription identifierDescription) {
 		this.identifierDescription = identifierDescription;
 	}
 
 	@Override
 	public String toString() {
 		return "EntityReturn(" + persister.getEntityName() + ")";
 	}
 
 	@Override
 	public EntityReturn makeCopy(CopyContext copyContext) {
 		return new EntityReturn( this, copyContext );
 	}
 
 	@Override
-	protected FetchOwnerDelegate getFetchOwnerDelegate() {
-		return fetchOwnerDelegate;
+	public SqlSelectFragmentResolver toSqlSelectFragmentResolver() {
+		return sqlSelectFragmentResolver;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/Fetch.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/Fetch.java
index 017a78e1e8..240c3c505c 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/Fetch.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/Fetch.java
@@ -1,89 +1,89 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi;
 
 import java.sql.ResultSet;
 import java.sql.SQLException;
 
 import org.hibernate.engine.FetchStrategy;
 import org.hibernate.loader.PropertyPath;
-import org.hibernate.loader.spi.ResultSetProcessingContext;
+import org.hibernate.loader.plan.exec.process.spi.ResultSetProcessingContext;
+import org.hibernate.type.Type;
 
 /**
  * Contract for associations that are being fetched.
  * <p/>
  * NOTE : can represent components/embeddables
  *
  * @author Steve Ebersole
  */
 public interface Fetch extends CopyableFetch {
 	/**
 	 * Obtain the owner of this fetch.
 	 *
 	 * @return The fetch owner.
 	 */
 	public FetchOwner getOwner();
 
 	/**
-	 * Obtain the name of the property, relative to the owner, being fetched.
+	 * Get the property path to this fetch
+	 *
+	 * @return The property path
+	 */
+	public PropertyPath getPropertyPath();
+
+	public Type getFetchedType();
+
+	/**
+	 * Gets the fetch strategy for this fetch.
 	 *
-	 * @return The fetched property name.
+	 * @return the fetch strategy for this fetch.
 	 */
-	public String getOwnerPropertyName();
+	public FetchStrategy getFetchStrategy();
 
 	/**
 	 * Is this fetch nullable?
 	 *
 	 * @return true, if this fetch is nullable; false, otherwise.
 	 */
 	public boolean isNullable();
 
+	public String getAdditionalJoinConditions();
+
 	/**
 	 * Generates the SQL select fragments for this fetch.  A select fragment is the column and formula references.
 	 *
 	 * @return the select fragments
 	 */
 	public String[] toSqlSelectFragments(String alias);
 
-	/**
-	 * Gets the fetch strategy for this fetch.
-	 *
-	 * @return the fetch strategy for this fetch.
-	 */
-	public FetchStrategy getFetchStrategy();
-
-	/**
-	 * Get the property path to this fetch
-	 *
-	 * @return The property path
-	 */
-	public PropertyPath getPropertyPath();
-
 	public void hydrate(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException;
 
 	public Object resolve(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException;
 
+	public void read(ResultSet resultSet, ResultSetProcessingContext context, Object owner) throws SQLException;
+
 	@Override
 	public Fetch makeCopy(CopyContext copyContext, FetchOwner fetchOwnerCopy);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/FetchOwner.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/FetchOwner.java
index 4d0f77fbea..963f4cb2e2 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/FetchOwner.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/FetchOwner.java
@@ -1,125 +1,136 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi;
 
 import org.hibernate.engine.FetchStrategy;
 import org.hibernate.loader.PropertyPath;
+import org.hibernate.loader.plan.spi.build.AbstractLoadPlanBuilderStrategy;
 import org.hibernate.loader.plan.spi.build.LoadPlanBuildingContext;
 import org.hibernate.persister.entity.EntityPersister;
+import org.hibernate.persister.entity.PropertyMapping;
+import org.hibernate.persister.walking.spi.AnyMappingDefinition;
 import org.hibernate.persister.walking.spi.AssociationAttributeDefinition;
+import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.persister.walking.spi.CompositionDefinition;
 import org.hibernate.type.Type;
 
 /**
  * Contract for owners of fetches.  Any non-scalar return could be a fetch owner.
  *
  * @author Steve Ebersole
  */
 public interface FetchOwner {
 	/**
 	 * Convenient constant for returning no fetches from {@link #getFetches()}
 	 */
 	public static final Fetch[] NO_FETCHES = new Fetch[0];
 
 	/**
 	 * Contract to add fetches to this owner.  Care should be taken in calling this method; it is intended
 	 * for Hibernate usage
 	 *
 	 * @param fetch The fetch to add
 	 */
 	public void addFetch(Fetch fetch);
 
 	/**
 	 * Retrieve the fetches owned by this return.
 	 *
 	 * @return The owned fetches.
 	 */
 	public Fetch[] getFetches();
 
 	/**
 	 * Returns the type of the specified fetch.
 	 *
 	 * @param fetch - the owned fetch.
 	 *
 	 * @return the type of the specified fetch.
 	 */
 	public Type getType(Fetch fetch);
 
 	/**
 	 * Is the specified fetch nullable?
 	 *
 	 * @param fetch - the owned fetch.
 	 *
 	 * @return true, if the fetch is nullable; false, otherwise.
 	 */
 	public boolean isNullable(Fetch fetch);
 
 	/**
 	 * Generates the SQL select fragments for the specified fetch.  A select fragment is the column and formula
 	 * references.
 	 *
 	 * @param fetch - the owned fetch.
 	 * @param alias The table alias to apply to the fragments (used to qualify column references)
 	 *
 	 * @return the select fragments
 	 */
 	public String[] toSqlSelectFragments(Fetch fetch, String alias);
 
 	/**
 	 * Is the asserted plan valid from this owner to a fetch?
 	 *
-	 * @param fetchStrategy The pla to validate
+	 * @param fetchStrategy The type of fetch to validate
+	 * @param attributeDefinition The attribute to be fetched
 	 */
-	public void validateFetchPlan(FetchStrategy fetchStrategy);
+	public void validateFetchPlan(FetchStrategy fetchStrategy, AttributeDefinition attributeDefinition);
 
 	/**
 	 * Retrieve the EntityPersister that is the base for any property references in the fetches it owns.
 	 *
 	 * @return The EntityPersister, for property name resolution.
 	 */
 	public EntityPersister retrieveFetchSourcePersister();
 
 	/**
 	 * Get the property path to this fetch owner
 	 *
 	 * @return The property path
 	 */
 	public PropertyPath getPropertyPath();
 
 	public CollectionFetch buildCollectionFetch(
 			AssociationAttributeDefinition attributeDefinition,
 			FetchStrategy fetchStrategy,
 			LoadPlanBuildingContext loadPlanBuildingContext);
 
 	public EntityFetch buildEntityFetch(
 			AssociationAttributeDefinition attributeDefinition,
 			FetchStrategy fetchStrategy,
 			LoadPlanBuildingContext loadPlanBuildingContext);
 
 	public CompositeFetch buildCompositeFetch(
 			CompositionDefinition attributeDefinition,
 			LoadPlanBuildingContext loadPlanBuildingContext);
 
+	public AnyFetch buildAnyFetch(
+			AttributeDefinition attribute,
+			AnyMappingDefinition anyDefinition,
+			FetchStrategy fetchStrategy,
+			LoadPlanBuildingContext loadPlanBuildingContext);
 
+	public SqlSelectFragmentResolver toSqlSelectFragmentResolver();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/FetchOwnerDelegate.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/FetchOwnerDelegate.java
deleted file mode 100644
index 350169dab4..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/FetchOwnerDelegate.java
+++ /dev/null
@@ -1,69 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.loader.plan.spi;
-
-import org.hibernate.type.Type;
-
-/**
- * This interface provides a delegate for a fetch owner to obtain details about an owned fetch.
- *
- * @author Gail Badner
- */
-public interface FetchOwnerDelegate {
-	public static interface FetchMetadata {
-		/**
-		 * Is the fetch nullable?
-		 *
-		 * @return true, if the fetch is nullable; false, otherwise.
-		 */
-		public boolean isNullable();
-
-		/**
-		 * Returns the type of the fetched attribute
-		 *
-		 * @return the type of the fetched attribute.
-		 */
-		public Type getType();
-
-		/**
-		 * Generates the SQL select fragments for the specified fetch.  A select fragment is the column and formula
-		 * references.
-		 *
-		 * @param alias The table alias to apply to the fragments (used to qualify column references)
-		 *
-		 * @return the select fragments
-		 */
-		public String[] toSqlSelectFragments(String alias);
-	}
-
-	/**
-	 * Locate the metadata for the specified Fetch.  Allows easier caching of the resolved information.
-	 *
-	 * @param fetch The fetch for which to locate metadata
-	 *
-	 * @return The metadata; never {@code null}, rather an exception is thrown if the information for the fetch cannot
-	 * be located.
-	 */
-	public FetchMetadata locateFetchMetadata(Fetch fetch);
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/IdentifierDescription.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/IdentifierDescription.java
index 62d8371196..2b676bcaeb 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/IdentifierDescription.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/IdentifierDescription.java
@@ -1,41 +1,44 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi;
 
 import java.sql.ResultSet;
 import java.sql.SQLException;
 
 import org.hibernate.engine.spi.EntityKey;
-import org.hibernate.loader.spi.ResultSetProcessingContext;
+import org.hibernate.loader.plan.exec.process.spi.ResultSetProcessingContext;
+import org.hibernate.persister.spi.HydratedCompoundValueHandler;
 
 /**
  * @author Steve Ebersole
  */
 public interface IdentifierDescription {
 	public Fetch[] getFetches();
 
 	public void hydrate(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException;
 
 	public EntityKey resolve(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException;
+
+	HydratedCompoundValueHandler getHydratedStateHandler(Fetch fetch);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/KeyManyToOneBidirectionalEntityFetch.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/KeyManyToOneBidirectionalEntityFetch.java
new file mode 100644
index 0000000000..73bbf9e361
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/KeyManyToOneBidirectionalEntityFetch.java
@@ -0,0 +1,62 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.spi;
+
+import org.hibernate.LockMode;
+import org.hibernate.engine.FetchStrategy;
+import org.hibernate.engine.spi.SessionFactoryImplementor;
+import org.hibernate.persister.walking.spi.AttributeDefinition;
+
+/**
+ * We can use the special type as a trigger in AliasResolutionContext, etc to lookup information based on
+ * the wrapped reference.  E.g.
+ *
+ * @author Steve Ebersole
+ */
+public class KeyManyToOneBidirectionalEntityFetch extends EntityFetch implements BidirectionalEntityFetch {
+	private final EntityReference targetEntityReference;
+
+	public KeyManyToOneBidirectionalEntityFetch(
+			SessionFactoryImplementor sessionFactory,
+			LockMode lockMode,
+			FetchOwner owner,
+			AttributeDefinition fetchedAttribute,
+			EntityReference targetEntityReference,
+			FetchStrategy fetchStrategy) {
+		super( sessionFactory, lockMode, owner, fetchedAttribute, fetchStrategy );
+		this.targetEntityReference = targetEntityReference;
+	}
+
+	public KeyManyToOneBidirectionalEntityFetch(
+			KeyManyToOneBidirectionalEntityFetch original,
+			CopyContext copyContext,
+			FetchOwner fetchOwnerCopy) {
+		super( original, copyContext, fetchOwnerCopy );
+		this.targetEntityReference = original.targetEntityReference;
+	}
+
+	public EntityReference getTargetEntityReference() {
+		return targetEntityReference;
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/LoadPlan.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/LoadPlan.java
index 0173b39714..fe5f3c89fe 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/LoadPlan.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/LoadPlan.java
@@ -1,61 +1,100 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi;
 
 import java.util.List;
 
 /**
  * Describes a plan for performing a load of results.
  *
  * Generally speaking there are 3 forms of load plans:<ul>
  *     <li>
  *         An entity load plan for handling get/load handling.  This form will typically have a single
  *         return (of type {@link EntityReturn}) defined by {@link #getReturns()}, possibly defining fetches.
  *     </li>
  *     <li>
  *         A collection initializer, used to load the contents of a collection.  This form will typically have a
  *         single return (of type {@link CollectionReturn} defined by {@link #getReturns()}, possibly defining fetches
  *     </li>
  *     <li>
  *         A query load plan which can contain multiple returns of mixed type (though implementing {@link Return}).
  *         Again, may possibly define fetches.
  *     </li>
  * </ul>
  *
  * @author Steve Ebersole
  */
 public interface LoadPlan {
+	public List<? extends Return> getReturns();
+
+	public Disposition getDisposition();
+
+	/**
+	 * Does this load plan indicate that lazy attributes are to be force fetched?
+	 * <p/>
+	 * Here we are talking about laziness in regards to the legacy bytecode enhancement which adds support for
+	 * partial selects of an entity's state (e.g., skip loading a lob initially, wait until/if it is needed)
+	 * <p/>
+	 * This one would effect the SQL that needs to get generated as well as how the result set would be read.
+	 * Therefore we make this part of the LoadPlan contract.
+	 * <p/>
+	 * NOTE that currently this is only relevant for HQL loaders when the HQL has specified the {@code FETCH ALL PROPERTIES}
+	 * key-phrase.  In all other cases, this returns false.
+
+	 * @return Whether or not to
+	 */
+	public boolean areLazyAttributesForceFetched();
+
 	/**
 	 * Convenient form of checking {@link #getReturns()} for scalar root returns.
 	 *
 	 * @return {@code true} if {@link #getReturns()} contained any scalar returns; {@code false} otherwise.
 	 */
 	public boolean hasAnyScalarReturns();
 
-	public List<Return> getReturns();
+	/**
+	 * Enumerated possibilities for describing the disposition of this LoadPlan.
+	 */
+	public static enum Disposition {
+		/**
+		 * This is an "entity loader" load plan, which describes a plan for loading one or more entity instances of
+		 * the same entity type.  There is a single return, which will be of type {@link EntityReturn}
+		 */
+		ENTITY_LOADER,
+		/**
+		 * This is a "collection initializer" load plan, which describes a plan for loading one or more entity instances of
+		 * the same collection type.  There is a single return, which will be of type {@link CollectionReturn}
+		 */
+		COLLECTION_INITIALIZER,
+		/**
+		 * We have a mixed load plan, which will have one or more returns of {@link EntityReturn} and {@link ScalarReturn}
+		 * (NOT {@link CollectionReturn}).
+		 */
+		MIXED
+	}
 
 	// todo : would also like to see "call back" style access for handling "subsequent actions" such as:
 	// 		1) follow-on locking
 	//		2) join fetch conversions to subselect fetches
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/Return.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/Return.java
index 19c700f57c..30bb6f97fe 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/Return.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/Return.java
@@ -1,67 +1,38 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi;
 
-import java.sql.ResultSet;
-import java.sql.SQLException;
-
-import org.hibernate.loader.spi.ResultSetProcessingContext;
-
 /**
  * Represents a return value in the query results.  Not the same as a result (column) in the JDBC ResultSet!
  * <p/>
  * Return is distinctly different from a {@link Fetch} and so modeled as completely separate hierarchy.
  *
  * @see ScalarReturn
  * @see EntityReturn
  * @see CollectionReturn
  *
  * @author Steve Ebersole
  */
 public interface Return {
-	public void hydrate(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException;
-
-	/**
-	 * Effectively performs first phase of two-phase loading.  For scalar results first/second phase is one.  For
-	 * entities, first phase is to resolve identifiers; second phase is to resolve the entity instances.
-	 *
-	 * @param resultSet The result set being processed
-	 * @param context The context for the processing
-	 *
-	 * @throws SQLException Indicates a problem access the JDBC result set
-	 */
-	public void resolve(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException;
-
-	/**
-	 * Essentially performs the second phase of two-phase loading.
-	 *
-	 * @param resultSet The result set being processed
-	 * @param context The context for the processing
-	 *
-	 * @return The read object
-	 *
-	 * @throws SQLException Indicates a problem access the JDBC result set
-	 */
-	public Object read(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException;
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/ScalarReturn.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/ScalarReturn.java
index 39fb4f01ae..12dfcaf0f7 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/ScalarReturn.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/ScalarReturn.java
@@ -1,69 +1,49 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi;
 
-import java.sql.ResultSet;
-import java.sql.SQLException;
-
 import org.hibernate.engine.spi.SessionFactoryImplementor;
-import org.hibernate.loader.spi.ResultSetProcessingContext;
 import org.hibernate.type.Type;
 
 /**
  * Represent a simple scalar return within a query result.  Generally this would be values of basic (String, Integer,
  * etc) or composite types.
+ * <p/>
+ * todo : we should link the Returns back to their "source"
+ * 		aka the entity/collection/etc that defines the qualifier used to qualify this Return's columns
  *
  * @author Steve Ebersole
  */
 public class ScalarReturn extends AbstractPlanNode implements Return {
 	private final Type type;
 
 	public ScalarReturn(SessionFactoryImplementor factory, Type type) {
 		super( factory );
 		this.type = type;
 	}
 
 	public Type getType() {
 		return type;
 	}
-
-	@Override
-	public void hydrate(ResultSet resultSet, ResultSetProcessingContext context) {
-		// nothing to do
-	}
-
-	@Override
-	public void resolve(ResultSet resultSet, ResultSetProcessingContext context) {
-		// nothing to do
-	}
-
-	@Override
-	public Object read(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
-		return type.nullSafeGet(
-				resultSet,
-				context.getLoadQueryAliasResolutionContext().resolveScalarReturnAliases( this ),
-				context.getSession(),
-				null );
-	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/spi/LoadQueryBuilder.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/SourceQualifiable.java
similarity index 61%
rename from hibernate-core/src/main/java/org/hibernate/loader/spi/LoadQueryBuilder.java
rename to hibernate-core/src/main/java/org/hibernate/loader/plan/spi/SourceQualifiable.java
index a88548f587..70368e8136 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/spi/LoadQueryBuilder.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/SourceQualifiable.java
@@ -1,44 +1,32 @@
 /*
- * jDocBook, processing of DocBook sources
+ * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.loader.spi;
-
-import org.hibernate.engine.spi.SessionFactoryImplementor;
+package org.hibernate.loader.plan.spi;
 
 /**
- * Builds a load query for generating SQL.
+ * Marker interface for LoadPlan nodes that can be qualifiable in the source queries.
  *
- * @author Gail Badner
+ * @author Steve Ebersole
  */
-public interface LoadQueryBuilder {
-
-	/**
-	 * Generates SQL for the performing the load.
-	 * @param batchSize - the batch size.
-	 * @param factory - the session factory.
-	 * @param aliasResolutionContext - the alias resolution context.
-	 *
-	 * @return the SQL string for performing the load
-	 */
-	String generateSql(int batchSize, SessionFactoryImplementor factory, LoadQueryAliasResolutionContext aliasResolutionContext);
+public class SourceQualifiable {
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/SqlSelectFragmentResolver.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/SqlSelectFragmentResolver.java
new file mode 100644
index 0000000000..e84f30252e
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/SqlSelectFragmentResolver.java
@@ -0,0 +1,40 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.spi;
+
+import org.hibernate.persister.walking.spi.AttributeDefinition;
+
+/**
+ * Delegate for resolving the "SQL select fragments" pertaining to an attribute.
+ * <p/>
+ * Most implementations will delegate to the {@link org.hibernate.persister.entity.PropertyMapping} portion
+ * of the EntityPersister contract via the "optional" {@link org.hibernate.persister.entity.Queryable} contract.
+ *
+ * @author Steve Ebersole
+ *
+ * @see org.hibernate.persister.entity.PropertyMapping
+ */
+public interface SqlSelectFragmentResolver {
+	public String[] toSqlSelectFragments(String alias, AttributeDefinition attributeDefinition);
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/build/AbstractLoadPlanBuilderStrategy.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/build/AbstractLoadPlanBuilderStrategy.java
index c95900e719..110da5e802 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/build/AbstractLoadPlanBuilderStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/build/AbstractLoadPlanBuilderStrategy.java
@@ -1,885 +1,903 @@
 /*
  * jDocBook, processing of DocBook sources
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi.build;
 
 import java.io.Serializable;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayDeque;
 import java.util.HashMap;
 import java.util.Map;
 
 import org.jboss.logging.Logger;
 import org.jboss.logging.MDC;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.cfg.NotYetImplementedException;
 import org.hibernate.engine.FetchStrategy;
-import org.hibernate.engine.FetchTiming;
+import org.hibernate.engine.FetchStyle;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.loader.PropertyPath;
 import org.hibernate.loader.plan.spi.AbstractFetchOwner;
-import org.hibernate.loader.plan.spi.AbstractFetchOwnerDelegate;
+import org.hibernate.loader.plan.spi.AnyFetch;
 import org.hibernate.loader.plan.spi.CollectionFetch;
 import org.hibernate.loader.plan.spi.CollectionReference;
 import org.hibernate.loader.plan.spi.CollectionReturn;
 import org.hibernate.loader.plan.spi.CompositeElementGraph;
 import org.hibernate.loader.plan.spi.CompositeFetch;
-import org.hibernate.loader.plan.spi.CompositeFetchOwnerDelegate;
 import org.hibernate.loader.plan.spi.EntityFetch;
+import org.hibernate.loader.plan.spi.EntityPersisterBasedSqlSelectFragmentResolver;
 import org.hibernate.loader.plan.spi.EntityReference;
 import org.hibernate.loader.plan.spi.EntityReturn;
 import org.hibernate.loader.plan.spi.Fetch;
 import org.hibernate.loader.plan.spi.FetchOwner;
-import org.hibernate.loader.plan.spi.FetchOwnerDelegate;
 import org.hibernate.loader.plan.spi.IdentifierDescription;
+import org.hibernate.loader.plan.spi.KeyManyToOneBidirectionalEntityFetch;
 import org.hibernate.loader.plan.spi.Return;
-import org.hibernate.loader.spi.ResultSetProcessingContext;
+import org.hibernate.loader.plan.spi.SqlSelectFragmentResolver;
+import org.hibernate.loader.plan.exec.process.spi.ResultSetProcessingContext;
 import org.hibernate.persister.entity.EntityPersister;
-import org.hibernate.persister.entity.Loadable;
+import org.hibernate.persister.entity.Queryable;
 import org.hibernate.persister.spi.HydratedCompoundValueHandler;
+import org.hibernate.persister.walking.internal.FetchStrategyHelper;
+import org.hibernate.persister.walking.spi.AnyMappingDefinition;
 import org.hibernate.persister.walking.spi.AssociationAttributeDefinition;
 import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.persister.walking.spi.CollectionDefinition;
 import org.hibernate.persister.walking.spi.CollectionElementDefinition;
 import org.hibernate.persister.walking.spi.CollectionIndexDefinition;
 import org.hibernate.persister.walking.spi.CompositeCollectionElementDefinition;
 import org.hibernate.persister.walking.spi.CompositionDefinition;
 import org.hibernate.persister.walking.spi.EntityDefinition;
 import org.hibernate.persister.walking.spi.EntityIdentifierDefinition;
 import org.hibernate.persister.walking.spi.WalkingException;
-import org.hibernate.type.CompositeType;
+import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
-import static org.hibernate.loader.spi.ResultSetProcessingContext.IdentifierResolutionContext;
-
 /**
  * @author Steve Ebersole
  */
 public abstract class AbstractLoadPlanBuilderStrategy implements LoadPlanBuilderStrategy, LoadPlanBuildingContext {
 	private static final Logger log = Logger.getLogger( AbstractLoadPlanBuilderStrategy.class );
 	private static final String MDC_KEY = "hibernateLoadPlanWalkPath";
 
 	private final SessionFactoryImplementor sessionFactory;
 
 	private ArrayDeque<FetchOwner> fetchOwnerStack = new ArrayDeque<FetchOwner>();
 	private ArrayDeque<CollectionReference> collectionReferenceStack = new ArrayDeque<CollectionReference>();
 
 	protected AbstractLoadPlanBuilderStrategy(SessionFactoryImplementor sessionFactory) {
 		this.sessionFactory = sessionFactory;
 	}
 
 	public SessionFactoryImplementor sessionFactory() {
 		return sessionFactory;
 	}
 
 	protected FetchOwner currentFetchOwner() {
 		return fetchOwnerStack.peekFirst();
 	}
 
 	@Override
 	public void start() {
 		if ( ! fetchOwnerStack.isEmpty() ) {
 			throw new WalkingException(
 					"Fetch owner stack was not empty on start; " +
 							"be sure to not use LoadPlanBuilderStrategy instances concurrently"
 			);
 		}
 		if ( ! collectionReferenceStack.isEmpty() ) {
 			throw new WalkingException(
 					"Collection reference stack was not empty on start; " +
 							"be sure to not use LoadPlanBuilderStrategy instances concurrently"
 			);
 		}
 		MDC.put( MDC_KEY, new MDCStack() );
 	}
 
 	@Override
 	public void finish() {
 		MDC.remove( MDC_KEY );
 		fetchOwnerStack.clear();
 		collectionReferenceStack.clear();
 	}
 
 	@Override
 	public void startingEntity(EntityDefinition entityDefinition) {
 		log.tracef(
 				"%s Starting entity : %s",
 				StringHelper.repeat( ">>", fetchOwnerStack.size() ),
 				entityDefinition.getEntityPersister().getEntityName()
 		);
 
 		if ( fetchOwnerStack.isEmpty() ) {
 			// this is a root...
 			if ( ! supportsRootEntityReturns() ) {
 				throw new HibernateException( "This strategy does not support root entity returns" );
 			}
 			final EntityReturn entityReturn = buildRootEntityReturn( entityDefinition );
 			addRootReturn( entityReturn );
 			pushToStack( entityReturn );
 		}
 		// otherwise this call should represent a fetch which should have been handled in #startingAttribute
 	}
 
 	protected boolean supportsRootEntityReturns() {
 		return false;
 	}
 
 	protected abstract void addRootReturn(Return rootReturn);
 
 	@Override
 	public void finishingEntity(EntityDefinition entityDefinition) {
 		// pop the current fetch owner, and make sure what we just popped represents this entity
 		final FetchOwner poppedFetchOwner = popFromStack();
 
 		if ( ! EntityReference.class.isInstance( poppedFetchOwner ) ) {
 			throw new WalkingException( "Mismatched FetchOwner from stack on pop" );
 		}
 
 		final EntityReference entityReference = (EntityReference) poppedFetchOwner;
 		// NOTE : this is not the most exhaustive of checks because of hierarchical associations (employee/manager)
 		if ( ! entityReference.getEntityPersister().equals( entityDefinition.getEntityPersister() ) ) {
 			throw new WalkingException( "Mismatched FetchOwner from stack on pop" );
 		}
 
 		log.tracef(
 				"%s Finished entity : %s",
 				StringHelper.repeat( "<<", fetchOwnerStack.size() ),
 				entityDefinition.getEntityPersister().getEntityName()
 		);
 	}
 
 	@Override
 	public void startingEntityIdentifier(EntityIdentifierDefinition entityIdentifierDefinition) {
 		log.tracef(
 				"%s Starting entity identifier : %s",
 				StringHelper.repeat( ">>", fetchOwnerStack.size() ),
 				entityIdentifierDefinition.getEntityDefinition().getEntityPersister().getEntityName()
 		);
 
 		final EntityReference entityReference = (EntityReference) currentFetchOwner();
 
 		// perform some stack validation
 		if ( ! entityReference.getEntityPersister().equals( entityIdentifierDefinition.getEntityDefinition().getEntityPersister() ) ) {
 			throw new WalkingException(
 					String.format(
 							"Encountered unexpected fetch owner [%s] in stack while processing entity identifier for [%s]",
 							entityReference.getEntityPersister().getEntityName(),
 							entityIdentifierDefinition.getEntityDefinition().getEntityPersister().getEntityName()
 					)
 			);
 		}
 
 		final FetchOwner identifierAttributeCollector;
 		if ( entityIdentifierDefinition.isEncapsulated() ) {
 			identifierAttributeCollector = new EncapsulatedIdentifierAttributeCollector( sessionFactory, entityReference );
 		}
 		else {
 			identifierAttributeCollector = new NonEncapsulatedIdentifierAttributeCollector( sessionFactory, entityReference );
 		}
 		pushToStack( identifierAttributeCollector );
 	}
 
 	@Override
 	public void finishingEntityIdentifier(EntityIdentifierDefinition entityIdentifierDefinition) {
 		// perform some stack validation on exit, first on the current stack element we want to pop
 		{
 			final FetchOwner poppedFetchOwner = popFromStack();
 
 			if ( ! AbstractIdentifierAttributeCollector.class.isInstance( poppedFetchOwner ) ) {
 				throw new WalkingException( "Unexpected state in FetchOwner stack" );
 			}
 
 			final EntityReference entityReference = (EntityReference) poppedFetchOwner;
 			if ( ! entityReference.getEntityPersister().equals( entityIdentifierDefinition.getEntityDefinition().getEntityPersister() ) ) {
 				throw new WalkingException(
 						String.format(
 								"Encountered unexpected fetch owner [%s] in stack while processing entity identifier for [%s]",
 								entityReference.getEntityPersister().getEntityName(),
 								entityIdentifierDefinition.getEntityDefinition().getEntityPersister().getEntityName()
 						)
 				);
 			}
 		}
 
 		// and then on the element before it
 		{
 			final FetchOwner currentFetchOwner = currentFetchOwner();
 			if ( ! EntityReference.class.isInstance( currentFetchOwner ) ) {
 				throw new WalkingException( "Unexpected state in FetchOwner stack" );
 			}
 			final EntityReference entityReference = (EntityReference) currentFetchOwner;
 			if ( ! entityReference.getEntityPersister().equals( entityIdentifierDefinition.getEntityDefinition().getEntityPersister() ) ) {
 				throw new WalkingException(
 						String.format(
 								"Encountered unexpected fetch owner [%s] in stack while processing entity identifier for [%s]",
 								entityReference.getEntityPersister().getEntityName(),
 								entityIdentifierDefinition.getEntityDefinition().getEntityPersister().getEntityName()
 						)
 				);
 			}
 		}
 
 		log.tracef(
 				"%s Finished entity identifier : %s",
 				StringHelper.repeat( "<<", fetchOwnerStack.size() ),
 				entityIdentifierDefinition.getEntityDefinition().getEntityPersister().getEntityName()
 		);
 	}
 
 	@Override
 	public void startingCollection(CollectionDefinition collectionDefinition) {
 		log.tracef(
 				"%s Starting collection : %s",
 				StringHelper.repeat( ">>", fetchOwnerStack.size() ),
 				collectionDefinition.getCollectionPersister().getRole()
 		);
 
 		if ( fetchOwnerStack.isEmpty() ) {
 			// this is a root...
 			if ( ! supportsRootCollectionReturns() ) {
 				throw new HibernateException( "This strategy does not support root collection returns" );
 			}
 			final CollectionReturn collectionReturn = buildRootCollectionReturn( collectionDefinition );
 			addRootReturn( collectionReturn );
 			pushToCollectionStack( collectionReturn );
 		}
 	}
 
 	protected boolean supportsRootCollectionReturns() {
 		return false;
 	}
 
 	@Override
 	public void startingCollectionIndex(CollectionIndexDefinition collectionIndexDefinition) {
 		final Type indexType = collectionIndexDefinition.getType();
 		if ( indexType.isAssociationType() || indexType.isComponentType() ) {
 			final CollectionReference collectionReference = collectionReferenceStack.peekFirst();
 			final FetchOwner indexGraph = collectionReference.getIndexGraph();
 			if ( indexGraph == null ) {
 				throw new WalkingException( "Collection reference did not return index handler" );
 			}
 			pushToStack( indexGraph );
 		}
 	}
 
 	@Override
 	public void finishingCollectionIndex(CollectionIndexDefinition collectionIndexDefinition) {
 		// nothing to do here
 		// 	- the element graph pushed while starting would be popped in finishing/Entity/finishingComposite
 	}
 
 	@Override
 	public void startingCollectionElements(CollectionElementDefinition elementDefinition) {
 		if ( elementDefinition.getType().isAssociationType() || elementDefinition.getType().isComponentType() ) {
 			final CollectionReference collectionReference = collectionReferenceStack.peekFirst();
 			final FetchOwner elementGraph = collectionReference.getElementGraph();
 			if ( elementGraph == null ) {
 				throw new WalkingException( "Collection reference did not return element handler" );
 			}
 			pushToStack( elementGraph );
 		}
 	}
 
 	@Override
 	public void finishingCollectionElements(CollectionElementDefinition elementDefinition) {
 		// nothing to do here
 		// 	- the element graph pushed while starting would be popped in finishing/Entity/finishingComposite
 	}
 
 	@Override
 	public void startingCompositeCollectionElement(CompositeCollectionElementDefinition compositeElementDefinition) {
-		System.out.println(
-				String.format(
-						"%s Starting composite collection element for (%s)",
-						StringHelper.repeat( ">>", fetchOwnerStack.size() ),
-						compositeElementDefinition.getCollectionDefinition().getCollectionPersister().getRole()
-				)
+		log.tracef(
+				"%s Starting composite collection element for (%s)",
+				StringHelper.repeat( ">>", fetchOwnerStack.size() ),
+				compositeElementDefinition.getCollectionDefinition().getCollectionPersister().getRole()
 		);
 	}
 
 	@Override
 	public void finishingCompositeCollectionElement(CompositeCollectionElementDefinition compositeElementDefinition) {
 		// pop the current fetch owner, and make sure what we just popped represents this composition
 		final FetchOwner poppedFetchOwner = popFromStack();
 
 		if ( ! CompositeElementGraph.class.isInstance( poppedFetchOwner ) ) {
 			throw new WalkingException( "Mismatched FetchOwner from stack on pop" );
 		}
 
 		// NOTE : not much else we can really check here atm since on the walking spi side we do not have path
 
 		log.tracef(
 				"%s Finished composite element for  : %s",
 				StringHelper.repeat( "<<", fetchOwnerStack.size() ),
 				compositeElementDefinition.getCollectionDefinition().getCollectionPersister().getRole()
 		);
 	}
 
 	@Override
 	public void finishingCollection(CollectionDefinition collectionDefinition) {
 		// pop the current fetch owner, and make sure what we just popped represents this collection
 		final CollectionReference collectionReference = popFromCollectionStack();
 		if ( ! collectionReference.getCollectionPersister().equals( collectionDefinition.getCollectionPersister() ) ) {
 			throw new WalkingException( "Mismatched FetchOwner from stack on pop" );
 		}
 
 		log.tracef(
 				"%s Finished collection : %s",
 				StringHelper.repeat( "<<", fetchOwnerStack.size() ),
 				collectionDefinition.getCollectionPersister().getRole()
 		);
 	}
 
 	@Override
 	public void startingComposite(CompositionDefinition compositionDefinition) {
 		log.tracef(
 				"%s Starting composition : %s",
 				StringHelper.repeat( ">>", fetchOwnerStack.size() ),
 				compositionDefinition.getName()
 		);
 
 		if ( fetchOwnerStack.isEmpty() ) {
 			throw new HibernateException( "A component cannot be the root of a walk nor a graph" );
 		}
 	}
 
 	@Override
 	public void finishingComposite(CompositionDefinition compositionDefinition) {
 		// pop the current fetch owner, and make sure what we just popped represents this composition
 		final FetchOwner poppedFetchOwner = popFromStack();
 
 		if ( ! CompositeFetch.class.isInstance( poppedFetchOwner ) ) {
 			throw new WalkingException( "Mismatched FetchOwner from stack on pop" );
 		}
 
 		// NOTE : not much else we can really check here atm since on the walking spi side we do not have path
 
 		log.tracef(
 				"%s Finished composition : %s",
 				StringHelper.repeat( "<<", fetchOwnerStack.size() ),
 				compositionDefinition.getName()
 		);
 	}
 
 	@Override
 	public boolean startingAttribute(AttributeDefinition attributeDefinition) {
 		log.tracef(
 				"%s Starting attribute %s",
 				StringHelper.repeat( ">>", fetchOwnerStack.size() ),
 				attributeDefinition
 		);
 
 		final Type attributeType = attributeDefinition.getType();
 
 		final boolean isComponentType = attributeType.isComponentType();
-		final boolean isBasicType = ! ( isComponentType || attributeType.isAssociationType() );
+		final boolean isAssociationType = attributeType.isAssociationType();
+		final boolean isBasicType = ! ( isComponentType || isAssociationType );
 
 		if ( isBasicType ) {
 			return true;
 		}
-		else if ( isComponentType ) {
-			return handleCompositeAttribute( (CompositionDefinition) attributeDefinition );
+		else if ( isAssociationType ) {
+			return handleAssociationAttribute( (AssociationAttributeDefinition) attributeDefinition );
 		}
 		else {
-			return handleAssociationAttribute( (AssociationAttributeDefinition) attributeDefinition );
+			return handleCompositeAttribute( (CompositionDefinition) attributeDefinition );
 		}
 	}
 
 	@Override
 	public void finishingAttribute(AttributeDefinition attributeDefinition) {
 		log.tracef(
 				"%s Finishing up attribute : %s",
 				StringHelper.repeat( "<<", fetchOwnerStack.size() ),
 				attributeDefinition
 		);
 	}
 
+	@Override
+	public void foundAny(AssociationAttributeDefinition attributeDefinition, AnyMappingDefinition anyDefinition) {
+		// for ANY mappings we need to build a Fetch:
+		//		1) fetch type is SELECT, timing might be IMMEDIATE or DELAYED depending on whether it was defined as lazy
+		//		2) (because the fetch cannot be a JOIN...) do not push it to the stack
+		final FetchStrategy fetchStrategy = determineFetchPlan( attributeDefinition );
+
+		final FetchOwner fetchOwner = currentFetchOwner();
+		fetchOwner.validateFetchPlan( fetchStrategy, attributeDefinition );
+
+		fetchOwner.buildAnyFetch(
+				attributeDefinition,
+				anyDefinition,
+				fetchStrategy,
+				this
+		);
+	}
+
 	protected boolean handleCompositeAttribute(CompositionDefinition attributeDefinition) {
 		final FetchOwner fetchOwner = currentFetchOwner();
 		final CompositeFetch fetch = fetchOwner.buildCompositeFetch( attributeDefinition, this );
 		pushToStack( fetch );
 		return true;
 	}
 
 	protected boolean handleAssociationAttribute(AssociationAttributeDefinition attributeDefinition) {
+		// todo : this seems to not be correct for one-to-one
 		final FetchStrategy fetchStrategy = determineFetchPlan( attributeDefinition );
-		if ( fetchStrategy.getTiming() != FetchTiming.IMMEDIATE ) {
+		if ( fetchStrategy.getStyle() != FetchStyle.JOIN ) {
 			return false;
 		}
+//		if ( fetchStrategy.getTiming() != FetchTiming.IMMEDIATE ) {
+//			return false;
+//		}
 
 		final FetchOwner fetchOwner = currentFetchOwner();
-		fetchOwner.validateFetchPlan( fetchStrategy );
+		fetchOwner.validateFetchPlan( fetchStrategy, attributeDefinition );
 
 		final Fetch associationFetch;
-		if ( attributeDefinition.isCollection() ) {
-			associationFetch = fetchOwner.buildCollectionFetch( attributeDefinition, fetchStrategy, this );
-			pushToCollectionStack( (CollectionReference) associationFetch );
+		final AssociationAttributeDefinition.AssociationNature nature = attributeDefinition.getAssociationNature();
+		if ( nature == AssociationAttributeDefinition.AssociationNature.ANY ) {
+			return false;
+//			throw new NotYetImplementedException( "AnyType support still in progress" );
 		}
-		else {
+		else if ( nature == AssociationAttributeDefinition.AssociationNature.ENTITY ) {
 			associationFetch = fetchOwner.buildEntityFetch(
 					attributeDefinition,
 					fetchStrategy,
 					this
 			);
 		}
+		else {
+			associationFetch = fetchOwner.buildCollectionFetch( attributeDefinition, fetchStrategy, this );
+			pushToCollectionStack( (CollectionReference) associationFetch );
+		}
 
 		if ( FetchOwner.class.isInstance( associationFetch) ) {
 			pushToStack( (FetchOwner) associationFetch );
 		}
 
 		return true;
 	}
 
 	protected abstract FetchStrategy determineFetchPlan(AssociationAttributeDefinition attributeDefinition);
 
 	protected int currentDepth() {
 		return fetchOwnerStack.size();
 	}
 
 	protected boolean isTooManyCollections() {
 		return false;
 	}
 
 	private void pushToStack(FetchOwner fetchOwner) {
 		log.trace( "Pushing fetch owner to stack : " + fetchOwner );
 		mdcStack().push( fetchOwner.getPropertyPath() );
 		fetchOwnerStack.addFirst( fetchOwner );
 	}
 
 	private MDCStack mdcStack() {
 		return (MDCStack) MDC.get( MDC_KEY );
 	}
 
 	private FetchOwner popFromStack() {
 		final FetchOwner last = fetchOwnerStack.removeFirst();
 		log.trace( "Popped fetch owner from stack : " + last );
 		mdcStack().pop();
 		if ( FetchStackAware.class.isInstance( last ) ) {
 			( (FetchStackAware) last ).poppedFromStack();
 		}
 		return last;
 	}
 
 	private void pushToCollectionStack(CollectionReference collectionReference) {
 		log.trace( "Pushing collection reference to stack : " + collectionReference );
 		mdcStack().push( collectionReference.getPropertyPath() );
 		collectionReferenceStack.addFirst( collectionReference );
 	}
 
 	private CollectionReference popFromCollectionStack() {
 		final CollectionReference last = collectionReferenceStack.removeFirst();
 		log.trace( "Popped collection reference from stack : " + last );
 		mdcStack().pop();
 		if ( FetchStackAware.class.isInstance( last ) ) {
 			( (FetchStackAware) last ).poppedFromStack();
 		}
 		return last;
 	}
 
 	protected abstract EntityReturn buildRootEntityReturn(EntityDefinition entityDefinition);
 
 	protected abstract CollectionReturn buildRootCollectionReturn(CollectionDefinition collectionDefinition);
 
 
 
 	// LoadPlanBuildingContext impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public SessionFactoryImplementor getSessionFactory() {
 		return sessionFactory();
 	}
 
 	public static interface FetchStackAware {
 		public void poppedFromStack();
 	}
 
 	protected static abstract class AbstractIdentifierAttributeCollector extends AbstractFetchOwner
 			implements FetchOwner, EntityReference, FetchStackAware {
 		protected final EntityReference entityReference;
+		private final EntityPersisterBasedSqlSelectFragmentResolver sqlSelectFragmentResolver;
 		protected final Map<Fetch,HydratedCompoundValueHandler> fetchToHydratedStateExtractorMap
 				= new HashMap<Fetch, HydratedCompoundValueHandler>();
 
 		public AbstractIdentifierAttributeCollector(SessionFactoryImplementor sessionFactory, EntityReference entityReference) {
 			super( sessionFactory );
 			this.entityReference = entityReference;
+			this.sqlSelectFragmentResolver = new EntityPersisterBasedSqlSelectFragmentResolver(
+					(Queryable) entityReference.getEntityPersister()
+			);
 		}
 
 		@Override
 		public LockMode getLockMode() {
 			return entityReference.getLockMode();
 		}
 
 		@Override
 		public EntityReference getEntityReference() {
 			return this;
 		}
 
 		@Override
 		public EntityPersister getEntityPersister() {
 			return entityReference.getEntityPersister();
 		}
 
 		@Override
 		public IdentifierDescription getIdentifierDescription() {
 			return entityReference.getIdentifierDescription();
 		}
 
 		@Override
 		public CollectionFetch buildCollectionFetch(
 				AssociationAttributeDefinition attributeDefinition,
 				FetchStrategy fetchStrategy,
 				LoadPlanBuildingContext loadPlanBuildingContext) {
 			throw new WalkingException( "Entity identifier cannot contain persistent collections" );
 		}
 
 		@Override
+		public AnyFetch buildAnyFetch(
+				AttributeDefinition attribute,
+				AnyMappingDefinition anyDefinition,
+				FetchStrategy fetchStrategy,
+				LoadPlanBuildingContext loadPlanBuildingContext) {
+			throw new WalkingException( "Entity identifier cannot contain ANY type mappings" );
+		}
+
+		@Override
 		public EntityFetch buildEntityFetch(
 				AssociationAttributeDefinition attributeDefinition,
 				FetchStrategy fetchStrategy,
 				LoadPlanBuildingContext loadPlanBuildingContext) {
 			// we have a key-many-to-one
 			//
 			// IMPL NOTE: we pass ourselves as the FetchOwner which will route the fetch back through our #addFetch
 			// 		impl.  We collect them there and later build the IdentifierDescription
+
+			// if `this` is a fetch and its owner is "the same" (bi-directionality) as the attribute to be join fetched
+			// we should wrap our FetchOwner as an EntityFetch.  That should solve everything except for the alias
+			// context lookups because of the different instances (because of wrapping).  So somehow the consumer of this
+			// needs to be able to unwrap it to do the alias lookup, and would have to know to do that.
+			//
+			//
+			// we are processing the EntityReference(Address) identifier.  we come across its key-many-to-one reference
+			// to Person.  Now, if EntityReference(Address) is an instance of EntityFetch(Address) there is a strong
+			// likelihood that we have a bi-directionality and need to handle that specially.
+			//
+			// how to best (a) find the bi-directionality and (b) represent that?
+
+			if ( EntityFetch.class.isInstance( entityReference ) ) {
+				// we just confirmed that EntityReference(Address) is an instance of EntityFetch(Address),
+				final EntityFetch entityFetch = (EntityFetch) entityReference;
+				final FetchOwner entityFetchOwner = entityFetch.getOwner();
+				// so at this point we need to see if entityFetchOwner and attributeDefinition refer to the
+				// "same thing".  "same thing" == "same type" && "same column(s)"?
+				//
+				// i make assumptions here that that the attribute type is the EntityType, is that always valid?
+				final EntityType attributeDefinitionTypeAsEntityType = (EntityType) attributeDefinition.getType();
+
+				final boolean sameType = attributeDefinitionTypeAsEntityType.getAssociatedEntityName().equals(
+						entityFetchOwner.retrieveFetchSourcePersister().getEntityName()
+				);
+
+				if ( sameType ) {
+					// check same columns as well?
+
+					return new KeyManyToOneBidirectionalEntityFetch(
+							sessionFactory(),
+							//ugh
+							LockMode.READ,
+							this,
+							attributeDefinition,
+							(EntityReference) entityFetchOwner,
+							fetchStrategy
+					);
+				}
+			}
+
 			final EntityFetch fetch = super.buildEntityFetch( attributeDefinition, fetchStrategy, loadPlanBuildingContext );
+
+			// pretty sure this HydratedCompoundValueExtractor stuff is not needed...
 			fetchToHydratedStateExtractorMap.put( fetch, attributeDefinition.getHydratedCompoundValueExtractor() );
 
 			return fetch;
 		}
 
+
 		@Override
 		public Type getType(Fetch fetch) {
-			return getFetchOwnerDelegate().locateFetchMetadata( fetch ).getType();
+			return fetch.getFetchedType();
 		}
 
 		@Override
 		public boolean isNullable(Fetch fetch) {
-			return getFetchOwnerDelegate().locateFetchMetadata( fetch ).isNullable();
+			return  fetch.isNullable();
 		}
 
 		@Override
 		public String[] toSqlSelectFragments(Fetch fetch, String alias) {
-			return getFetchOwnerDelegate().locateFetchMetadata( fetch ).toSqlSelectFragments( alias );
+			return fetch.toSqlSelectFragments( alias );
+		}
+
+		@Override
+		public SqlSelectFragmentResolver toSqlSelectFragmentResolver() {
+			return sqlSelectFragmentResolver;
 		}
 
 		@Override
 		public void poppedFromStack() {
 			final IdentifierDescription identifierDescription = buildIdentifierDescription();
 			entityReference.injectIdentifierDescription( identifierDescription );
 		}
 
 		protected abstract IdentifierDescription buildIdentifierDescription();
 
 		@Override
-		public void validateFetchPlan(FetchStrategy fetchStrategy) {
-			( (FetchOwner) entityReference ).validateFetchPlan( fetchStrategy );
+		public void validateFetchPlan(FetchStrategy fetchStrategy, AttributeDefinition attributeDefinition) {
+			( (FetchOwner) entityReference ).validateFetchPlan( fetchStrategy, attributeDefinition );
 		}
 
 		@Override
 		public EntityPersister retrieveFetchSourcePersister() {
 			return ( (FetchOwner) entityReference ).retrieveFetchSourcePersister();
 		}
 
 		@Override
 		public void injectIdentifierDescription(IdentifierDescription identifierDescription) {
 			throw new WalkingException(
 					"IdentifierDescription collector should not get injected with IdentifierDescription"
 			);
 		}
 	}
 
 	protected static class EncapsulatedIdentifierAttributeCollector extends AbstractIdentifierAttributeCollector {
 		private final PropertyPath propertyPath;
-		private final FetchOwnerDelegate delegate;
 
 		public EncapsulatedIdentifierAttributeCollector(
 				final SessionFactoryImplementor sessionFactory,
 				final EntityReference entityReference) {
 			super( sessionFactory, entityReference );
 			this.propertyPath = ( (FetchOwner) entityReference ).getPropertyPath();
-			this.delegate = new AbstractFetchOwnerDelegate() {
-				final boolean isCompositeType = entityReference.getEntityPersister().getIdentifierType().isComponentType();
-
-				@Override
-				protected FetchMetadata buildFetchMetadata(Fetch fetch) {
-					if ( !isCompositeType ) {
-						throw new WalkingException( "Non-composite identifier cannot be a fetch owner" );
-					}
-
-					if ( !fetch.getOwnerPropertyName().equals( entityReference.getEntityPersister().getIdentifierPropertyName() ) ) {
-						throw new IllegalArgumentException(
-								String.format(
-										"Fetch owner property name [%s] is not the same as the identifier prop" +
-												fetch.getOwnerPropertyName(),
-										entityReference.getEntityPersister().getIdentifierPropertyName()
-								)
-						);
-					}
-
-					return new FetchMetadata() {
-						@Override
-						public boolean isNullable() {
-							return false;
-						}
-
-						@Override
-						public Type getType() {
-							return entityReference.getEntityPersister().getIdentifierType();
-						}
-
-						@Override
-						public String[] toSqlSelectFragments(String alias) {
-							// should not ever be called iiuc...
-							throw new WalkingException( "Should not be called" );
-						}
-					};
-				}
-			};
 		}
 
 		@Override
 		protected IdentifierDescription buildIdentifierDescription() {
 			return new IdentifierDescriptionImpl(
 					entityReference,
 					getFetches(),
 					null
 			);
 		}
 
 		@Override
-		protected FetchOwnerDelegate getFetchOwnerDelegate() {
-			return delegate;
-		}
-
-		@Override
 		public PropertyPath getPropertyPath() {
 			return propertyPath;
 		}
 	}
 
 	protected static class NonEncapsulatedIdentifierAttributeCollector extends AbstractIdentifierAttributeCollector {
 		private final PropertyPath propertyPath;
-		private final FetchOwnerDelegate fetchOwnerDelegate;
 
 		public NonEncapsulatedIdentifierAttributeCollector(
 				final SessionFactoryImplementor sessionfactory,
 				final EntityReference entityReference) {
 			super( sessionfactory, entityReference );
 			this.propertyPath = ( (FetchOwner) entityReference ).getPropertyPath().append( "<id>" );
-			this.fetchOwnerDelegate = new AbstractFetchOwnerDelegate() {
-				final boolean isCompositeType = entityReference.getEntityPersister().getIdentifierType().isComponentType();
-				final CompositeType idType = (CompositeType) entityReference.getEntityPersister().getIdentifierType();
-
-
-				@Override
-				protected FetchMetadata buildFetchMetadata(Fetch fetch) {
-					if ( !isCompositeType ) {
-						throw new WalkingException( "Non-composite identifier cannot be a fetch owner" );
-					}
-
-					final int subPropertyIndex = locateSubPropertyIndex( idType, fetch.getOwnerPropertyName() );
-
-					return new FetchMetadata() {
-						final Type subType = idType.getSubtypes()[ subPropertyIndex ];
-
-						@Override
-						public boolean isNullable() {
-							return false;
-						}
-
-						@Override
-						public Type getType() {
-							return subType;
-						}
-
-						@Override
-						public String[] toSqlSelectFragments(String alias) {
-							// should not ever be called iiuc...
-							throw new WalkingException( "Should not be called" );
-						}
-					};
-				}
-
-				private int locateSubPropertyIndex(CompositeType idType, String ownerPropertyName) {
-					for ( int i = 0; i < idType.getPropertyNames().length; i++ ) {
-						if ( ownerPropertyName.equals( idType.getPropertyNames()[i] ) ) {
-							return i;
-						}
-					}
-					// does not bode well if we get here...
-					throw new IllegalStateException(
-							String.format(
-									"Unable to locate fetched attribute [%s] as part of composite identifier [%s]",
-									ownerPropertyName,
-									getPropertyPath().getFullPath()
-							)
-
-					);
-				}
-
-			};
 		}
 
 		@Override
 		protected IdentifierDescription buildIdentifierDescription() {
 			return new IdentifierDescriptionImpl(
 					entityReference,
 					getFetches(),
 					fetchToHydratedStateExtractorMap
 			);
 		}
 
 		@Override
 		public PropertyPath getPropertyPath() {
 			return propertyPath;
 		}
-
-
-		@Override
-		protected FetchOwnerDelegate getFetchOwnerDelegate() {
-			return fetchOwnerDelegate;
-		}
-
 	}
 
 	private static class IdentifierDescriptionImpl implements IdentifierDescription {
 		private final EntityReference entityReference;
 		private final Fetch[] identifierFetches;
 		private final Map<Fetch,HydratedCompoundValueHandler> fetchToHydratedStateExtractorMap;
 
 		private IdentifierDescriptionImpl(
 				EntityReference entityReference,
 				Fetch[] identifierFetches,
 				Map<Fetch, HydratedCompoundValueHandler> fetchToHydratedStateExtractorMap) {
 			this.entityReference = entityReference;
 			this.identifierFetches = identifierFetches;
 			this.fetchToHydratedStateExtractorMap = fetchToHydratedStateExtractorMap;
 		}
 
 		@Override
 		public Fetch[] getFetches() {
 			return identifierFetches;
 		}
 
 		@Override
+		public HydratedCompoundValueHandler getHydratedStateHandler(Fetch fetch) {
+			return fetchToHydratedStateExtractorMap == null ? null : fetchToHydratedStateExtractorMap.get( fetch );
+		}
+
+		@Override
 		public void hydrate(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
-			final IdentifierResolutionContext ownerIdentifierResolutionContext =
-					context.getIdentifierResolutionContext( entityReference );
-			final Object ownerIdentifierHydratedState = ownerIdentifierResolutionContext.getHydratedForm();
+			final ResultSetProcessingContext.EntityReferenceProcessingState ownerEntityReferenceProcessingState =
+					context.getProcessingState( entityReference );
+			final Object ownerIdentifierHydratedState = ownerEntityReferenceProcessingState.getIdentifierHydratedForm();
 
 			if ( ownerIdentifierHydratedState != null ) {
 				for ( Fetch fetch : identifierFetches ) {
 					if ( fetch instanceof EntityFetch ) {
-						final IdentifierResolutionContext identifierResolutionContext =
-								context.getIdentifierResolutionContext( (EntityFetch) fetch );
+						final ResultSetProcessingContext.EntityReferenceProcessingState fetchEntityReferenceProcessingState =
+								context.getProcessingState( (EntityFetch) fetch );
 						// if the identifier was already hydrated, nothing to do
-						if ( identifierResolutionContext.getHydratedForm() != null ) {
+						if ( fetchEntityReferenceProcessingState.getIdentifierHydratedForm() != null ) {
 							continue;
 						}
 						// try to extract the sub-hydrated value from the owners tuple array
 						if ( fetchToHydratedStateExtractorMap != null && ownerIdentifierHydratedState != null ) {
 							Serializable extracted = (Serializable) fetchToHydratedStateExtractorMap.get( fetch )
 									.extract( ownerIdentifierHydratedState );
-							identifierResolutionContext.registerHydratedForm( extracted );
+							fetchEntityReferenceProcessingState.registerIdentifierHydratedForm( extracted );
 							continue;
 						}
 
 						// if we can't, then read from result set
 						fetch.hydrate( resultSet, context );
 					}
 					else {
 						throw new NotYetImplementedException( "Cannot hydrate identifier Fetch that is not an EntityFetch" );
 					}
 				}
 				return;
 			}
 
+			final String[] columnNames;
+			if ( EntityFetch.class.isInstance( entityReference )
+					&& !FetchStrategyHelper.isJoinFetched( ((EntityFetch) entityReference).getFetchStrategy() ) ) {
+				final EntityFetch fetch = (EntityFetch) entityReference;
+				final FetchOwner fetchOwner = fetch.getOwner();
+				if ( EntityReference.class.isInstance( fetchOwner ) ) {
+					throw new NotYetImplementedException();
+//					final EntityReference ownerEntityReference = (EntityReference) fetchOwner;
+//					final EntityAliases ownerEntityAliases = context.getAliasResolutionContext()
+//							.resolveEntityColumnAliases( ownerEntityReference );
+//					final int propertyIndex = ownerEntityReference.getEntityPersister()
+//							.getEntityMetamodel()
+//							.getPropertyIndex( fetch.getOwnerPropertyName() );
+//					columnNames = ownerEntityAliases.getSuffixedPropertyAliases()[ propertyIndex ];
+				}
+				else {
+					// todo : better message here...
+					throw new WalkingException( "Cannot locate association column names" );
+				}
+			}
+			else {
+				columnNames = context.getAliasResolutionContext()
+						.resolveAliases( entityReference )
+						.getColumnAliases()
+						.getSuffixedKeyAliases();
+			}
+
 			final Object hydratedIdentifierState = entityReference.getEntityPersister().getIdentifierType().hydrate(
 					resultSet,
-					context.getLoadQueryAliasResolutionContext().resolveEntityColumnAliases( entityReference ).getSuffixedKeyAliases(),
+					columnNames,
 					context.getSession(),
 					null
 			);
-			context.getIdentifierResolutionContext( entityReference ).registerHydratedForm( hydratedIdentifierState );
+			context.getProcessingState( entityReference ).registerIdentifierHydratedForm( hydratedIdentifierState );
 		}
 
 		@Override
 		public EntityKey resolve(ResultSet resultSet, ResultSetProcessingContext context) throws SQLException {
 			for ( Fetch fetch : identifierFetches ) {
 				resolveIdentifierFetch( resultSet, context, fetch );
 			}
 
-			final IdentifierResolutionContext ownerIdentifierResolutionContext =
-					context.getIdentifierResolutionContext( entityReference );
-			Object hydratedState = ownerIdentifierResolutionContext.getHydratedForm();
+			final ResultSetProcessingContext.EntityReferenceProcessingState ownerEntityReferenceProcessingState =
+					context.getProcessingState( entityReference );
+			Object hydratedState = ownerEntityReferenceProcessingState.getIdentifierHydratedForm();
 			Serializable resolvedId = (Serializable) entityReference.getEntityPersister()
 					.getIdentifierType()
 					.resolve( hydratedState, context.getSession(), null );
 			return context.getSession().generateEntityKey( resolvedId, entityReference.getEntityPersister() );
 		}
 	}
 
 	private static void resolveIdentifierFetch(
 			ResultSet resultSet,
 			ResultSetProcessingContext context,
 			Fetch fetch) throws SQLException {
 		if ( fetch instanceof EntityFetch ) {
 			EntityFetch entityFetch = (EntityFetch) fetch;
-			final IdentifierResolutionContext identifierResolutionContext =
-					context.getIdentifierResolutionContext( entityFetch );
-			if ( identifierResolutionContext.getEntityKey() != null ) {
+			final ResultSetProcessingContext.EntityReferenceProcessingState entityReferenceProcessingState =
+					context.getProcessingState( entityFetch );
+			if ( entityReferenceProcessingState.getEntityKey() != null ) {
 				return;
 			}
 
 			EntityKey fetchKey = entityFetch.resolveInIdentifier( resultSet, context );
-			identifierResolutionContext.registerEntityKey( fetchKey );
+			entityReferenceProcessingState.registerEntityKey( fetchKey );
 		}
 		else if ( fetch instanceof CompositeFetch ) {
 			for ( Fetch subFetch : ( (CompositeFetch) fetch ).getFetches() ) {
 				resolveIdentifierFetch( resultSet, context, subFetch );
 			}
 		}
 	}
 
 	public static class MDCStack {
 		private ArrayDeque<PropertyPath> pathStack = new ArrayDeque<PropertyPath>();
 
 		public void push(PropertyPath path) {
 			pathStack.addFirst( path );
 		}
 
 		public void pop() {
 			pathStack.removeFirst();
 		}
 
 		public String toString() {
 			final PropertyPath path = pathStack.peekFirst();
 			return path == null ? "<no-path>" : path.getFullPath();
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/build/LoadPlanBuilder.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/build/LoadPlanBuilder.java
index 19d3499d0c..4c3d025489 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/build/LoadPlanBuilder.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/build/LoadPlanBuilder.java
@@ -1,65 +1,66 @@
 /*
  * jDocBook, processing of DocBook sources
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi.build;
 
 import org.hibernate.loader.plan.spi.LoadPlan;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.walking.spi.MetadataDrivenModelGraphVisitor;
 
 /**
- * Coordinates building of a {@link org.hibernate.loader.plan.spi.LoadPlan} between the {@link org.hibernate.persister.walking.spi.MetadataDrivenModelGraphVisitor} and
+ * Coordinates building of a {@link org.hibernate.loader.plan.spi.LoadPlan} between the
+ * {@link org.hibernate.persister.walking.spi.MetadataDrivenModelGraphVisitor} and
  * {@link LoadPlanBuilderStrategy}
  *
  * @author Steve Ebersole
  */
 public class LoadPlanBuilder {
 	/**
 	 * Coordinates building a LoadPlan that defines just a single root entity return (may have fetches).
 	 * <p/>
 	 * Typically this includes building load plans for entity loading or cascade loading.
 	 *
 	 * @param strategy The strategy defining the load plan shaping
 	 * @param persister The persister for the entity forming the root of the load plan.
 	 *
 	 * @return The built load plan.
 	 */
 	public static LoadPlan buildRootEntityLoadPlan(LoadPlanBuilderStrategy strategy, EntityPersister persister) {
 		MetadataDrivenModelGraphVisitor.visitEntity( strategy, persister );
 		return strategy.buildLoadPlan();
 	}
 
 	/**
 	 * Coordinates building a LoadPlan that defines just a single root collection return (may have fetches).
 	 *
 	 * @param strategy The strategy defining the load plan shaping
 	 * @param persister The persister for the collection forming the root of the load plan.
 	 *
 	 * @return The built load plan.
 	 */
 	public static LoadPlan buildRootCollectionLoadPlan(LoadPlanBuilderStrategy strategy, CollectionPersister persister) {
 		MetadataDrivenModelGraphVisitor.visitCollection( strategy, persister );
 		return strategy.buildLoadPlan();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/build/LoadPlanBuilderStrategy.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/build/LoadPlanBuilderStrategy.java
index 64bc8c486b..120af2a638 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/build/LoadPlanBuilderStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/build/LoadPlanBuilderStrategy.java
@@ -1,41 +1,42 @@
 /*
  * jDocBook, processing of DocBook sources
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi.build;
 
 import org.hibernate.loader.plan.spi.LoadPlan;
 import org.hibernate.persister.walking.spi.AssociationVisitationStrategy;
 
 /**
- * Specialized {@link org.hibernate.persister.walking.spi.AssociationVisitationStrategy} implementation for building {@link org.hibernate.loader.plan.spi.LoadPlan} instances.
+ * Specialized {@link org.hibernate.persister.walking.spi.AssociationVisitationStrategy} implementation for
+ * building {@link org.hibernate.loader.plan.spi.LoadPlan} instances.
  *
  * @author Steve Ebersole
  */
 public interface LoadPlanBuilderStrategy extends AssociationVisitationStrategy {
 	/**
 	 * After visitation is done, build the load plan.
 	 *
 	 * @return The load plan
 	 */
 	public LoadPlan buildLoadPlan();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/build/LoadPlanBuildingContext.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/build/LoadPlanBuildingContext.java
index 46833340d5..30f63b5f48 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/build/LoadPlanBuildingContext.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/build/LoadPlanBuildingContext.java
@@ -1,33 +1,40 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi.build;
 
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 
 /**
+ * Provides access to context needed in building a LoadPlan.
+ *
  * @author Steve Ebersole
  */
 public interface LoadPlanBuildingContext {
+	/**
+	 * Access to the SessionFactory
+	 *
+	 * @return The SessionFactory
+	 */
 	public SessionFactoryImplementor getSessionFactory();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/build/package-info.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/build/package-info.java
new file mode 100644
index 0000000000..e69de29bb2
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/visit/DelegatedLoadPlanVisitationStrategy.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/visit/DelegatedLoadPlanVisitationStrategy.java
index bfa7ff79e9..1dd773e364 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/visit/DelegatedLoadPlanVisitationStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/visit/DelegatedLoadPlanVisitationStrategy.java
@@ -1,118 +1,129 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi.visit;
 
+import org.hibernate.loader.plan.spi.AnyFetch;
 import org.hibernate.loader.plan.spi.CollectionFetch;
 import org.hibernate.loader.plan.spi.CollectionReturn;
 import org.hibernate.loader.plan.spi.CompositeFetch;
 import org.hibernate.loader.plan.spi.EntityFetch;
 import org.hibernate.loader.plan.spi.EntityReturn;
 import org.hibernate.loader.plan.spi.FetchOwner;
 import org.hibernate.loader.plan.spi.LoadPlan;
 import org.hibernate.loader.plan.spi.Return;
 import org.hibernate.loader.plan.spi.ScalarReturn;
 
 /**
  * @author Steve Ebersole
  */
 public class DelegatedLoadPlanVisitationStrategy implements LoadPlanVisitationStrategy {
 	private final ReturnGraphVisitationStrategy returnGraphVisitationStrategy;
 
 	public DelegatedLoadPlanVisitationStrategy(ReturnGraphVisitationStrategy returnGraphVisitationStrategy) {
 		this.returnGraphVisitationStrategy = returnGraphVisitationStrategy;
 	}
 
 	@Override
 	public void start(LoadPlan loadPlan) {
 	}
 
 	@Override
 	public void finish(LoadPlan loadPlan) {
 	}
 
 	@Override
 	public void startingRootReturn(Return rootReturn) {
 		returnGraphVisitationStrategy.startingRootReturn( rootReturn );
 	}
 
 	@Override
 	public void finishingRootReturn(Return rootReturn) {
 		returnGraphVisitationStrategy.finishingRootReturn( rootReturn );
 	}
 
 	@Override
 	public void handleScalarReturn(ScalarReturn scalarReturn) {
 		returnGraphVisitationStrategy.handleScalarReturn( scalarReturn );
 	}
 
 	@Override
 	public void handleEntityReturn(EntityReturn rootEntityReturn) {
 		returnGraphVisitationStrategy.handleEntityReturn( rootEntityReturn );
 	}
 
 	@Override
 	public void handleCollectionReturn(CollectionReturn rootCollectionReturn) {
 		returnGraphVisitationStrategy.handleCollectionReturn( rootCollectionReturn );
 	}
 
 	@Override
 	public void startingFetches(FetchOwner fetchOwner) {
 		returnGraphVisitationStrategy.startingFetches( fetchOwner );
 	}
 
 	@Override
 	public void finishingFetches(FetchOwner fetchOwner) {
 		returnGraphVisitationStrategy.finishingFetches( fetchOwner );
 	}
 
 	@Override
 	public void startingEntityFetch(EntityFetch fetch) {
 		returnGraphVisitationStrategy.startingEntityFetch( fetch );
 	}
 
 	@Override
 	public void finishingEntityFetch(EntityFetch fetch) {
 		returnGraphVisitationStrategy.finishingEntityFetch( fetch );
 	}
 
 	@Override
 	public void startingCollectionFetch(CollectionFetch fetch) {
 		returnGraphVisitationStrategy.startingCollectionFetch( fetch );
 	}
 
 	@Override
 	public void finishingCollectionFetch(CollectionFetch fetch) {
 		returnGraphVisitationStrategy.finishingCollectionFetch( fetch );
 	}
 
 	@Override
 	public void startingCompositeFetch(CompositeFetch fetch) {
 		returnGraphVisitationStrategy.startingCompositeFetch( fetch );
 	}
 
 	@Override
 	public void finishingCompositeFetch(CompositeFetch fetch) {
 		returnGraphVisitationStrategy.finishingCompositeFetch( fetch );
 	}
+
+	@Override
+	public void startingAnyFetch(AnyFetch fetch) {
+		returnGraphVisitationStrategy.startingAnyFetch( fetch );
+	}
+
+	@Override
+	public void finishingAnyFetch(AnyFetch fetch) {
+		returnGraphVisitationStrategy.finishingAnyFetch( fetch );
+	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/visit/LoadPlanVisitationStrategyAdapter.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/visit/LoadPlanVisitationStrategyAdapter.java
index ca85c40cc2..7e80079c22 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/visit/LoadPlanVisitationStrategyAdapter.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/visit/LoadPlanVisitationStrategyAdapter.java
@@ -1,101 +1,110 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi.visit;
 
+import org.hibernate.loader.plan.spi.AnyFetch;
 import org.hibernate.loader.plan.spi.CollectionFetch;
 import org.hibernate.loader.plan.spi.CollectionReturn;
 import org.hibernate.loader.plan.spi.CompositeFetch;
 import org.hibernate.loader.plan.spi.EntityFetch;
 import org.hibernate.loader.plan.spi.EntityReturn;
 import org.hibernate.loader.plan.spi.FetchOwner;
 import org.hibernate.loader.plan.spi.LoadPlan;
 import org.hibernate.loader.plan.spi.Return;
 import org.hibernate.loader.plan.spi.ScalarReturn;
 
 /**
  * @author Steve Ebersole
  */
 public class LoadPlanVisitationStrategyAdapter implements LoadPlanVisitationStrategy {
 	public static final LoadPlanVisitationStrategyAdapter INSTANCE = new LoadPlanVisitationStrategyAdapter();
 
 	@Override
 	public void start(LoadPlan loadPlan) {
 	}
 
 	@Override
 	public void finish(LoadPlan loadPlan) {
 	}
 
 	@Override
 	public void startingRootReturn(Return rootReturn) {
 	}
 
 	@Override
 	public void finishingRootReturn(Return rootReturn) {
 	}
 
 	@Override
 	public void handleScalarReturn(ScalarReturn scalarReturn) {
 	}
 
 	@Override
 	public void handleEntityReturn(EntityReturn rootEntityReturn) {
 	}
 
 	@Override
 	public void handleCollectionReturn(CollectionReturn rootCollectionReturn) {
 	}
 
 	@Override
 	public void startingFetches(FetchOwner fetchOwner) {
 	}
 
 	@Override
 	public void finishingFetches(FetchOwner fetchOwner) {
 	}
 
 	@Override
 	public void startingEntityFetch(EntityFetch entityFetch) {
 	}
 
 	@Override
 	public void finishingEntityFetch(EntityFetch entityFetch) {
 	}
 
 	@Override
 	public void startingCollectionFetch(CollectionFetch collectionFetch) {
 	}
 
 	@Override
 	public void finishingCollectionFetch(CollectionFetch collectionFetch) {
 	}
 
 	@Override
 	public void startingCompositeFetch(CompositeFetch fetch) {
 	}
 
 	@Override
 	public void finishingCompositeFetch(CompositeFetch fetch) {
 	}
+
+	@Override
+	public void startingAnyFetch(AnyFetch fetch) {
+	}
+
+	@Override
+	public void finishingAnyFetch(AnyFetch fetch) {
+	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/visit/ReturnGraphVisitationStrategy.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/visit/ReturnGraphVisitationStrategy.java
index 02d78e5597..0b7a0914b0 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/visit/ReturnGraphVisitationStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/visit/ReturnGraphVisitationStrategy.java
@@ -1,139 +1,154 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi.visit;
 
+import org.hibernate.loader.plan.spi.AnyFetch;
 import org.hibernate.loader.plan.spi.CollectionFetch;
 import org.hibernate.loader.plan.spi.CollectionReturn;
 import org.hibernate.loader.plan.spi.CompositeFetch;
 import org.hibernate.loader.plan.spi.EntityFetch;
 import org.hibernate.loader.plan.spi.EntityReturn;
 import org.hibernate.loader.plan.spi.FetchOwner;
 import org.hibernate.loader.plan.spi.Return;
 import org.hibernate.loader.plan.spi.ScalarReturn;
 
 /**
  * A strategy for visiting a root {@link Return} and fetches it defines.
  *
  * @author Steve Ebersole
  */
 public interface ReturnGraphVisitationStrategy {
 	/**
 	 * Notification that a new root return branch is being started.  Will be followed by calls
 	 * to one of the following based on the type of return:<ul>
 	 *     <li>{@link #handleScalarReturn}</li>
 	 *     <li>{@link #handleEntityReturn}</li>
 	 *     <li>{@link #handleCollectionReturn}</li>
 	 * </ul>
 	 *
 	 * @param rootReturn The root return at the root of the branch.
 	 */
 	public void startingRootReturn(Return rootReturn);
 
 	/**
 	 * Notification that we are finishing up processing a root return branch
 	 *
 	 * @param rootReturn The RootReturn we are finishing up processing.
 	 */
 	public void finishingRootReturn(Return rootReturn);
 
 	/**
 	 * Notification that a scalar return is being processed.  Will be surrounded by calls to
 	 * {@link #startingRootReturn} and {@link #finishingRootReturn}
 	 *
 	 * @param scalarReturn The scalar return
 	 */
 	public void handleScalarReturn(ScalarReturn scalarReturn);
 
 	/**
 	 * Notification that a root entity return is being processed.  Will be surrounded by calls to
 	 * {@link #startingRootReturn} and {@link #finishingRootReturn}
 	 *
 	 * @param rootEntityReturn The root entity return
 	 */
 	public void handleEntityReturn(EntityReturn rootEntityReturn);
 
 	/**
 	 * Notification that a root collection return is being processed.  Will be surrounded by calls to
 	 * {@link #startingRootReturn} and {@link #finishingRootReturn}
 	 *
 	 * @param rootCollectionReturn The root collection return
 	 */
 	public void handleCollectionReturn(CollectionReturn rootCollectionReturn);
 
 	/**
 	 * Notification that we are about to start processing the fetches for the given fetch owner.
 	 *
 	 * @param fetchOwner The fetch owner.
 	 */
 	public void startingFetches(FetchOwner fetchOwner);
 
 	/**
 	 * Notification that we are finishing up processing the fetches for the given fetch owner.
 	 *
 	 * @param fetchOwner The fetch owner.
 	 */
 	public void finishingFetches(FetchOwner fetchOwner);
 
 	/**
 	 * Notification we are starting the processing of an entity fetch
 	 *
 	 * @param entityFetch The entity fetch
 	 */
 	public void startingEntityFetch(EntityFetch entityFetch);
 
 	/**
 	 * Notification that we are finishing up the processing of an entity fetch
 	 *
 	 * @param entityFetch The entity fetch
 	 */
 	public void finishingEntityFetch(EntityFetch entityFetch);
 
 	/**
 	 * Notification we are starting the processing of a collection fetch
 	 *
 	 * @param collectionFetch The collection fetch
 	 */
 	public void startingCollectionFetch(CollectionFetch collectionFetch);
 
 	/**
 	 * Notification that we are finishing up the processing of a collection fetch
 	 *
 	 * @param collectionFetch The collection fetch
 	 */
 	public void finishingCollectionFetch(CollectionFetch collectionFetch);
 
 	/**
 	 * Notification we are starting the processing of a component fetch
 	 *
 	 * @param fetch The composite fetch
 	 */
 	public void startingCompositeFetch(CompositeFetch fetch);
 
 	/**
 	 * Notification that we are finishing up the processing of a composite fetch
 	 *
 	 * @param fetch The composite fetch
 	 */
 	public void finishingCompositeFetch(CompositeFetch fetch);
+
+	/**
+	 * Notification we are starting the processing of a ANY fetch
+	 *
+	 * @param fetch The ANY fetch
+	 */
+	public void startingAnyFetch(AnyFetch fetch);
+
+	/**
+	 * Notification that we are finishing up the processing of a ANY fetch
+	 *
+	 * @param fetch The ANY fetch
+	 */
+	public void finishingAnyFetch(AnyFetch fetch);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/visit/ReturnGraphVisitationStrategyAdapter.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/visit/ReturnGraphVisitationStrategyAdapter.java
index 1432cc955d..d6f57a2ac6 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/visit/ReturnGraphVisitationStrategyAdapter.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/visit/ReturnGraphVisitationStrategyAdapter.java
@@ -1,92 +1,101 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi.visit;
 
+import org.hibernate.loader.plan.spi.AnyFetch;
 import org.hibernate.loader.plan.spi.CollectionFetch;
 import org.hibernate.loader.plan.spi.CollectionReturn;
 import org.hibernate.loader.plan.spi.CompositeFetch;
 import org.hibernate.loader.plan.spi.EntityFetch;
 import org.hibernate.loader.plan.spi.EntityReturn;
 import org.hibernate.loader.plan.spi.FetchOwner;
 import org.hibernate.loader.plan.spi.Return;
 import org.hibernate.loader.plan.spi.ScalarReturn;
 
 /**
  * @author Steve Ebersole
  */
 public class ReturnGraphVisitationStrategyAdapter implements ReturnGraphVisitationStrategy {
 	public static final ReturnGraphVisitationStrategyAdapter INSTANCE = new ReturnGraphVisitationStrategyAdapter();
 
 	@Override
 	public void startingRootReturn(Return rootReturn) {
 	}
 
 	@Override
 	public void finishingRootReturn(Return rootReturn) {
 	}
 
 	@Override
 	public void handleScalarReturn(ScalarReturn scalarReturn) {
 	}
 
 	@Override
 	public void handleEntityReturn(EntityReturn rootEntityReturn) {
 	}
 
 	@Override
 	public void handleCollectionReturn(CollectionReturn rootCollectionReturn) {
 	}
 
 	@Override
 	public void startingFetches(FetchOwner fetchOwner) {
 	}
 
 	@Override
 	public void finishingFetches(FetchOwner fetchOwner) {
 	}
 
 	@Override
 	public void startingEntityFetch(EntityFetch entityFetch) {
 	}
 
 	@Override
 	public void finishingEntityFetch(EntityFetch entityFetch) {
 	}
 
 	@Override
 	public void startingCollectionFetch(CollectionFetch collectionFetch) {
 	}
 
 	@Override
 	public void finishingCollectionFetch(CollectionFetch collectionFetch) {
 	}
 
 	@Override
 	public void startingCompositeFetch(CompositeFetch fetch) {
 	}
 
 	@Override
 	public void finishingCompositeFetch(CompositeFetch fetch) {
 	}
+
+	@Override
+	public void startingAnyFetch(AnyFetch fetch) {
+	}
+
+	@Override
+	public void finishingAnyFetch(AnyFetch fetch) {
+	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/visit/ReturnGraphVisitor.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/visit/ReturnGraphVisitor.java
index 85036e69f9..e512167c33 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/visit/ReturnGraphVisitor.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/visit/ReturnGraphVisitor.java
@@ -1,128 +1,128 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi.visit;
 
 import java.util.List;
 
 import org.hibernate.loader.plan.spi.CollectionFetch;
 import org.hibernate.loader.plan.spi.CollectionReturn;
 import org.hibernate.loader.plan.spi.CompositeFetch;
 import org.hibernate.loader.plan.spi.EntityFetch;
 import org.hibernate.loader.plan.spi.EntityReturn;
 import org.hibernate.loader.plan.spi.Fetch;
 import org.hibernate.loader.plan.spi.FetchOwner;
 import org.hibernate.loader.plan.spi.Return;
 import org.hibernate.loader.plan.spi.ScalarReturn;
 
 /**
  * @author Steve Ebersole
  */
 public class ReturnGraphVisitor {
 	private final ReturnGraphVisitationStrategy strategy;
 
 	public ReturnGraphVisitor(ReturnGraphVisitationStrategy strategy) {
 		this.strategy = strategy;
 	}
 
 	public void visit(Return... rootReturns) {
 		for ( Return rootReturn : rootReturns ) {
 			visitRootReturn( rootReturn );
 		}
 	}
 
-	public void visit(List<Return> rootReturns) {
+	public void visit(List<? extends Return> rootReturns) {
 		for ( Return rootReturn : rootReturns ) {
 			visitRootReturn( rootReturn );
 		}
 	}
 
 	private void visitRootReturn(Return rootReturn) {
 		strategy.startingRootReturn( rootReturn );
 
 		if ( org.hibernate.loader.plan.spi.ScalarReturn.class.isInstance( rootReturn ) ) {
 			strategy.handleScalarReturn( (ScalarReturn) rootReturn );
 		}
 		else {
 			visitNonScalarRootReturn( rootReturn );
 		}
 
 		strategy.finishingRootReturn( rootReturn );
 	}
 
 	private void visitNonScalarRootReturn(Return rootReturn) {
 		if ( EntityReturn.class.isInstance( rootReturn ) ) {
 			strategy.handleEntityReturn( (EntityReturn) rootReturn );
 			visitFetches( (EntityReturn) rootReturn );
 		}
 		else if ( CollectionReturn.class.isInstance( rootReturn ) ) {
 			strategy.handleCollectionReturn( (CollectionReturn) rootReturn );
 			final CollectionReturn collectionReturn = (CollectionReturn) rootReturn;
 			visitFetches( collectionReturn.getIndexGraph() );
 			visitFetches( collectionReturn.getElementGraph() );
 		}
 		else {
 			throw new IllegalStateException(
 					"Unexpected return type encountered; expecting a non-scalar root return, but found " +
 							rootReturn.getClass().getName()
 			);
 		}
 	}
 
 	private void visitFetches(FetchOwner fetchOwner) {
 		if ( fetchOwner != null ) {
 			strategy.startingFetches( fetchOwner );
 
 			for ( Fetch fetch : fetchOwner.getFetches() ) {
 				visitFetch( fetch );
 			}
 
 			strategy.finishingFetches( fetchOwner );
 		}
 	}
 
 	private void visitFetch(Fetch fetch) {
 		if ( EntityFetch.class.isInstance( fetch ) ) {
 			strategy.startingEntityFetch( (EntityFetch) fetch );
 			visitFetches( (EntityFetch) fetch );
 			strategy.finishingEntityFetch( (EntityFetch) fetch );
 		}
 		else if ( CollectionFetch.class.isInstance( fetch ) ) {
 			strategy.startingCollectionFetch( (CollectionFetch) fetch );
 			visitFetches( ( (CollectionFetch) fetch ).getIndexGraph() );
 			visitFetches( ( (CollectionFetch) fetch ).getElementGraph() );
 			strategy.finishingCollectionFetch( (CollectionFetch) fetch );
 		}
 		else if ( CompositeFetch.class.isInstance( fetch ) ) {
 			strategy.startingCompositeFetch( (CompositeFetch) fetch );
 			visitFetches( (CompositeFetch) fetch );
 			strategy.finishingCompositeFetch( (CompositeFetch) fetch );
 		}
 		else {
 			throw new IllegalStateException(
 					"Unexpected return type encountered; expecting a fetch return, but found " +
 							fetch.getClass().getName()
 			);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/spi/LoadPlanAdvisor.java b/hibernate-core/src/main/java/org/hibernate/loader/spi/LoadPlanAdvisor.java
index e7c0e2c60e..0d3f647d9a 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/spi/LoadPlanAdvisor.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/spi/LoadPlanAdvisor.java
@@ -1,49 +1,49 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.spi;
 
 import org.hibernate.loader.plan.spi.LoadPlan;
 
 /**
- * An advisor that can be made available to the {@link ResultSetProcessor} and {@link ScrollableResultSetProcessor}.
+ * An advisor that can be made available to the {@link org.hibernate.loader.plan.exec.process.spi.ResultSetProcessor} and {@link org.hibernate.loader.plan.exec.process.spi.ScrollableResultSetProcessor}.
  *
  * The processors consult with the advisor, if one is provided, as a means to influence the load plan, meaning that
  * the advisor might add fetches.  A caveat is that any added fetches cannot be join fetches (they cannot alter the
  * SQL); if a fetch is added as {@link org.hibernate.engine.FetchTiming#IMMEDIATE}, it must be a "subsequent form":
  * {@link org.hibernate.engine.FetchStyle#SELECT}, {@link org.hibernate.engine.FetchStyle#SUBSELECT},
  * {@link org.hibernate.engine.FetchStyle#BATCH}.
  *
  * @author Steve Ebersole
  */
 public interface LoadPlanAdvisor {
 	/**
 	 * Advise on the given LoadPlan, returning a new LoadPlan if any additions are needed.  It is the responsibility
 	 * of the advisor to return the original load plan if no additions were needed
 	 *
 	 * @param loadPlan The load plan to advise on.
 	 *
 	 * @return The original or advised load plan.
 	 */
 	public LoadPlan advise(LoadPlan loadPlan);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/spi/ResultSetProcessingContext.java b/hibernate-core/src/main/java/org/hibernate/loader/spi/ResultSetProcessingContext.java
deleted file mode 100644
index ccb12fcc1a..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/loader/spi/ResultSetProcessingContext.java
+++ /dev/null
@@ -1,103 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.loader.spi;
-
-import java.sql.ResultSet;
-import java.sql.SQLException;
-import java.util.Set;
-
-import org.hibernate.LockMode;
-import org.hibernate.engine.spi.EntityKey;
-import org.hibernate.engine.spi.QueryParameters;
-import org.hibernate.engine.spi.SessionImplementor;
-import org.hibernate.loader.EntityAliases;
-import org.hibernate.loader.plan.spi.EntityReference;
-import org.hibernate.persister.entity.EntityPersister;
-import org.hibernate.type.EntityType;
-
-/**
- * @author Steve Ebersole
- */
-public interface ResultSetProcessingContext {
-	public SessionImplementor getSession();
-
-	public QueryParameters getQueryParameters();
-
-	public EntityKey getDictatedRootEntityKey();
-
-	public static interface IdentifierResolutionContext {
-		public EntityReference getEntityReference();
-
-		public void registerHydratedForm(Object hydratedForm);
-
-		public Object getHydratedForm();
-
-		public void registerEntityKey(EntityKey entityKey);
-
-		public EntityKey getEntityKey();
-	}
-
-	public IdentifierResolutionContext getIdentifierResolutionContext(EntityReference entityReference);
-
-	public Set<IdentifierResolutionContext> getIdentifierResolutionContexts();
-
-	public LoadQueryAliasResolutionContext getLoadQueryAliasResolutionContext();
-
-	public void registerHydratedEntity(EntityPersister persister, EntityKey entityKey, Object entityInstance);
-
-	public static interface EntityKeyResolutionContext {
-		public EntityPersister getEntityPersister();
-		public LockMode getLockMode();
-		public EntityReference getEntityReference();
-	}
-
-	public Object resolveEntityKey(EntityKey entityKey, EntityKeyResolutionContext entityKeyContext);
-
-
-	// should be able to get rid of the methods below here from the interface ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-	public void checkVersion(
-			ResultSet resultSet,
-			EntityPersister persister,
-			EntityAliases entityAliases,
-			EntityKey entityKey,
-			Object entityInstance) throws SQLException;
-
-	public String getConcreteEntityTypeName(
-			ResultSet resultSet,
-			EntityPersister persister,
-			EntityAliases entityAliases,
-			EntityKey entityKey) throws SQLException;
-
-	public void loadFromResultSet(
-			ResultSet resultSet,
-			Object entityInstance,
-			String concreteEntityTypeName,
-			EntityKey entityKey,
-			EntityAliases entityAliases,
-			LockMode acquiredLockMode,
-			EntityPersister persister,
-			boolean eagerFetch,
-			EntityType associationType) throws SQLException;
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java
index 990a2a21fc..732058a398 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java
@@ -1,2066 +1,2084 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.collection;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Map;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.FetchMode;
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.TransientObjectException;
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
 import org.hibernate.cache.spi.entry.CacheEntryStructure;
 import org.hibernate.cache.spi.entry.StructuredCollectionCacheEntry;
 import org.hibernate.cache.spi.entry.StructuredMapCacheEntry;
 import org.hibernate.cache.spi.entry.UnstructuredCacheEntry;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.NotYetImplementedException;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.batch.internal.BasicBatchKey;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.SubselectFetch;
 import org.hibernate.exception.spi.SQLExceptionConverter;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.FilterAliasGenerator;
 import org.hibernate.internal.FilterHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.jdbc.Expectation;
 import org.hibernate.jdbc.Expectations;
 import org.hibernate.loader.collection.CollectionInitializer;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Formula;
 import org.hibernate.mapping.IdentifierCollection;
 import org.hibernate.mapping.IndexedCollection;
 import org.hibernate.mapping.List;
 import org.hibernate.mapping.Selectable;
 import org.hibernate.mapping.Table;
 import org.hibernate.metadata.CollectionMetadata;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.PropertyMapping;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.persister.walking.internal.CompositionSingularSubAttributesHelper;
+import org.hibernate.persister.walking.internal.StandardAnyTypeDefinition;
+import org.hibernate.persister.walking.spi.AnyMappingDefinition;
 import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.persister.walking.spi.AttributeSource;
 import org.hibernate.persister.walking.spi.CollectionDefinition;
 import org.hibernate.persister.walking.spi.CollectionElementDefinition;
 import org.hibernate.persister.walking.spi.CollectionIndexDefinition;
 import org.hibernate.persister.walking.spi.CompositeCollectionElementDefinition;
 import org.hibernate.persister.walking.spi.CompositionDefinition;
 import org.hibernate.persister.walking.spi.EntityDefinition;
+import org.hibernate.persister.walking.spi.WalkingException;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.sql.Alias;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.sql.SimpleSelect;
 import org.hibernate.sql.Template;
 import org.hibernate.sql.ordering.antlr.ColumnMapper;
 import org.hibernate.sql.ordering.antlr.ColumnReference;
 import org.hibernate.sql.ordering.antlr.FormulaReference;
 import org.hibernate.sql.ordering.antlr.OrderByAliasResolver;
 import org.hibernate.sql.ordering.antlr.OrderByTranslation;
 import org.hibernate.sql.ordering.antlr.SqlValueReference;
+import org.hibernate.type.AnyType;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * Base implementation of the <tt>QueryableCollection</tt> interface.
  *
  * @author Gavin King
  * @see BasicCollectionPersister
  * @see OneToManyPersister
  */
 public abstract class AbstractCollectionPersister
 		implements CollectionMetadata, SQLLoadableCollection {
 
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger( CoreMessageLogger.class,
 			AbstractCollectionPersister.class.getName() );
 
 	// TODO: encapsulate the protected instance variables!
 
 	private final String role;
 
 	// SQL statements
 	private final String sqlDeleteString;
 	private final String sqlInsertRowString;
 	private final String sqlUpdateRowString;
 	private final String sqlDeleteRowString;
 	private final String sqlSelectSizeString;
 	private final String sqlSelectRowByIndexString;
 	private final String sqlDetectRowByIndexString;
 	private final String sqlDetectRowByElementString;
 
 	protected final boolean hasWhere;
 	protected final String sqlWhereString;
 	private final String sqlWhereStringTemplate;
 
 	private final boolean hasOrder;
 	private final OrderByTranslation orderByTranslation;
 
 	private final boolean hasManyToManyOrder;
 	private final OrderByTranslation manyToManyOrderByTranslation;
 
 	private final int baseIndex;
 
 	private final String nodeName;
 	private final String elementNodeName;
 	private final String indexNodeName;
 	private String mappedByProperty;
 
 	protected final boolean indexContainsFormula;
 	protected final boolean elementIsPureFormula;
 
 	// types
 	private final Type keyType;
 	private final Type indexType;
 	protected final Type elementType;
 	private final Type identifierType;
 
 	// columns
 	protected final String[] keyColumnNames;
 	protected final String[] indexColumnNames;
 	protected final String[] indexFormulaTemplates;
 	protected final String[] indexFormulas;
 	protected final boolean[] indexColumnIsSettable;
 	protected final String[] elementColumnNames;
 	protected final String[] elementColumnWriters;
 	protected final String[] elementColumnReaders;
 	protected final String[] elementColumnReaderTemplates;
 	protected final String[] elementFormulaTemplates;
 	protected final String[] elementFormulas;
 	protected final boolean[] elementColumnIsSettable;
 	protected final boolean[] elementColumnIsInPrimaryKey;
 	protected final String[] indexColumnAliases;
 	protected final String[] elementColumnAliases;
 	protected final String[] keyColumnAliases;
 
 	protected final String identifierColumnName;
 	private final String identifierColumnAlias;
 	// private final String unquotedIdentifierColumnName;
 
 	protected final String qualifiedTableName;
 
 	private final String queryLoaderName;
 
 	private final boolean isPrimitiveArray;
 	private final boolean isArray;
 	protected final boolean hasIndex;
 	protected final boolean hasIdentifier;
 	private final boolean isLazy;
 	private final boolean isExtraLazy;
 	protected final boolean isInverse;
 	private final boolean isMutable;
 	private final boolean isVersioned;
 	protected final int batchSize;
 	private final FetchMode fetchMode;
 	private final boolean hasOrphanDelete;
 	private final boolean subselectLoadable;
 
 	// extra information about the element type
 	private final Class elementClass;
 	private final String entityName;
 
 	private final Dialect dialect;
 	protected final SqlExceptionHelper sqlExceptionHelper;
 	private final SessionFactoryImplementor factory;
 	private final EntityPersister ownerPersister;
 	private final IdentifierGenerator identifierGenerator;
 	private final PropertyMapping elementPropertyMapping;
 	private final EntityPersister elementPersister;
 	private final CollectionRegionAccessStrategy cacheAccessStrategy;
 	private final CollectionType collectionType;
 	private CollectionInitializer initializer;
 
 	private final CacheEntryStructure cacheEntryStructure;
 
 	// dynamic filters for the collection
 	private final FilterHelper filterHelper;
 
 	// dynamic filters specifically for many-to-many inside the collection
 	private final FilterHelper manyToManyFilterHelper;
 
 	private final String manyToManyWhereString;
 	private final String manyToManyWhereTemplate;
 
 	// custom sql
 	private final boolean insertCallable;
 	private final boolean updateCallable;
 	private final boolean deleteCallable;
 	private final boolean deleteAllCallable;
 	private ExecuteUpdateResultCheckStyle insertCheckStyle;
 	private ExecuteUpdateResultCheckStyle updateCheckStyle;
 	private ExecuteUpdateResultCheckStyle deleteCheckStyle;
 	private ExecuteUpdateResultCheckStyle deleteAllCheckStyle;
 
 	private final Serializable[] spaces;
 
 	private Map collectionPropertyColumnAliases = new HashMap();
 	private Map collectionPropertyColumnNames = new HashMap();
 
 	public AbstractCollectionPersister(
 			final Collection collection,
 			final CollectionRegionAccessStrategy cacheAccessStrategy,
 			final Configuration cfg,
 			final SessionFactoryImplementor factory) throws MappingException, CacheException {
 
 		this.factory = factory;
 		this.cacheAccessStrategy = cacheAccessStrategy;
 		if ( factory.getSettings().isStructuredCacheEntriesEnabled() ) {
 			cacheEntryStructure = collection.isMap()
 					? StructuredMapCacheEntry.INSTANCE
 					: StructuredCollectionCacheEntry.INSTANCE;
 		}
 		else {
 			cacheEntryStructure = UnstructuredCacheEntry.INSTANCE;
 		}
 
 		dialect = factory.getDialect();
 		sqlExceptionHelper = factory.getSQLExceptionHelper();
 		collectionType = collection.getCollectionType();
 		role = collection.getRole();
 		entityName = collection.getOwnerEntityName();
 		ownerPersister = factory.getEntityPersister( entityName );
 		queryLoaderName = collection.getLoaderName();
 		nodeName = collection.getNodeName();
 		isMutable = collection.isMutable();
 		mappedByProperty = collection.getMappedByProperty();
 
 		Table table = collection.getCollectionTable();
 		fetchMode = collection.getElement().getFetchMode();
 		elementType = collection.getElement().getType();
 		// isSet = collection.isSet();
 		// isSorted = collection.isSorted();
 		isPrimitiveArray = collection.isPrimitiveArray();
 		isArray = collection.isArray();
 		subselectLoadable = collection.isSubselectLoadable();
 
 		qualifiedTableName = table.getQualifiedName(
 				dialect,
 				factory.getSettings().getDefaultCatalogName(),
 				factory.getSettings().getDefaultSchemaName()
 				);
 
 		int spacesSize = 1 + collection.getSynchronizedTables().size();
 		spaces = new String[spacesSize];
 		spaces[0] = qualifiedTableName;
 		Iterator iter = collection.getSynchronizedTables().iterator();
 		for ( int i = 1; i < spacesSize; i++ ) {
 			spaces[i] = (String) iter.next();
 		}
 
 		sqlWhereString = StringHelper.isNotEmpty( collection.getWhere() ) ? "( " + collection.getWhere() + ") " : null;
 		hasWhere = sqlWhereString != null;
 		sqlWhereStringTemplate = hasWhere ?
 				Template.renderWhereStringTemplate( sqlWhereString, dialect, factory.getSqlFunctionRegistry() ) :
 				null;
 
 		hasOrphanDelete = collection.hasOrphanDelete();
 
 		int batch = collection.getBatchSize();
 		if ( batch == -1 ) {
 			batch = factory.getSettings().getDefaultBatchFetchSize();
 		}
 		batchSize = batch;
 
 		isVersioned = collection.isOptimisticLocked();
 
 		// KEY
 
 		keyType = collection.getKey().getType();
 		iter = collection.getKey().getColumnIterator();
 		int keySpan = collection.getKey().getColumnSpan();
 		keyColumnNames = new String[keySpan];
 		keyColumnAliases = new String[keySpan];
 		int k = 0;
 		while ( iter.hasNext() ) {
 			// NativeSQL: collect key column and auto-aliases
 			Column col = ( (Column) iter.next() );
 			keyColumnNames[k] = col.getQuotedName( dialect );
 			keyColumnAliases[k] = col.getAlias( dialect, collection.getOwner().getRootTable() );
 			k++;
 		}
 
 		// unquotedKeyColumnNames = StringHelper.unQuote(keyColumnAliases);
 
 		// ELEMENT
 
 		String elemNode = collection.getElementNodeName();
 		if ( elementType.isEntityType() ) {
 			String entityName = ( (EntityType) elementType ).getAssociatedEntityName();
 			elementPersister = factory.getEntityPersister( entityName );
 			if ( elemNode == null ) {
 				elemNode = cfg.getClassMapping( entityName ).getNodeName();
 			}
 			// NativeSQL: collect element column and auto-aliases
 
 		}
 		else {
 			elementPersister = null;
 		}
 		elementNodeName = elemNode;
 
 		int elementSpan = collection.getElement().getColumnSpan();
 		elementColumnAliases = new String[elementSpan];
 		elementColumnNames = new String[elementSpan];
 		elementColumnWriters = new String[elementSpan];
 		elementColumnReaders = new String[elementSpan];
 		elementColumnReaderTemplates = new String[elementSpan];
 		elementFormulaTemplates = new String[elementSpan];
 		elementFormulas = new String[elementSpan];
 		elementColumnIsSettable = new boolean[elementSpan];
 		elementColumnIsInPrimaryKey = new boolean[elementSpan];
 		boolean isPureFormula = true;
 		boolean hasNotNullableColumns = false;
 		int j = 0;
 		iter = collection.getElement().getColumnIterator();
 		while ( iter.hasNext() ) {
 			Selectable selectable = (Selectable) iter.next();
 			elementColumnAliases[j] = selectable.getAlias( dialect, table );
 			if ( selectable.isFormula() ) {
 				Formula form = (Formula) selectable;
 				elementFormulaTemplates[j] = form.getTemplate( dialect, factory.getSqlFunctionRegistry() );
 				elementFormulas[j] = form.getFormula();
 			}
 			else {
 				Column col = (Column) selectable;
 				elementColumnNames[j] = col.getQuotedName( dialect );
 				elementColumnWriters[j] = col.getWriteExpr();
 				elementColumnReaders[j] = col.getReadExpr( dialect );
 				elementColumnReaderTemplates[j] = col.getTemplate( dialect, factory.getSqlFunctionRegistry() );
 				elementColumnIsSettable[j] = true;
 				elementColumnIsInPrimaryKey[j] = !col.isNullable();
 				if ( !col.isNullable() ) {
 					hasNotNullableColumns = true;
 				}
 				isPureFormula = false;
 			}
 			j++;
 		}
 		elementIsPureFormula = isPureFormula;
 
 		// workaround, for backward compatibility of sets with no
 		// not-null columns, assume all columns are used in the
 		// row locator SQL
 		if ( !hasNotNullableColumns ) {
 			Arrays.fill( elementColumnIsInPrimaryKey, true );
 		}
 
 		// INDEX AND ROW SELECT
 
 		hasIndex = collection.isIndexed();
 		if ( hasIndex ) {
 			// NativeSQL: collect index column and auto-aliases
 			IndexedCollection indexedCollection = (IndexedCollection) collection;
 			indexType = indexedCollection.getIndex().getType();
 			int indexSpan = indexedCollection.getIndex().getColumnSpan();
 			iter = indexedCollection.getIndex().getColumnIterator();
 			indexColumnNames = new String[indexSpan];
 			indexFormulaTemplates = new String[indexSpan];
 			indexFormulas = new String[indexSpan];
 			indexColumnIsSettable = new boolean[indexSpan];
 			indexColumnAliases = new String[indexSpan];
 			int i = 0;
 			boolean hasFormula = false;
 			while ( iter.hasNext() ) {
 				Selectable s = (Selectable) iter.next();
 				indexColumnAliases[i] = s.getAlias( dialect );
 				if ( s.isFormula() ) {
 					Formula indexForm = (Formula) s;
 					indexFormulaTemplates[i] = indexForm.getTemplate( dialect, factory.getSqlFunctionRegistry() );
 					indexFormulas[i] = indexForm.getFormula();
 					hasFormula = true;
 				}
 				else {
 					Column indexCol = (Column) s;
 					indexColumnNames[i] = indexCol.getQuotedName( dialect );
 					indexColumnIsSettable[i] = true;
 				}
 				i++;
 			}
 			indexContainsFormula = hasFormula;
 			baseIndex = indexedCollection.isList() ?
 					( (List) indexedCollection ).getBaseIndex() : 0;
 
 			indexNodeName = indexedCollection.getIndexNodeName();
 
 		}
 		else {
 			indexContainsFormula = false;
 			indexColumnIsSettable = null;
 			indexFormulaTemplates = null;
 			indexFormulas = null;
 			indexType = null;
 			indexColumnNames = null;
 			indexColumnAliases = null;
 			baseIndex = 0;
 			indexNodeName = null;
 		}
 
 		hasIdentifier = collection.isIdentified();
 		if ( hasIdentifier ) {
 			if ( collection.isOneToMany() ) {
 				throw new MappingException( "one-to-many collections with identifiers are not supported" );
 			}
 			IdentifierCollection idColl = (IdentifierCollection) collection;
 			identifierType = idColl.getIdentifier().getType();
 			iter = idColl.getIdentifier().getColumnIterator();
 			Column col = (Column) iter.next();
 			identifierColumnName = col.getQuotedName( dialect );
 			identifierColumnAlias = col.getAlias( dialect );
 			// unquotedIdentifierColumnName = identifierColumnAlias;
 			identifierGenerator = idColl.getIdentifier().createIdentifierGenerator(
 					cfg.getIdentifierGeneratorFactory(),
 					factory.getDialect(),
 					factory.getSettings().getDefaultCatalogName(),
 					factory.getSettings().getDefaultSchemaName(),
 					null
 					);
 		}
 		else {
 			identifierType = null;
 			identifierColumnName = null;
 			identifierColumnAlias = null;
 			// unquotedIdentifierColumnName = null;
 			identifierGenerator = null;
 		}
 
 		// GENERATE THE SQL:
 
 		// sqlSelectString = sqlSelectString();
 		// sqlSelectRowString = sqlSelectRowString();
 
 		if ( collection.getCustomSQLInsert() == null ) {
 			sqlInsertRowString = generateInsertRowString();
 			insertCallable = false;
 			insertCheckStyle = ExecuteUpdateResultCheckStyle.COUNT;
 		}
 		else {
 			sqlInsertRowString = collection.getCustomSQLInsert();
 			insertCallable = collection.isCustomInsertCallable();
 			insertCheckStyle = collection.getCustomSQLInsertCheckStyle() == null
 					? ExecuteUpdateResultCheckStyle.determineDefault( collection.getCustomSQLInsert(), insertCallable )
 					: collection.getCustomSQLInsertCheckStyle();
 		}
 
 		if ( collection.getCustomSQLUpdate() == null ) {
 			sqlUpdateRowString = generateUpdateRowString();
 			updateCallable = false;
 			updateCheckStyle = ExecuteUpdateResultCheckStyle.COUNT;
 		}
 		else {
 			sqlUpdateRowString = collection.getCustomSQLUpdate();
 			updateCallable = collection.isCustomUpdateCallable();
 			updateCheckStyle = collection.getCustomSQLUpdateCheckStyle() == null
 					? ExecuteUpdateResultCheckStyle.determineDefault( collection.getCustomSQLUpdate(), insertCallable )
 					: collection.getCustomSQLUpdateCheckStyle();
 		}
 
 		if ( collection.getCustomSQLDelete() == null ) {
 			sqlDeleteRowString = generateDeleteRowString();
 			deleteCallable = false;
 			deleteCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 		else {
 			sqlDeleteRowString = collection.getCustomSQLDelete();
 			deleteCallable = collection.isCustomDeleteCallable();
 			deleteCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 
 		if ( collection.getCustomSQLDeleteAll() == null ) {
 			sqlDeleteString = generateDeleteString();
 			deleteAllCallable = false;
 			deleteAllCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 		else {
 			sqlDeleteString = collection.getCustomSQLDeleteAll();
 			deleteAllCallable = collection.isCustomDeleteAllCallable();
 			deleteAllCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 
 		sqlSelectSizeString = generateSelectSizeString( collection.isIndexed() && !collection.isMap() );
 		sqlDetectRowByIndexString = generateDetectRowByIndexString();
 		sqlDetectRowByElementString = generateDetectRowByElementString();
 		sqlSelectRowByIndexString = generateSelectRowByIndexString();
 
 		logStaticSQL();
 
 		isLazy = collection.isLazy();
 		isExtraLazy = collection.isExtraLazy();
 
 		isInverse = collection.isInverse();
 
 		if ( collection.isArray() ) {
 			elementClass = ( (org.hibernate.mapping.Array) collection ).getElementClass();
 		}
 		else {
 			// for non-arrays, we don't need to know the element class
 			elementClass = null; // elementType.returnedClass();
 		}
 
 		if ( elementType.isComponentType() ) {
 			elementPropertyMapping = new CompositeElementPropertyMapping(
 					elementColumnNames,
 					elementColumnReaders,
 					elementColumnReaderTemplates,
 					elementFormulaTemplates,
 					(CompositeType) elementType,
 					factory
 					);
 		}
 		else if ( !elementType.isEntityType() ) {
 			elementPropertyMapping = new ElementPropertyMapping(
 					elementColumnNames,
 					elementType
 					);
 		}
 		else {
 			if ( elementPersister instanceof PropertyMapping ) { // not all classpersisters implement PropertyMapping!
 				elementPropertyMapping = (PropertyMapping) elementPersister;
 			}
 			else {
 				elementPropertyMapping = new ElementPropertyMapping(
 						elementColumnNames,
 						elementType
 						);
 			}
 		}
 
 		hasOrder = collection.getOrderBy() != null;
 		if ( hasOrder ) {
 			orderByTranslation = Template.translateOrderBy(
 					collection.getOrderBy(),
 					new ColumnMapperImpl(),
 					factory,
 					dialect,
 					factory.getSqlFunctionRegistry()
 			);
 		}
 		else {
 			orderByTranslation = null;
 		}
 
 		// Handle any filters applied to this collection
 		filterHelper = new FilterHelper( collection.getFilters(), factory);
 
 		// Handle any filters applied to this collection for many-to-many
 		manyToManyFilterHelper = new FilterHelper( collection.getManyToManyFilters(), factory);
 		manyToManyWhereString = StringHelper.isNotEmpty( collection.getManyToManyWhere() ) ?
 				"( " + collection.getManyToManyWhere() + ")" :
 				null;
 		manyToManyWhereTemplate = manyToManyWhereString == null ?
 				null :
 				Template.renderWhereStringTemplate( manyToManyWhereString, factory.getDialect(), factory.getSqlFunctionRegistry() );
 
 		hasManyToManyOrder = collection.getManyToManyOrdering() != null;
 		if ( hasManyToManyOrder ) {
 			manyToManyOrderByTranslation = Template.translateOrderBy(
 					collection.getManyToManyOrdering(),
 					new ColumnMapperImpl(),
 					factory,
 					dialect,
 					factory.getSqlFunctionRegistry()
 			);
 		}
 		else {
 			manyToManyOrderByTranslation = null;
 		}
 
 		initCollectionPropertyMap();
 	}
 
 	private class ColumnMapperImpl implements ColumnMapper {
 		@Override
 		public SqlValueReference[] map(String reference) {
 			final String[] columnNames;
 			final String[] formulaTemplates;
 
 			// handle the special "$element$" property name...
 			if ( "$element$".equals( reference ) ) {
 				columnNames = elementColumnNames;
 				formulaTemplates = elementFormulaTemplates;
 			}
 			else {
 				columnNames = elementPropertyMapping.toColumns( reference );
 				formulaTemplates = formulaTemplates( reference, columnNames.length );
 			}
 
 			final SqlValueReference[] result = new SqlValueReference[ columnNames.length ];
 			int i = 0;
 			for ( final String columnName : columnNames ) {
 				if ( columnName == null ) {
 					// if the column name is null, it indicates that this index in the property value mapping is
 					// actually represented by a formula.
 //					final int propertyIndex = elementPersister.getEntityMetamodel().getPropertyIndex( reference );
 					final String formulaTemplate = formulaTemplates[i];
 					result[i] = new FormulaReference() {
 						@Override
 						public String getFormulaFragment() {
 							return formulaTemplate;
 						}
 					};
 				}
 				else {
 					result[i] = new ColumnReference() {
 						@Override
 						public String getColumnName() {
 							return columnName;
 						}
 					};
 				}
 				i++;
 			}
 			return result;
 		}
 	}
 
 	private String[] formulaTemplates(String reference, int expectedSize) {
 		try {
 			final int propertyIndex = elementPersister.getEntityMetamodel().getPropertyIndex( reference );
 			return  ( (Queryable) elementPersister ).getSubclassPropertyFormulaTemplateClosure()[propertyIndex];
 		}
 		catch (Exception e) {
 			return new String[expectedSize];
 		}
 	}
 
 	public void postInstantiate() throws MappingException {
 		initializer = queryLoaderName == null ?
 				createCollectionInitializer( LoadQueryInfluencers.NONE ) :
 				new NamedQueryCollectionInitializer( queryLoaderName, this );
 	}
 
 	protected void logStaticSQL() {
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "Static SQL for collection: %s", getRole() );
 			if ( getSQLInsertRowString() != null ) LOG.debugf( " Row insert: %s", getSQLInsertRowString() );
 			if ( getSQLUpdateRowString() != null ) LOG.debugf( " Row update: %s", getSQLUpdateRowString() );
 			if ( getSQLDeleteRowString() != null ) LOG.debugf( " Row delete: %s", getSQLDeleteRowString() );
 			if ( getSQLDeleteString() != null ) LOG.debugf( " One-shot delete: %s", getSQLDeleteString() );
 		}
 	}
 
 	public void initialize(Serializable key, SessionImplementor session) throws HibernateException {
 		getAppropriateInitializer( key, session ).initialize( key, session );
 	}
 
 	protected CollectionInitializer getAppropriateInitializer(Serializable key, SessionImplementor session) {
 		if ( queryLoaderName != null ) {
 			// if there is a user-specified loader, return that
 			// TODO: filters!?
 			return initializer;
 		}
 		CollectionInitializer subselectInitializer = getSubselectInitializer( key, session );
 		if ( subselectInitializer != null ) {
 			return subselectInitializer;
 		}
 		else if ( session.getEnabledFilters().isEmpty() ) {
 			return initializer;
 		}
 		else {
 			return createCollectionInitializer( session.getLoadQueryInfluencers() );
 		}
 	}
 
 	private CollectionInitializer getSubselectInitializer(Serializable key, SessionImplementor session) {
 
 		if ( !isSubselectLoadable() ) {
 			return null;
 		}
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 
 		SubselectFetch subselect = persistenceContext.getBatchFetchQueue()
 				.getSubselect( session.generateEntityKey( key, getOwnerEntityPersister() ) );
 
 		if ( subselect == null ) {
 			return null;
 		}
 		else {
 
 			// Take care of any entities that might have
 			// been evicted!
 			Iterator iter = subselect.getResult().iterator();
 			while ( iter.hasNext() ) {
 				if ( !persistenceContext.containsEntity( (EntityKey) iter.next() ) ) {
 					iter.remove();
 				}
 			}
 
 			// Run a subquery loader
 			return createSubselectInitializer( subselect, session );
 		}
 	}
 
 	protected abstract CollectionInitializer createSubselectInitializer(SubselectFetch subselect, SessionImplementor session);
 
 	protected abstract CollectionInitializer createCollectionInitializer(LoadQueryInfluencers loadQueryInfluencers)
 			throws MappingException;
 
 	public CollectionRegionAccessStrategy getCacheAccessStrategy() {
 		return cacheAccessStrategy;
 	}
 
 	public boolean hasCache() {
 		return cacheAccessStrategy != null;
 	}
 
 	public CollectionType getCollectionType() {
 		return collectionType;
 	}
 
 	protected String getSQLWhereString(String alias) {
 		return StringHelper.replace( sqlWhereStringTemplate, Template.TEMPLATE, alias );
 	}
 
 	public String getSQLOrderByString(String alias) {
 		return hasOrdering()
 				? orderByTranslation.injectAliases( new StandardOrderByAliasResolver( alias ) )
 				: "";
 	}
 
 	public String getManyToManyOrderByString(String alias) {
 		return hasManyToManyOrdering()
 				? manyToManyOrderByTranslation.injectAliases( new StandardOrderByAliasResolver( alias ) )
 				: "";
 	}
 
 	public FetchMode getFetchMode() {
 		return fetchMode;
 	}
 
 	public boolean hasOrdering() {
 		return hasOrder;
 	}
 
 	public boolean hasManyToManyOrdering() {
 		return isManyToMany() && hasManyToManyOrder;
 	}
 
 	public boolean hasWhere() {
 		return hasWhere;
 	}
 
 	protected String getSQLDeleteString() {
 		return sqlDeleteString;
 	}
 
 	protected String getSQLInsertRowString() {
 		return sqlInsertRowString;
 	}
 
 	protected String getSQLUpdateRowString() {
 		return sqlUpdateRowString;
 	}
 
 	protected String getSQLDeleteRowString() {
 		return sqlDeleteRowString;
 	}
 
 	public Type getKeyType() {
 		return keyType;
 	}
 
 	public Type getIndexType() {
 		return indexType;
 	}
 
 	public Type getElementType() {
 		return elementType;
 	}
 
 	/**
 	 * Return the element class of an array, or null otherwise
 	 */
 	public Class getElementClass() { // needed by arrays
 		return elementClass;
 	}
 
 	public Object readElement(ResultSet rs, Object owner, String[] aliases, SessionImplementor session)
 			throws HibernateException, SQLException {
 		return getElementType().nullSafeGet( rs, aliases, session, owner );
 	}
 
 	public Object readIndex(ResultSet rs, String[] aliases, SessionImplementor session)
 			throws HibernateException, SQLException {
 		Object index = getIndexType().nullSafeGet( rs, aliases, session, null );
 		if ( index == null ) {
 			throw new HibernateException( "null index column for collection: " + role );
 		}
 		index = decrementIndexByBase( index );
 		return index;
 	}
 
 	protected Object decrementIndexByBase(Object index) {
 		if ( baseIndex != 0 ) {
             index = (Integer)index - baseIndex;
 		}
 		return index;
 	}
 
 	public Object readIdentifier(ResultSet rs, String alias, SessionImplementor session)
 			throws HibernateException, SQLException {
 		Object id = getIdentifierType().nullSafeGet( rs, alias, session, null );
 		if ( id == null ) {
 			throw new HibernateException( "null identifier column for collection: " + role );
 		}
 		return id;
 	}
 
 	public Object readKey(ResultSet rs, String[] aliases, SessionImplementor session)
 			throws HibernateException, SQLException {
 		return getKeyType().nullSafeGet( rs, aliases, session, null );
 	}
 
 	/**
 	 * Write the key to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeKey(PreparedStatement st, Serializable key, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 
 		if ( key == null ) {
 			throw new NullPointerException( "null key for collection: " + role ); // an assertion
 		}
 		getKeyType().nullSafeSet( st, key, i, session );
 		return i + keyColumnAliases.length;
 	}
 
 	/**
 	 * Write the element to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeElement(PreparedStatement st, Object elt, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		getElementType().nullSafeSet( st, elt, i, elementColumnIsSettable, session );
 		return i + ArrayHelper.countTrue( elementColumnIsSettable );
 
 	}
 
 	/**
 	 * Write the index to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeIndex(PreparedStatement st, Object index, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		getIndexType().nullSafeSet( st, incrementIndexByBase( index ), i, indexColumnIsSettable, session );
 		return i + ArrayHelper.countTrue( indexColumnIsSettable );
 	}
 
 	protected Object incrementIndexByBase(Object index) {
 		if ( baseIndex != 0 ) {
             index = (Integer)index + baseIndex;
 		}
 		return index;
 	}
 
 	/**
 	 * Write the element to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeElementToWhere(PreparedStatement st, Object elt, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		if ( elementIsPureFormula ) {
 			throw new AssertionFailure( "cannot use a formula-based element in the where condition" );
 		}
 		getElementType().nullSafeSet( st, elt, i, elementColumnIsInPrimaryKey, session );
 		return i + elementColumnAliases.length;
 
 	}
 
 	/**
 	 * Write the index to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeIndexToWhere(PreparedStatement st, Object index, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		if ( indexContainsFormula ) {
 			throw new AssertionFailure( "cannot use a formula-based index in the where condition" );
 		}
 		getIndexType().nullSafeSet( st, incrementIndexByBase( index ), i, session );
 		return i + indexColumnAliases.length;
 	}
 
 	/**
 	 * Write the identifier to a JDBC <tt>PreparedStatement</tt>
 	 */
 	public int writeIdentifier(PreparedStatement st, Object id, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 
 		getIdentifierType().nullSafeSet( st, id, i, session );
 		return i + 1;
 	}
 
 	public boolean isPrimitiveArray() {
 		return isPrimitiveArray;
 	}
 
 	public boolean isArray() {
 		return isArray;
 	}
 
 	public String[] getKeyColumnAliases(String suffix) {
 		return new Alias( suffix ).toAliasStrings( keyColumnAliases );
 	}
 
 	public String[] getElementColumnAliases(String suffix) {
 		return new Alias( suffix ).toAliasStrings( elementColumnAliases );
 	}
 
 	public String[] getIndexColumnAliases(String suffix) {
 		if ( hasIndex ) {
 			return new Alias( suffix ).toAliasStrings( indexColumnAliases );
 		}
 		else {
 			return null;
 		}
 	}
 
 	public String getIdentifierColumnAlias(String suffix) {
 		if ( hasIdentifier ) {
 			return new Alias( suffix ).toAliasString( identifierColumnAlias );
 		}
 		else {
 			return null;
 		}
 	}
 
 	public String getIdentifierColumnName() {
 		if ( hasIdentifier ) {
 			return identifierColumnName;
 		}
 		else {
 			return null;
 		}
 	}
 
 	/**
 	 * Generate a list of collection index, key and element columns
 	 */
 	public String selectFragment(String alias, String columnSuffix) {
 		SelectFragment frag = generateSelectFragment( alias, columnSuffix );
 		appendElementColumns( frag, alias );
 		appendIndexColumns( frag, alias );
 		appendIdentifierColumns( frag, alias );
 
 		return frag.toFragmentString()
 				.substring( 2 ); // strip leading ','
 	}
 
 	protected String generateSelectSizeString(boolean isIntegerIndexed) {
 		String selectValue = isIntegerIndexed ?
 				"max(" + getIndexColumnNames()[0] + ") + 1" : // lists, arrays
 				"count(" + getElementColumnNames()[0] + ")"; // sets, maps, bags
 		return new SimpleSelect( dialect )
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addColumn( selectValue )
 				.toStatementString();
 	}
 
 	protected String generateDetectRowByIndexString() {
 		if ( !hasIndex() ) {
 			return null;
 		}
 		return new SimpleSelect( dialect )
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addCondition( getIndexColumnNames(), "=?" )
 				.addCondition( indexFormulas, "=?" )
 				.addColumn( "1" )
 				.toStatementString();
 	}
 
 	protected String generateSelectRowByIndexString() {
 		if ( !hasIndex() ) {
 			return null;
 		}
 		return new SimpleSelect( dialect )
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addCondition( getIndexColumnNames(), "=?" )
 				.addCondition( indexFormulas, "=?" )
 				.addColumns( getElementColumnNames(), elementColumnAliases )
 				.addColumns( indexFormulas, indexColumnAliases )
 				.toStatementString();
 	}
 
 	protected String generateDetectRowByElementString() {
 		return new SimpleSelect( dialect )
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addCondition( getElementColumnNames(), "=?" )
 				.addCondition( elementFormulas, "=?" )
 				.addColumn( "1" )
 				.toStatementString();
 	}
 
 	protected SelectFragment generateSelectFragment(String alias, String columnSuffix) {
 		return new SelectFragment()
 				.setSuffix( columnSuffix )
 				.addColumns( alias, keyColumnNames, keyColumnAliases );
 	}
 
 	protected void appendElementColumns(SelectFragment frag, String elemAlias) {
 		for ( int i = 0; i < elementColumnIsSettable.length; i++ ) {
 			if ( elementColumnIsSettable[i] ) {
 				frag.addColumnTemplate( elemAlias, elementColumnReaderTemplates[i], elementColumnAliases[i] );
 			}
 			else {
 				frag.addFormula( elemAlias, elementFormulaTemplates[i], elementColumnAliases[i] );
 			}
 		}
 	}
 
 	protected void appendIndexColumns(SelectFragment frag, String alias) {
 		if ( hasIndex ) {
 			for ( int i = 0; i < indexColumnIsSettable.length; i++ ) {
 				if ( indexColumnIsSettable[i] ) {
 					frag.addColumn( alias, indexColumnNames[i], indexColumnAliases[i] );
 				}
 				else {
 					frag.addFormula( alias, indexFormulaTemplates[i], indexColumnAliases[i] );
 				}
 			}
 		}
 	}
 
 	protected void appendIdentifierColumns(SelectFragment frag, String alias) {
 		if ( hasIdentifier ) {
 			frag.addColumn( alias, identifierColumnName, identifierColumnAlias );
 		}
 	}
 
 	public String[] getIndexColumnNames() {
 		return indexColumnNames;
 	}
 
 	public String[] getIndexFormulas() {
 		return indexFormulas;
 	}
 
 	public String[] getIndexColumnNames(String alias) {
 		return qualify( alias, indexColumnNames, indexFormulaTemplates );
 
 	}
 
 	public String[] getElementColumnNames(String alias) {
 		return qualify( alias, elementColumnNames, elementFormulaTemplates );
 	}
 
 	private static String[] qualify(String alias, String[] columnNames, String[] formulaTemplates) {
 		int span = columnNames.length;
 		String[] result = new String[span];
 		for ( int i = 0; i < span; i++ ) {
 			if ( columnNames[i] == null ) {
 				result[i] = StringHelper.replace( formulaTemplates[i], Template.TEMPLATE, alias );
 			}
 			else {
 				result[i] = StringHelper.qualify( alias, columnNames[i] );
 			}
 		}
 		return result;
 	}
 
 	public String[] getElementColumnNames() {
 		return elementColumnNames; // TODO: something with formulas...
 	}
 
 	public String[] getKeyColumnNames() {
 		return keyColumnNames;
 	}
 
 	public boolean hasIndex() {
 		return hasIndex;
 	}
 
 	public boolean isLazy() {
 		return isLazy;
 	}
 
 	public boolean isInverse() {
 		return isInverse;
 	}
 
 	public String getTableName() {
 		return qualifiedTableName;
 	}
 
 	private BasicBatchKey removeBatchKey;
 
 	public void remove(Serializable id, SessionImplementor session) throws HibernateException {
 		if ( !isInverse && isRowDeleteEnabled() ) {
 
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf( "Deleting collection: %s",
 						MessageHelper.collectionInfoString( this, id, getFactory() ) );
 			}
 
 			// Remove all the old entries
 
 			try {
 				int offset = 1;
 				PreparedStatement st = null;
 				Expectation expectation = Expectations.appropriateExpectation( getDeleteAllCheckStyle() );
 				boolean callable = isDeleteAllCallable();
 				boolean useBatch = expectation.canBeBatched();
 				String sql = getSQLDeleteString();
 				if ( useBatch ) {
 					if ( removeBatchKey == null ) {
 						removeBatchKey = new BasicBatchKey(
 								getRole() + "#REMOVE",
 								expectation
 								);
 					}
 					st = session.getTransactionCoordinator()
 							.getJdbcCoordinator()
 							.getBatch( removeBatchKey )
 							.getBatchStatement( sql, callable );
 				}
 				else {
 					st = session.getTransactionCoordinator()
 							.getJdbcCoordinator()
 							.getStatementPreparer()
 							.prepareStatement( sql, callable );
 				}
 
 				try {
 					offset += expectation.prepare( st );
 
 					writeKey( st, id, offset, session );
 					if ( useBatch ) {
 						session.getTransactionCoordinator()
 								.getJdbcCoordinator()
 								.getBatch( removeBatchKey )
 								.addToBatch();
 					}
 					else {
 						expectation.verifyOutcome( session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 					}
 				}
 				catch ( SQLException sqle ) {
 					if ( useBatch ) {
 						session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
 					}
 					throw sqle;
 				}
 				finally {
 					if ( !useBatch ) {
 						session.getTransactionCoordinator().getJdbcCoordinator().release( st );
 					}
 				}
 
 				LOG.debug( "Done deleting collection" );
 			}
 			catch ( SQLException sqle ) {
 				throw sqlExceptionHelper.convert(
 						sqle,
 						"could not delete collection: " +
 								MessageHelper.collectionInfoString( this, id, getFactory() ),
 						getSQLDeleteString()
 						);
 			}
 
 		}
 
 	}
 
 	protected BasicBatchKey recreateBatchKey;
 
 	public void recreate(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( !isInverse && isRowInsertEnabled() ) {
 
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf( "Inserting collection: %s",
 						MessageHelper.collectionInfoString( this, collection, id, session ) );
 			}
 
 			try {
 				// create all the new entries
 				Iterator entries = collection.entries( this );
 				if ( entries.hasNext() ) {
 					Expectation expectation = Expectations.appropriateExpectation( getInsertCheckStyle() );
 					collection.preInsert( this );
 					int i = 0;
 					int count = 0;
 					while ( entries.hasNext() ) {
 
 						final Object entry = entries.next();
 						if ( collection.entryExists( entry, i ) ) {
 							int offset = 1;
 							PreparedStatement st = null;
 							boolean callable = isInsertCallable();
 							boolean useBatch = expectation.canBeBatched();
 							String sql = getSQLInsertRowString();
 
 							if ( useBatch ) {
 								if ( recreateBatchKey == null ) {
 									recreateBatchKey = new BasicBatchKey(
 											getRole() + "#RECREATE",
 											expectation
 											);
 								}
 								st = session.getTransactionCoordinator()
 										.getJdbcCoordinator()
 										.getBatch( recreateBatchKey )
 										.getBatchStatement( sql, callable );
 							}
 							else {
 								st = session.getTransactionCoordinator()
 										.getJdbcCoordinator()
 										.getStatementPreparer()
 										.prepareStatement( sql, callable );
 							}
 
 							try {
 								offset += expectation.prepare( st );
 
 								// TODO: copy/paste from insertRows()
 								int loc = writeKey( st, id, offset, session );
 								if ( hasIdentifier ) {
 									loc = writeIdentifier( st, collection.getIdentifier( entry, i ), loc, session );
 								}
 								if ( hasIndex /* && !indexIsFormula */) {
 									loc = writeIndex( st, collection.getIndex( entry, i, this ), loc, session );
 								}
 								loc = writeElement( st, collection.getElement( entry ), loc, session );
 
 								if ( useBatch ) {
 									session.getTransactionCoordinator()
 											.getJdbcCoordinator()
 											.getBatch( recreateBatchKey )
 											.addToBatch();
 								}
 								else {
 									expectation.verifyOutcome( session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 								}
 
 								collection.afterRowInsert( this, entry, i );
 								count++;
 							}
 							catch ( SQLException sqle ) {
 								if ( useBatch ) {
 									session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
 								}
 								throw sqle;
 							}
 							finally {
 								if ( !useBatch ) {
 									session.getTransactionCoordinator().getJdbcCoordinator().release( st );
 								}
 							}
 
 						}
 						i++;
 					}
 
 					LOG.debugf( "Done inserting collection: %s rows inserted", count );
 
 				}
 				else {
 					LOG.debug( "Collection was empty" );
 				}
 			}
 			catch ( SQLException sqle ) {
 				throw sqlExceptionHelper.convert(
 						sqle,
 						"could not insert collection: " +
 								MessageHelper.collectionInfoString( this, collection, id, session ),
 						getSQLInsertRowString()
 						);
 			}
 		}
 	}
 
 	protected boolean isRowDeleteEnabled() {
 		return true;
 	}
 
 	private BasicBatchKey deleteBatchKey;
 
 	public void deleteRows(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( !isInverse && isRowDeleteEnabled() ) {
 
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf( "Deleting rows of collection: %s",
 						MessageHelper.collectionInfoString( this, collection, id, session ) );
 			}
 
 			boolean deleteByIndex = !isOneToMany() && hasIndex && !indexContainsFormula;
 			final Expectation expectation = Expectations.appropriateExpectation( getDeleteCheckStyle() );
 			try {
 				// delete all the deleted entries
 				Iterator deletes = collection.getDeletes( this, !deleteByIndex );
 				if ( deletes.hasNext() ) {
 					int offset = 1;
 					int count = 0;
 					while ( deletes.hasNext() ) {
 						PreparedStatement st = null;
 						boolean callable = isDeleteCallable();
 						boolean useBatch = expectation.canBeBatched();
 						String sql = getSQLDeleteRowString();
 
 						if ( useBatch ) {
 							if ( deleteBatchKey == null ) {
 								deleteBatchKey = new BasicBatchKey(
 										getRole() + "#DELETE",
 										expectation
 										);
 							}
 							st = session.getTransactionCoordinator()
 									.getJdbcCoordinator()
 									.getBatch( deleteBatchKey )
 									.getBatchStatement( sql, callable );
 						}
 						else {
 							st = session.getTransactionCoordinator()
 									.getJdbcCoordinator()
 									.getStatementPreparer()
 									.prepareStatement( sql, callable );
 						}
 
 						try {
 							expectation.prepare( st );
 
 							Object entry = deletes.next();
 							int loc = offset;
 							if ( hasIdentifier ) {
 								writeIdentifier( st, entry, loc, session );
 							}
 							else {
 								loc = writeKey( st, id, loc, session );
 								if ( deleteByIndex ) {
 									writeIndexToWhere( st, entry, loc, session );
 								}
 								else {
 									writeElementToWhere( st, entry, loc, session );
 								}
 							}
 
 							if ( useBatch ) {
 								session.getTransactionCoordinator()
 										.getJdbcCoordinator()
 										.getBatch( deleteBatchKey )
 										.addToBatch();
 							}
 							else {
 								expectation.verifyOutcome( session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 							}
 							count++;
 						}
 						catch ( SQLException sqle ) {
 							if ( useBatch ) {
 								session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
 							}
 							throw sqle;
 						}
 						finally {
 							if ( !useBatch ) {
 								session.getTransactionCoordinator().getJdbcCoordinator().release( st );
 							}
 						}
 
 						LOG.debugf( "Done deleting collection rows: %s deleted", count );
 					}
 				}
 				else {
 					LOG.debug( "No rows to delete" );
 				}
 			}
 			catch ( SQLException sqle ) {
 				throw sqlExceptionHelper.convert(
 						sqle,
 						"could not delete collection rows: " +
 								MessageHelper.collectionInfoString( this, collection, id, session ),
 						getSQLDeleteRowString()
 						);
 			}
 		}
 	}
 
 	protected boolean isRowInsertEnabled() {
 		return true;
 	}
 
 	private BasicBatchKey insertBatchKey;
 
 	public void insertRows(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( !isInverse && isRowInsertEnabled() ) {
 
 			if ( LOG.isDebugEnabled() ) LOG.debugf( "Inserting rows of collection: %s",
 					MessageHelper.collectionInfoString( this, collection, id, session ) );
 
 			try {
 				// insert all the new entries
 				collection.preInsert( this );
 				Iterator entries = collection.entries( this );
 				Expectation expectation = Expectations.appropriateExpectation( getInsertCheckStyle() );
 				boolean callable = isInsertCallable();
 				boolean useBatch = expectation.canBeBatched();
 				String sql = getSQLInsertRowString();
 				int i = 0;
 				int count = 0;
 				while ( entries.hasNext() ) {
 					int offset = 1;
 					Object entry = entries.next();
 					PreparedStatement st = null;
 					if ( collection.needsInserting( entry, i, elementType ) ) {
 
 						if ( useBatch ) {
 							if ( insertBatchKey == null ) {
 								insertBatchKey = new BasicBatchKey(
 										getRole() + "#INSERT",
 										expectation
 										);
 							}
 							if ( st == null ) {
 								st = session.getTransactionCoordinator()
 										.getJdbcCoordinator()
 										.getBatch( insertBatchKey )
 										.getBatchStatement( sql, callable );
 							}
 						}
 						else {
 							st = session.getTransactionCoordinator()
 									.getJdbcCoordinator()
 									.getStatementPreparer()
 									.prepareStatement( sql, callable );
 						}
 
 						try {
 							offset += expectation.prepare( st );
 							// TODO: copy/paste from recreate()
 							offset = writeKey( st, id, offset, session );
 							if ( hasIdentifier ) {
 								offset = writeIdentifier( st, collection.getIdentifier( entry, i ), offset, session );
 							}
 							if ( hasIndex /* && !indexIsFormula */) {
 								offset = writeIndex( st, collection.getIndex( entry, i, this ), offset, session );
 							}
 							writeElement( st, collection.getElement( entry ), offset, session );
 
 							if ( useBatch ) {
 								session.getTransactionCoordinator().getJdbcCoordinator().getBatch( insertBatchKey ).addToBatch();
 							}
 							else {
 								expectation.verifyOutcome( session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 							}
 							collection.afterRowInsert( this, entry, i );
 							count++;
 						}
 						catch ( SQLException sqle ) {
 							if ( useBatch ) {
 								session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
 							}
 							throw sqle;
 						}
 						finally {
 							if ( !useBatch ) {
 								session.getTransactionCoordinator().getJdbcCoordinator().release( st );
 							}
 						}
 					}
 					i++;
 				}
 				LOG.debugf( "Done inserting rows: %s inserted", count );
 			}
 			catch ( SQLException sqle ) {
 				throw sqlExceptionHelper.convert(
 						sqle,
 						"could not insert collection rows: " +
 								MessageHelper.collectionInfoString( this, collection, id, session ),
 						getSQLInsertRowString()
 						);
 			}
 
 		}
 	}
 
 	public String getRole() {
 		return role;
 	}
 
 	public String getOwnerEntityName() {
 		return entityName;
 	}
 
 	public EntityPersister getOwnerEntityPersister() {
 		return ownerPersister;
 	}
 
 	public IdentifierGenerator getIdentifierGenerator() {
 		return identifierGenerator;
 	}
 
 	public Type getIdentifierType() {
 		return identifierType;
 	}
 
 	public boolean hasOrphanDelete() {
 		return hasOrphanDelete;
 	}
 
 	public Type toType(String propertyName) throws QueryException {
 		if ( "index".equals( propertyName ) ) {
 			return indexType;
 		}
 		return elementPropertyMapping.toType( propertyName );
 	}
 
 	public abstract boolean isManyToMany();
 
 	public String getManyToManyFilterFragment(String alias, Map enabledFilters) {
 		StringBuilder buffer = new StringBuilder();
 		manyToManyFilterHelper.render( buffer, elementPersister.getFilterAliasGenerator(alias), enabledFilters );
 
 		if ( manyToManyWhereString != null ) {
 			buffer.append( " and " )
 					.append( StringHelper.replace( manyToManyWhereTemplate, Template.TEMPLATE, alias ) );
 		}
 
 		return buffer.toString();
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public String[] toColumns(String alias, String propertyName) throws QueryException {
 		if ( "index".equals( propertyName ) ) {
 			return qualify( alias, indexColumnNames, indexFormulaTemplates );
 		}
 		return elementPropertyMapping.toColumns( alias, propertyName );
 	}
 
 	private String[] indexFragments;
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public String[] toColumns(String propertyName) throws QueryException {
 		if ( "index".equals( propertyName ) ) {
 			if ( indexFragments == null ) {
 				String[] tmp = new String[indexColumnNames.length];
 				for ( int i = 0; i < indexColumnNames.length; i++ ) {
 					tmp[i] = indexColumnNames[i] == null
 							? indexFormulas[i]
 							: indexColumnNames[i];
 					indexFragments = tmp;
 				}
 			}
 			return indexFragments;
 		}
 
 		return elementPropertyMapping.toColumns( propertyName );
 	}
 
 	public Type getType() {
 		return elementPropertyMapping.getType(); // ==elementType ??
 	}
 
 	public String getName() {
 		return getRole();
 	}
 
 	public EntityPersister getElementPersister() {
 		if ( elementPersister == null ) {
 			throw new AssertionFailure( "not an association" );
 		}
 		return elementPersister;
 	}
 
 	public boolean isCollection() {
 		return true;
 	}
 
 	public Serializable[] getCollectionSpaces() {
 		return spaces;
 	}
 
 	protected abstract String generateDeleteString();
 
 	protected abstract String generateDeleteRowString();
 
 	protected abstract String generateUpdateRowString();
 
 	protected abstract String generateInsertRowString();
 
 	public void updateRows(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( !isInverse && collection.isRowUpdatePossible() ) {
 
 			LOG.debugf( "Updating rows of collection: %s#%s", role, id );
 
 			// update all the modified entries
 			int count = doUpdateRows( id, collection, session );
 
 			LOG.debugf( "Done updating rows: %s updated", count );
 		}
 	}
 
 	protected abstract int doUpdateRows(Serializable key, PersistentCollection collection, SessionImplementor session)
 			throws HibernateException;
 
 	public void processQueuedOps(PersistentCollection collection, Serializable key, SessionImplementor session)
 			throws HibernateException {
 		if ( collection.hasQueuedOperations() ) {
 			doProcessQueuedOps( collection, key, session );
 		}
 	}
 
 	protected abstract void doProcessQueuedOps(PersistentCollection collection, Serializable key, SessionImplementor session)
 			throws HibernateException;
 
 	public CollectionMetadata getCollectionMetadata() {
 		return this;
 	}
 
 	public SessionFactoryImplementor getFactory() {
 		return factory;
 	}
 
 	protected String filterFragment(String alias) throws MappingException {
 		return hasWhere() ? " and " + getSQLWhereString( alias ) : "";
 	}
 
 	public String filterFragment(String alias, Map enabledFilters) throws MappingException {
 
 		StringBuilder sessionFilterFragment = new StringBuilder();
 		filterHelper.render( sessionFilterFragment, getFilterAliasGenerator(alias), enabledFilters );
 
 		return sessionFilterFragment.append( filterFragment( alias ) ).toString();
 	}
 
 	public String oneToManyFilterFragment(String alias) throws MappingException {
 		return "";
 	}
 
 	protected boolean isInsertCallable() {
 		return insertCallable;
 	}
 
 	protected ExecuteUpdateResultCheckStyle getInsertCheckStyle() {
 		return insertCheckStyle;
 	}
 
 	protected boolean isUpdateCallable() {
 		return updateCallable;
 	}
 
 	protected ExecuteUpdateResultCheckStyle getUpdateCheckStyle() {
 		return updateCheckStyle;
 	}
 
 	protected boolean isDeleteCallable() {
 		return deleteCallable;
 	}
 
 	protected ExecuteUpdateResultCheckStyle getDeleteCheckStyle() {
 		return deleteCheckStyle;
 	}
 
 	protected boolean isDeleteAllCallable() {
 		return deleteAllCallable;
 	}
 
 	protected ExecuteUpdateResultCheckStyle getDeleteAllCheckStyle() {
 		return deleteAllCheckStyle;
 	}
 
 	public String toString() {
 		return StringHelper.unqualify( getClass().getName() ) + '(' + role + ')';
 	}
 
 	public boolean isVersioned() {
 		return isVersioned && getOwnerEntityPersister().isVersioned();
 	}
 
 	public String getNodeName() {
 		return nodeName;
 	}
 
 	public String getElementNodeName() {
 		return elementNodeName;
 	}
 
 	public String getIndexNodeName() {
 		return indexNodeName;
 	}
 
 	// TODO: deprecate???
 	protected SQLExceptionConverter getSQLExceptionConverter() {
 		return getSQLExceptionHelper().getSqlExceptionConverter();
 	}
 
 	// TODO: needed???
 	protected SqlExceptionHelper getSQLExceptionHelper() {
 		return sqlExceptionHelper;
 	}
 
 	public CacheEntryStructure getCacheEntryStructure() {
 		return cacheEntryStructure;
 	}
 
 	public boolean isAffectedByEnabledFilters(SessionImplementor session) {
 		return filterHelper.isAffectedBy( session.getEnabledFilters() ) ||
 				( isManyToMany() && manyToManyFilterHelper.isAffectedBy( session.getEnabledFilters() ) );
 	}
 
 	public boolean isSubselectLoadable() {
 		return subselectLoadable;
 	}
 
 	public boolean isMutable() {
 		return isMutable;
 	}
 
 	public String[] getCollectionPropertyColumnAliases(String propertyName, String suffix) {
 		String rawAliases[] = (String[]) collectionPropertyColumnAliases.get( propertyName );
 
 		if ( rawAliases == null ) {
 			return null;
 		}
 
 		String result[] = new String[rawAliases.length];
 		for ( int i = 0; i < rawAliases.length; i++ ) {
 			result[i] = new Alias( suffix ).toUnquotedAliasString( rawAliases[i] );
 		}
 		return result;
 	}
 
 	// TODO: formulas ?
 	public void initCollectionPropertyMap() {
 
 		initCollectionPropertyMap( "key", keyType, keyColumnAliases, keyColumnNames );
 		initCollectionPropertyMap( "element", elementType, elementColumnAliases, elementColumnNames );
 		if ( hasIndex ) {
 			initCollectionPropertyMap( "index", indexType, indexColumnAliases, indexColumnNames );
 		}
 		if ( hasIdentifier ) {
 			initCollectionPropertyMap(
 					"id",
 					identifierType,
 					new String[] { identifierColumnAlias },
 					new String[] { identifierColumnName } );
 		}
 	}
 
 	private void initCollectionPropertyMap(String aliasName, Type type, String[] columnAliases, String[] columnNames) {
 
 		collectionPropertyColumnAliases.put( aliasName, columnAliases );
 		collectionPropertyColumnNames.put( aliasName, columnNames );
 
 		if ( type.isComponentType() ) {
 			CompositeType ct = (CompositeType) type;
 			String[] propertyNames = ct.getPropertyNames();
 			for ( int i = 0; i < propertyNames.length; i++ ) {
 				String name = propertyNames[i];
 				collectionPropertyColumnAliases.put( aliasName + "." + name, columnAliases[i] );
 				collectionPropertyColumnNames.put( aliasName + "." + name, columnNames[i] );
 			}
 		}
 
 	}
 
 	public int getSize(Serializable key, SessionImplementor session) {
 		try {
 			PreparedStatement st = session.getTransactionCoordinator()
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( sqlSelectSizeString );
 			try {
 				getKeyType().nullSafeSet( st, key, 1, session );
 				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st );
 				try {
 					return rs.next() ? rs.getInt( 1 ) - baseIndex : 0;
 				}
 				finally {
 					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, st );
 				}
 			}
 			finally {
 				session.getTransactionCoordinator().getJdbcCoordinator().release( st );
 			}
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not retrieve collection size: " +
 							MessageHelper.collectionInfoString( this, key, getFactory() ),
 					sqlSelectSizeString
 					);
 		}
 	}
 
 	public boolean indexExists(Serializable key, Object index, SessionImplementor session) {
 		return exists( key, incrementIndexByBase( index ), getIndexType(), sqlDetectRowByIndexString, session );
 	}
 
 	public boolean elementExists(Serializable key, Object element, SessionImplementor session) {
 		return exists( key, element, getElementType(), sqlDetectRowByElementString, session );
 	}
 
 	private boolean exists(Serializable key, Object indexOrElement, Type indexOrElementType, String sql, SessionImplementor session) {
 		try {
 			PreparedStatement st = session.getTransactionCoordinator()
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( sql );
 			try {
 				getKeyType().nullSafeSet( st, key, 1, session );
 				indexOrElementType.nullSafeSet( st, indexOrElement, keyColumnNames.length + 1, session );
 				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st );
 				try {
 					return rs.next();
 				}
 				finally {
 					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, st );
 				}
 			}
 			catch ( TransientObjectException e ) {
 				return false;
 			}
 			finally {
 				session.getTransactionCoordinator().getJdbcCoordinator().release( st );
 			}
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not check row existence: " +
 							MessageHelper.collectionInfoString( this, key, getFactory() ),
 					sqlSelectSizeString
 					);
 		}
 	}
 
 	public Object getElementByIndex(Serializable key, Object index, SessionImplementor session, Object owner) {
 		try {
 			PreparedStatement st = session.getTransactionCoordinator()
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( sqlSelectRowByIndexString );
 			try {
 				getKeyType().nullSafeSet( st, key, 1, session );
 				getIndexType().nullSafeSet( st, incrementIndexByBase( index ), keyColumnNames.length + 1, session );
 				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st );
 				try {
 					if ( rs.next() ) {
 						return getElementType().nullSafeGet( rs, elementColumnAliases, session, owner );
 					}
 					else {
 						return null;
 					}
 				}
 				finally {
 					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, st );
 				}
 			}
 			finally {
 				session.getTransactionCoordinator().getJdbcCoordinator().release( st );
 			}
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not read row: " +
 							MessageHelper.collectionInfoString( this, key, getFactory() ),
 					sqlSelectSizeString
 					);
 		}
 	}
 
 	public boolean isExtraLazy() {
 		return isExtraLazy;
 	}
 
 	protected Dialect getDialect() {
 		return dialect;
 	}
 
 	/**
 	 * Intended for internal use only. In fact really only currently used from
 	 * test suite for assertion purposes.
 	 *
 	 * @return The default collection initializer for this persister/collection.
 	 */
 	public CollectionInitializer getInitializer() {
 		return initializer;
 	}
 
 	public int getBatchSize() {
 		return batchSize;
 	}
 
 	public String getMappedByProperty() {
 		return mappedByProperty;
 	}
 
 	private class StandardOrderByAliasResolver implements OrderByAliasResolver {
 		private final String rootAlias;
 
 		private StandardOrderByAliasResolver(String rootAlias) {
 			this.rootAlias = rootAlias;
 		}
 
 		@Override
 		public String resolveTableAlias(String columnReference) {
 			if ( elementPersister == null ) {
 				// we have collection of non-entity elements...
 				return rootAlias;
 			}
 			else {
 				return ( (Loadable) elementPersister ).getTableAliasForColumn( columnReference, rootAlias );
 			}
 		}
 	}
 
 	public abstract FilterAliasGenerator getFilterAliasGenerator(final String rootAlias);
 
 	// ColectionDefinition impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public CollectionPersister getCollectionPersister() {
 		return this;
 	}
 
 	@Override
 	public CollectionIndexDefinition getIndexDefinition() {
 		if ( ! hasIndex() ) {
 			return null;
 		}
 
 		return new CollectionIndexDefinition() {
 			@Override
 			public CollectionDefinition getCollectionDefinition() {
 				return AbstractCollectionPersister.this;
 			}
 
 			@Override
 			public Type getType() {
 				return getIndexType();
 			}
 
 			@Override
 			public EntityDefinition toEntityDefinition() {
 				if ( getType().isComponentType() ) {
 					throw new IllegalStateException( "Cannot treat composite collection index type as entity" );
 				}
 				return (EntityPersister) ( (AssociationType) getIndexType() ).getAssociatedJoinable( getFactory() );
 			}
 
 			@Override
 			public CompositionDefinition toCompositeDefinition() {
 				if ( ! getType().isComponentType() ) {
 					throw new IllegalStateException( "Cannot treat entity collection index type as composite" );
 				}
 				// todo : implement
 				throw new NotYetImplementedException();
 			}
 		};
 	}
 
 	@Override
 	public CollectionElementDefinition getElementDefinition() {
 		return new CollectionElementDefinition() {
 			@Override
 			public CollectionDefinition getCollectionDefinition() {
 				return AbstractCollectionPersister.this;
 			}
 
 			@Override
 			public Type getType() {
 				return getElementType();
 			}
 
 			@Override
+			public AnyMappingDefinition toAnyMappingDefinition() {
+				final Type type = getType();
+				if ( ! type.isAnyType() ) {
+					throw new WalkingException( "Cannot treat collection element type as ManyToAny" );
+				}
+				return new StandardAnyTypeDefinition( (AnyType) type, isLazy() || isExtraLazy() );
+			}
+
+			@Override
 			public EntityDefinition toEntityDefinition() {
 				if ( getType().isComponentType() ) {
-					throw new IllegalStateException( "Cannot treat composite collection element type as entity" );
+					throw new WalkingException( "Cannot treat composite collection element type as entity" );
 				}
 				return getElementPersister();
 			}
 
 			@Override
 			public CompositeCollectionElementDefinition toCompositeElementDefinition() {
 
 				if ( ! getType().isComponentType() ) {
-					throw new IllegalStateException( "Cannot treat entity collection element type as composite" );
+					throw new WalkingException( "Cannot treat entity collection element type as composite" );
 				}
 
 				return new CompositeCollectionElementDefinition() {
 					@Override
 					public String getName() {
 						return "";
 					}
 
 					@Override
 					public Type getType() {
 						return getElementType();
 					}
 
 					@Override
+					public boolean isNullable() {
+						return false;
+					}
+
+					@Override
 					public AttributeSource getSource() {
 						// TODO: what if this is a collection w/in an encapsulated composition attribute?
 						// should return the encapsulated composition attribute instead???
 						return getOwnerEntityPersister();
 					}
 
 					@Override
 					public Iterable<AttributeDefinition> getAttributes() {
 						return CompositionSingularSubAttributesHelper.getCompositeCollectionElementSubAttributes( this );
 					}
 
 					@Override
 					public CollectionDefinition getCollectionDefinition() {
 						return AbstractCollectionPersister.this;
 					}
 				};
 			}
 		};
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java
index 3ad089ffe0..acdfa30464 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java
@@ -1,1031 +1,1032 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.entity;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collections;
 import java.util.Comparator;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.EntityMode;
 import org.hibernate.FetchMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.StaleStateException;
 import org.hibernate.bytecode.instrumentation.spi.FieldInterceptor;
 import org.hibernate.bytecode.instrumentation.spi.LazyPropertyInitializer;
 import org.hibernate.bytecode.spi.EntityInstrumentationMetadata;
 import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.cache.spi.access.NaturalIdRegionAccessStrategy;
 import org.hibernate.cache.spi.entry.CacheEntry;
 import org.hibernate.cache.spi.entry.CacheEntryStructure;
 import org.hibernate.cache.spi.entry.ReferenceCacheEntryImpl;
 import org.hibernate.cache.spi.entry.StandardCacheEntryImpl;
 import org.hibernate.cache.spi.entry.StructuredCacheEntry;
 import org.hibernate.cache.spi.entry.UnstructuredCacheEntry;
 import org.hibernate.dialect.lock.LockingStrategy;
 import org.hibernate.engine.OptimisticLockStyle;
 import org.hibernate.engine.internal.StatefulPersistenceContext;
 import org.hibernate.engine.internal.Versioning;
 import org.hibernate.engine.jdbc.batch.internal.BasicBatchKey;
 import org.hibernate.engine.spi.CachedNaturalIdValueSource;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.engine.spi.CascadeStyles;
 import org.hibernate.engine.spi.CascadingActions;
 import org.hibernate.engine.spi.EntityEntry;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.spi.FilterDefinition;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.engine.spi.PersistenceContext.NaturalIdHelper;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.ValueInclusion;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.PostInsertIdentifierGenerator;
 import org.hibernate.id.PostInsertIdentityPersister;
 import org.hibernate.id.insert.Binder;
 import org.hibernate.id.insert.InsertGeneratedIdentifierDelegate;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.FilterConfiguration;
 import org.hibernate.internal.FilterHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.jdbc.Expectation;
 import org.hibernate.jdbc.Expectations;
 import org.hibernate.jdbc.TooManyRowsAffectedException;
 import org.hibernate.loader.entity.BatchingEntityLoaderBuilder;
 import org.hibernate.loader.entity.CascadeEntityLoader;
 import org.hibernate.loader.entity.EntityLoader;
 import org.hibernate.loader.entity.UniqueEntityLoader;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.Selectable;
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.metamodel.binding.AssociationAttributeBinding;
 import org.hibernate.metamodel.binding.AttributeBinding;
 import org.hibernate.metamodel.binding.EntityBinding;
 import org.hibernate.metamodel.binding.SimpleValueBinding;
 import org.hibernate.metamodel.binding.SingularAttributeBinding;
 import org.hibernate.metamodel.relational.DerivedValue;
 import org.hibernate.metamodel.relational.Value;
 import org.hibernate.persister.walking.internal.EntityIdentifierDefinitionHelper;
 import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.persister.walking.spi.EntityIdentifierDefinition;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.property.BackrefPropertyAccessor;
 import org.hibernate.sql.Alias;
 import org.hibernate.sql.Delete;
 import org.hibernate.sql.Insert;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.JoinType;
 import org.hibernate.sql.Select;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.sql.SimpleSelect;
 import org.hibernate.sql.Template;
 import org.hibernate.sql.Update;
 import org.hibernate.tuple.entity.EntityMetamodel;
 import org.hibernate.tuple.entity.EntityTuplizer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeHelper;
 import org.hibernate.type.VersionType;
 import org.jboss.logging.Logger;
 
 /**
  * Basic functionality for persisting an entity via JDBC
  * through either generated or custom SQL
  *
  * @author Gavin King
  */
 public abstract class AbstractEntityPersister
 		implements OuterJoinLoadable, Queryable, ClassMetadata, UniqueKeyLoadable,
 				   SQLLoadable, LazyPropertyInitializer, PostInsertIdentityPersister, Lockable {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        AbstractEntityPersister.class.getName());
 
 	public static final String ENTITY_CLASS = "class";
 
 	// moved up from AbstractEntityPersister ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	private final SessionFactoryImplementor factory;
 	private final EntityRegionAccessStrategy cacheAccessStrategy;
 	private final NaturalIdRegionAccessStrategy naturalIdRegionAccessStrategy;
 	private final boolean isLazyPropertiesCacheable;
 	private final CacheEntryHelper cacheEntryHelper;
 	private final EntityMetamodel entityMetamodel;
 	private final EntityTuplizer entityTuplizer;
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private final String[] rootTableKeyColumnNames;
 	private final String[] rootTableKeyColumnReaders;
 	private final String[] rootTableKeyColumnReaderTemplates;
 	private final String[] identifierAliases;
 	private final int identifierColumnSpan;
 	private final String versionColumnName;
 	private final boolean hasFormulaProperties;
 	private final int batchSize;
 	private final boolean hasSubselectLoadableCollections;
 	protected final String rowIdName;
 
 	private final Set lazyProperties;
 
 	// The optional SQL string defined in the where attribute
 	private final String sqlWhereString;
 	private final String sqlWhereStringTemplate;
 
 	//information about properties of this class,
 	//including inherited properties
 	//(only really needed for updatable/insertable properties)
 	private final int[] propertyColumnSpans;
 	private final String[] propertySubclassNames;
 	private final String[][] propertyColumnAliases;
 	private final String[][] propertyColumnNames;
 	private final String[][] propertyColumnFormulaTemplates;
 	private final String[][] propertyColumnReaderTemplates;
 	private final String[][] propertyColumnWriters;
 	private final boolean[][] propertyColumnUpdateable;
 	private final boolean[][] propertyColumnInsertable;
 	private final boolean[] propertyUniqueness;
 	private final boolean[] propertySelectable;
 	
 	private final List<Integer> lobProperties = new ArrayList<Integer>();
 
 	//information about lazy properties of this class
 	private final String[] lazyPropertyNames;
 	private final int[] lazyPropertyNumbers;
 	private final Type[] lazyPropertyTypes;
 	private final String[][] lazyPropertyColumnAliases;
 
 	//information about all properties in class hierarchy
 	private final String[] subclassPropertyNameClosure;
 	private final String[] subclassPropertySubclassNameClosure;
 	private final Type[] subclassPropertyTypeClosure;
 	private final String[][] subclassPropertyFormulaTemplateClosure;
 	private final String[][] subclassPropertyColumnNameClosure;
 	private final String[][] subclassPropertyColumnReaderClosure;
 	private final String[][] subclassPropertyColumnReaderTemplateClosure;
 	private final FetchMode[] subclassPropertyFetchModeClosure;
 	private final boolean[] subclassPropertyNullabilityClosure;
 	private final boolean[] propertyDefinedOnSubclass;
 	private final int[][] subclassPropertyColumnNumberClosure;
 	private final int[][] subclassPropertyFormulaNumberClosure;
 	private final CascadeStyle[] subclassPropertyCascadeStyleClosure;
 
 	//information about all columns/formulas in class hierarchy
 	private final String[] subclassColumnClosure;
 	private final boolean[] subclassColumnLazyClosure;
 	private final String[] subclassColumnAliasClosure;
 	private final boolean[] subclassColumnSelectableClosure;
 	private final String[] subclassColumnReaderTemplateClosure;
 	private final String[] subclassFormulaClosure;
 	private final String[] subclassFormulaTemplateClosure;
 	private final String[] subclassFormulaAliasClosure;
 	private final boolean[] subclassFormulaLazyClosure;
 
 	// dynamic filters attached to the class-level
 	private final FilterHelper filterHelper;
 
 	private final Set affectingFetchProfileNames = new HashSet();
 
 	private final Map uniqueKeyLoaders = new HashMap();
 	private final Map lockers = new HashMap();
 	private final Map loaders = new HashMap();
 
 	// SQL strings
 	private String sqlVersionSelectString;
 	private String sqlSnapshotSelectString;
 	private String sqlLazySelectString;
 
 	private String sqlIdentityInsertString;
 	private String sqlUpdateByRowIdString;
 	private String sqlLazyUpdateByRowIdString;
 
 	private String[] sqlDeleteStrings;
 	private String[] sqlInsertStrings;
 	private String[] sqlUpdateStrings;
 	private String[] sqlLazyUpdateStrings;
 
 	private String sqlInsertGeneratedValuesSelectString;
 	private String sqlUpdateGeneratedValuesSelectString;
 
 	//Custom SQL (would be better if these were private)
 	protected boolean[] insertCallable;
 	protected boolean[] updateCallable;
 	protected boolean[] deleteCallable;
 	protected String[] customSQLInsert;
 	protected String[] customSQLUpdate;
 	protected String[] customSQLDelete;
 	protected ExecuteUpdateResultCheckStyle[] insertResultCheckStyles;
 	protected ExecuteUpdateResultCheckStyle[] updateResultCheckStyles;
 	protected ExecuteUpdateResultCheckStyle[] deleteResultCheckStyles;
 
 	private InsertGeneratedIdentifierDelegate identityDelegate;
 
 	private boolean[] tableHasColumns;
 
 	private final String loaderName;
 
 	private UniqueEntityLoader queryLoader;
 
 	private final String temporaryIdTableName;
 	private final String temporaryIdTableDDL;
 
 	private final Map subclassPropertyAliases = new HashMap();
 	private final Map subclassPropertyColumnNames = new HashMap();
 
 	protected final BasicEntityPropertyMapping propertyMapping;
 
 	protected void addDiscriminatorToInsert(Insert insert) {}
 
 	protected void addDiscriminatorToSelect(SelectFragment select, String name, String suffix) {}
 
 	protected abstract int[] getSubclassColumnTableNumberClosure();
 
 	protected abstract int[] getSubclassFormulaTableNumberClosure();
 
 	public abstract String getSubclassTableName(int j);
 
 	protected abstract String[] getSubclassTableKeyColumns(int j);
 
 	protected abstract boolean isClassOrSuperclassTable(int j);
 
 	protected abstract int getSubclassTableSpan();
 
 	protected abstract int getTableSpan();
 
 	protected abstract boolean isTableCascadeDeleteEnabled(int j);
 
 	protected abstract String getTableName(int j);
 
 	protected abstract String[] getKeyColumns(int j);
 
 	protected abstract boolean isPropertyOfTable(int property, int j);
 
 	protected abstract int[] getPropertyTableNumbersInSelect();
 
 	protected abstract int[] getPropertyTableNumbers();
 
 	protected abstract int getSubclassPropertyTableNumber(int i);
 
 	protected abstract String filterFragment(String alias) throws MappingException;
 
 	private static final String DISCRIMINATOR_ALIAS = "clazz_";
 
 	public String getDiscriminatorColumnName() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	public String getDiscriminatorColumnReaders() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	public String getDiscriminatorColumnReaderTemplate() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	protected String getDiscriminatorAlias() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	protected String getDiscriminatorFormulaTemplate() {
 		return null;
 	}
 
 	protected boolean isInverseTable(int j) {
 		return false;
 	}
 
 	protected boolean isNullableTable(int j) {
 		return false;
 	}
 
 	protected boolean isNullableSubclassTable(int j) {
 		return false;
 	}
 
 	protected boolean isInverseSubclassTable(int j) {
 		return false;
 	}
 
 	public boolean isSubclassEntityName(String entityName) {
 		return entityMetamodel.getSubclassEntityNames().contains(entityName);
 	}
 
 	private boolean[] getTableHasColumns() {
 		return tableHasColumns;
 	}
 
 	public String[] getRootTableKeyColumnNames() {
 		return rootTableKeyColumnNames;
 	}
 
 	protected String[] getSQLUpdateByRowIdStrings() {
 		if ( sqlUpdateByRowIdString == null ) {
 			throw new AssertionFailure( "no update by row id" );
 		}
 		String[] result = new String[getTableSpan() + 1];
 		result[0] = sqlUpdateByRowIdString;
 		System.arraycopy( sqlUpdateStrings, 0, result, 1, getTableSpan() );
 		return result;
 	}
 
 	protected String[] getSQLLazyUpdateByRowIdStrings() {
 		if ( sqlLazyUpdateByRowIdString == null ) {
 			throw new AssertionFailure( "no update by row id" );
 		}
 		String[] result = new String[getTableSpan()];
 		result[0] = sqlLazyUpdateByRowIdString;
 		for ( int i = 1; i < getTableSpan(); i++ ) {
 			result[i] = sqlLazyUpdateStrings[i];
 		}
 		return result;
 	}
 
 	protected String getSQLSnapshotSelectString() {
 		return sqlSnapshotSelectString;
 	}
 
 	protected String getSQLLazySelectString() {
 		return sqlLazySelectString;
 	}
 
 	protected String[] getSQLDeleteStrings() {
 		return sqlDeleteStrings;
 	}
 
 	protected String[] getSQLInsertStrings() {
 		return sqlInsertStrings;
 	}
 
 	protected String[] getSQLUpdateStrings() {
 		return sqlUpdateStrings;
 	}
 
 	protected String[] getSQLLazyUpdateStrings() {
 		return sqlLazyUpdateStrings;
 	}
 
 	/**
 	 * The query that inserts a row, letting the database generate an id
 	 *
 	 * @return The IDENTITY-based insertion query.
 	 */
 	protected String getSQLIdentityInsertString() {
 		return sqlIdentityInsertString;
 	}
 
 	protected String getVersionSelectString() {
 		return sqlVersionSelectString;
 	}
 
 	protected boolean isInsertCallable(int j) {
 		return insertCallable[j];
 	}
 
 	protected boolean isUpdateCallable(int j) {
 		return updateCallable[j];
 	}
 
 	protected boolean isDeleteCallable(int j) {
 		return deleteCallable[j];
 	}
 
 	protected boolean isSubclassPropertyDeferred(String propertyName, String entityName) {
 		return false;
 	}
 
 	protected boolean isSubclassTableSequentialSelect(int j) {
 		return false;
 	}
 
 	public boolean hasSequentialSelect() {
 		return false;
 	}
 
 	/**
 	 * Decide which tables need to be updated.
 	 * <p/>
 	 * The return here is an array of boolean values with each index corresponding
 	 * to a given table in the scope of this persister.
 	 *
 	 * @param dirtyProperties The indices of all the entity properties considered dirty.
 	 * @param hasDirtyCollection Whether any collections owned by the entity which were considered dirty.
 	 *
 	 * @return Array of booleans indicating which table require updating.
 	 */
 	protected boolean[] getTableUpdateNeeded(final int[] dirtyProperties, boolean hasDirtyCollection) {
 
 		if ( dirtyProperties == null ) {
 			return getTableHasColumns(); // for objects that came in via update()
 		}
 		else {
 			boolean[] updateability = getPropertyUpdateability();
 			int[] propertyTableNumbers = getPropertyTableNumbers();
 			boolean[] tableUpdateNeeded = new boolean[ getTableSpan() ];
 			for ( int i = 0; i < dirtyProperties.length; i++ ) {
 				int property = dirtyProperties[i];
 				int table = propertyTableNumbers[property];
 				tableUpdateNeeded[table] = tableUpdateNeeded[table] ||
 						( getPropertyColumnSpan(property) > 0 && updateability[property] );
 			}
 			if ( isVersioned() ) {
 				tableUpdateNeeded[0] = tableUpdateNeeded[0] ||
 					Versioning.isVersionIncrementRequired( dirtyProperties, hasDirtyCollection, getPropertyVersionability() );
 			}
 			return tableUpdateNeeded;
 		}
 	}
 
 	public boolean hasRowId() {
 		return rowIdName != null;
 	}
 
 	protected boolean[][] getPropertyColumnUpdateable() {
 		return propertyColumnUpdateable;
 	}
 
 	protected boolean[][] getPropertyColumnInsertable() {
 		return propertyColumnInsertable;
 	}
 
 	protected boolean[] getPropertySelectable() {
 		return propertySelectable;
 	}
 
 	public AbstractEntityPersister(
 			final PersistentClass persistentClass,
 			final EntityRegionAccessStrategy cacheAccessStrategy,
 			final NaturalIdRegionAccessStrategy naturalIdRegionAccessStrategy,
 			final SessionFactoryImplementor factory) throws HibernateException {
 
 		// moved up from AbstractEntityPersister ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		this.factory = factory;
 		this.cacheAccessStrategy = cacheAccessStrategy;
 		this.naturalIdRegionAccessStrategy = naturalIdRegionAccessStrategy;
 		isLazyPropertiesCacheable = persistentClass.isLazyPropertiesCacheable();
 
 		this.entityMetamodel = new EntityMetamodel( persistentClass, this, factory );
 		this.entityTuplizer = this.entityMetamodel.getTuplizer();
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 		int batch = persistentClass.getBatchSize();
 		if ( batch == -1 ) {
 			batch = factory.getSettings().getDefaultBatchFetchSize();
 		}
 		batchSize = batch;
 		hasSubselectLoadableCollections = persistentClass.hasSubselectLoadableCollections();
 
 		propertyMapping = new BasicEntityPropertyMapping( this );
 
 		// IDENTIFIER
 
 		identifierColumnSpan = persistentClass.getIdentifier().getColumnSpan();
 		rootTableKeyColumnNames = new String[identifierColumnSpan];
 		rootTableKeyColumnReaders = new String[identifierColumnSpan];
 		rootTableKeyColumnReaderTemplates = new String[identifierColumnSpan];
 		identifierAliases = new String[identifierColumnSpan];
 
 		rowIdName = persistentClass.getRootTable().getRowId();
 
 		loaderName = persistentClass.getLoaderName();
 
 		Iterator iter = persistentClass.getIdentifier().getColumnIterator();
 		int i = 0;
 		while ( iter.hasNext() ) {
 			Column col = ( Column ) iter.next();
 			rootTableKeyColumnNames[i] = col.getQuotedName( factory.getDialect() );
 			rootTableKeyColumnReaders[i] = col.getReadExpr( factory.getDialect() );
 			rootTableKeyColumnReaderTemplates[i] = col.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 			identifierAliases[i] = col.getAlias( factory.getDialect(), persistentClass.getRootTable() );
 			i++;
 		}
 
 		// VERSION
 
 		if ( persistentClass.isVersioned() ) {
 			versionColumnName = ( ( Column ) persistentClass.getVersion().getColumnIterator().next() ).getQuotedName( factory.getDialect() );
 		}
 		else {
 			versionColumnName = null;
 		}
 
 		//WHERE STRING
 
 		sqlWhereString = StringHelper.isNotEmpty( persistentClass.getWhere() ) ? "( " + persistentClass.getWhere() + ") " : null;
 		sqlWhereStringTemplate = sqlWhereString == null ?
 				null :
 				Template.renderWhereStringTemplate( sqlWhereString, factory.getDialect(), factory.getSqlFunctionRegistry() );
 
 		// PROPERTIES
 
 		final boolean lazyAvailable = isInstrumented();
 
 		int hydrateSpan = entityMetamodel.getPropertySpan();
 		propertyColumnSpans = new int[hydrateSpan];
 		propertySubclassNames = new String[hydrateSpan];
 		propertyColumnAliases = new String[hydrateSpan][];
 		propertyColumnNames = new String[hydrateSpan][];
 		propertyColumnFormulaTemplates = new String[hydrateSpan][];
 		propertyColumnReaderTemplates = new String[hydrateSpan][];
 		propertyColumnWriters = new String[hydrateSpan][];
 		propertyUniqueness = new boolean[hydrateSpan];
 		propertySelectable = new boolean[hydrateSpan];
 		propertyColumnUpdateable = new boolean[hydrateSpan][];
 		propertyColumnInsertable = new boolean[hydrateSpan][];
 		HashSet thisClassProperties = new HashSet();
 
 		lazyProperties = new HashSet();
 		ArrayList lazyNames = new ArrayList();
 		ArrayList lazyNumbers = new ArrayList();
 		ArrayList lazyTypes = new ArrayList();
 		ArrayList lazyColAliases = new ArrayList();
 
 		iter = persistentClass.getPropertyClosureIterator();
 		i = 0;
 		boolean foundFormula = false;
 		while ( iter.hasNext() ) {
 			Property prop = ( Property ) iter.next();
 			thisClassProperties.add( prop );
 
 			int span = prop.getColumnSpan();
 			propertyColumnSpans[i] = span;
 			propertySubclassNames[i] = prop.getPersistentClass().getEntityName();
 			String[] colNames = new String[span];
 			String[] colAliases = new String[span];
 			String[] colReaderTemplates = new String[span];
 			String[] colWriters = new String[span];
 			String[] formulaTemplates = new String[span];
 			Iterator colIter = prop.getColumnIterator();
 			int k = 0;
 			while ( colIter.hasNext() ) {
 				Selectable thing = ( Selectable ) colIter.next();
 				colAliases[k] = thing.getAlias( factory.getDialect() , prop.getValue().getTable() );
 				if ( thing.isFormula() ) {
 					foundFormula = true;
 					formulaTemplates[k] = thing.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 				}
 				else {
 					Column col = (Column)thing;
 					colNames[k] = col.getQuotedName( factory.getDialect() );
 					colReaderTemplates[k] = col.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 					colWriters[k] = col.getWriteExpr();
 				}
 				k++;
 			}
 			propertyColumnNames[i] = colNames;
 			propertyColumnFormulaTemplates[i] = formulaTemplates;
 			propertyColumnReaderTemplates[i] = colReaderTemplates;
 			propertyColumnWriters[i] = colWriters;
 			propertyColumnAliases[i] = colAliases;
 
 			if ( lazyAvailable && prop.isLazy() ) {
 				lazyProperties.add( prop.getName() );
 				lazyNames.add( prop.getName() );
 				lazyNumbers.add( i );
 				lazyTypes.add( prop.getValue().getType() );
 				lazyColAliases.add( colAliases );
 			}
 
 			propertyColumnUpdateable[i] = prop.getValue().getColumnUpdateability();
 			propertyColumnInsertable[i] = prop.getValue().getColumnInsertability();
 
 			propertySelectable[i] = prop.isSelectable();
 
 			propertyUniqueness[i] = prop.getValue().isAlternateUniqueKey();
 			
 			if (prop.isLob() && getFactory().getDialect().forceLobAsLastValue() ) {
 				lobProperties.add( i );
 			}
 
 			i++;
 
 		}
 		hasFormulaProperties = foundFormula;
 		lazyPropertyColumnAliases = ArrayHelper.to2DStringArray( lazyColAliases );
 		lazyPropertyNames = ArrayHelper.toStringArray( lazyNames );
 		lazyPropertyNumbers = ArrayHelper.toIntArray( lazyNumbers );
 		lazyPropertyTypes = ArrayHelper.toTypeArray( lazyTypes );
 
 		// SUBCLASS PROPERTY CLOSURE
 
 		ArrayList columns = new ArrayList();
 		ArrayList columnsLazy = new ArrayList();
 		ArrayList columnReaderTemplates = new ArrayList();
 		ArrayList aliases = new ArrayList();
 		ArrayList formulas = new ArrayList();
 		ArrayList formulaAliases = new ArrayList();
 		ArrayList formulaTemplates = new ArrayList();
 		ArrayList formulasLazy = new ArrayList();
 		ArrayList types = new ArrayList();
 		ArrayList names = new ArrayList();
 		ArrayList classes = new ArrayList();
 		ArrayList templates = new ArrayList();
 		ArrayList propColumns = new ArrayList();
 		ArrayList propColumnReaders = new ArrayList();
 		ArrayList propColumnReaderTemplates = new ArrayList();
 		ArrayList joinedFetchesList = new ArrayList();
 		ArrayList cascades = new ArrayList();
 		ArrayList definedBySubclass = new ArrayList();
 		ArrayList propColumnNumbers = new ArrayList();
 		ArrayList propFormulaNumbers = new ArrayList();
 		ArrayList columnSelectables = new ArrayList();
 		ArrayList propNullables = new ArrayList();
 
 		iter = persistentClass.getSubclassPropertyClosureIterator();
 		while ( iter.hasNext() ) {
 			Property prop = ( Property ) iter.next();
 			names.add( prop.getName() );
 			classes.add( prop.getPersistentClass().getEntityName() );
 			boolean isDefinedBySubclass = !thisClassProperties.contains( prop );
 			definedBySubclass.add( Boolean.valueOf( isDefinedBySubclass ) );
 			propNullables.add( Boolean.valueOf( prop.isOptional() || isDefinedBySubclass ) ); //TODO: is this completely correct?
 			types.add( prop.getType() );
 
 			Iterator colIter = prop.getColumnIterator();
 			String[] cols = new String[prop.getColumnSpan()];
 			String[] readers = new String[prop.getColumnSpan()];
 			String[] readerTemplates = new String[prop.getColumnSpan()];
 			String[] forms = new String[prop.getColumnSpan()];
 			int[] colnos = new int[prop.getColumnSpan()];
 			int[] formnos = new int[prop.getColumnSpan()];
 			int l = 0;
 			Boolean lazy = Boolean.valueOf( prop.isLazy() && lazyAvailable );
 			while ( colIter.hasNext() ) {
 				Selectable thing = ( Selectable ) colIter.next();
 				if ( thing.isFormula() ) {
 					String template = thing.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 					formnos[l] = formulaTemplates.size();
 					colnos[l] = -1;
 					formulaTemplates.add( template );
 					forms[l] = template;
 					formulas.add( thing.getText( factory.getDialect() ) );
 					formulaAliases.add( thing.getAlias( factory.getDialect() ) );
 					formulasLazy.add( lazy );
 				}
 				else {
 					Column col = (Column)thing;
 					String colName = col.getQuotedName( factory.getDialect() );
 					colnos[l] = columns.size(); //before add :-)
 					formnos[l] = -1;
 					columns.add( colName );
 					cols[l] = colName;
 					aliases.add( thing.getAlias( factory.getDialect(), prop.getValue().getTable() ) );
 					columnsLazy.add( lazy );
 					columnSelectables.add( Boolean.valueOf( prop.isSelectable() ) );
 
 					readers[l] = col.getReadExpr( factory.getDialect() );
 					String readerTemplate = col.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 					readerTemplates[l] = readerTemplate;
 					columnReaderTemplates.add( readerTemplate );
 				}
 				l++;
 			}
 			propColumns.add( cols );
 			propColumnReaders.add( readers );
 			propColumnReaderTemplates.add( readerTemplates );
 			templates.add( forms );
 			propColumnNumbers.add( colnos );
 			propFormulaNumbers.add( formnos );
 
 			joinedFetchesList.add( prop.getValue().getFetchMode() );
 			cascades.add( prop.getCascadeStyle() );
 		}
 		subclassColumnClosure = ArrayHelper.toStringArray( columns );
 		subclassColumnAliasClosure = ArrayHelper.toStringArray( aliases );
 		subclassColumnLazyClosure = ArrayHelper.toBooleanArray( columnsLazy );
 		subclassColumnSelectableClosure = ArrayHelper.toBooleanArray( columnSelectables );
 		subclassColumnReaderTemplateClosure = ArrayHelper.toStringArray( columnReaderTemplates );
 
 		subclassFormulaClosure = ArrayHelper.toStringArray( formulas );
 		subclassFormulaTemplateClosure = ArrayHelper.toStringArray( formulaTemplates );
 		subclassFormulaAliasClosure = ArrayHelper.toStringArray( formulaAliases );
 		subclassFormulaLazyClosure = ArrayHelper.toBooleanArray( formulasLazy );
 
 		subclassPropertyNameClosure = ArrayHelper.toStringArray( names );
 		subclassPropertySubclassNameClosure = ArrayHelper.toStringArray( classes );
 		subclassPropertyTypeClosure = ArrayHelper.toTypeArray( types );
 		subclassPropertyNullabilityClosure = ArrayHelper.toBooleanArray( propNullables );
 		subclassPropertyFormulaTemplateClosure = ArrayHelper.to2DStringArray( templates );
 		subclassPropertyColumnNameClosure = ArrayHelper.to2DStringArray( propColumns );
 		subclassPropertyColumnReaderClosure = ArrayHelper.to2DStringArray( propColumnReaders );
 		subclassPropertyColumnReaderTemplateClosure = ArrayHelper.to2DStringArray( propColumnReaderTemplates );
 		subclassPropertyColumnNumberClosure = ArrayHelper.to2DIntArray( propColumnNumbers );
 		subclassPropertyFormulaNumberClosure = ArrayHelper.to2DIntArray( propFormulaNumbers );
 
 		subclassPropertyCascadeStyleClosure = new CascadeStyle[cascades.size()];
 		iter = cascades.iterator();
 		int j = 0;
 		while ( iter.hasNext() ) {
 			subclassPropertyCascadeStyleClosure[j++] = ( CascadeStyle ) iter.next();
 		}
 		subclassPropertyFetchModeClosure = new FetchMode[joinedFetchesList.size()];
 		iter = joinedFetchesList.iterator();
 		j = 0;
 		while ( iter.hasNext() ) {
 			subclassPropertyFetchModeClosure[j++] = ( FetchMode ) iter.next();
 		}
 
 		propertyDefinedOnSubclass = new boolean[definedBySubclass.size()];
 		iter = definedBySubclass.iterator();
 		j = 0;
 		while ( iter.hasNext() ) {
 			propertyDefinedOnSubclass[j++] = (Boolean) iter.next();
 		}
 
 		// Handle any filters applied to the class level
 		filterHelper = new FilterHelper( persistentClass.getFilters(), factory );
 
 		temporaryIdTableName = persistentClass.getTemporaryIdTableName();
 		temporaryIdTableDDL = persistentClass.getTemporaryIdTableDDL();
 
 		this.cacheEntryHelper = buildCacheEntryHelper();
 	}
 
 	protected CacheEntryHelper buildCacheEntryHelper() {
 		if ( cacheAccessStrategy == null ) {
 			// the entity defined no caching...
 			return NoopCacheEntryHelper.INSTANCE;
 		}
 
 		if ( canUseReferenceCacheEntries() ) {
 			entityMetamodel.setLazy( false );
 			// todo : do we also need to unset proxy factory?
 			return new ReferenceCacheEntryHelper( this );
 		}
 
 		return factory.getSettings().isStructuredCacheEntriesEnabled()
 				? new StructuredCacheEntryHelper( this )
 				: new StandardCacheEntryHelper( this );
 	}
 
 	protected boolean canUseReferenceCacheEntries() {
 		// todo : should really validate that the cache access type is read-only
 
 		if ( ! factory.getSettings().isDirectReferenceCacheEntriesEnabled() ) {
 			return false;
 		}
 
 		// for now, limit this to just entities that:
 		// 		1) are immutable
 		if ( entityMetamodel.isMutable() ) {
 			return false;
 		}
 
 		//		2)  have no associations.  Eventually we want to be a little more lenient with associations.
 		for ( Type type : getSubclassPropertyTypeClosure() ) {
 			if ( type.isAssociationType() ) {
 				return false;
 			}
 		}
 
 		return true;
 	}
 
 
 	public AbstractEntityPersister(
 			final EntityBinding entityBinding,
 			final EntityRegionAccessStrategy cacheAccessStrategy,
 			final NaturalIdRegionAccessStrategy naturalIdRegionAccessStrategy,
 			final SessionFactoryImplementor factory) throws HibernateException {
 		this.factory = factory;
 		this.cacheAccessStrategy = cacheAccessStrategy;
 		this.naturalIdRegionAccessStrategy = naturalIdRegionAccessStrategy;
 		this.isLazyPropertiesCacheable =
 				entityBinding.getHierarchyDetails().getCaching() == null ?
 						false :
 						entityBinding.getHierarchyDetails().getCaching().isCacheLazyProperties();
 		this.entityMetamodel = new EntityMetamodel( entityBinding, this, factory );
 		this.entityTuplizer = this.entityMetamodel.getTuplizer();
 		int batch = entityBinding.getBatchSize();
 		if ( batch == -1 ) {
 			batch = factory.getSettings().getDefaultBatchFetchSize();
 		}
 		batchSize = batch;
 		hasSubselectLoadableCollections = entityBinding.hasSubselectLoadableCollections();
 
 		propertyMapping = new BasicEntityPropertyMapping( this );
 
 		// IDENTIFIER
 
 		identifierColumnSpan = entityBinding.getHierarchyDetails().getEntityIdentifier().getValueBinding().getSimpleValueSpan();
 		rootTableKeyColumnNames = new String[identifierColumnSpan];
 		rootTableKeyColumnReaders = new String[identifierColumnSpan];
 		rootTableKeyColumnReaderTemplates = new String[identifierColumnSpan];
 		identifierAliases = new String[identifierColumnSpan];
 
 		rowIdName = entityBinding.getRowId();
 
 		loaderName = entityBinding.getCustomLoaderName();
 
 		int i = 0;
 		for ( org.hibernate.metamodel.relational.Column col : entityBinding.getPrimaryTable().getPrimaryKey().getColumns() ) {
 			rootTableKeyColumnNames[i] = col.getColumnName().encloseInQuotesIfQuoted( factory.getDialect() );
 			if ( col.getReadFragment() == null ) {
 				rootTableKeyColumnReaders[i] = rootTableKeyColumnNames[i];
 				rootTableKeyColumnReaderTemplates[i] = getTemplateFromColumn( col, factory );
 			}
 			else {
 				rootTableKeyColumnReaders[i] = col.getReadFragment();
 				rootTableKeyColumnReaderTemplates[i] = getTemplateFromString( rootTableKeyColumnReaders[i], factory );
 			}
 			identifierAliases[i] = col.getAlias( factory.getDialect() );
 			i++;
 		}
 
 		// VERSION
 
 		if ( entityBinding.isVersioned() ) {
 			final Value versioningValue = entityBinding.getHierarchyDetails().getVersioningAttributeBinding().getValue();
 			if ( ! org.hibernate.metamodel.relational.Column.class.isInstance( versioningValue ) ) {
 				throw new AssertionFailure( "Bad versioning attribute binding : " + versioningValue );
 			}
 			org.hibernate.metamodel.relational.Column versionColumn = org.hibernate.metamodel.relational.Column.class.cast( versioningValue );
 			versionColumnName = versionColumn.getColumnName().encloseInQuotesIfQuoted( factory.getDialect() );
 		}
 		else {
 			versionColumnName = null;
 		}
 
 		//WHERE STRING
 
 		sqlWhereString = StringHelper.isNotEmpty( entityBinding.getWhereFilter() ) ? "( " + entityBinding.getWhereFilter() + ") " : null;
 		sqlWhereStringTemplate = getTemplateFromString( sqlWhereString, factory );
 
 		// PROPERTIES
 
 		final boolean lazyAvailable = isInstrumented();
 
 		int hydrateSpan = entityMetamodel.getPropertySpan();
 		propertyColumnSpans = new int[hydrateSpan];
 		propertySubclassNames = new String[hydrateSpan];
 		propertyColumnAliases = new String[hydrateSpan][];
 		propertyColumnNames = new String[hydrateSpan][];
 		propertyColumnFormulaTemplates = new String[hydrateSpan][];
 		propertyColumnReaderTemplates = new String[hydrateSpan][];
 		propertyColumnWriters = new String[hydrateSpan][];
 		propertyUniqueness = new boolean[hydrateSpan];
 		propertySelectable = new boolean[hydrateSpan];
 		propertyColumnUpdateable = new boolean[hydrateSpan][];
 		propertyColumnInsertable = new boolean[hydrateSpan][];
 		HashSet thisClassProperties = new HashSet();
 
 		lazyProperties = new HashSet();
 		ArrayList lazyNames = new ArrayList();
 		ArrayList lazyNumbers = new ArrayList();
 		ArrayList lazyTypes = new ArrayList();
 		ArrayList lazyColAliases = new ArrayList();
 
 		i = 0;
 		boolean foundFormula = false;
 		for ( AttributeBinding attributeBinding : entityBinding.getAttributeBindingClosure() ) {
 			if ( attributeBinding == entityBinding.getHierarchyDetails().getEntityIdentifier().getValueBinding() ) {
 				// entity identifier is not considered a "normal" property
 				continue;
 			}
 
 			if ( ! attributeBinding.getAttribute().isSingular() ) {
 				// collections handled separately
 				continue;
 			}
 
 			final SingularAttributeBinding singularAttributeBinding = (SingularAttributeBinding) attributeBinding;
 
 			thisClassProperties.add( singularAttributeBinding );
 
 			propertySubclassNames[i] = ( (EntityBinding) singularAttributeBinding.getContainer() ).getEntity().getName();
 
 			int span = singularAttributeBinding.getSimpleValueSpan();
 			propertyColumnSpans[i] = span;
 
 			String[] colNames = new String[span];
 			String[] colAliases = new String[span];
 			String[] colReaderTemplates = new String[span];
 			String[] colWriters = new String[span];
 			String[] formulaTemplates = new String[span];
 			boolean[] propertyColumnInsertability = new boolean[span];
 			boolean[] propertyColumnUpdatability = new boolean[span];
 
 			int k = 0;
 
 			for ( SimpleValueBinding valueBinding : singularAttributeBinding.getSimpleValueBindings() ) {
 				colAliases[k] = valueBinding.getSimpleValue().getAlias( factory.getDialect() );
 				if ( valueBinding.isDerived() ) {
 					foundFormula = true;
 					formulaTemplates[ k ] = getTemplateFromString( ( (DerivedValue) valueBinding.getSimpleValue() ).getExpression(), factory );
 				}
 				else {
 					org.hibernate.metamodel.relational.Column col = ( org.hibernate.metamodel.relational.Column ) valueBinding.getSimpleValue();
 					colNames[k] = col.getColumnName().encloseInQuotesIfQuoted( factory.getDialect() );
 					colReaderTemplates[k] = getTemplateFromColumn( col, factory );
 					colWriters[k] = col.getWriteFragment() == null ? "?" : col.getWriteFragment();
 				}
 				propertyColumnInsertability[k] = valueBinding.isIncludeInInsert();
 				propertyColumnUpdatability[k] = valueBinding.isIncludeInUpdate();
 				k++;
 			}
 			propertyColumnNames[i] = colNames;
 			propertyColumnFormulaTemplates[i] = formulaTemplates;
 			propertyColumnReaderTemplates[i] = colReaderTemplates;
 			propertyColumnWriters[i] = colWriters;
 			propertyColumnAliases[i] = colAliases;
 
 			propertyColumnUpdateable[i] = propertyColumnUpdatability;
 			propertyColumnInsertable[i] = propertyColumnInsertability;
 
 			if ( lazyAvailable && singularAttributeBinding.isLazy() ) {
 				lazyProperties.add( singularAttributeBinding.getAttribute().getName() );
 				lazyNames.add( singularAttributeBinding.getAttribute().getName() );
 				lazyNumbers.add( i );
 				lazyTypes.add( singularAttributeBinding.getHibernateTypeDescriptor().getResolvedTypeMapping());
 				lazyColAliases.add( colAliases );
 			}
 
 
 			// TODO: fix this when backrefs are working
 			//propertySelectable[i] = singularAttributeBinding.isBackRef();
 			propertySelectable[i] = true;
 
 			propertyUniqueness[i] = singularAttributeBinding.isAlternateUniqueKey();
 			
 			// TODO: Does this need AttributeBindings wired into lobProperties?  Currently in Property only.
 
 			i++;
 
 		}
 		hasFormulaProperties = foundFormula;
 		lazyPropertyColumnAliases = ArrayHelper.to2DStringArray( lazyColAliases );
 		lazyPropertyNames = ArrayHelper.toStringArray( lazyNames );
 		lazyPropertyNumbers = ArrayHelper.toIntArray( lazyNumbers );
 		lazyPropertyTypes = ArrayHelper.toTypeArray( lazyTypes );
 
 		// SUBCLASS PROPERTY CLOSURE
 
 		List<String> columns = new ArrayList<String>();
 		List<Boolean> columnsLazy = new ArrayList<Boolean>();
 		List<String> columnReaderTemplates = new ArrayList<String>();
 		List<String> aliases = new ArrayList<String>();
 		List<String> formulas = new ArrayList<String>();
 		List<String> formulaAliases = new ArrayList<String>();
 		List<String> formulaTemplates = new ArrayList<String>();
 		List<Boolean> formulasLazy = new ArrayList<Boolean>();
 		List<Type> types = new ArrayList<Type>();
 		List<String> names = new ArrayList<String>();
 		List<String> classes = new ArrayList<String>();
 		List<String[]> templates = new ArrayList<String[]>();
 		List<String[]> propColumns = new ArrayList<String[]>();
 		List<String[]> propColumnReaders = new ArrayList<String[]>();
 		List<String[]> propColumnReaderTemplates = new ArrayList<String[]>();
 		List<FetchMode> joinedFetchesList = new ArrayList<FetchMode>();
 		List<CascadeStyle> cascades = new ArrayList<CascadeStyle>();
 		List<Boolean> definedBySubclass = new ArrayList<Boolean>();
 		List<int[]> propColumnNumbers = new ArrayList<int[]>();
 		List<int[]> propFormulaNumbers = new ArrayList<int[]>();
 		List<Boolean> columnSelectables = new ArrayList<Boolean>();
 		List<Boolean> propNullables = new ArrayList<Boolean>();
 
 		for ( AttributeBinding attributeBinding : entityBinding.getSubEntityAttributeBindingClosure() ) {
 			if ( attributeBinding == entityBinding.getHierarchyDetails().getEntityIdentifier().getValueBinding() ) {
 				// entity identifier is not considered a "normal" property
 				continue;
@@ -1498,3668 +1499,3780 @@ public abstract class AbstractEntityPersister
 		}
 
 		if ( hasRowId() ) {
 			select.addColumn( tableAlias, rowIdName, ROWID_ALIAS );
 		}
 
 		return select;
 	}
 
 	public Object[] getDatabaseSnapshot(Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Getting current persistent state for: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		try {
 			PreparedStatement ps = session.getTransactionCoordinator()
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( getSQLSnapshotSelectString() );
 			try {
 				getIdentifierType().nullSafeSet( ps, id, 1, session );
 				//if ( isVersioned() ) getVersionType().nullSafeSet( ps, version, getIdentifierColumnSpan()+1, session );
 				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( ps );
 				try {
 					//if there is no resulting row, return null
 					if ( !rs.next() ) {
 						return null;
 					}
 					//otherwise return the "hydrated" state (ie. associations are not resolved)
 					Type[] types = getPropertyTypes();
 					Object[] values = new Object[types.length];
 					boolean[] includeProperty = getPropertyUpdateability();
 					for ( int i = 0; i < types.length; i++ ) {
 						if ( includeProperty[i] ) {
 							values[i] = types[i].hydrate( rs, getPropertyAliases( "", i ), session, null ); //null owner ok??
 						}
 					}
 					return values;
 				}
 				finally {
 					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, ps );
 				}
 			}
 			finally {
 				session.getTransactionCoordinator().getJdbcCoordinator().release( ps );
 			}
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"could not retrieve snapshot: " + MessageHelper.infoString( this, id, getFactory() ),
 			        getSQLSnapshotSelectString()
 			);
 		}
 
 	}
 
 	@Override
 	public Serializable getIdByUniqueKey(Serializable key, String uniquePropertyName, SessionImplementor session) throws HibernateException {
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracef(
 					"resolving unique key [%s] to identifier for entity [%s]",
 					key,
 					getEntityName()
 			);
 		}
 
 		int propertyIndex = getSubclassPropertyIndex( uniquePropertyName );
 		if ( propertyIndex < 0 ) {
 			throw new HibernateException(
 					"Could not determine Type for property [" + uniquePropertyName + "] on entity [" + getEntityName() + "]"
 			);
 		}
 		Type propertyType = getSubclassPropertyType( propertyIndex );
 
 		try {
 			PreparedStatement ps = session.getTransactionCoordinator()
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( generateIdByUniqueKeySelectString( uniquePropertyName ) );
 			try {
 				propertyType.nullSafeSet( ps, key, 1, session );
 				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( ps );
 				try {
 					//if there is no resulting row, return null
 					if ( !rs.next() ) {
 						return null;
 					}
 					return (Serializable) getIdentifierType().nullSafeGet( rs, getIdentifierAliases(), session, null );
 				}
 				finally {
 					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, ps );
 				}
 			}
 			finally {
 				session.getTransactionCoordinator().getJdbcCoordinator().release( ps );
 			}
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					String.format(
 							"could not resolve unique property [%s] to identifier for entity [%s]",
 							uniquePropertyName,
 							getEntityName()
 					),
 					getSQLSnapshotSelectString()
 			);
 		}
 
 	}
 
 	protected String generateIdByUniqueKeySelectString(String uniquePropertyName) {
 		Select select = new Select( getFactory().getDialect() );
 
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "resolve id by unique property [" + getEntityName() + "." + uniquePropertyName + "]" );
 		}
 
 		final String rooAlias = getRootAlias();
 
 		select.setFromClause( fromTableFragment( rooAlias ) + fromJoinFragment( rooAlias, true, false ) );
 
 		SelectFragment selectFragment = new SelectFragment();
 		selectFragment.addColumns( rooAlias, getIdentifierColumnNames(), getIdentifierAliases() );
 		select.setSelectClause( selectFragment );
 
 		StringBuilder whereClauseBuffer = new StringBuilder();
 		final int uniquePropertyIndex = getSubclassPropertyIndex( uniquePropertyName );
 		final String uniquePropertyTableAlias = generateTableAlias(
 				rooAlias,
 				getSubclassPropertyTableNumber( uniquePropertyIndex )
 		);
 		String sep = "";
 		for ( String columnTemplate : getSubclassPropertyColumnReaderTemplateClosure()[uniquePropertyIndex] ) {
 			if ( columnTemplate == null ) {
 				continue;
 			}
 			final String columnReference = StringHelper.replace( columnTemplate, Template.TEMPLATE, uniquePropertyTableAlias );
 			whereClauseBuffer.append( sep ).append( columnReference ).append( "=?" );
 			sep = " and ";
 		}
 		for ( String formulaTemplate : getSubclassPropertyFormulaTemplateClosure()[uniquePropertyIndex] ) {
 			if ( formulaTemplate == null ) {
 				continue;
 			}
 			final String formulaReference = StringHelper.replace( formulaTemplate, Template.TEMPLATE, uniquePropertyTableAlias );
 			whereClauseBuffer.append( sep ).append( formulaReference ).append( "=?" );
 			sep = " and ";
 		}
 		whereClauseBuffer.append( whereJoinFragment( rooAlias, true, false ) );
 
 		select.setWhereClause( whereClauseBuffer.toString() );
 
 		return select.setOuterJoins( "", "" ).toStatementString();
 	}
 
 
 	/**
 	 * Generate the SQL that selects the version number by id
 	 */
 	protected String generateSelectVersionString() {
 		SimpleSelect select = new SimpleSelect( getFactory().getDialect() )
 				.setTableName( getVersionedTableName() );
 		if ( isVersioned() ) {
 			select.addColumn( versionColumnName );
 		}
 		else {
 			select.addColumns( rootTableKeyColumnNames );
 		}
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "get version " + getEntityName() );
 		}
 		return select.addCondition( rootTableKeyColumnNames, "=?" ).toStatementString();
 	}
 
 	public boolean[] getPropertyUniqueness() {
 		return propertyUniqueness;
 	}
 
 	protected String generateInsertGeneratedValuesSelectString() {
 		return generateGeneratedValuesSelectString( getPropertyInsertGenerationInclusions() );
 	}
 
 	protected String generateUpdateGeneratedValuesSelectString() {
 		return generateGeneratedValuesSelectString( getPropertyUpdateGenerationInclusions() );
 	}
 
 	private String generateGeneratedValuesSelectString(ValueInclusion[] inclusions) {
 		Select select = new Select( getFactory().getDialect() );
 
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "get generated state " + getEntityName() );
 		}
 
 		String[] aliasedIdColumns = StringHelper.qualify( getRootAlias(), getIdentifierColumnNames() );
 
 		// Here we render the select column list based on the properties defined as being generated.
 		// For partial component generation, we currently just re-select the whole component
 		// rather than trying to handle the individual generated portions.
 		String selectClause = concretePropertySelectFragment( getRootAlias(), inclusions );
 		selectClause = selectClause.substring( 2 );
 
 		String fromClause = fromTableFragment( getRootAlias() ) +
 				fromJoinFragment( getRootAlias(), true, false );
 
 		String whereClause = new StringBuilder()
 			.append( StringHelper.join( "=? and ", aliasedIdColumns ) )
 			.append( "=?" )
 			.append( whereJoinFragment( getRootAlias(), true, false ) )
 			.toString();
 
 		return select.setSelectClause( selectClause )
 				.setFromClause( fromClause )
 				.setOuterJoins( "", "" )
 				.setWhereClause( whereClause )
 				.toStatementString();
 	}
 
 	protected static interface InclusionChecker {
 		public boolean includeProperty(int propertyNumber);
 	}
 
 	protected String concretePropertySelectFragment(String alias, final ValueInclusion[] inclusions) {
 		return concretePropertySelectFragment(
 				alias,
 				new InclusionChecker() {
 					// TODO : currently we really do not handle ValueInclusion.PARTIAL...
 					// ValueInclusion.PARTIAL would indicate parts of a component need to
 					// be included in the select; currently we then just render the entire
 					// component into the select clause in that case.
 					public boolean includeProperty(int propertyNumber) {
 						return inclusions[propertyNumber] != ValueInclusion.NONE;
 					}
 				}
 		);
 	}
 
 	protected String concretePropertySelectFragment(String alias, final boolean[] includeProperty) {
 		return concretePropertySelectFragment(
 				alias,
 				new InclusionChecker() {
 					public boolean includeProperty(int propertyNumber) {
 						return includeProperty[propertyNumber];
 					}
 				}
 		);
 	}
 
 	protected String concretePropertySelectFragment(String alias, InclusionChecker inclusionChecker) {
 		int propertyCount = getPropertyNames().length;
 		int[] propertyTableNumbers = getPropertyTableNumbersInSelect();
 		SelectFragment frag = new SelectFragment();
 		for ( int i = 0; i < propertyCount; i++ ) {
 			if ( inclusionChecker.includeProperty( i ) ) {
 				frag.addColumnTemplates(
 						generateTableAlias( alias, propertyTableNumbers[i] ),
 						propertyColumnReaderTemplates[i],
 						propertyColumnAliases[i]
 				);
 				frag.addFormulas(
 						generateTableAlias( alias, propertyTableNumbers[i] ),
 						propertyColumnFormulaTemplates[i],
 						propertyColumnAliases[i]
 				);
 			}
 		}
 		return frag.toFragmentString();
 	}
 
 	protected String generateSnapshotSelectString() {
 
 		//TODO: should we use SELECT .. FOR UPDATE?
 
 		Select select = new Select( getFactory().getDialect() );
 
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "get current state " + getEntityName() );
 		}
 
 		String[] aliasedIdColumns = StringHelper.qualify( getRootAlias(), getIdentifierColumnNames() );
 		String selectClause = StringHelper.join( ", ", aliasedIdColumns ) +
 				concretePropertySelectFragment( getRootAlias(), getPropertyUpdateability() );
 
 		String fromClause = fromTableFragment( getRootAlias() ) +
 				fromJoinFragment( getRootAlias(), true, false );
 
 		String whereClause = new StringBuilder()
 			.append( StringHelper.join( "=? and ",
 					aliasedIdColumns ) )
 			.append( "=?" )
 			.append( whereJoinFragment( getRootAlias(), true, false ) )
 			.toString();
 
 		/*if ( isVersioned() ) {
 			where.append(" and ")
 				.append( getVersionColumnName() )
 				.append("=?");
 		}*/
 
 		return select.setSelectClause( selectClause )
 				.setFromClause( fromClause )
 				.setOuterJoins( "", "" )
 				.setWhereClause( whereClause )
 				.toStatementString();
 	}
 
 	public Object forceVersionIncrement(Serializable id, Object currentVersion, SessionImplementor session) {
 		if ( !isVersioned() ) {
 			throw new AssertionFailure( "cannot force version increment on non-versioned entity" );
 		}
 
 		if ( isVersionPropertyGenerated() ) {
 			// the difficulty here is exactly what do we update in order to
 			// force the version to be incremented in the db...
 			throw new HibernateException( "LockMode.FORCE is currently not supported for generated version properties" );
 		}
 
 		Object nextVersion = getVersionType().next( currentVersion, session );
         if (LOG.isTraceEnabled()) LOG.trace("Forcing version increment [" + MessageHelper.infoString(this, id, getFactory()) + "; "
                                             + getVersionType().toLoggableString(currentVersion, getFactory()) + " -> "
                                             + getVersionType().toLoggableString(nextVersion, getFactory()) + "]");
 
 		// todo : cache this sql...
 		String versionIncrementString = generateVersionIncrementUpdateString();
 		PreparedStatement st = null;
 		try {
 			st = session.getTransactionCoordinator()
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( versionIncrementString, false );
 			try {
 				getVersionType().nullSafeSet( st, nextVersion, 1, session );
 				getIdentifierType().nullSafeSet( st, id, 2, session );
 				getVersionType().nullSafeSet( st, currentVersion, 2 + getIdentifierColumnSpan(), session );
 				int rows = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( st );
 				if ( rows != 1 ) {
 					throw new StaleObjectStateException( getEntityName(), id );
 				}
 			}
 			finally {
 				session.getTransactionCoordinator().getJdbcCoordinator().release( st );
 			}
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not retrieve version: " +
 					MessageHelper.infoString( this, id, getFactory() ),
 					getVersionSelectString()
 				);
 		}
 
 		return nextVersion;
 	}
 
 	private String generateVersionIncrementUpdateString() {
 		Update update = new Update( getFactory().getDialect() );
 		update.setTableName( getTableName( 0 ) );
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			update.setComment( "forced version increment" );
 		}
 		update.addColumn( getVersionColumnName() );
 		update.addPrimaryKeyColumns( getIdentifierColumnNames() );
 		update.setVersionColumnName( getVersionColumnName() );
 		return update.toStatementString();
 	}
 
 	/**
 	 * Retrieve the version number
 	 */
 	public Object getCurrentVersion(Serializable id, SessionImplementor session) throws HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Getting version: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		try {
 			PreparedStatement st = session.getTransactionCoordinator()
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( getVersionSelectString() );
 			try {
 				getIdentifierType().nullSafeSet( st, id, 1, session );
 				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st );
 				try {
 					if ( !rs.next() ) {
 						return null;
 					}
 					if ( !isVersioned() ) {
 						return this;
 					}
 					return getVersionType().nullSafeGet( rs, getVersionColumnName(), session, null );
 				}
 				finally {
 					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, st );
 				}
 			}
 			finally {
 				session.getTransactionCoordinator().getJdbcCoordinator().release( st );
 			}
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"could not retrieve version: " + MessageHelper.infoString( this, id, getFactory() ),
 					getVersionSelectString()
 			);
 		}
 	}
 
 	protected void initLockers() {
 		lockers.put( LockMode.READ, generateLocker( LockMode.READ ) );
 		lockers.put( LockMode.UPGRADE, generateLocker( LockMode.UPGRADE ) );
 		lockers.put( LockMode.UPGRADE_NOWAIT, generateLocker( LockMode.UPGRADE_NOWAIT ) );
 		lockers.put( LockMode.UPGRADE_SKIPLOCKED, generateLocker( LockMode.UPGRADE_SKIPLOCKED ) );
 		lockers.put( LockMode.FORCE, generateLocker( LockMode.FORCE ) );
 		lockers.put( LockMode.PESSIMISTIC_READ, generateLocker( LockMode.PESSIMISTIC_READ ) );
 		lockers.put( LockMode.PESSIMISTIC_WRITE, generateLocker( LockMode.PESSIMISTIC_WRITE ) );
 		lockers.put( LockMode.PESSIMISTIC_FORCE_INCREMENT, generateLocker( LockMode.PESSIMISTIC_FORCE_INCREMENT ) );
 		lockers.put( LockMode.OPTIMISTIC, generateLocker( LockMode.OPTIMISTIC ) );
 		lockers.put( LockMode.OPTIMISTIC_FORCE_INCREMENT, generateLocker( LockMode.OPTIMISTIC_FORCE_INCREMENT ) );
 	}
 
 	protected LockingStrategy generateLocker(LockMode lockMode) {
 		return factory.getDialect().getLockingStrategy( this, lockMode );
 	}
 
 	private LockingStrategy getLocker(LockMode lockMode) {
 		return ( LockingStrategy ) lockers.get( lockMode );
 	}
 
 	public void lock(
 			Serializable id,
 	        Object version,
 	        Object object,
 	        LockMode lockMode,
 	        SessionImplementor session) throws HibernateException {
 		getLocker( lockMode ).lock( id, version, object, LockOptions.WAIT_FOREVER, session );
 	}
 
 	public void lock(
 			Serializable id,
 	        Object version,
 	        Object object,
 	        LockOptions lockOptions,
 	        SessionImplementor session) throws HibernateException {
 		getLocker( lockOptions.getLockMode() ).lock( id, version, object, lockOptions.getTimeOut(), session );
 	}
 
 	public String getRootTableName() {
 		return getSubclassTableName( 0 );
 	}
 
 	public String getRootTableAlias(String drivingAlias) {
 		return drivingAlias;
 	}
 
 	public String[] getRootTableIdentifierColumnNames() {
 		return getRootTableKeyColumnNames();
 	}
 
 	public String[] toColumns(String alias, String propertyName) throws QueryException {
 		return propertyMapping.toColumns( alias, propertyName );
 	}
 
 	public String[] toColumns(String propertyName) throws QueryException {
 		return propertyMapping.getColumnNames( propertyName );
 	}
 
 	public Type toType(String propertyName) throws QueryException {
 		return propertyMapping.toType( propertyName );
 	}
 
 	public String[] getPropertyColumnNames(String propertyName) {
 		return propertyMapping.getColumnNames( propertyName );
 	}
 
 	/**
 	 * Warning:
 	 * When there are duplicated property names in the subclasses
 	 * of the class, this method may return the wrong table
 	 * number for the duplicated subclass property (note that
 	 * SingleTableEntityPersister defines an overloaded form
 	 * which takes the entity name.
 	 */
 	public int getSubclassPropertyTableNumber(String propertyPath) {
 		String rootPropertyName = StringHelper.root(propertyPath);
 		Type type = propertyMapping.toType(rootPropertyName);
 		if ( type.isAssociationType() ) {
 			AssociationType assocType = ( AssociationType ) type;
 			if ( assocType.useLHSPrimaryKey() ) {
 				// performance op to avoid the array search
 				return 0;
 			}
 			else if ( type.isCollectionType() ) {
 				// properly handle property-ref-based associations
 				rootPropertyName = assocType.getLHSPropertyName();
 			}
 		}
 		//Enable for HHH-440, which we don't like:
 		/*if ( type.isComponentType() && !propertyName.equals(rootPropertyName) ) {
 			String unrooted = StringHelper.unroot(propertyName);
 			int idx = ArrayHelper.indexOf( getSubclassColumnClosure(), unrooted );
 			if ( idx != -1 ) {
 				return getSubclassColumnTableNumberClosure()[idx];
 			}
 		}*/
 		int index = ArrayHelper.indexOf( getSubclassPropertyNameClosure(), rootPropertyName); //TODO: optimize this better!
 		return index==-1 ? 0 : getSubclassPropertyTableNumber(index);
 	}
 
 	public Declarer getSubclassPropertyDeclarer(String propertyPath) {
 		int tableIndex = getSubclassPropertyTableNumber( propertyPath );
 		if ( tableIndex == 0 ) {
 			return Declarer.CLASS;
 		}
 		else if ( isClassOrSuperclassTable( tableIndex ) ) {
 			return Declarer.SUPERCLASS;
 		}
 		else {
 			return Declarer.SUBCLASS;
 		}
 	}
 
 	private DiscriminatorMetadata discriminatorMetadata;
 
 	public DiscriminatorMetadata getTypeDiscriminatorMetadata() {
 		if ( discriminatorMetadata == null ) {
 			discriminatorMetadata = buildTypeDiscriminatorMetadata();
 		}
 		return discriminatorMetadata;
 	}
 
 	private DiscriminatorMetadata buildTypeDiscriminatorMetadata() {
 		return new DiscriminatorMetadata() {
 			public String getSqlFragment(String sqlQualificationAlias) {
 				return toColumns( sqlQualificationAlias, ENTITY_CLASS )[0];
 			}
 
 			public Type getResolutionType() {
 				return new DiscriminatorType( getDiscriminatorType(), AbstractEntityPersister.this );
 			}
 		};
 	}
 
 	public static String generateTableAlias(String rootAlias, int tableNumber) {
 		if ( tableNumber == 0 ) {
 			return rootAlias;
 		}
 		StringBuilder buf = new StringBuilder().append( rootAlias );
 		if ( !rootAlias.endsWith( "_" ) ) {
 			buf.append( '_' );
 		}
 		return buf.append( tableNumber ).append( '_' ).toString();
 	}
 
 	public String[] toColumns(String name, final int i) {
 		final String alias = generateTableAlias( name, getSubclassPropertyTableNumber( i ) );
 		String[] cols = getSubclassPropertyColumnNames( i );
 		String[] templates = getSubclassPropertyFormulaTemplateClosure()[i];
 		String[] result = new String[cols.length];
 		for ( int j = 0; j < cols.length; j++ ) {
 			if ( cols[j] == null ) {
 				result[j] = StringHelper.replace( templates[j], Template.TEMPLATE, alias );
 			}
 			else {
 				result[j] = StringHelper.qualify( alias, cols[j] );
 			}
 		}
 		return result;
 	}
 
 	private int getSubclassPropertyIndex(String propertyName) {
 		return ArrayHelper.indexOf(subclassPropertyNameClosure, propertyName);
 	}
 
 	protected String[] getPropertySubclassNames() {
 		return propertySubclassNames;
 	}
 
 	public String[] getPropertyColumnNames(int i) {
 		return propertyColumnNames[i];
 	}
 
 	public String[] getPropertyColumnWriters(int i) {
 		return propertyColumnWriters[i];
 	}
 
 	protected int getPropertyColumnSpan(int i) {
 		return propertyColumnSpans[i];
 	}
 
 	protected boolean hasFormulaProperties() {
 		return hasFormulaProperties;
 	}
 
 	public FetchMode getFetchMode(int i) {
 		return subclassPropertyFetchModeClosure[i];
 	}
 
 	public CascadeStyle getCascadeStyle(int i) {
 		return subclassPropertyCascadeStyleClosure[i];
 	}
 
 	public Type getSubclassPropertyType(int i) {
 		return subclassPropertyTypeClosure[i];
 	}
 
 	public String getSubclassPropertyName(int i) {
 		return subclassPropertyNameClosure[i];
 	}
 
 	public int countSubclassProperties() {
 		return subclassPropertyTypeClosure.length;
 	}
 
 	public String[] getSubclassPropertyColumnNames(int i) {
 		return subclassPropertyColumnNameClosure[i];
 	}
 
 	public boolean isDefinedOnSubclass(int i) {
 		return propertyDefinedOnSubclass[i];
 	}
 
 	@Override
 	public String[][] getSubclassPropertyFormulaTemplateClosure() {
 		return subclassPropertyFormulaTemplateClosure;
 	}
 
 	protected Type[] getSubclassPropertyTypeClosure() {
 		return subclassPropertyTypeClosure;
 	}
 
 	protected String[][] getSubclassPropertyColumnNameClosure() {
 		return subclassPropertyColumnNameClosure;
 	}
 
 	public String[][] getSubclassPropertyColumnReaderClosure() {
 		return subclassPropertyColumnReaderClosure;
 	}
 
 	public String[][] getSubclassPropertyColumnReaderTemplateClosure() {
 		return subclassPropertyColumnReaderTemplateClosure;
 	}
 
 	protected String[] getSubclassPropertyNameClosure() {
 		return subclassPropertyNameClosure;
 	}
 
 	protected String[] getSubclassPropertySubclassNameClosure() {
 		return subclassPropertySubclassNameClosure;
 	}
 
 	protected String[] getSubclassColumnClosure() {
 		return subclassColumnClosure;
 	}
 
 	protected String[] getSubclassColumnAliasClosure() {
 		return subclassColumnAliasClosure;
 	}
 
 	public String[] getSubclassColumnReaderTemplateClosure() {
 		return subclassColumnReaderTemplateClosure;
 	}
 
 	protected String[] getSubclassFormulaClosure() {
 		return subclassFormulaClosure;
 	}
 
 	protected String[] getSubclassFormulaTemplateClosure() {
 		return subclassFormulaTemplateClosure;
 	}
 
 	protected String[] getSubclassFormulaAliasClosure() {
 		return subclassFormulaAliasClosure;
 	}
 
 	public String[] getSubclassPropertyColumnAliases(String propertyName, String suffix) {
 		String rawAliases[] = ( String[] ) subclassPropertyAliases.get( propertyName );
 
 		if ( rawAliases == null ) {
 			return null;
 		}
 
 		String result[] = new String[rawAliases.length];
 		for ( int i = 0; i < rawAliases.length; i++ ) {
 			result[i] = new Alias( suffix ).toUnquotedAliasString( rawAliases[i] );
 		}
 		return result;
 	}
 
 	public String[] getSubclassPropertyColumnNames(String propertyName) {
 		//TODO: should we allow suffixes on these ?
 		return ( String[] ) subclassPropertyColumnNames.get( propertyName );
 	}
 
 
 
 	//This is really ugly, but necessary:
 	/**
 	 * Must be called by subclasses, at the end of their constructors
 	 */
 	protected void initSubclassPropertyAliasesMap(PersistentClass model) throws MappingException {
 
 		// ALIASES
 		internalInitSubclassPropertyAliasesMap( null, model.getSubclassPropertyClosureIterator() );
 
 		// aliases for identifier ( alias.id ); skip if the entity defines a non-id property named 'id'
 		if ( ! entityMetamodel.hasNonIdentifierPropertyNamedId() ) {
 			subclassPropertyAliases.put( ENTITY_ID, getIdentifierAliases() );
 			subclassPropertyColumnNames.put( ENTITY_ID, getIdentifierColumnNames() );
 		}
 
 		// aliases named identifier ( alias.idname )
 		if ( hasIdentifierProperty() ) {
 			subclassPropertyAliases.put( getIdentifierPropertyName(), getIdentifierAliases() );
 			subclassPropertyColumnNames.put( getIdentifierPropertyName(), getIdentifierColumnNames() );
 		}
 
 		// aliases for composite-id's
 		if ( getIdentifierType().isComponentType() ) {
 			// Fetch embedded identifiers propertynames from the "virtual" identifier component
 			CompositeType componentId = ( CompositeType ) getIdentifierType();
 			String[] idPropertyNames = componentId.getPropertyNames();
 			String[] idAliases = getIdentifierAliases();
 			String[] idColumnNames = getIdentifierColumnNames();
 
 			for ( int i = 0; i < idPropertyNames.length; i++ ) {
 				if ( entityMetamodel.hasNonIdentifierPropertyNamedId() ) {
 					subclassPropertyAliases.put(
 							ENTITY_ID + "." + idPropertyNames[i],
 							new String[] { idAliases[i] }
 					);
 					subclassPropertyColumnNames.put(
 							ENTITY_ID + "." + getIdentifierPropertyName() + "." + idPropertyNames[i],
 							new String[] { idColumnNames[i] }
 					);
 				}
 //				if (hasIdentifierProperty() && !ENTITY_ID.equals( getIdentifierPropertyName() ) ) {
 				if ( hasIdentifierProperty() ) {
 					subclassPropertyAliases.put(
 							getIdentifierPropertyName() + "." + idPropertyNames[i],
 							new String[] { idAliases[i] }
 					);
 					subclassPropertyColumnNames.put(
 							getIdentifierPropertyName() + "." + idPropertyNames[i],
 							new String[] { idColumnNames[i] }
 					);
 				}
 				else {
 					// embedded composite ids ( alias.idname1, alias.idname2 )
 					subclassPropertyAliases.put( idPropertyNames[i], new String[] { idAliases[i] } );
 					subclassPropertyColumnNames.put( idPropertyNames[i],  new String[] { idColumnNames[i] } );
 				}
 			}
 		}
 
 		if ( entityMetamodel.isPolymorphic() ) {
 			subclassPropertyAliases.put( ENTITY_CLASS, new String[] { getDiscriminatorAlias() } );
 			subclassPropertyColumnNames.put( ENTITY_CLASS, new String[] { getDiscriminatorColumnName() } );
 		}
 
 	}
 
 	/**
 	 * Must be called by subclasses, at the end of their constructors
 	 */
 	protected void initSubclassPropertyAliasesMap(EntityBinding model) throws MappingException {
 
 		// ALIASES
 
 		// TODO: Fix when subclasses are working (HHH-6337)
 		//internalInitSubclassPropertyAliasesMap( null, model.getSubclassPropertyClosureIterator() );
 
 		// aliases for identifier ( alias.id ); skip if the entity defines a non-id property named 'id'
 		if ( ! entityMetamodel.hasNonIdentifierPropertyNamedId() ) {
 			subclassPropertyAliases.put( ENTITY_ID, getIdentifierAliases() );
 			subclassPropertyColumnNames.put( ENTITY_ID, getIdentifierColumnNames() );
 		}
 
 		// aliases named identifier ( alias.idname )
 		if ( hasIdentifierProperty() ) {
 			subclassPropertyAliases.put( getIdentifierPropertyName(), getIdentifierAliases() );
 			subclassPropertyColumnNames.put( getIdentifierPropertyName(), getIdentifierColumnNames() );
 		}
 
 		// aliases for composite-id's
 		if ( getIdentifierType().isComponentType() ) {
 			// Fetch embedded identifiers propertynames from the "virtual" identifier component
 			CompositeType componentId = ( CompositeType ) getIdentifierType();
 			String[] idPropertyNames = componentId.getPropertyNames();
 			String[] idAliases = getIdentifierAliases();
 			String[] idColumnNames = getIdentifierColumnNames();
 
 			for ( int i = 0; i < idPropertyNames.length; i++ ) {
 				if ( entityMetamodel.hasNonIdentifierPropertyNamedId() ) {
 					subclassPropertyAliases.put(
 							ENTITY_ID + "." + idPropertyNames[i],
 							new String[] { idAliases[i] }
 					);
 					subclassPropertyColumnNames.put(
 							ENTITY_ID + "." + getIdentifierPropertyName() + "." + idPropertyNames[i],
 							new String[] { idColumnNames[i] }
 					);
 				}
 //				if (hasIdentifierProperty() && !ENTITY_ID.equals( getIdentifierPropertyName() ) ) {
 				if ( hasIdentifierProperty() ) {
 					subclassPropertyAliases.put(
 							getIdentifierPropertyName() + "." + idPropertyNames[i],
 							new String[] { idAliases[i] }
 					);
 					subclassPropertyColumnNames.put(
 							getIdentifierPropertyName() + "." + idPropertyNames[i],
 							new String[] { idColumnNames[i] }
 					);
 				}
 				else {
 					// embedded composite ids ( alias.idname1, alias.idname2 )
 					subclassPropertyAliases.put( idPropertyNames[i], new String[] { idAliases[i] } );
 					subclassPropertyColumnNames.put( idPropertyNames[i],  new String[] { idColumnNames[i] } );
 				}
 			}
 		}
 
 		if ( entityMetamodel.isPolymorphic() ) {
 			subclassPropertyAliases.put( ENTITY_CLASS, new String[] { getDiscriminatorAlias() } );
 			subclassPropertyColumnNames.put( ENTITY_CLASS, new String[] { getDiscriminatorColumnName() } );
 		}
 
 	}
 
 	private void internalInitSubclassPropertyAliasesMap(String path, Iterator propertyIterator) {
 		while ( propertyIterator.hasNext() ) {
 
 			Property prop = ( Property ) propertyIterator.next();
 			String propname = path == null ? prop.getName() : path + "." + prop.getName();
 			if ( prop.isComposite() ) {
 				Component component = ( Component ) prop.getValue();
 				Iterator compProps = component.getPropertyIterator();
 				internalInitSubclassPropertyAliasesMap( propname, compProps );
 			}
 			else {
 				String[] aliases = new String[prop.getColumnSpan()];
 				String[] cols = new String[prop.getColumnSpan()];
 				Iterator colIter = prop.getColumnIterator();
 				int l = 0;
 				while ( colIter.hasNext() ) {
 					Selectable thing = ( Selectable ) colIter.next();
 					aliases[l] = thing.getAlias( getFactory().getDialect(), prop.getValue().getTable() );
 					cols[l] = thing.getText( getFactory().getDialect() ); // TODO: skip formulas?
 					l++;
 				}
 
 				subclassPropertyAliases.put( propname, aliases );
 				subclassPropertyColumnNames.put( propname, cols );
 			}
 		}
 
 	}
 
 	public Object loadByUniqueKey(
 			String propertyName,
 			Object uniqueKey,
 			SessionImplementor session) throws HibernateException {
 		return getAppropriateUniqueKeyLoader( propertyName, session ).loadByUniqueKey( session, uniqueKey );
 	}
 
 	private EntityLoader getAppropriateUniqueKeyLoader(String propertyName, SessionImplementor session) {
 		final boolean useStaticLoader = !session.getLoadQueryInfluencers().hasEnabledFilters()
 				&& !session.getLoadQueryInfluencers().hasEnabledFetchProfiles()
 				&& propertyName.indexOf('.')<0; //ugly little workaround for fact that createUniqueKeyLoaders() does not handle component properties
 
 		if ( useStaticLoader ) {
 			return ( EntityLoader ) uniqueKeyLoaders.get( propertyName );
 		}
 		else {
 			return createUniqueKeyLoader(
 					propertyMapping.toType( propertyName ),
 					propertyMapping.toColumns( propertyName ),
 					session.getLoadQueryInfluencers()
 			);
 		}
 	}
 
 	public int getPropertyIndex(String propertyName) {
 		return entityMetamodel.getPropertyIndex(propertyName);
 	}
 
 	protected void createUniqueKeyLoaders() throws MappingException {
 		Type[] propertyTypes = getPropertyTypes();
 		String[] propertyNames = getPropertyNames();
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			if ( propertyUniqueness[i] ) {
 				//don't need filters for the static loaders
 				uniqueKeyLoaders.put(
 						propertyNames[i],
 						createUniqueKeyLoader(
 								propertyTypes[i],
 								getPropertyColumnNames( i ),
 								LoadQueryInfluencers.NONE
 						)
 				);
 				//TODO: create uk loaders for component properties
 			}
 		}
 	}
 
 	private EntityLoader createUniqueKeyLoader(
 			Type uniqueKeyType,
 			String[] columns,
 			LoadQueryInfluencers loadQueryInfluencers) {
 		if ( uniqueKeyType.isEntityType() ) {
 			String className = ( ( EntityType ) uniqueKeyType ).getAssociatedEntityName();
 			uniqueKeyType = getFactory().getEntityPersister( className ).getIdentifierType();
 		}
 		return new EntityLoader(
 				this,
 				columns,
 				uniqueKeyType,
 				1,
 				LockMode.NONE,
 				getFactory(),
 				loadQueryInfluencers
 		);
 	}
 
 	protected String getSQLWhereString(String alias) {
 		return StringHelper.replace( sqlWhereStringTemplate, Template.TEMPLATE, alias );
 	}
 
 	protected boolean hasWhere() {
 		return sqlWhereString != null;
 	}
 
 	private void initOrdinaryPropertyPaths(Mapping mapping) throws MappingException {
 		for ( int i = 0; i < getSubclassPropertyNameClosure().length; i++ ) {
 			propertyMapping.initPropertyPaths( getSubclassPropertyNameClosure()[i],
 					getSubclassPropertyTypeClosure()[i],
 					getSubclassPropertyColumnNameClosure()[i],
 					getSubclassPropertyColumnReaderClosure()[i],
 					getSubclassPropertyColumnReaderTemplateClosure()[i],
 					getSubclassPropertyFormulaTemplateClosure()[i],
 					mapping );
 		}
 	}
 
 	private void initIdentifierPropertyPaths(Mapping mapping) throws MappingException {
 		String idProp = getIdentifierPropertyName();
 		if ( idProp != null ) {
 			propertyMapping.initPropertyPaths( idProp, getIdentifierType(), getIdentifierColumnNames(),
 					getIdentifierColumnReaders(), getIdentifierColumnReaderTemplates(), null, mapping );
 		}
 		if ( entityMetamodel.getIdentifierProperty().isEmbedded() ) {
 			propertyMapping.initPropertyPaths( null, getIdentifierType(), getIdentifierColumnNames(),
 					getIdentifierColumnReaders(), getIdentifierColumnReaderTemplates(), null, mapping );
 		}
 		if ( ! entityMetamodel.hasNonIdentifierPropertyNamedId() ) {
 			propertyMapping.initPropertyPaths( ENTITY_ID, getIdentifierType(), getIdentifierColumnNames(),
 					getIdentifierColumnReaders(), getIdentifierColumnReaderTemplates(), null, mapping );
 		}
 	}
 
 	private void initDiscriminatorPropertyPath(Mapping mapping) throws MappingException {
 		propertyMapping.initPropertyPaths( ENTITY_CLASS,
 				getDiscriminatorType(),
 				new String[]{getDiscriminatorColumnName()},
 				new String[]{getDiscriminatorColumnReaders()},
 				new String[]{getDiscriminatorColumnReaderTemplate()},
 				new String[]{getDiscriminatorFormulaTemplate()},
 				getFactory() );
 	}
 
 	protected void initPropertyPaths(Mapping mapping) throws MappingException {
 		initOrdinaryPropertyPaths(mapping);
 		initOrdinaryPropertyPaths(mapping); //do two passes, for collection property-ref!
 		initIdentifierPropertyPaths(mapping);
 		if ( entityMetamodel.isPolymorphic() ) {
 			initDiscriminatorPropertyPath( mapping );
 		}
 	}
 
 	protected UniqueEntityLoader createEntityLoader(
 			LockMode lockMode,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		//TODO: disable batch loading if lockMode > READ?
 		return BatchingEntityLoaderBuilder.getBuilder( getFactory() )
 				.buildLoader( this, batchSize, lockMode, getFactory(), loadQueryInfluencers );
 	}
 
 	protected UniqueEntityLoader createEntityLoader(
 			LockOptions lockOptions,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		//TODO: disable batch loading if lockMode > READ?
 		return BatchingEntityLoaderBuilder.getBuilder( getFactory() )
 				.buildLoader( this, batchSize, lockOptions, getFactory(), loadQueryInfluencers );
 	}
 
+	/**
+	 * Used internally to create static loaders.  These are the default set of loaders used to handle get()/load()
+	 * processing.  lock() handling is done by the LockingStrategy instances (see {@link #getLocker})
+	 *
+	 * @param lockMode The lock mode to apply to the thing being loaded.
+	 * @return
+	 *
+	 * @throws MappingException
+	 */
 	protected UniqueEntityLoader createEntityLoader(LockMode lockMode) throws MappingException {
 		return createEntityLoader( lockMode, LoadQueryInfluencers.NONE );
 	}
 
 	protected boolean check(int rows, Serializable id, int tableNumber, Expectation expectation, PreparedStatement statement) throws HibernateException {
 		try {
 			expectation.verifyOutcome( rows, statement, -1 );
 		}
 		catch( StaleStateException e ) {
 			if ( !isNullableTable( tableNumber ) ) {
 				if ( getFactory().getStatistics().isStatisticsEnabled() ) {
 					getFactory().getStatisticsImplementor()
 							.optimisticFailure( getEntityName() );
 				}
 				throw new StaleObjectStateException( getEntityName(), id );
 			}
 			return false;
 		}
 		catch( TooManyRowsAffectedException e ) {
 			throw new HibernateException(
 					"Duplicate identifier in table for: " +
 					MessageHelper.infoString( this, id, getFactory() )
 			);
 		}
 		catch ( Throwable t ) {
 			return false;
 		}
 		return true;
 	}
 
 	protected String generateUpdateString(boolean[] includeProperty, int j, boolean useRowId) {
 		return generateUpdateString( includeProperty, j, null, useRowId );
 	}
 
 	/**
 	 * Generate the SQL that updates a row by id (and version)
 	 */
 	protected String generateUpdateString(final boolean[] includeProperty,
 										  final int j,
 										  final Object[] oldFields,
 										  final boolean useRowId) {
 
 		Update update = new Update( getFactory().getDialect() ).setTableName( getTableName( j ) );
 
 		// select the correct row by either pk or rowid
 		if ( useRowId ) {
 			update.addPrimaryKeyColumns( new String[]{rowIdName} ); //TODO: eventually, rowIdName[j]
 		}
 		else {
 			update.addPrimaryKeyColumns( getKeyColumns( j ) );
 		}
 
 		boolean hasColumns = false;
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j ) 
 					&& !lobProperties.contains( i ) ) {
 				// this is a property of the table, which we are updating
 				update.addColumns( getPropertyColumnNames(i),
 						propertyColumnUpdateable[i], propertyColumnWriters[i] );
 				hasColumns = hasColumns || getPropertyColumnSpan( i ) > 0;
 			}
 		}
 		
 		// HHH-4635
 		// Oracle expects all Lob properties to be last in inserts
 		// and updates.  Insert them at the end.
 		for ( int i : lobProperties ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j ) ) {
 				// this property belongs on the table and is to be inserted
 				update.addColumns( getPropertyColumnNames(i),
 						propertyColumnUpdateable[i], propertyColumnWriters[i] );
 				hasColumns = true;
 			}
 		}
 
 		if ( j == 0 && isVersioned() && entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.VERSION ) {
 			// this is the root (versioned) table, and we are using version-based
 			// optimistic locking;  if we are not updating the version, also don't
 			// check it (unless this is a "generated" version column)!
 			if ( checkVersion( includeProperty ) ) {
 				update.setVersionColumnName( getVersionColumnName() );
 				hasColumns = true;
 			}
 		}
 		else if ( isAllOrDirtyOptLocking() && oldFields != null ) {
 			// we are using "all" or "dirty" property-based optimistic locking
 
 			boolean[] includeInWhere = entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.ALL
 					? getPropertyUpdateability() //optimistic-lock="all", include all updatable properties
 					: includeProperty; 			 //optimistic-lock="dirty", include all properties we are updating this time
 
 			boolean[] versionability = getPropertyVersionability();
 			Type[] types = getPropertyTypes();
 			for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 				boolean include = includeInWhere[i] &&
 						isPropertyOfTable( i, j ) &&
 						versionability[i];
 				if ( include ) {
 					// this property belongs to the table, and it is not specifically
 					// excluded from optimistic locking by optimistic-lock="false"
 					String[] propertyColumnNames = getPropertyColumnNames( i );
 					String[] propertyColumnWriters = getPropertyColumnWriters( i );
 					boolean[] propertyNullness = types[i].toColumnNullness( oldFields[i], getFactory() );
 					for ( int k=0; k<propertyNullness.length; k++ ) {
 						if ( propertyNullness[k] ) {
 							update.addWhereColumn( propertyColumnNames[k], "=" + propertyColumnWriters[k] );
 						}
 						else {
 							update.addWhereColumn( propertyColumnNames[k], " is null" );
 						}
 					}
 				}
 			}
 
 		}
 
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			update.setComment( "update " + getEntityName() );
 		}
 
 		return hasColumns ? update.toStatementString() : null;
 	}
 
 	private boolean checkVersion(final boolean[] includeProperty) {
         return includeProperty[ getVersionProperty() ] ||
 				entityMetamodel.getPropertyUpdateGenerationInclusions()[ getVersionProperty() ] != ValueInclusion.NONE;
 	}
 
 	protected String generateInsertString(boolean[] includeProperty, int j) {
 		return generateInsertString( false, includeProperty, j );
 	}
 
 	protected String generateInsertString(boolean identityInsert, boolean[] includeProperty) {
 		return generateInsertString( identityInsert, includeProperty, 0 );
 	}
 
 	/**
 	 * Generate the SQL that inserts a row
 	 */
 	protected String generateInsertString(boolean identityInsert,
 			boolean[] includeProperty, int j) {
 
 		// todo : remove the identityInsert param and variations;
 		//   identity-insert strings are now generated from generateIdentityInsertString()
 
 		Insert insert = new Insert( getFactory().getDialect() )
 				.setTableName( getTableName( j ) );
 
 		// add normal properties
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			
 			if ( includeProperty[i] && isPropertyOfTable( i, j )
 					&& !lobProperties.contains( i ) ) {
 				// this property belongs on the table and is to be inserted
 				insert.addColumns( getPropertyColumnNames(i),
 						propertyColumnInsertable[i],
 						propertyColumnWriters[i] );
 			}
 		}
 
 		// add the discriminator
 		if ( j == 0 ) {
 			addDiscriminatorToInsert( insert );
 		}
 
 		// add the primary key
 		if ( j == 0 && identityInsert ) {
 			insert.addIdentityColumn( getKeyColumns( 0 )[0] );
 		}
 		else {
 			insert.addColumns( getKeyColumns( j ) );
 		}
 
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			insert.setComment( "insert " + getEntityName() );
 		}
 		
 		// HHH-4635
 		// Oracle expects all Lob properties to be last in inserts
 		// and updates.  Insert them at the end.
 		for ( int i : lobProperties ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j ) ) {
 				// this property belongs on the table and is to be inserted
 				insert.addColumns( getPropertyColumnNames(i),
 						propertyColumnInsertable[i],
 						propertyColumnWriters[i] );
 			}
 		}
 
 		String result = insert.toStatementString();
 
 		// append the SQL to return the generated identifier
 		if ( j == 0 && identityInsert && useInsertSelectIdentity() ) { //TODO: suck into Insert
 			result = getFactory().getDialect().appendIdentitySelectToInsert( result );
 		}
 
 		return result;
 	}
 
 	/**
 	 * Used to generate an insery statement against the root table in the
 	 * case of identifier generation strategies where the insert statement
 	 * executions actually generates the identifier value.
 	 *
 	 * @param includeProperty indices of the properties to include in the
 	 * insert statement.
 	 * @return The insert SQL statement string
 	 */
 	protected String generateIdentityInsertString(boolean[] includeProperty) {
 		Insert insert = identityDelegate.prepareIdentifierGeneratingInsert();
 		insert.setTableName( getTableName( 0 ) );
 
 		// add normal properties except lobs
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, 0 ) && !lobProperties.contains( i ) ) {
 				// this property belongs on the table and is to be inserted
 				insert.addColumns( getPropertyColumnNames(i), propertyColumnInsertable[i], propertyColumnWriters[i] );
 			}
 		}
 
 		// HHH-4635 & HHH-8103
 		// Oracle expects all Lob properties to be last in inserts
 		// and updates.  Insert them at the end.
 		for ( int i : lobProperties ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, 0 ) ) {
 				insert.addColumns( getPropertyColumnNames(i), propertyColumnInsertable[i], propertyColumnWriters[i] );
 			}
 		}
 
 		// add the discriminator
 		addDiscriminatorToInsert( insert );
 
 		// delegate already handles PK columns
 
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			insert.setComment( "insert " + getEntityName() );
 		}
 
 		return insert.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL that deletes a row by id (and version)
 	 */
 	protected String generateDeleteString(int j) {
 		Delete delete = new Delete()
 				.setTableName( getTableName( j ) )
 				.addPrimaryKeyColumns( getKeyColumns( j ) );
 		if ( j == 0 ) {
 			delete.setVersionColumnName( getVersionColumnName() );
 		}
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			delete.setComment( "delete " + getEntityName() );
 		}
 		return delete.toStatementString();
 	}
 
 	protected int dehydrate(
 			Serializable id,
 			Object[] fields,
 			boolean[] includeProperty,
 			boolean[][] includeColumns,
 			int j,
 			PreparedStatement st,
 			SessionImplementor session,
 			boolean isUpdate) throws HibernateException, SQLException {
 		return dehydrate( id, fields, null, includeProperty, includeColumns, j, st, session, 1, isUpdate );
 	}
 
 	/**
 	 * Marshall the fields of a persistent instance to a prepared statement
 	 */
 	protected int dehydrate(
 			final Serializable id,
 	        final Object[] fields,
 	        final Object rowId,
 	        final boolean[] includeProperty,
 	        final boolean[][] includeColumns,
 	        final int j,
 	        final PreparedStatement ps,
 	        final SessionImplementor session,
 	        int index,
 	        boolean isUpdate ) throws SQLException, HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Dehydrating entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j )
 					&& !lobProperties.contains( i )) {
 				getPropertyTypes()[i].nullSafeSet( ps, fields[i], index, includeColumns[i], session );
 				index += ArrayHelper.countTrue( includeColumns[i] ); //TODO:  this is kinda slow...
 			}
 		}
 		
 		if ( !isUpdate ) {
 			index += dehydrateId( id, rowId, ps, session, index );
 		}
 		
 		// HHH-4635
 		// Oracle expects all Lob properties to be last in inserts
 		// and updates.  Insert them at the end.
 		for ( int i : lobProperties ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j ) ) {
 				getPropertyTypes()[i].nullSafeSet( ps, fields[i], index, includeColumns[i], session );
 				index += ArrayHelper.countTrue( includeColumns[i] ); //TODO:  this is kinda slow...
 			}
 		}
 		
 		if ( isUpdate ) {
 			index += dehydrateId( id, rowId, ps, session, index );
 		}
 
 		return index;
 
 	}
 	
 	private int dehydrateId( 
 			final Serializable id,
 			final Object rowId,
 			final PreparedStatement ps,
 	        final SessionImplementor session,
 			int index ) throws SQLException {
 		if ( rowId != null ) {
 			ps.setObject( index, rowId );
 			return 1;
 		} else if ( id != null ) {
 			getIdentifierType().nullSafeSet( ps, id, index, session );
 			return getIdentifierColumnSpan();
 		}
 		return 0;
 	}
 
 	/**
 	 * Unmarshall the fields of a persistent instance from a result set,
 	 * without resolving associations or collections. Question: should
 	 * this really be here, or should it be sent back to Loader?
 	 */
 	public Object[] hydrate(
 			final ResultSet rs,
 	        final Serializable id,
 	        final Object object,
 	        final Loadable rootLoadable,
 	        final String[][] suffixedPropertyColumns,
 	        final boolean allProperties,
 	        final SessionImplementor session) throws SQLException, HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Hydrating entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		final AbstractEntityPersister rootPersister = (AbstractEntityPersister) rootLoadable;
 
 		final boolean hasDeferred = rootPersister.hasSequentialSelect();
 		PreparedStatement sequentialSelect = null;
 		ResultSet sequentialResultSet = null;
 		boolean sequentialSelectEmpty = false;
 		try {
 
 			if ( hasDeferred ) {
 				final String sql = rootPersister.getSequentialSelect( getEntityName() );
 				if ( sql != null ) {
 					//TODO: I am not so sure about the exception handling in this bit!
 					sequentialSelect = session.getTransactionCoordinator()
 							.getJdbcCoordinator()
 							.getStatementPreparer()
 							.prepareStatement( sql );
 					rootPersister.getIdentifierType().nullSafeSet( sequentialSelect, id, 1, session );
 					sequentialResultSet = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( sequentialSelect );
 					if ( !sequentialResultSet.next() ) {
 						// TODO: Deal with the "optional" attribute in the <join> mapping;
 						// this code assumes that optional defaults to "true" because it
 						// doesn't actually seem to work in the fetch="join" code
 						//
 						// Note that actual proper handling of optional-ality here is actually
 						// more involved than this patch assumes.  Remember that we might have
 						// multiple <join/> mappings associated with a single entity.  Really
 						// a couple of things need to happen to properly handle optional here:
 						//  1) First and foremost, when handling multiple <join/>s, we really
 						//      should be using the entity root table as the driving table;
 						//      another option here would be to choose some non-optional joined
 						//      table to use as the driving table.  In all likelihood, just using
 						//      the root table is much simplier
 						//  2) Need to add the FK columns corresponding to each joined table
 						//      to the generated select list; these would then be used when
 						//      iterating the result set to determine whether all non-optional
 						//      data is present
 						// My initial thoughts on the best way to deal with this would be
 						// to introduce a new SequentialSelect abstraction that actually gets
 						// generated in the persisters (ok, SingleTable...) and utilized here.
 						// It would encapsulated all this required optional-ality checking...
 						sequentialSelectEmpty = true;
 					}
 				}
 			}
 
 			final String[] propNames = getPropertyNames();
 			final Type[] types = getPropertyTypes();
 			final Object[] values = new Object[types.length];
 			final boolean[] laziness = getPropertyLaziness();
 			final String[] propSubclassNames = getSubclassPropertySubclassNameClosure();
 
 			for ( int i = 0; i < types.length; i++ ) {
 				if ( !propertySelectable[i] ) {
 					values[i] = BackrefPropertyAccessor.UNKNOWN;
 				}
 				else if ( allProperties || !laziness[i] ) {
 					//decide which ResultSet to get the property value from:
 					final boolean propertyIsDeferred = hasDeferred &&
 							rootPersister.isSubclassPropertyDeferred( propNames[i], propSubclassNames[i] );
 					if ( propertyIsDeferred && sequentialSelectEmpty ) {
 						values[i] = null;
 					}
 					else {
 						final ResultSet propertyResultSet = propertyIsDeferred ? sequentialResultSet : rs;
 						final String[] cols = propertyIsDeferred ? propertyColumnAliases[i] : suffixedPropertyColumns[i];
 						values[i] = types[i].hydrate( propertyResultSet, cols, session, object );
 					}
 				}
 				else {
 					values[i] = LazyPropertyInitializer.UNFETCHED_PROPERTY;
 				}
 			}
 
 			if ( sequentialResultSet != null ) {
 				session.getTransactionCoordinator().getJdbcCoordinator().release( sequentialResultSet, sequentialSelect );
 			}
 
 			return values;
 
 		}
 		finally {
 			if ( sequentialSelect != null ) {
 				session.getTransactionCoordinator().getJdbcCoordinator().release( sequentialSelect );
 			}
 		}
 	}
 
 	protected boolean useInsertSelectIdentity() {
 		return !useGetGeneratedKeys() && getFactory().getDialect().supportsInsertSelectIdentity();
 	}
 
 	protected boolean useGetGeneratedKeys() {
 		return getFactory().getSettings().isGetGeneratedKeysEnabled();
 	}
 
 	protected String getSequentialSelect(String entityName) {
 		throw new UnsupportedOperationException("no sequential selects");
 	}
 
 	/**
 	 * Perform an SQL INSERT, and then retrieve a generated identifier.
 	 * <p/>
 	 * This form is used for PostInsertIdentifierGenerator-style ids (IDENTITY,
 	 * select, etc).
 	 */
 	protected Serializable insert(
 			final Object[] fields,
 	        final boolean[] notNull,
 	        String sql,
 	        final Object object,
 	        final SessionImplementor session) throws HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Inserting entity: {0} (native id)", getEntityName() );
 			if ( isVersioned() ) {
 				LOG.tracev( "Version: {0}", Versioning.getVersion( fields, this ) );
 			}
 		}
 
 		Binder binder = new Binder() {
 			public void bindValues(PreparedStatement ps) throws SQLException {
 				dehydrate( null, fields, notNull, propertyColumnInsertable, 0, ps, session, false );
 			}
 			public Object getEntity() {
 				return object;
 			}
 		};
 
 		return identityDelegate.performInsert( sql, session, binder );
 	}
 
 	public String getIdentitySelectString() {
 		//TODO: cache this in an instvar
 		return getFactory().getDialect().getIdentitySelectString(
 				getTableName(0),
 				getKeyColumns(0)[0],
 				getIdentifierType().sqlTypes( getFactory() )[0]
 		);
 	}
 
 	public String getSelectByUniqueKeyString(String propertyName) {
 		return new SimpleSelect( getFactory().getDialect() )
 			.setTableName( getTableName(0) )
 			.addColumns( getKeyColumns(0) )
 			.addCondition( getPropertyColumnNames(propertyName), "=?" )
 			.toStatementString();
 	}
 
 	private BasicBatchKey inserBatchKey;
 
 	/**
 	 * Perform an SQL INSERT.
 	 * <p/>
 	 * This for is used for all non-root tables as well as the root table
 	 * in cases where the identifier value is known before the insert occurs.
 	 */
 	protected void insert(
 			final Serializable id,
 	        final Object[] fields,
 	        final boolean[] notNull,
 	        final int j,
 	        final String sql,
 	        final Object object,
 	        final SessionImplementor session) throws HibernateException {
 
 		if ( isInverseTable( j ) ) {
 			return;
 		}
 
 		//note: it is conceptually possible that a UserType could map null to
 		//	  a non-null value, so the following is arguable:
 		if ( isNullableTable( j ) && isAllNull( fields, j ) ) {
 			return;
 		}
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Inserting entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 			if ( j == 0 && isVersioned() )
 				LOG.tracev( "Version: {0}", Versioning.getVersion( fields, this ) );
 		}
 
 		// TODO : shouldn't inserts be Expectations.NONE?
 		final Expectation expectation = Expectations.appropriateExpectation( insertResultCheckStyles[j] );
 		// we can't batch joined inserts, *especially* not if it is an identity insert;
 		// nor can we batch statements where the expectation is based on an output param
 		final boolean useBatch = j == 0 && expectation.canBeBatched();
 		if ( useBatch && inserBatchKey == null ) {
 			inserBatchKey = new BasicBatchKey(
 					getEntityName() + "#INSERT",
 					expectation
 			);
 		}
 		final boolean callable = isInsertCallable( j );
 
 		try {
 			// Render the SQL query
 			final PreparedStatement insert;
 			if ( useBatch ) {
 				insert = session.getTransactionCoordinator()
 						.getJdbcCoordinator()
 						.getBatch( inserBatchKey )
 						.getBatchStatement( sql, callable );
 			}
 			else {
 				insert = session.getTransactionCoordinator()
 						.getJdbcCoordinator()
 						.getStatementPreparer()
 						.prepareStatement( sql, callable );
 			}
 
 			try {
 				int index = 1;
 				index += expectation.prepare( insert );
 
 				// Write the values of fields onto the prepared statement - we MUST use the state at the time the
 				// insert was issued (cos of foreign key constraints). Not necessarily the object's current state
 
 				dehydrate( id, fields, null, notNull, propertyColumnInsertable, j, insert, session, index, false );
 
 				if ( useBatch ) {
 					session.getTransactionCoordinator().getJdbcCoordinator().getBatch( inserBatchKey ).addToBatch();
 				}
 				else {
 					expectation.verifyOutcome( session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( insert ), insert, -1 );
 				}
 
 			}
 			catch ( SQLException e ) {
 				if ( useBatch ) {
 					session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
 				}
 				throw e;
 			}
 			finally {
 				if ( !useBatch ) {
 					session.getTransactionCoordinator().getJdbcCoordinator().release( insert );
 				}
 			}
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"could not insert: " + MessageHelper.infoString( this ),
 					sql
 			);
 		}
 
 	}
 
 	/**
 	 * Perform an SQL UPDATE or SQL INSERT
 	 */
 	protected void updateOrInsert(
 			final Serializable id,
 	        final Object[] fields,
 	        final Object[] oldFields,
 	        final Object rowId,
 	        final boolean[] includeProperty,
 	        final int j,
 	        final Object oldVersion,
 	        final Object object,
 	        final String sql,
 	        final SessionImplementor session) throws HibernateException {
 
 		if ( !isInverseTable( j ) ) {
 
 			final boolean isRowToUpdate;
 			if ( isNullableTable( j ) && oldFields != null && isAllNull( oldFields, j ) ) {
 				//don't bother trying to update, we know there is no row there yet
 				isRowToUpdate = false;
 			}
 			else if ( isNullableTable( j ) && isAllNull( fields, j ) ) {
 				//if all fields are null, we might need to delete existing row
 				isRowToUpdate = true;
 				delete( id, oldVersion, j, object, getSQLDeleteStrings()[j], session, null );
 			}
 			else {
 				//there is probably a row there, so try to update
 				//if no rows were updated, we will find out
 				isRowToUpdate = update( id, fields, oldFields, rowId, includeProperty, j, oldVersion, object, sql, session );
 			}
 
 			if ( !isRowToUpdate && !isAllNull( fields, j ) ) {
 				// assume that the row was not there since it previously had only null
 				// values, so do an INSERT instead
 				//TODO: does not respect dynamic-insert
 				insert( id, fields, getPropertyInsertability(), j, getSQLInsertStrings()[j], object, session );
 			}
 
 		}
 
 	}
 
 	private BasicBatchKey updateBatchKey;
 
 	protected boolean update(
 			final Serializable id,
 	        final Object[] fields,
 	        final Object[] oldFields,
 	        final Object rowId,
 	        final boolean[] includeProperty,
 	        final int j,
 	        final Object oldVersion,
 	        final Object object,
 	        final String sql,
 	        final SessionImplementor session) throws HibernateException {
 
 		final Expectation expectation = Expectations.appropriateExpectation( updateResultCheckStyles[j] );
 		final boolean useBatch = j == 0 && expectation.canBeBatched() && isBatchable(); //note: updates to joined tables can't be batched...
 		if ( useBatch && updateBatchKey == null ) {
 			updateBatchKey = new BasicBatchKey(
 					getEntityName() + "#UPDATE",
 					expectation
 			);
 		}
 		final boolean callable = isUpdateCallable( j );
 		final boolean useVersion = j == 0 && isVersioned();
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Updating entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 			if ( useVersion )
 				LOG.tracev( "Existing version: {0} -> New version:{1}", oldVersion, fields[getVersionProperty()] );
 		}
 
 		try {
 			int index = 1; // starting index
 			final PreparedStatement update;
 			if ( useBatch ) {
 				update = session.getTransactionCoordinator()
 						.getJdbcCoordinator()
 						.getBatch( updateBatchKey )
 						.getBatchStatement( sql, callable );
 			}
 			else {
 				update = session.getTransactionCoordinator()
 						.getJdbcCoordinator()
 						.getStatementPreparer()
 						.prepareStatement( sql, callable );
 			}
 
 			try {
 				index+= expectation.prepare( update );
 
 				//Now write the values of fields onto the prepared statement
 				index = dehydrate( id, fields, rowId, includeProperty, propertyColumnUpdateable, j, update, session, index, true );
 
 				// Write any appropriate versioning conditional parameters
 				if ( useVersion && entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.VERSION ) {
 					if ( checkVersion( includeProperty ) ) {
 						getVersionType().nullSafeSet( update, oldVersion, index, session );
 					}
 				}
 				else if ( isAllOrDirtyOptLocking() && oldFields != null ) {
 					boolean[] versionability = getPropertyVersionability(); //TODO: is this really necessary????
 					boolean[] includeOldField = entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.ALL
 							? getPropertyUpdateability()
 							: includeProperty;
 					Type[] types = getPropertyTypes();
 					for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 						boolean include = includeOldField[i] &&
 								isPropertyOfTable( i, j ) &&
 								versionability[i]; //TODO: is this really necessary????
 						if ( include ) {
 							boolean[] settable = types[i].toColumnNullness( oldFields[i], getFactory() );
 							types[i].nullSafeSet(
 									update,
 									oldFields[i],
 									index,
 									settable,
 									session
 								);
 							index += ArrayHelper.countTrue(settable);
 						}
 					}
 				}
 
 				if ( useBatch ) {
 					session.getTransactionCoordinator().getJdbcCoordinator().getBatch( updateBatchKey ).addToBatch();
 					return true;
 				}
 				else {
 					return check( session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( update ), id, j, expectation, update );
 				}
 
 			}
 			catch ( SQLException e ) {
 				if ( useBatch ) {
 					session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
 				}
 				throw e;
 			}
 			finally {
 				if ( !useBatch ) {
 					session.getTransactionCoordinator().getJdbcCoordinator().release( update );
 				}
 			}
 
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"could not update: " + MessageHelper.infoString( this, id, getFactory() ),
 					sql
 				);
 		}
 	}
 
 	private BasicBatchKey deleteBatchKey;
 
 	/**
 	 * Perform an SQL DELETE
 	 */
 	protected void delete(
 			final Serializable id,
 			final Object version,
 			final int j,
 			final Object object,
 			final String sql,
 			final SessionImplementor session,
 			final Object[] loadedState) throws HibernateException {
 
 		if ( isInverseTable( j ) ) {
 			return;
 		}
 
 		final boolean useVersion = j == 0 && isVersioned();
 		final boolean callable = isDeleteCallable( j );
 		final Expectation expectation = Expectations.appropriateExpectation( deleteResultCheckStyles[j] );
 		final boolean useBatch = j == 0 && isBatchable() && expectation.canBeBatched();
 		if ( useBatch && deleteBatchKey == null ) {
 			deleteBatchKey = new BasicBatchKey(
 					getEntityName() + "#DELETE",
 					expectation
 			);
 		}
 
 		final boolean traceEnabled = LOG.isTraceEnabled();
 		if ( traceEnabled ) {
 			LOG.tracev( "Deleting entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 			if ( useVersion )
 				LOG.tracev( "Version: {0}", version );
 		}
 
 		if ( isTableCascadeDeleteEnabled( j ) ) {
 			if ( traceEnabled ) {
 				LOG.tracev( "Delete handled by foreign key constraint: {0}", getTableName( j ) );
 			}
 			return; //EARLY EXIT!
 		}
 
 		try {
 			//Render the SQL query
 			PreparedStatement delete;
 			int index = 1;
 			if ( useBatch ) {
 				delete = session.getTransactionCoordinator()
 						.getJdbcCoordinator()
 						.getBatch( deleteBatchKey )
 						.getBatchStatement( sql, callable );
 			}
 			else {
 				delete = session.getTransactionCoordinator()
 						.getJdbcCoordinator()
 						.getStatementPreparer()
 						.prepareStatement( sql, callable );
 			}
 
 			try {
 
 				index += expectation.prepare( delete );
 
 				// Do the key. The key is immutable so we can use the _current_ object state - not necessarily
 				// the state at the time the delete was issued
 				getIdentifierType().nullSafeSet( delete, id, index, session );
 				index += getIdentifierColumnSpan();
 
 				// We should use the _current_ object state (ie. after any updates that occurred during flush)
 
 				if ( useVersion ) {
 					getVersionType().nullSafeSet( delete, version, index, session );
 				}
 				else if ( isAllOrDirtyOptLocking() && loadedState != null ) {
 					boolean[] versionability = getPropertyVersionability();
 					Type[] types = getPropertyTypes();
 					for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 						if ( isPropertyOfTable( i, j ) && versionability[i] ) {
 							// this property belongs to the table and it is not specifically
 							// excluded from optimistic locking by optimistic-lock="false"
 							boolean[] settable = types[i].toColumnNullness( loadedState[i], getFactory() );
 							types[i].nullSafeSet( delete, loadedState[i], index, settable, session );
 							index += ArrayHelper.countTrue( settable );
 						}
 					}
 				}
 
 				if ( useBatch ) {
 					session.getTransactionCoordinator().getJdbcCoordinator().getBatch( deleteBatchKey ).addToBatch();
 				}
 				else {
 					check( session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( delete ), id, j, expectation, delete );
 				}
 
 			}
 			catch ( SQLException sqle ) {
 				if ( useBatch ) {
 					session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
 				}
 				throw sqle;
 			}
 			finally {
 				if ( !useBatch ) {
 					session.getTransactionCoordinator().getJdbcCoordinator().release( delete );
 				}
 			}
 
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not delete: " +
 					MessageHelper.infoString( this, id, getFactory() ),
 					sql
 				);
 
 		}
 
 	}
 
 	private String[] getUpdateStrings(boolean byRowId, boolean lazy) {
 		if ( byRowId ) {
 			return lazy ? getSQLLazyUpdateByRowIdStrings() : getSQLUpdateByRowIdStrings();
 		}
 		else {
 			return lazy ? getSQLLazyUpdateStrings() : getSQLUpdateStrings();
 		}
 	}
 
 	/**
 	 * Update an object
 	 */
 	public void update(
 			final Serializable id,
 	        final Object[] fields,
 	        final int[] dirtyFields,
 	        final boolean hasDirtyCollection,
 	        final Object[] oldFields,
 	        final Object oldVersion,
 	        final Object object,
 	        final Object rowId,
 	        final SessionImplementor session) throws HibernateException {
 
 		//note: dirtyFields==null means we had no snapshot, and we couldn't get one using select-before-update
 		//	  oldFields==null just means we had no snapshot to begin with (we might have used select-before-update to get the dirtyFields)
 
 		final boolean[] tableUpdateNeeded = getTableUpdateNeeded( dirtyFields, hasDirtyCollection );
 		final int span = getTableSpan();
 
 		final boolean[] propsToUpdate;
 		final String[] updateStrings;
 		EntityEntry entry = session.getPersistenceContext().getEntry( object );
 
 		// Ensure that an immutable or non-modifiable entity is not being updated unless it is
 		// in the process of being deleted.
 		if ( entry == null && ! isMutable() ) {
 			throw new IllegalStateException( "Updating immutable entity that is not in session yet!" );
 		}
 		if ( ( entityMetamodel.isDynamicUpdate() && dirtyFields != null ) ) {
 			// We need to generate the UPDATE SQL when dynamic-update="true"
 			propsToUpdate = getPropertiesToUpdate( dirtyFields, hasDirtyCollection );
 			// don't need to check laziness (dirty checking algorithm handles that)
 			updateStrings = new String[span];
 			for ( int j = 0; j < span; j++ ) {
 				updateStrings[j] = tableUpdateNeeded[j] ?
 						generateUpdateString( propsToUpdate, j, oldFields, j == 0 && rowId != null ) :
 						null;
 			}
 		}
 		else if ( ! isModifiableEntity( entry ) ) {
 			// We need to generate UPDATE SQL when a non-modifiable entity (e.g., read-only or immutable)
 			// needs:
 			// - to have references to transient entities set to null before being deleted
 			// - to have version incremented do to a "dirty" association
 			// If dirtyFields == null, then that means that there are no dirty properties to
 			// to be updated; an empty array for the dirty fields needs to be passed to
 			// getPropertiesToUpdate() instead of null.
 			propsToUpdate = getPropertiesToUpdate(
 					( dirtyFields == null ? ArrayHelper.EMPTY_INT_ARRAY : dirtyFields ),
 					hasDirtyCollection
 			);
 			// don't need to check laziness (dirty checking algorithm handles that)
 			updateStrings = new String[span];
 			for ( int j = 0; j < span; j++ ) {
 				updateStrings[j] = tableUpdateNeeded[j] ?
 						generateUpdateString( propsToUpdate, j, oldFields, j == 0 && rowId != null ) :
 						null;
 			}
 		}
 		else {
 			// For the case of dynamic-update="false", or no snapshot, we use the static SQL
 			updateStrings = getUpdateStrings(
 					rowId != null,
 					hasUninitializedLazyProperties( object )
 			);
 			propsToUpdate = getPropertyUpdateability( object );
 		}
 
 		for ( int j = 0; j < span; j++ ) {
 			// Now update only the tables with dirty properties (and the table with the version number)
 			if ( tableUpdateNeeded[j] ) {
 				updateOrInsert(
 						id,
 						fields,
 						oldFields,
 						j == 0 ? rowId : null,
 						propsToUpdate,
 						j,
 						oldVersion,
 						object,
 						updateStrings[j],
 						session
 					);
 			}
 		}
 	}
 
 	public Serializable insert(Object[] fields, Object object, SessionImplementor session)
 			throws HibernateException {
 
 		final int span = getTableSpan();
 		final Serializable id;
 		if ( entityMetamodel.isDynamicInsert() ) {
 			// For the case of dynamic-insert="true", we need to generate the INSERT SQL
 			boolean[] notNull = getPropertiesToInsert( fields );
 			id = insert( fields, notNull, generateInsertString( true, notNull ), object, session );
 			for ( int j = 1; j < span; j++ ) {
 				insert( id, fields, notNull, j, generateInsertString( notNull, j ), object, session );
 			}
 		}
 		else {
 			// For the case of dynamic-insert="false", use the static SQL
 			id = insert( fields, getPropertyInsertability(), getSQLIdentityInsertString(), object, session );
 			for ( int j = 1; j < span; j++ ) {
 				insert( id, fields, getPropertyInsertability(), j, getSQLInsertStrings()[j], object, session );
 			}
 		}
 		return id;
 	}
 
 	public void insert(Serializable id, Object[] fields, Object object, SessionImplementor session)
 			throws HibernateException {
 
 		final int span = getTableSpan();
 		if ( entityMetamodel.isDynamicInsert() ) {
 			// For the case of dynamic-insert="true", we need to generate the INSERT SQL
 			boolean[] notNull = getPropertiesToInsert( fields );
 			for ( int j = 0; j < span; j++ ) {
 				insert( id, fields, notNull, j, generateInsertString( notNull, j ), object, session );
 			}
 		}
 		else {
 			// For the case of dynamic-insert="false", use the static SQL
 			for ( int j = 0; j < span; j++ ) {
 				insert( id, fields, getPropertyInsertability(), j, getSQLInsertStrings()[j], object, session );
 			}
 		}
 	}
 
 	/**
 	 * Delete an object
 	 */
 	public void delete(Serializable id, Object version, Object object, SessionImplementor session)
 			throws HibernateException {
 		final int span = getTableSpan();
 		boolean isImpliedOptimisticLocking = !entityMetamodel.isVersioned() && isAllOrDirtyOptLocking();
 		Object[] loadedState = null;
 		if ( isImpliedOptimisticLocking ) {
 			// need to treat this as if it where optimistic-lock="all" (dirty does *not* make sense);
 			// first we need to locate the "loaded" state
 			//
 			// Note, it potentially could be a proxy, so doAfterTransactionCompletion the location the safe way...
 			final EntityKey key = session.generateEntityKey( id, this );
 			Object entity = session.getPersistenceContext().getEntity( key );
 			if ( entity != null ) {
 				EntityEntry entry = session.getPersistenceContext().getEntry( entity );
 				loadedState = entry.getLoadedState();
 			}
 		}
 
 		final String[] deleteStrings;
 		if ( isImpliedOptimisticLocking && loadedState != null ) {
 			// we need to utilize dynamic delete statements
 			deleteStrings = generateSQLDeletStrings( loadedState );
 		}
 		else {
 			// otherwise, utilize the static delete statements
 			deleteStrings = getSQLDeleteStrings();
 		}
 
 		for ( int j = span - 1; j >= 0; j-- ) {
 			delete( id, version, j, object, deleteStrings[j], session, loadedState );
 		}
 
 	}
 
 	private boolean isAllOrDirtyOptLocking() {
 		return entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.DIRTY
 				|| entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.ALL;
 	}
 
 	private String[] generateSQLDeletStrings(Object[] loadedState) {
 		int span = getTableSpan();
 		String[] deleteStrings = new String[span];
 		for ( int j = span - 1; j >= 0; j-- ) {
 			Delete delete = new Delete()
 					.setTableName( getTableName( j ) )
 					.addPrimaryKeyColumns( getKeyColumns( j ) );
 			if ( getFactory().getSettings().isCommentsEnabled() ) {
 				delete.setComment( "delete " + getEntityName() + " [" + j + "]" );
 			}
 
 			boolean[] versionability = getPropertyVersionability();
 			Type[] types = getPropertyTypes();
 			for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 				if ( isPropertyOfTable( i, j ) && versionability[i] ) {
 					// this property belongs to the table and it is not specifically
 					// excluded from optimistic locking by optimistic-lock="false"
 					String[] propertyColumnNames = getPropertyColumnNames( i );
 					boolean[] propertyNullness = types[i].toColumnNullness( loadedState[i], getFactory() );
 					for ( int k = 0; k < propertyNullness.length; k++ ) {
 						if ( propertyNullness[k] ) {
 							delete.addWhereFragment( propertyColumnNames[k] + " = ?" );
 						}
 						else {
 							delete.addWhereFragment( propertyColumnNames[k] + " is null" );
 						}
 					}
 				}
 			}
 			deleteStrings[j] = delete.toStatementString();
 		}
 		return deleteStrings;
 	}
 
 	protected void logStaticSQL() {
         if ( LOG.isDebugEnabled() ) {
             LOG.debugf( "Static SQL for entity: %s", getEntityName() );
             if ( sqlLazySelectString != null ) {
 				LOG.debugf( " Lazy select: %s", sqlLazySelectString );
 			}
             if ( sqlVersionSelectString != null ) {
 				LOG.debugf( " Version select: %s", sqlVersionSelectString );
 			}
             if ( sqlSnapshotSelectString != null ) {
 				LOG.debugf( " Snapshot select: %s", sqlSnapshotSelectString );
 			}
 			for ( int j = 0; j < getTableSpan(); j++ ) {
                 LOG.debugf( " Insert %s: %s", j, getSQLInsertStrings()[j] );
                 LOG.debugf( " Update %s: %s", j, getSQLUpdateStrings()[j] );
                 LOG.debugf( " Delete %s: %s", j, getSQLDeleteStrings()[j] );
 			}
             if ( sqlIdentityInsertString != null ) {
 				LOG.debugf( " Identity insert: %s", sqlIdentityInsertString );
 			}
             if ( sqlUpdateByRowIdString != null ) {
 				LOG.debugf( " Update by row id (all fields): %s", sqlUpdateByRowIdString );
 			}
             if ( sqlLazyUpdateByRowIdString != null ) {
 				LOG.debugf( " Update by row id (non-lazy fields): %s", sqlLazyUpdateByRowIdString );
 			}
             if ( sqlInsertGeneratedValuesSelectString != null ) {
 				LOG.debugf( " Insert-generated property select: %s", sqlInsertGeneratedValuesSelectString );
 			}
             if ( sqlUpdateGeneratedValuesSelectString != null ) {
 				LOG.debugf( " Update-generated property select: %s", sqlUpdateGeneratedValuesSelectString );
 			}
 		}
 	}
 
 	public String filterFragment(String alias, Map enabledFilters) throws MappingException {
 		final StringBuilder sessionFilterFragment = new StringBuilder();
 		filterHelper.render( sessionFilterFragment, getFilterAliasGenerator(alias), enabledFilters );
 		return sessionFilterFragment.append( filterFragment( alias ) ).toString();
 	}
 
 	public String generateFilterConditionAlias(String rootAlias) {
 		return rootAlias;
 	}
 
 	public String oneToManyFilterFragment(String alias) throws MappingException {
 		return "";
 	}
 
 	public String fromJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses) {
 		return getSubclassTableSpan() == 1 ?
 				"" : //just a performance opt!
 				createJoin( alias, innerJoin, includeSubclasses ).toFromFragmentString();
 	}
 
 	public String whereJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses) {
 		return getSubclassTableSpan() == 1 ?
 				"" : //just a performance opt!
 				createJoin( alias, innerJoin, includeSubclasses ).toWhereFragmentString();
 	}
 
 	protected boolean isSubclassTableLazy(int j) {
 		return false;
 	}
 
 	protected JoinFragment createJoin(String name, boolean innerJoin, boolean includeSubclasses) {
 		final String[] idCols = StringHelper.qualify( name, getIdentifierColumnNames() ); //all joins join to the pk of the driving table
 		final JoinFragment join = getFactory().getDialect().createOuterJoinFragment();
 		final int tableSpan = getSubclassTableSpan();
 		for ( int j = 1; j < tableSpan; j++ ) { //notice that we skip the first table; it is the driving table!
 			final boolean joinIsIncluded = isClassOrSuperclassTable( j ) ||
 					( includeSubclasses && !isSubclassTableSequentialSelect( j ) && !isSubclassTableLazy( j ) );
 			if ( joinIsIncluded ) {
 				join.addJoin( getSubclassTableName( j ),
 						generateTableAlias( name, j ),
 						idCols,
 						getSubclassTableKeyColumns( j ),
 						innerJoin && isClassOrSuperclassTable( j ) && !isInverseTable( j ) && !isNullableTable( j ) ?
 						JoinType.INNER_JOIN : //we can inner join to superclass tables (the row MUST be there)
 						JoinType.LEFT_OUTER_JOIN //we can never inner join to subclass tables
 					);
 			}
 		}
 		return join;
 	}
 
 	protected JoinFragment createJoin(int[] tableNumbers, String drivingAlias) {
 		final String[] keyCols = StringHelper.qualify( drivingAlias, getSubclassTableKeyColumns( tableNumbers[0] ) );
 		final JoinFragment jf = getFactory().getDialect().createOuterJoinFragment();
 		for ( int i = 1; i < tableNumbers.length; i++ ) { //skip the driving table
 			final int j = tableNumbers[i];
 			jf.addJoin( getSubclassTableName( j ),
 					generateTableAlias( getRootAlias(), j ),
 					keyCols,
 					getSubclassTableKeyColumns( j ),
 					isInverseSubclassTable( j ) || isNullableSubclassTable( j ) ?
 					JoinType.LEFT_OUTER_JOIN :
 					JoinType.INNER_JOIN );
 		}
 		return jf;
 	}
 
 	protected SelectFragment createSelect(final int[] subclassColumnNumbers,
 										  final int[] subclassFormulaNumbers) {
 
 		SelectFragment selectFragment = new SelectFragment();
 
 		int[] columnTableNumbers = getSubclassColumnTableNumberClosure();
 		String[] columnAliases = getSubclassColumnAliasClosure();
 		String[] columnReaderTemplates = getSubclassColumnReaderTemplateClosure();
 		for ( int i = 0; i < subclassColumnNumbers.length; i++ ) {
 			int columnNumber = subclassColumnNumbers[i];
 			if ( subclassColumnSelectableClosure[columnNumber] ) {
 				final String subalias = generateTableAlias( getRootAlias(), columnTableNumbers[columnNumber] );
 				selectFragment.addColumnTemplate( subalias, columnReaderTemplates[columnNumber], columnAliases[columnNumber] );
 			}
 		}
 
 		int[] formulaTableNumbers = getSubclassFormulaTableNumberClosure();
 		String[] formulaTemplates = getSubclassFormulaTemplateClosure();
 		String[] formulaAliases = getSubclassFormulaAliasClosure();
 		for ( int i = 0; i < subclassFormulaNumbers.length; i++ ) {
 			int formulaNumber = subclassFormulaNumbers[i];
 			final String subalias = generateTableAlias( getRootAlias(), formulaTableNumbers[formulaNumber] );
 			selectFragment.addFormula( subalias, formulaTemplates[formulaNumber], formulaAliases[formulaNumber] );
 		}
 
 		return selectFragment;
 	}
 
 	protected String createFrom(int tableNumber, String alias) {
 		return getSubclassTableName( tableNumber ) + ' ' + alias;
 	}
 
 	protected String createWhereByKey(int tableNumber, String alias) {
 		//TODO: move to .sql package, and refactor with similar things!
 		return StringHelper.join( "=? and ",
 				StringHelper.qualify( alias, getSubclassTableKeyColumns( tableNumber ) ) ) + "=?";
 	}
 
 	protected String renderSelect(
 			final int[] tableNumbers,
 	        final int[] columnNumbers,
 	        final int[] formulaNumbers) {
 
 		Arrays.sort( tableNumbers ); //get 'em in the right order (not that it really matters)
 
 		//render the where and from parts
 		int drivingTable = tableNumbers[0];
 		final String drivingAlias = generateTableAlias( getRootAlias(), drivingTable ); //we *could* regerate this inside each called method!
 		final String where = createWhereByKey( drivingTable, drivingAlias );
 		final String from = createFrom( drivingTable, drivingAlias );
 
 		//now render the joins
 		JoinFragment jf = createJoin( tableNumbers, drivingAlias );
 
 		//now render the select clause
 		SelectFragment selectFragment = createSelect( columnNumbers, formulaNumbers );
 
 		//now tie it all together
 		Select select = new Select( getFactory().getDialect() );
 		select.setSelectClause( selectFragment.toFragmentString().substring( 2 ) );
 		select.setFromClause( from );
 		select.setWhereClause( where );
 		select.setOuterJoins( jf.toFromFragmentString(), jf.toWhereFragmentString() );
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "sequential select " + getEntityName() );
 		}
 		return select.toStatementString();
 	}
 
 	private String getRootAlias() {
 		return StringHelper.generateAlias( getEntityName() );
 	}
 
+	/**
+	 * Post-construct is a callback for AbstractEntityPersister subclasses to call after they are all done with their
+	 * constructor processing.  It allows AbstractEntityPersister to extend its construction after all subclass-specific
+	 * details have been handled.
+	 *
+	 * @param mapping The mapping
+	 *
+	 * @throws MappingException Indicates a problem accessing the Mapping
+	 */
 	protected void postConstruct(Mapping mapping) throws MappingException {
-		initPropertyPaths(mapping);
+		initPropertyPaths( mapping );
+
+		//doLateInit();
+		prepareEntityIdentifierDefinition();
+	}
+
+	private void doLateInit() {
+		generateEntityDefinition();
 
 		//insert/update/delete SQL
 		final int joinSpan = getTableSpan();
 		sqlDeleteStrings = new String[joinSpan];
 		sqlInsertStrings = new String[joinSpan];
 		sqlUpdateStrings = new String[joinSpan];
 		sqlLazyUpdateStrings = new String[joinSpan];
 
 		sqlUpdateByRowIdString = rowIdName == null ?
 				null :
 				generateUpdateString( getPropertyUpdateability(), 0, true );
 		sqlLazyUpdateByRowIdString = rowIdName == null ?
 				null :
 				generateUpdateString( getNonLazyPropertyUpdateability(), 0, true );
 
 		for ( int j = 0; j < joinSpan; j++ ) {
 			sqlInsertStrings[j] = customSQLInsert[j] == null ?
 					generateInsertString( getPropertyInsertability(), j ) :
 					customSQLInsert[j];
 			sqlUpdateStrings[j] = customSQLUpdate[j] == null ?
 					generateUpdateString( getPropertyUpdateability(), j, false ) :
 					customSQLUpdate[j];
 			sqlLazyUpdateStrings[j] = customSQLUpdate[j] == null ?
 					generateUpdateString( getNonLazyPropertyUpdateability(), j, false ) :
 					customSQLUpdate[j];
 			sqlDeleteStrings[j] = customSQLDelete[j] == null ?
 					generateDeleteString( j ) :
 					customSQLDelete[j];
 		}
 
 		tableHasColumns = new boolean[joinSpan];
 		for ( int j = 0; j < joinSpan; j++ ) {
 			tableHasColumns[j] = sqlUpdateStrings[j] != null;
 		}
 
 		//select SQL
 		sqlSnapshotSelectString = generateSnapshotSelectString();
 		sqlLazySelectString = generateLazySelectString();
 		sqlVersionSelectString = generateSelectVersionString();
 		if ( hasInsertGeneratedProperties() ) {
 			sqlInsertGeneratedValuesSelectString = generateInsertGeneratedValuesSelectString();
 		}
 		if ( hasUpdateGeneratedProperties() ) {
 			sqlUpdateGeneratedValuesSelectString = generateUpdateGeneratedValuesSelectString();
 		}
 		if ( isIdentifierAssignedByInsert() ) {
 			identityDelegate = ( ( PostInsertIdentifierGenerator ) getIdentifierGenerator() )
 					.getInsertGeneratedIdentifierDelegate( this, getFactory().getDialect(), useGetGeneratedKeys() );
 			sqlIdentityInsertString = customSQLInsert[0] == null
 					? generateIdentityInsertString( getPropertyInsertability() )
 					: customSQLInsert[0];
 		}
 		else {
 			sqlIdentityInsertString = null;
 		}
 
 		logStaticSQL();
-
 	}
 
-	public void postInstantiate() throws MappingException {
-		generateEntityDefinition();
+	public final void postInstantiate() throws MappingException {
+		doLateInit();
+//		generateEntityDefinition();
 
 		createLoaders();
 		createUniqueKeyLoaders();
 		createQueryLoader();
 	}
 
 	//needed by subclasses to override the createLoader strategy
 	protected Map getLoaders() {
 		return loaders;
 	}
 
 	//Relational based Persisters should be content with this implementation
 	protected void createLoaders() {
 		final Map loaders = getLoaders();
 		loaders.put( LockMode.NONE, createEntityLoader( LockMode.NONE ) );
 
 		UniqueEntityLoader readLoader = createEntityLoader( LockMode.READ );
 		loaders.put( LockMode.READ, readLoader );
 
 		//TODO: inexact, what we really need to know is: are any outer joins used?
 		boolean disableForUpdate = getSubclassTableSpan() > 1 &&
 				hasSubclasses() &&
 				!getFactory().getDialect().supportsOuterJoinForUpdate();
 
 		loaders.put(
 				LockMode.UPGRADE,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.UPGRADE )
 			);
 		loaders.put(
 				LockMode.UPGRADE_NOWAIT,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.UPGRADE_NOWAIT )
 			);
 		loaders.put(
 				LockMode.UPGRADE_SKIPLOCKED,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.UPGRADE_SKIPLOCKED )
 			);
 		loaders.put(
 				LockMode.FORCE,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.FORCE )
 			);
 		loaders.put(
 				LockMode.PESSIMISTIC_READ,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.PESSIMISTIC_READ )
 			);
 		loaders.put(
 				LockMode.PESSIMISTIC_WRITE,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.PESSIMISTIC_WRITE )
 			);
 		loaders.put(
 				LockMode.PESSIMISTIC_FORCE_INCREMENT,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.PESSIMISTIC_FORCE_INCREMENT )
 			);
 		loaders.put( LockMode.OPTIMISTIC, createEntityLoader( LockMode.OPTIMISTIC) );
 		loaders.put( LockMode.OPTIMISTIC_FORCE_INCREMENT, createEntityLoader(LockMode.OPTIMISTIC_FORCE_INCREMENT) );
 
 		loaders.put(
 				"merge",
 				new CascadeEntityLoader( this, CascadingActions.MERGE, getFactory() )
 			);
 		loaders.put(
 				"refresh",
 				new CascadeEntityLoader( this, CascadingActions.REFRESH, getFactory() )
 			);
 	}
 
 	protected void createQueryLoader() {
 		if ( loaderName != null ) {
 			queryLoader = new NamedQueryLoader( loaderName, this );
 		}
 	}
 
 	/**
 	 * Load an instance using either the <tt>forUpdateLoader</tt> or the outer joining <tt>loader</tt>,
 	 * depending upon the value of the <tt>lock</tt> parameter
 	 */
 	public Object load(Serializable id, Object optionalObject, LockMode lockMode, SessionImplementor session) {
 		return load( id, optionalObject, new LockOptions().setLockMode(lockMode), session );
 	}
 
 	/**
 	 * Load an instance using either the <tt>forUpdateLoader</tt> or the outer joining <tt>loader</tt>,
 	 * depending upon the value of the <tt>lock</tt> parameter
 	 */
 	public Object load(Serializable id, Object optionalObject, LockOptions lockOptions, SessionImplementor session)
 			throws HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Fetching entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		final UniqueEntityLoader loader = getAppropriateLoader(lockOptions, session );
 		return loader.load( id, optionalObject, session, lockOptions );
 	}
 
 	public void registerAffectingFetchProfile(String fetchProfileName) {
 		affectingFetchProfileNames.add( fetchProfileName );
 	}
 
 	private boolean isAffectedByEnabledFetchProfiles(SessionImplementor session) {
 		Iterator itr = session.getLoadQueryInfluencers().getEnabledFetchProfileNames().iterator();
 		while ( itr.hasNext() ) {
 			if ( affectingFetchProfileNames.contains( itr.next() ) ) {
 				return true;
 			}
 		}
 		return false;
 	}
 
 	private boolean isAffectedByEnabledFilters(SessionImplementor session) {
 		return session.getLoadQueryInfluencers().hasEnabledFilters()
 				&& filterHelper.isAffectedBy( session.getLoadQueryInfluencers().getEnabledFilters() );
 	}
 
 	private UniqueEntityLoader getAppropriateLoader(LockOptions lockOptions, SessionImplementor session) {
 		if ( queryLoader != null ) {
 			// if the user specified a custom query loader we need to that
 			// regardless of any other consideration
 			return queryLoader;
 		}
 		else if ( isAffectedByEnabledFilters( session ) ) {
 			// because filters affect the rows returned (because they add
 			// restrictions) these need to be next in precedence
 			return createEntityLoader(lockOptions, session.getLoadQueryInfluencers() );
 		}
 		else if ( session.getLoadQueryInfluencers().getInternalFetchProfile() != null && LockMode.UPGRADE.greaterThan( lockOptions.getLockMode() ) ) {
 			// Next, we consider whether an 'internal' fetch profile has been set.
 			// This indicates a special fetch profile Hibernate needs applied
 			// (for its merge loading process e.g.).
 			return ( UniqueEntityLoader ) getLoaders().get( session.getLoadQueryInfluencers().getInternalFetchProfile() );
 		}
 		else if ( isAffectedByEnabledFetchProfiles( session ) ) {
 			// If the session has associated influencers we need to adjust the
 			// SQL query used for loading based on those influencers
 			return createEntityLoader(lockOptions, session.getLoadQueryInfluencers() );
 		}
 		else if ( lockOptions.getTimeOut() != LockOptions.WAIT_FOREVER ) {
 			return createEntityLoader( lockOptions, session.getLoadQueryInfluencers() );
 		}
 		else {
 			return ( UniqueEntityLoader ) getLoaders().get( lockOptions.getLockMode() );
 		}
 	}
 
 	private boolean isAllNull(Object[] array, int tableNumber) {
 		for ( int i = 0; i < array.length; i++ ) {
 			if ( isPropertyOfTable( i, tableNumber ) && array[i] != null ) {
 				return false;
 			}
 		}
 		return true;
 	}
 
 	public boolean isSubclassPropertyNullable(int i) {
 		return subclassPropertyNullabilityClosure[i];
 	}
 
 	/**
 	 * Transform the array of property indexes to an array of booleans,
 	 * true when the property is dirty
 	 */
 	protected final boolean[] getPropertiesToUpdate(final int[] dirtyProperties, final boolean hasDirtyCollection) {
 		final boolean[] propsToUpdate = new boolean[ entityMetamodel.getPropertySpan() ];
 		final boolean[] updateability = getPropertyUpdateability(); //no need to check laziness, dirty checking handles that
 		for ( int j = 0; j < dirtyProperties.length; j++ ) {
 			int property = dirtyProperties[j];
 			if ( updateability[property] ) {
 				propsToUpdate[property] = true;
 			}
 		}
 		if ( isVersioned() && updateability[getVersionProperty() ]) {
 			propsToUpdate[ getVersionProperty() ] =
 				Versioning.isVersionIncrementRequired( dirtyProperties, hasDirtyCollection, getPropertyVersionability() );
 		}
 		return propsToUpdate;
 	}
 
 	/**
 	 * Transform the array of property indexes to an array of booleans,
 	 * true when the property is insertable and non-null
 	 */
 	protected boolean[] getPropertiesToInsert(Object[] fields) {
 		boolean[] notNull = new boolean[fields.length];
 		boolean[] insertable = getPropertyInsertability();
 		for ( int i = 0; i < fields.length; i++ ) {
 			notNull[i] = insertable[i] && fields[i] != null;
 		}
 		return notNull;
 	}
 
 	/**
 	 * Locate the property-indices of all properties considered to be dirty.
 	 *
 	 * @param currentState The current state of the entity (the state to be checked).
 	 * @param previousState The previous state of the entity (the state to be checked against).
 	 * @param entity The entity for which we are checking state dirtiness.
 	 * @param session The session in which the check is occurring.
 	 * @return <tt>null</tt> or the indices of the dirty properties
 	 * @throws HibernateException
 	 */
 	public int[] findDirty(Object[] currentState, Object[] previousState, Object entity, SessionImplementor session)
 	throws HibernateException {
 		int[] props = TypeHelper.findDirty(
 				entityMetamodel.getProperties(),
 				currentState,
 				previousState,
 				propertyColumnUpdateable,
 				hasUninitializedLazyProperties( entity ),
 				session
 			);
 		if ( props == null ) {
 			return null;
 		}
 		else {
 			logDirtyProperties( props );
 			return props;
 		}
 	}
 
 	/**
 	 * Locate the property-indices of all properties considered to be dirty.
 	 *
 	 * @param old The old state of the entity.
 	 * @param current The current state of the entity.
 	 * @param entity The entity for which we are checking state modification.
 	 * @param session The session in which the check is occurring.
 	 * @return <tt>null</tt> or the indices of the modified properties
 	 * @throws HibernateException
 	 */
 	public int[] findModified(Object[] old, Object[] current, Object entity, SessionImplementor session)
 	throws HibernateException {
 		int[] props = TypeHelper.findModified(
 				entityMetamodel.getProperties(),
 				current,
 				old,
 				propertyColumnUpdateable,
 				hasUninitializedLazyProperties( entity ),
 				session
 			);
 		if ( props == null ) {
 			return null;
 		}
 		else {
 			logDirtyProperties( props );
 			return props;
 		}
 	}
 
 	/**
 	 * Which properties appear in the SQL update?
 	 * (Initialized, updateable ones!)
 	 */
 	protected boolean[] getPropertyUpdateability(Object entity) {
 		return hasUninitializedLazyProperties( entity )
 				? getNonLazyPropertyUpdateability()
 				: getPropertyUpdateability();
 	}
 
 	private void logDirtyProperties(int[] props) {
 		if ( LOG.isTraceEnabled() ) {
 			for ( int i = 0; i < props.length; i++ ) {
 				String propertyName = entityMetamodel.getProperties()[ props[i] ].getName();
 				LOG.trace( StringHelper.qualify( getEntityName(), propertyName ) + " is dirty" );
 			}
 		}
 	}
 
 	public SessionFactoryImplementor getFactory() {
 		return factory;
 	}
 
 	public EntityMetamodel getEntityMetamodel() {
 		return entityMetamodel;
 	}
 
 	public boolean hasCache() {
 		return cacheAccessStrategy != null;
 	}
 
 	public EntityRegionAccessStrategy getCacheAccessStrategy() {
 		return cacheAccessStrategy;
 	}
 
 	@Override
 	public CacheEntryStructure getCacheEntryStructure() {
 		return cacheEntryHelper.getCacheEntryStructure();
 	}
 
 	@Override
 	public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session) {
 		return cacheEntryHelper.buildCacheEntry( entity, state, version, session );
 	}
 
 	public boolean hasNaturalIdCache() {
 		return naturalIdRegionAccessStrategy != null;
 	}
 	
 	public NaturalIdRegionAccessStrategy getNaturalIdCacheAccessStrategy() {
 		return naturalIdRegionAccessStrategy;
 	}
 
 	public Comparator getVersionComparator() {
 		return isVersioned() ? getVersionType().getComparator() : null;
 	}
 
 	// temporary ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	public final String getEntityName() {
 		return entityMetamodel.getName();
 	}
 
 	public EntityType getEntityType() {
 		return entityMetamodel.getEntityType();
 	}
 
 	public boolean isPolymorphic() {
 		return entityMetamodel.isPolymorphic();
 	}
 
 	public boolean isInherited() {
 		return entityMetamodel.isInherited();
 	}
 
 	public boolean hasCascades() {
 		return entityMetamodel.hasCascades();
 	}
 
 	public boolean hasIdentifierProperty() {
 		return !entityMetamodel.getIdentifierProperty().isVirtual();
 	}
 
 	public VersionType getVersionType() {
 		return ( VersionType ) locateVersionType();
 	}
 
 	private Type locateVersionType() {
 		return entityMetamodel.getVersionProperty() == null ?
 				null :
 				entityMetamodel.getVersionProperty().getType();
 	}
 
 	public int getVersionProperty() {
 		return entityMetamodel.getVersionPropertyIndex();
 	}
 
 	public boolean isVersioned() {
 		return entityMetamodel.isVersioned();
 	}
 
 	public boolean isIdentifierAssignedByInsert() {
 		return entityMetamodel.getIdentifierProperty().isIdentifierAssignedByInsert();
 	}
 
 	public boolean hasLazyProperties() {
 		return entityMetamodel.hasLazyProperties();
 	}
 
 //	public boolean hasUninitializedLazyProperties(Object entity) {
 //		if ( hasLazyProperties() ) {
 //			InterceptFieldCallback callback = ( ( InterceptFieldEnabled ) entity ).getInterceptFieldCallback();
 //			return callback != null && !( ( FieldInterceptor ) callback ).isInitialized();
 //		}
 //		else {
 //			return false;
 //		}
 //	}
 
 	public void afterReassociate(Object entity, SessionImplementor session) {
 		if ( getEntityMetamodel().getInstrumentationMetadata().isInstrumented() ) {
 			FieldInterceptor interceptor = getEntityMetamodel().getInstrumentationMetadata().extractInterceptor( entity );
 			if ( interceptor != null ) {
 				interceptor.setSession( session );
 			}
 			else {
 				FieldInterceptor fieldInterceptor = getEntityMetamodel().getInstrumentationMetadata().injectInterceptor(
 						entity,
 						getEntityName(),
 						null,
 						session
 				);
 				fieldInterceptor.dirty();
 			}
 		}
 
 		handleNaturalIdReattachment( entity, session );
 	}
 
 	private void handleNaturalIdReattachment(Object entity, SessionImplementor session) {
 		if ( ! hasNaturalIdentifier() ) {
 			return;
 		}
 
 		if ( getEntityMetamodel().hasImmutableNaturalId() ) {
 			// we assume there were no changes to natural id during detachment for now, that is validated later
 			// during flush.
 			return;
 		}
 
 		final NaturalIdHelper naturalIdHelper = session.getPersistenceContext().getNaturalIdHelper();
 		final Serializable id = getIdentifier( entity, session );
 
 		// for reattachment of mutable natural-ids, we absolutely positively have to grab the snapshot from the
 		// database, because we have no other way to know if the state changed while detached.
 		final Object[] naturalIdSnapshot;
 		final Object[] entitySnapshot = session.getPersistenceContext().getDatabaseSnapshot( id, this );
 		if ( entitySnapshot == StatefulPersistenceContext.NO_ROW ) {
 			naturalIdSnapshot = null;
 		}
 		else {
 			naturalIdSnapshot = naturalIdHelper.extractNaturalIdValues( entitySnapshot, this );
 		}
 
 		naturalIdHelper.removeSharedNaturalIdCrossReference( this, id, naturalIdSnapshot );
 		naturalIdHelper.manageLocalNaturalIdCrossReference(
 				this,
 				id,
 				naturalIdHelper.extractNaturalIdValues( entity, this ),
 				naturalIdSnapshot,
 				CachedNaturalIdValueSource.UPDATE
 		);
 	}
 
 	public Boolean isTransient(Object entity, SessionImplementor session) throws HibernateException {
 		final Serializable id;
 		if ( canExtractIdOutOfEntity() ) {
 			id = getIdentifier( entity, session );
 		}
 		else {
 			id = null;
 		}
 		// we *always* assume an instance with a null
 		// identifier or no identifier property is unsaved!
 		if ( id == null ) {
 			return Boolean.TRUE;
 		}
 
 		// check the version unsaved-value, if appropriate
 		final Object version = getVersion( entity );
 		if ( isVersioned() ) {
 			// let this take precedence if defined, since it works for
 			// assigned identifiers
 			Boolean result = entityMetamodel.getVersionProperty()
 					.getUnsavedValue().isUnsaved( version );
 			if ( result != null ) {
 				return result;
 			}
 		}
 
 		// check the id unsaved-value
 		Boolean result = entityMetamodel.getIdentifierProperty()
 				.getUnsavedValue().isUnsaved( id );
 		if ( result != null ) {
 			return result;
 		}
 
 		// check to see if it is in the second-level cache
 		if ( hasCache() ) {
 			CacheKey ck = session.generateCacheKey( id, getIdentifierType(), getRootEntityName() );
 			if ( getCacheAccessStrategy().get( ck, session.getTimestamp() ) != null ) {
 				return Boolean.FALSE;
 			}
 		}
 
 		return null;
 	}
 
 	public boolean hasCollections() {
 		return entityMetamodel.hasCollections();
 	}
 
 	public boolean hasMutableProperties() {
 		return entityMetamodel.hasMutableProperties();
 	}
 
 	public boolean isMutable() {
 		return entityMetamodel.isMutable();
 	}
 
 	private boolean isModifiableEntity(EntityEntry entry) {
 
 		return ( entry == null ? isMutable() : entry.isModifiableEntity() );
 	}
 
 	public boolean isAbstract() {
 		return entityMetamodel.isAbstract();
 	}
 
 	public boolean hasSubclasses() {
 		return entityMetamodel.hasSubclasses();
 	}
 
 	public boolean hasProxy() {
 		return entityMetamodel.isLazy();
 	}
 
 	public IdentifierGenerator getIdentifierGenerator() throws HibernateException {
 		return entityMetamodel.getIdentifierProperty().getIdentifierGenerator();
 	}
 
 	public String getRootEntityName() {
 		return entityMetamodel.getRootName();
 	}
 
 	public ClassMetadata getClassMetadata() {
 		return this;
 	}
 
 	public String getMappedSuperclass() {
 		return entityMetamodel.getSuperclass();
 	}
 
 	public boolean isExplicitPolymorphism() {
 		return entityMetamodel.isExplicitPolymorphism();
 	}
 
 	protected boolean useDynamicUpdate() {
 		return entityMetamodel.isDynamicUpdate();
 	}
 
 	protected boolean useDynamicInsert() {
 		return entityMetamodel.isDynamicInsert();
 	}
 
 	protected boolean hasEmbeddedCompositeIdentifier() {
 		return entityMetamodel.getIdentifierProperty().isEmbedded();
 	}
 
 	public boolean canExtractIdOutOfEntity() {
 		return hasIdentifierProperty() || hasEmbeddedCompositeIdentifier() || hasIdentifierMapper();
 	}
 
 	private boolean hasIdentifierMapper() {
 		return entityMetamodel.getIdentifierProperty().hasIdentifierMapper();
 	}
 
 	public String[] getKeyColumnNames() {
 		return getIdentifierColumnNames();
 	}
 
 	public String getName() {
 		return getEntityName();
 	}
 
 	public boolean isCollection() {
 		return false;
 	}
 
 	public boolean consumesEntityAlias() {
 		return true;
 	}
 
 	public boolean consumesCollectionAlias() {
 		return false;
 	}
 
 	public Type getPropertyType(String propertyName) throws MappingException {
 		return propertyMapping.toType( propertyName );
 	}
 
 	public Type getType() {
 		return entityMetamodel.getEntityType();
 	}
 
 	public boolean isSelectBeforeUpdateRequired() {
 		return entityMetamodel.isSelectBeforeUpdate();
 	}
 
 	protected final OptimisticLockStyle optimisticLockStyle() {
 		return entityMetamodel.getOptimisticLockStyle();
 	}
 
 	public Object createProxy(Serializable id, SessionImplementor session) throws HibernateException {
 		return entityMetamodel.getTuplizer().createProxy( id, session );
 	}
 
 	public String toString() {
 		return StringHelper.unqualify( getClass().getName() ) +
 				'(' + entityMetamodel.getName() + ')';
 	}
 
 	public final String selectFragment(
 			Joinable rhs,
 			String rhsAlias,
 			String lhsAlias,
 			String entitySuffix,
 			String collectionSuffix,
 			boolean includeCollectionColumns) {
 		return selectFragment( lhsAlias, entitySuffix );
 	}
 
 	public boolean isInstrumented() {
 		return entityMetamodel.isInstrumented();
 	}
 
 	public boolean hasInsertGeneratedProperties() {
 		return entityMetamodel.hasInsertGeneratedValues();
 	}
 
 	public boolean hasUpdateGeneratedProperties() {
 		return entityMetamodel.hasUpdateGeneratedValues();
 	}
 
 	public boolean isVersionPropertyGenerated() {
 		return isVersioned() && ( getPropertyUpdateGenerationInclusions() [ getVersionProperty() ] != ValueInclusion.NONE );
 	}
 
 	public boolean isVersionPropertyInsertable() {
 		return isVersioned() && getPropertyInsertability() [ getVersionProperty() ];
 	}
 
 	public void afterInitialize(Object entity, boolean lazyPropertiesAreUnfetched, SessionImplementor session) {
 		getEntityTuplizer().afterInitialize( entity, lazyPropertiesAreUnfetched, session );
 	}
 
 	public String[] getPropertyNames() {
 		return entityMetamodel.getPropertyNames();
 	}
 
 	public Type[] getPropertyTypes() {
 		return entityMetamodel.getPropertyTypes();
 	}
 
 	public boolean[] getPropertyLaziness() {
 		return entityMetamodel.getPropertyLaziness();
 	}
 
 	public boolean[] getPropertyUpdateability() {
 		return entityMetamodel.getPropertyUpdateability();
 	}
 
 	public boolean[] getPropertyCheckability() {
 		return entityMetamodel.getPropertyCheckability();
 	}
 
 	public boolean[] getNonLazyPropertyUpdateability() {
 		return entityMetamodel.getNonlazyPropertyUpdateability();
 	}
 
 	public boolean[] getPropertyInsertability() {
 		return entityMetamodel.getPropertyInsertability();
 	}
 
 	public ValueInclusion[] getPropertyInsertGenerationInclusions() {
 		return entityMetamodel.getPropertyInsertGenerationInclusions();
 	}
 
 	public ValueInclusion[] getPropertyUpdateGenerationInclusions() {
 		return entityMetamodel.getPropertyUpdateGenerationInclusions();
 	}
 
 	public boolean[] getPropertyNullability() {
 		return entityMetamodel.getPropertyNullability();
 	}
 
 	public boolean[] getPropertyVersionability() {
 		return entityMetamodel.getPropertyVersionability();
 	}
 
 	public CascadeStyle[] getPropertyCascadeStyles() {
 		return entityMetamodel.getCascadeStyles();
 	}
 
 	public final Class getMappedClass() {
 		return getEntityTuplizer().getMappedClass();
 	}
 
 	public boolean implementsLifecycle() {
 		return getEntityTuplizer().isLifecycleImplementor();
 	}
 
 	public Class getConcreteProxyClass() {
 		return getEntityTuplizer().getConcreteProxyClass();
 	}
 
 	public void setPropertyValues(Object object, Object[] values) {
 		getEntityTuplizer().setPropertyValues( object, values );
 	}
 
 	public void setPropertyValue(Object object, int i, Object value) {
 		getEntityTuplizer().setPropertyValue( object, i, value );
 	}
 
 	public Object[] getPropertyValues(Object object) {
 		return getEntityTuplizer().getPropertyValues( object );
 	}
 
 	@Override
 	public Object getPropertyValue(Object object, int i) {
 		return getEntityTuplizer().getPropertyValue( object, i );
 	}
 
 	@Override
 	public Object getPropertyValue(Object object, String propertyName) {
 		return getEntityTuplizer().getPropertyValue( object, propertyName );
 	}
 
 	@Override
 	public Serializable getIdentifier(Object object) {
 		return getEntityTuplizer().getIdentifier( object, null );
 	}
 
 	@Override
 	public Serializable getIdentifier(Object entity, SessionImplementor session) {
 		return getEntityTuplizer().getIdentifier( entity, session );
 	}
 
 	@Override
 	public void setIdentifier(Object entity, Serializable id, SessionImplementor session) {
 		getEntityTuplizer().setIdentifier( entity, id, session );
 	}
 
 	@Override
 	public Object getVersion(Object object) {
 		return getEntityTuplizer().getVersion( object );
 	}
 
 	@Override
 	public Object instantiate(Serializable id, SessionImplementor session) {
 		return getEntityTuplizer().instantiate( id, session );
 	}
 
 	@Override
 	public boolean isInstance(Object object) {
 		return getEntityTuplizer().isInstance( object );
 	}
 
 	@Override
 	public boolean hasUninitializedLazyProperties(Object object) {
 		return getEntityTuplizer().hasUninitializedLazyProperties( object );
 	}
 
 	@Override
 	public void resetIdentifier(Object entity, Serializable currentId, Object currentVersion, SessionImplementor session) {
 		getEntityTuplizer().resetIdentifier( entity, currentId, currentVersion, session );
 	}
 
 	@Override
 	public EntityPersister getSubclassEntityPersister(Object instance, SessionFactoryImplementor factory) {
 		if ( !hasSubclasses() ) {
 			return this;
 		}
 		else {
 			final String concreteEntityName = getEntityTuplizer().determineConcreteSubclassEntityName(
 					instance,
 					factory
 			);
 			if ( concreteEntityName == null || getEntityName().equals( concreteEntityName ) ) {
 				// the contract of EntityTuplizer.determineConcreteSubclassEntityName says that returning null
 				// is an indication that the specified entity-name (this.getEntityName) should be used.
 				return this;
 			}
 			else {
 				return factory.getEntityPersister( concreteEntityName );
 			}
 		}
 	}
 
 	public boolean isMultiTable() {
 		return false;
 	}
 
 	public String getTemporaryIdTableName() {
 		return temporaryIdTableName;
 	}
 
 	public String getTemporaryIdTableDDL() {
 		return temporaryIdTableDDL;
 	}
 
 	protected int getPropertySpan() {
 		return entityMetamodel.getPropertySpan();
 	}
 
 	public Object[] getPropertyValuesToInsert(Object object, Map mergeMap, SessionImplementor session) throws HibernateException {
 		return getEntityTuplizer().getPropertyValuesToInsert( object, mergeMap, session );
 	}
 
 	public void processInsertGeneratedProperties(Serializable id, Object entity, Object[] state, SessionImplementor session) {
 		if ( !hasInsertGeneratedProperties() ) {
 			throw new AssertionFailure("no insert-generated properties");
 		}
 		processGeneratedProperties( id, entity, state, session, sqlInsertGeneratedValuesSelectString, getPropertyInsertGenerationInclusions() );
 	}
 
 	public void processUpdateGeneratedProperties(Serializable id, Object entity, Object[] state, SessionImplementor session) {
 		if ( !hasUpdateGeneratedProperties() ) {
 			throw new AssertionFailure("no update-generated properties");
 		}
 		processGeneratedProperties( id, entity, state, session, sqlUpdateGeneratedValuesSelectString, getPropertyUpdateGenerationInclusions() );
 	}
 
 	private void processGeneratedProperties(
 			Serializable id,
 	        Object entity,
 	        Object[] state,
 	        SessionImplementor session,
 	        String selectionSQL,
 	        ValueInclusion[] includeds) {
 		// force immediate execution of the insert batch (if one)
 		session.getTransactionCoordinator().getJdbcCoordinator().executeBatch();
 
 		try {
 			PreparedStatement ps = session.getTransactionCoordinator()
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( selectionSQL );
 			try {
 				getIdentifierType().nullSafeSet( ps, id, 1, session );
 				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( ps );
 				try {
 					if ( !rs.next() ) {
 						throw new HibernateException(
 								"Unable to locate row for retrieval of generated properties: " +
 								MessageHelper.infoString( this, id, getFactory() )
 							);
 					}
 					for ( int i = 0; i < getPropertySpan(); i++ ) {
 						if ( includeds[i] != ValueInclusion.NONE ) {
 							Object hydratedState = getPropertyTypes()[i].hydrate( rs, getPropertyAliases( "", i ), session, entity );
 							state[i] = getPropertyTypes()[i].resolve( hydratedState, session, entity );
 							setPropertyValue( entity, i, state[i] );
 						}
 					}
 				}
 				finally {
 					if ( rs != null ) {
 						session.getTransactionCoordinator().getJdbcCoordinator().release( rs, ps );
 					}
 				}
 			}
 			finally {
 				session.getTransactionCoordinator().getJdbcCoordinator().release( ps );
 			}
 		}
 		catch( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"unable to select generated column values",
 					selectionSQL
 			);
 		}
 
 	}
 
 	public String getIdentifierPropertyName() {
 		return entityMetamodel.getIdentifierProperty().getName();
 	}
 
 	public Type getIdentifierType() {
 		return entityMetamodel.getIdentifierProperty().getType();
 	}
 
 	public boolean hasSubselectLoadableCollections() {
 		return hasSubselectLoadableCollections;
 	}
 
 	public int[] getNaturalIdentifierProperties() {
 		return entityMetamodel.getNaturalIdentifierProperties();
 	}
 
 	public Object[] getNaturalIdentifierSnapshot(Serializable id, SessionImplementor session) throws HibernateException {
 		if ( !hasNaturalIdentifier() ) {
 			throw new MappingException( "persistent class did not define a natural-id : " + MessageHelper.infoString( this ) );
 		}
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Getting current natural-id snapshot state for: {0}",
 					MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		int[] naturalIdPropertyIndexes = getNaturalIdentifierProperties();
 		int naturalIdPropertyCount = naturalIdPropertyIndexes.length;
 		boolean[] naturalIdMarkers = new boolean[ getPropertySpan() ];
 		Type[] extractionTypes = new Type[ naturalIdPropertyCount ];
 		for ( int i = 0; i < naturalIdPropertyCount; i++ ) {
 			extractionTypes[i] = getPropertyTypes()[ naturalIdPropertyIndexes[i] ];
 			naturalIdMarkers[ naturalIdPropertyIndexes[i] ] = true;
 		}
 
 		///////////////////////////////////////////////////////////////////////
 		// TODO : look at perhaps caching this...
 		Select select = new Select( getFactory().getDialect() );
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "get current natural-id state " + getEntityName() );
 		}
 		select.setSelectClause( concretePropertySelectFragmentSansLeadingComma( getRootAlias(), naturalIdMarkers ) );
 		select.setFromClause( fromTableFragment( getRootAlias() ) + fromJoinFragment( getRootAlias(), true, false ) );
 
 		String[] aliasedIdColumns = StringHelper.qualify( getRootAlias(), getIdentifierColumnNames() );
 		String whereClause = new StringBuilder()
 			.append( StringHelper.join( "=? and ",
 					aliasedIdColumns ) )
 			.append( "=?" )
 			.append( whereJoinFragment( getRootAlias(), true, false ) )
 			.toString();
 
 		String sql = select.setOuterJoins( "", "" )
 				.setWhereClause( whereClause )
 				.toStatementString();
 		///////////////////////////////////////////////////////////////////////
 
 		Object[] snapshot = new Object[ naturalIdPropertyCount ];
 		try {
 			PreparedStatement ps = session.getTransactionCoordinator()
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( sql );
 			try {
 				getIdentifierType().nullSafeSet( ps, id, 1, session );
 				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( ps );
 				try {
 					//if there is no resulting row, return null
 					if ( !rs.next() ) {
 						return null;
 					}
 					final EntityKey key = session.generateEntityKey( id, this );
 					Object owner = session.getPersistenceContext().getEntity( key );
 					for ( int i = 0; i < naturalIdPropertyCount; i++ ) {
 						snapshot[i] = extractionTypes[i].hydrate( rs, getPropertyAliases( "", naturalIdPropertyIndexes[i] ), session, null );
 						if (extractionTypes[i].isEntityType()) {
 							snapshot[i] = extractionTypes[i].resolve(snapshot[i], session, owner);
 						}
 					}
 					return snapshot;
 				}
 				finally {
 					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, ps );
 				}
 			}
 			finally {
 				session.getTransactionCoordinator().getJdbcCoordinator().release( ps );
 			}
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"could not retrieve snapshot: " + MessageHelper.infoString( this, id, getFactory() ),
 			        sql
 			);
 		}
 	}
 
 	@Override
 	public Serializable loadEntityIdByNaturalId(
 			Object[] naturalIdValues,
 			LockOptions lockOptions,
 			SessionImplementor session) {
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracef(
 					"Resolving natural-id [%s] to id : %s ",
 					naturalIdValues,
 					MessageHelper.infoString( this )
 			);
 		}
 
 		final boolean[] valueNullness = determineValueNullness( naturalIdValues );
 		final String sqlEntityIdByNaturalIdString = determinePkByNaturalIdQuery( valueNullness );
 
 		try {
 			PreparedStatement ps = session.getTransactionCoordinator()
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( sqlEntityIdByNaturalIdString );
 			try {
 				int positions = 1;
 				int loop = 0;
 				for ( int idPosition : getNaturalIdentifierProperties() ) {
 					final Object naturalIdValue = naturalIdValues[loop++];
 					if ( naturalIdValue != null ) {
 						final Type type = getPropertyTypes()[idPosition];
 						type.nullSafeSet( ps, naturalIdValue, positions, session );
 						positions += type.getColumnSpan( session.getFactory() );
 					}
 				}
 				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( ps );
 				try {
 					// if there is no resulting row, return null
 					if ( !rs.next() ) {
 						return null;
 					}
 
 					return (Serializable) getIdentifierType().hydrate( rs, getIdentifierAliases(), session, null );
 				}
 				finally {
 					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, ps );
 				}
 			}
 			finally {
 				session.getTransactionCoordinator().getJdbcCoordinator().release( ps );
 			}
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					String.format(
 							"could not resolve natural-id [%s] to id : %s",
 							naturalIdValues,
 							MessageHelper.infoString( this )
 					),
 					sqlEntityIdByNaturalIdString
 			);
 		}
 	}
 
 	private boolean[] determineValueNullness(Object[] naturalIdValues) {
 		boolean[] nullness = new boolean[ naturalIdValues.length ];
 		for ( int i = 0; i < naturalIdValues.length; i++ ) {
 			nullness[i] = naturalIdValues[i] == null;
 		}
 		return nullness;
 	}
 
 	private Boolean naturalIdIsNonNullable;
 	private String cachedPkByNonNullableNaturalIdQuery;
 
 	private String determinePkByNaturalIdQuery(boolean[] valueNullness) {
 		if ( ! hasNaturalIdentifier() ) {
 			throw new HibernateException( "Attempt to build natural-id -> PK resolution query for entity that does not define natural id" );
 		}
 
 		// performance shortcut for cases where the natural-id is defined as completely non-nullable
 		if ( isNaturalIdNonNullable() ) {
 			if ( valueNullness != null && ! ArrayHelper.isAllFalse( valueNullness ) ) {
 				throw new HibernateException( "Null value(s) passed to lookup by non-nullable natural-id" );
 			}
 			if ( cachedPkByNonNullableNaturalIdQuery == null ) {
 				cachedPkByNonNullableNaturalIdQuery = generateEntityIdByNaturalIdSql( null );
 			}
 			return cachedPkByNonNullableNaturalIdQuery;
 		}
 
 		// Otherwise, regenerate it each time
 		return generateEntityIdByNaturalIdSql( valueNullness );
 	}
 
 	protected boolean isNaturalIdNonNullable() {
 		if ( naturalIdIsNonNullable == null ) {
 			naturalIdIsNonNullable = determineNaturalIdNullability();
 		}
 		return naturalIdIsNonNullable;
 	}
 
 	private boolean determineNaturalIdNullability() {
 		boolean[] nullability = getPropertyNullability();
 		for ( int position : getNaturalIdentifierProperties() ) {
 			// if any individual property is nullable, return false
 			if ( nullability[position] ) {
 				return false;
 			}
 		}
 		// return true if we found no individually nullable properties
 		return true;
 	}
 
 	private String generateEntityIdByNaturalIdSql(boolean[] valueNullness) {
 		EntityPersister rootPersister = getFactory().getEntityPersister( getRootEntityName() );
 		if ( rootPersister != this ) {
 			if ( rootPersister instanceof AbstractEntityPersister ) {
 				return ( (AbstractEntityPersister) rootPersister ).generateEntityIdByNaturalIdSql( valueNullness );
 			}
 		}
 
 		Select select = new Select( getFactory().getDialect() );
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "get current natural-id->entity-id state " + getEntityName() );
 		}
 
 		final String rootAlias = getRootAlias();
 
 		select.setSelectClause( identifierSelectFragment( rootAlias, "" ) );
 		select.setFromClause( fromTableFragment( rootAlias ) + fromJoinFragment( rootAlias, true, false ) );
 
 		final StringBuilder whereClause = new StringBuilder();
 		final int[] propertyTableNumbers = getPropertyTableNumbers();
 		final int[] naturalIdPropertyIndexes = this.getNaturalIdentifierProperties();
 		int valuesIndex = -1;
 		for ( int propIdx = 0; propIdx < naturalIdPropertyIndexes.length; propIdx++ ) {
 			valuesIndex++;
 			if ( propIdx > 0 ) {
 				whereClause.append( " and " );
 			}
 
 			final int naturalIdIdx = naturalIdPropertyIndexes[propIdx];
 			final String tableAlias = generateTableAlias( rootAlias, propertyTableNumbers[naturalIdIdx] );
 			final String[] propertyColumnNames = getPropertyColumnNames( naturalIdIdx );
 			final String[] aliasedPropertyColumns = StringHelper.qualify( tableAlias, propertyColumnNames );
 
 			if ( valueNullness != null && valueNullness[valuesIndex] ) {
 				whereClause.append( StringHelper.join( " is null and ", aliasedPropertyColumns ) ).append( " is null" );
 			}
 			else {
 				whereClause.append( StringHelper.join( "=? and ", aliasedPropertyColumns ) ).append( "=?" );
 			}
 		}
 
 		whereClause.append( whereJoinFragment( getRootAlias(), true, false ) );
 
 		return select.setOuterJoins( "", "" ).setWhereClause( whereClause.toString() ).toStatementString();
 	}
 
 	protected String concretePropertySelectFragmentSansLeadingComma(String alias, boolean[] include) {
 		String concretePropertySelectFragment = concretePropertySelectFragment( alias, include );
 		int firstComma = concretePropertySelectFragment.indexOf( ", " );
 		if ( firstComma == 0 ) {
 			concretePropertySelectFragment = concretePropertySelectFragment.substring( 2 );
 		}
 		return concretePropertySelectFragment;
 	}
 
 	public boolean hasNaturalIdentifier() {
 		return entityMetamodel.hasNaturalIdentifier();
 	}
 
 	public void setPropertyValue(Object object, String propertyName, Object value) {
 		getEntityTuplizer().setPropertyValue( object, propertyName, value );
 	}
 	
 	public static int getTableId(String tableName, String[] tables) {
 		for ( int j = 0; j < tables.length; j++ ) {
 			if ( tableName.equalsIgnoreCase( tables[j] ) ) {
 				return j;
 			}
 		}
 		throw new AssertionFailure( "Table " + tableName + " not found" );
 	}
 	
 	@Override
 	public EntityMode getEntityMode() {
 		return entityMetamodel.getEntityMode();
 	}
 
 	@Override
 	public EntityTuplizer getEntityTuplizer() {
 		return entityTuplizer;
 	}
 
 	@Override
 	public EntityInstrumentationMetadata getInstrumentationMetadata() {
 		return entityMetamodel.getInstrumentationMetadata();
 	}
 
 	@Override
 	public String getTableAliasForColumn(String columnName, String rootAlias) {
 		return generateTableAlias( rootAlias, determineTableNumberForColumn( columnName ) );
 	}
 
 	public int determineTableNumberForColumn(String columnName) {
 		return 0;
 	}
 
 	/**
 	 * Consolidated these onto a single helper because the 2 pieces work in tandem.
 	 */
 	public static interface CacheEntryHelper {
 		public CacheEntryStructure getCacheEntryStructure();
 
 		public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session);
 	}
 
 	private static class StandardCacheEntryHelper implements CacheEntryHelper {
 		private final EntityPersister persister;
 
 		private StandardCacheEntryHelper(EntityPersister persister) {
 			this.persister = persister;
 		}
 
 		@Override
 		public CacheEntryStructure getCacheEntryStructure() {
 			return UnstructuredCacheEntry.INSTANCE;
 		}
 
 		@Override
 		public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session) {
 			return new StandardCacheEntryImpl(
 					state,
 					persister,
 					persister.hasUninitializedLazyProperties( entity ),
 					version,
 					session,
 					entity
 			);
 		}
 	}
 
 	private static class ReferenceCacheEntryHelper implements CacheEntryHelper {
 		private final EntityPersister persister;
 
 		private ReferenceCacheEntryHelper(EntityPersister persister) {
 			this.persister = persister;
 		}
 
 		@Override
 		public CacheEntryStructure getCacheEntryStructure() {
 			return UnstructuredCacheEntry.INSTANCE;
 		}
 
 		@Override
 		public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session) {
 			return new ReferenceCacheEntryImpl( entity, persister.getEntityName() );
 		}
 	}
 
 	private static class StructuredCacheEntryHelper implements CacheEntryHelper {
 		private final EntityPersister persister;
 		private final StructuredCacheEntry structure;
 
 		private StructuredCacheEntryHelper(EntityPersister persister) {
 			this.persister = persister;
 			this.structure = new StructuredCacheEntry( persister );
 		}
 
 		@Override
 		public CacheEntryStructure getCacheEntryStructure() {
 			return structure;
 		}
 
 		@Override
 		public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session) {
 			return new StandardCacheEntryImpl(
 					state,
 					persister,
 					persister.hasUninitializedLazyProperties( entity ),
 					version,
 					session,
 					entity
 			);
 		}
 	}
 
 	private static class NoopCacheEntryHelper implements CacheEntryHelper {
 		public static final NoopCacheEntryHelper INSTANCE = new NoopCacheEntryHelper();
 
 		@Override
 		public CacheEntryStructure getCacheEntryStructure() {
 			return UnstructuredCacheEntry.INSTANCE;
 		}
 
 		@Override
 		public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session) {
 			throw new HibernateException( "Illegal attempt to build cache entry for non-cached entity" );
 		}
 	}
 
 
 	// EntityDefinition impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private EntityIdentifierDefinition entityIdentifierDefinition;
 	private Iterable<AttributeDefinition> embeddedCompositeIdentifierAttributes;
 	private Iterable<AttributeDefinition> attributeDefinitions;
 
 	protected void generateEntityDefinition() {
 		prepareEntityIdentifierDefinition();
 		collectAttributeDefinitions();
 	}
 
 	@Override
 	public EntityPersister getEntityPersister() {
 		return this;
 	}
 
 	@Override
 	public EntityIdentifierDefinition getEntityKeyDefinition() {
 		return entityIdentifierDefinition;
 	}
 
 	@Override
 	public Iterable<AttributeDefinition> getAttributes() {
 		return attributeDefinitions;
 	}
 
 
 	private void prepareEntityIdentifierDefinition() {
+		if ( entityIdentifierDefinition != null ) {
+			return;
+		}
 		final Type idType = getIdentifierType();
 
 		if ( !idType.isComponentType() ) {
 			entityIdentifierDefinition =
 					EntityIdentifierDefinitionHelper.buildSimpleEncapsulatedIdentifierDefinition( this );
 			return;
 		}
 
 		final CompositeType cidType = (CompositeType) idType;
 		if ( !cidType.isEmbedded() ) {
 			entityIdentifierDefinition =
 					EntityIdentifierDefinitionHelper.buildEncapsulatedCompositeIdentifierDefinition( this );
 			return;
 		}
 
 		entityIdentifierDefinition =
 				EntityIdentifierDefinitionHelper.buildNonEncapsulatedCompositeIdentifierDefinition( this );
 	}
 
-	private void collectAttributeDefinitions() {
-		// todo : leverage the attribute definitions housed on EntityMetamodel
-		// 		for that to work, we'd have to be able to walk our super entity persister(s)
-		attributeDefinitions = new Iterable<AttributeDefinition>() {
-			@Override
-			public Iterator<AttributeDefinition> iterator() {
-				return new Iterator<AttributeDefinition>() {
-//					private final int numberOfAttributes = countSubclassProperties();
-					private final int numberOfAttributes = entityMetamodel.getPropertySpan();
-					private int currentAttributeNumber = 0;
-
-					@Override
-					public boolean hasNext() {
-						return currentAttributeNumber < numberOfAttributes;
-					}
+	private void collectAttributeDefinitions(List<AttributeDefinition> definitions, EntityMetamodel metamodel) {
+		for ( int i = 0; i < metamodel.getPropertySpan(); i++ ) {
+			definitions.add( metamodel.getProperties()[i] );
+		}
 
-					@Override
-					public AttributeDefinition next() {
-						final int attributeNumber = currentAttributeNumber;
-						currentAttributeNumber++;
-						return entityMetamodel.getProperties()[ attributeNumber ];
-					}
+		// see if there are any subclass persisters...
+		final Set<String> subClassEntityNames = metamodel.getSubclassEntityNames();
+		if ( subClassEntityNames == null ) {
+			return;
+		}
 
-					@Override
-					public void remove() {
-						throw new UnsupportedOperationException( "Remove operation not supported here" );
-					}
-				};
+		// see if we can find the persisters...
+		for ( String subClassEntityName : subClassEntityNames ) {
+			if ( metamodel.getName().equals( subClassEntityName ) ) {
+				// skip it
+				continue;
 			}
-		};
+			try {
+				final EntityPersister subClassEntityPersister = factory.getEntityPersister( subClassEntityName );
+				collectAttributeDefinitions( definitions, subClassEntityPersister.getEntityMetamodel() );
+			}
+			catch (MappingException e) {
+				throw new IllegalStateException(
+						String.format(
+								"Could not locate subclass EntityPersister [%s] while processing EntityPersister [%s]",
+								subClassEntityName,
+								metamodel.getName()
+						),
+						e
+				);
+			}
+		}
 	}
+
+	private void collectAttributeDefinitions() {
+		// todo : I think this works purely based on luck atm
+		// 		specifically in terms of the sub/super class entity persister(s) being available.  Bit of chicken-egg
+		// 		problem there:
+		//			* If I do this during postConstruct (as it is now), it works as long as the
+		//			super entity persister is already registered, but I don't think that is necessarily true.
+		//			* If I do this during postInstantiate then lots of stuff in postConstruct breaks if we want
+		//			to try and drive SQL generation on these (which we do ultimately).  A possible solution there
+		//			would be to delay all SQL generation until postInstantiate
+
+		List<AttributeDefinition> attributeDefinitions = new ArrayList<AttributeDefinition>();
+		collectAttributeDefinitions( attributeDefinitions, getEntityMetamodel() );
+
+
+//		EntityMetamodel currentEntityMetamodel = this.getEntityMetamodel();
+//		while ( currentEntityMetamodel != null ) {
+//			for ( int i = 0; i < currentEntityMetamodel.getPropertySpan(); i++ ) {
+//				attributeDefinitions.add( currentEntityMetamodel.getProperties()[i] );
+//			}
+//			// see if there is a super class EntityMetamodel
+//			final String superEntityName = currentEntityMetamodel.getSuperclass();
+//			if ( superEntityName != null ) {
+//				currentEntityMetamodel = factory.getEntityPersister( superEntityName ).getEntityMetamodel();
+//			}
+//			else {
+//				currentEntityMetamodel = null;
+//			}
+//		}
+
+		this.attributeDefinitions = Collections.unmodifiableList( attributeDefinitions );
+//		// todo : leverage the attribute definitions housed on EntityMetamodel
+//		// 		for that to work, we'd have to be able to walk our super entity persister(s)
+//		this.attributeDefinitions = new Iterable<AttributeDefinition>() {
+//			@Override
+//			public Iterator<AttributeDefinition> iterator() {
+//				return new Iterator<AttributeDefinition>() {
+////					private final int numberOfAttributes = countSubclassProperties();
+////					private final int numberOfAttributes = entityMetamodel.getPropertySpan();
+//
+//					EntityMetamodel currentEntityMetamodel = entityMetamodel;
+//					int numberOfAttributesInCurrentEntityMetamodel = currentEntityMetamodel.getPropertySpan();
+//
+//					private int currentAttributeNumber;
+//
+//					@Override
+//					public boolean hasNext() {
+//						return currentEntityMetamodel != null
+//								&& currentAttributeNumber < numberOfAttributesInCurrentEntityMetamodel;
+//					}
+//
+//					@Override
+//					public AttributeDefinition next() {
+//						final int attributeNumber = currentAttributeNumber;
+//						currentAttributeNumber++;
+//						final AttributeDefinition next = currentEntityMetamodel.getProperties()[ attributeNumber ];
+//
+//						if ( currentAttributeNumber >= numberOfAttributesInCurrentEntityMetamodel ) {
+//							// see if there is a super class EntityMetamodel
+//							final String superEntityName = currentEntityMetamodel.getSuperclass();
+//							if ( superEntityName != null ) {
+//								currentEntityMetamodel = factory.getEntityPersister( superEntityName ).getEntityMetamodel();
+//								if ( currentEntityMetamodel != null ) {
+//									numberOfAttributesInCurrentEntityMetamodel = currentEntityMetamodel.getPropertySpan();
+//									currentAttributeNumber = 0;
+//								}
+//							}
+//						}
+//
+//						return next;
+//					}
+//
+//					@Override
+//					public void remove() {
+//						throw new UnsupportedOperationException( "Remove operation not supported here" );
+//					}
+//				};
+//			}
+//		};
+	}
+
+
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/entity/SingleTableEntityPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/entity/SingleTableEntityPersister.java
index d5f62787c6..bbe5c3e2af 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/entity/SingleTableEntityPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/entity/SingleTableEntityPersister.java
@@ -27,1031 +27,1031 @@ import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.cache.spi.access.NaturalIdRegionAccessStrategy;
 import org.hibernate.engine.spi.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.DynamicFilterAliasGenerator;
 import org.hibernate.internal.FilterAliasGenerator;
 import org.hibernate.internal.util.MarkerObject;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Formula;
 import org.hibernate.mapping.Join;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.Selectable;
 import org.hibernate.mapping.Subclass;
 import org.hibernate.mapping.Table;
 import org.hibernate.mapping.Value;
 import org.hibernate.metamodel.binding.AttributeBinding;
 import org.hibernate.metamodel.binding.CustomSQL;
 import org.hibernate.metamodel.binding.EntityBinding;
 import org.hibernate.metamodel.binding.SimpleValueBinding;
 import org.hibernate.metamodel.binding.SingularAttributeBinding;
 import org.hibernate.metamodel.relational.DerivedValue;
 import org.hibernate.metamodel.relational.SimpleValue;
 import org.hibernate.metamodel.relational.TableSpecification;
 import org.hibernate.sql.InFragment;
 import org.hibernate.sql.Insert;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.DiscriminatorType;
 import org.hibernate.type.Type;
 
 /**
  * The default implementation of the <tt>EntityPersister</tt> interface.
  * Implements the "table-per-class-hierarchy" or "roll-up" mapping strategy
  * for an entity class and its inheritence hierarchy.  This is implemented
  * as a single table holding all classes in the hierarchy with a discrimator
  * column used to determine which concrete class is referenced.
  *
  * @author Gavin King
  */
 public class SingleTableEntityPersister extends AbstractEntityPersister {
 
 	// the class hierarchy structure
 	private final int joinSpan;
 	private final String[] qualifiedTableNames;
 	private final boolean[] isInverseTable;
 	private final boolean[] isNullableTable;
 	private final String[][] keyColumnNames;
 	private final boolean[] cascadeDeleteEnabled;
 	private final boolean hasSequentialSelects;
 	
 	private final String[] spaces;
 
 	private final String[] subclassClosure;
 
 	private final String[] subclassTableNameClosure;
 	private final boolean[] subclassTableIsLazyClosure;
 	private final boolean[] isInverseSubclassTable;
 	private final boolean[] isNullableSubclassTable;
 	private final boolean[] subclassTableSequentialSelect;
 	private final String[][] subclassTableKeyColumnClosure;
 	private final boolean[] isClassOrSuperclassTable;
 
 	// properties of this class, including inherited properties
 	private final int[] propertyTableNumbers;
 
 	// the closure of all columns used by the entire hierarchy including
 	// subclasses and superclasses of this class
 	private final int[] subclassPropertyTableNumberClosure;
 
 	private final int[] subclassColumnTableNumberClosure;
 	private final int[] subclassFormulaTableNumberClosure;
 
 	// discriminator column
 	private final Map subclassesByDiscriminatorValue = new HashMap();
 	private final boolean forceDiscriminator;
 	private final String discriminatorColumnName;
 	private final String discriminatorColumnReaders;
 	private final String discriminatorColumnReaderTemplate;
 	private final String discriminatorFormula;
 	private final String discriminatorFormulaTemplate;
 	private final String discriminatorAlias;
 	private final Type discriminatorType;
 	private final Object discriminatorValue;
 	private final String discriminatorSQLValue;
 	private final boolean discriminatorInsertable;
 
 	private final String[] constraintOrderedTableNames;
 	private final String[][] constraintOrderedKeyColumnNames;
 
 	//private final Map propertyTableNumbersByName = new HashMap();
 	private final Map propertyTableNumbersByNameAndSubclass = new HashMap();
 	
 	private final Map sequentialSelectStringsByEntityName = new HashMap();
 
 	private static final Object NULL_DISCRIMINATOR = new MarkerObject("<null discriminator>");
 	private static final Object NOT_NULL_DISCRIMINATOR = new MarkerObject("<not null discriminator>");
 	private static final String NULL_STRING = "null";
 	private static final String NOT_NULL_STRING = "not null";
 
 	//INITIALIZATION:
 
 	public SingleTableEntityPersister(
 			final PersistentClass persistentClass, 
 			final EntityRegionAccessStrategy cacheAccessStrategy,
 			final NaturalIdRegionAccessStrategy naturalIdRegionAccessStrategy,
 			final SessionFactoryImplementor factory,
 			final Mapping mapping) throws HibernateException {
 
 		super( persistentClass, cacheAccessStrategy, naturalIdRegionAccessStrategy, factory );
 
 		// CLASS + TABLE
 
 		joinSpan = persistentClass.getJoinClosureSpan()+1;
 		qualifiedTableNames = new String[joinSpan];
 		isInverseTable = new boolean[joinSpan];
 		isNullableTable = new boolean[joinSpan];
 		keyColumnNames = new String[joinSpan][];
 		final Table table = persistentClass.getRootTable();
 		qualifiedTableNames[0] = table.getQualifiedName( 
 				factory.getDialect(), 
 				factory.getSettings().getDefaultCatalogName(), 
 				factory.getSettings().getDefaultSchemaName() 
 		);
 		isInverseTable[0] = false;
 		isNullableTable[0] = false;
 		keyColumnNames[0] = getIdentifierColumnNames();
 		cascadeDeleteEnabled = new boolean[joinSpan];
 
 		// Custom sql
 		customSQLInsert = new String[joinSpan];
 		customSQLUpdate = new String[joinSpan];
 		customSQLDelete = new String[joinSpan];
 		insertCallable = new boolean[joinSpan];
 		updateCallable = new boolean[joinSpan];
 		deleteCallable = new boolean[joinSpan];
 		insertResultCheckStyles = new ExecuteUpdateResultCheckStyle[joinSpan];
 		updateResultCheckStyles = new ExecuteUpdateResultCheckStyle[joinSpan];
 		deleteResultCheckStyles = new ExecuteUpdateResultCheckStyle[joinSpan];
 
 		customSQLInsert[0] = persistentClass.getCustomSQLInsert();
 		insertCallable[0] = customSQLInsert[0] != null && persistentClass.isCustomInsertCallable();
 		insertResultCheckStyles[0] = persistentClass.getCustomSQLInsertCheckStyle() == null
 									  ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLInsert[0], insertCallable[0] )
 									  : persistentClass.getCustomSQLInsertCheckStyle();
 		customSQLUpdate[0] = persistentClass.getCustomSQLUpdate();
 		updateCallable[0] = customSQLUpdate[0] != null && persistentClass.isCustomUpdateCallable();
 		updateResultCheckStyles[0] = persistentClass.getCustomSQLUpdateCheckStyle() == null
 									  ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLUpdate[0], updateCallable[0] )
 									  : persistentClass.getCustomSQLUpdateCheckStyle();
 		customSQLDelete[0] = persistentClass.getCustomSQLDelete();
 		deleteCallable[0] = customSQLDelete[0] != null && persistentClass.isCustomDeleteCallable();
 		deleteResultCheckStyles[0] = persistentClass.getCustomSQLDeleteCheckStyle() == null
 									  ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLDelete[0], deleteCallable[0] )
 									  : persistentClass.getCustomSQLDeleteCheckStyle();
 
 		// JOINS
 
 		Iterator joinIter = persistentClass.getJoinClosureIterator();
 		int j = 1;
 		while ( joinIter.hasNext() ) {
 			Join join = (Join) joinIter.next();
 			qualifiedTableNames[j] = join.getTable().getQualifiedName( 
 					factory.getDialect(), 
 					factory.getSettings().getDefaultCatalogName(), 
 					factory.getSettings().getDefaultSchemaName() 
 			);
 			isInverseTable[j] = join.isInverse();
 			isNullableTable[j] = join.isOptional();
 			cascadeDeleteEnabled[j] = join.getKey().isCascadeDeleteEnabled() && 
 				factory.getDialect().supportsCascadeDelete();
 
 			customSQLInsert[j] = join.getCustomSQLInsert();
 			insertCallable[j] = customSQLInsert[j] != null && join.isCustomInsertCallable();
 			insertResultCheckStyles[j] = join.getCustomSQLInsertCheckStyle() == null
 			                              ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLInsert[j], insertCallable[j] )
 		                                  : join.getCustomSQLInsertCheckStyle();
 			customSQLUpdate[j] = join.getCustomSQLUpdate();
 			updateCallable[j] = customSQLUpdate[j] != null && join.isCustomUpdateCallable();
 			updateResultCheckStyles[j] = join.getCustomSQLUpdateCheckStyle() == null
 			                              ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLUpdate[j], updateCallable[j] )
 		                                  : join.getCustomSQLUpdateCheckStyle();
 			customSQLDelete[j] = join.getCustomSQLDelete();
 			deleteCallable[j] = customSQLDelete[j] != null && join.isCustomDeleteCallable();
 			deleteResultCheckStyles[j] = join.getCustomSQLDeleteCheckStyle() == null
 			                              ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLDelete[j], deleteCallable[j] )
 		                                  : join.getCustomSQLDeleteCheckStyle();
 
 			Iterator iter = join.getKey().getColumnIterator();
 			keyColumnNames[j] = new String[ join.getKey().getColumnSpan() ];
 			int i = 0;
 			while ( iter.hasNext() ) {
 				Column col = (Column) iter.next();
 				keyColumnNames[j][i++] = col.getQuotedName( factory.getDialect() );
 			}
 
 			j++;
 		}
 
 		constraintOrderedTableNames = new String[qualifiedTableNames.length];
 		constraintOrderedKeyColumnNames = new String[qualifiedTableNames.length][];
 		for ( int i = qualifiedTableNames.length - 1, position = 0; i >= 0; i--, position++ ) {
 			constraintOrderedTableNames[position] = qualifiedTableNames[i];
 			constraintOrderedKeyColumnNames[position] = keyColumnNames[i];
 		}
 
 		spaces = ArrayHelper.join(
 				qualifiedTableNames, 
 				ArrayHelper.toStringArray( persistentClass.getSynchronizedTables() )
 		);
 		
 		final boolean lazyAvailable = isInstrumented();
 
 		boolean hasDeferred = false;
 		ArrayList subclassTables = new ArrayList();
 		ArrayList joinKeyColumns = new ArrayList();
 		ArrayList<Boolean> isConcretes = new ArrayList<Boolean>();
 		ArrayList<Boolean> isDeferreds = new ArrayList<Boolean>();
 		ArrayList<Boolean> isInverses = new ArrayList<Boolean>();
 		ArrayList<Boolean> isNullables = new ArrayList<Boolean>();
 		ArrayList<Boolean> isLazies = new ArrayList<Boolean>();
 		subclassTables.add( qualifiedTableNames[0] );
 		joinKeyColumns.add( getIdentifierColumnNames() );
 		isConcretes.add(Boolean.TRUE);
 		isDeferreds.add(Boolean.FALSE);
 		isInverses.add(Boolean.FALSE);
 		isNullables.add(Boolean.FALSE);
 		isLazies.add(Boolean.FALSE);
 		joinIter = persistentClass.getSubclassJoinClosureIterator();
 		while ( joinIter.hasNext() ) {
 			Join join = (Join) joinIter.next();
 			isConcretes.add( persistentClass.isClassOrSuperclassJoin(join) );
 			isDeferreds.add( join.isSequentialSelect() );
 			isInverses.add( join.isInverse() );
 			isNullables.add( join.isOptional() );
 			isLazies.add( lazyAvailable && join.isLazy() );
 			if ( join.isSequentialSelect() && !persistentClass.isClassOrSuperclassJoin(join) ) hasDeferred = true;
 			subclassTables.add( join.getTable().getQualifiedName( 
 					factory.getDialect(), 
 					factory.getSettings().getDefaultCatalogName(), 
 					factory.getSettings().getDefaultSchemaName() 
 			) );
 			Iterator iter = join.getKey().getColumnIterator();
 			String[] keyCols = new String[ join.getKey().getColumnSpan() ];
 			int i = 0;
 			while ( iter.hasNext() ) {
 				Column col = (Column) iter.next();
 				keyCols[i++] = col.getQuotedName( factory.getDialect() );
 			}
 			joinKeyColumns.add(keyCols);
 		}
 		
 		subclassTableSequentialSelect = ArrayHelper.toBooleanArray(isDeferreds);
 		subclassTableNameClosure = ArrayHelper.toStringArray(subclassTables);
 		subclassTableIsLazyClosure = ArrayHelper.toBooleanArray(isLazies);
 		subclassTableKeyColumnClosure = ArrayHelper.to2DStringArray( joinKeyColumns );
 		isClassOrSuperclassTable = ArrayHelper.toBooleanArray(isConcretes);
 		isInverseSubclassTable = ArrayHelper.toBooleanArray(isInverses);
 		isNullableSubclassTable = ArrayHelper.toBooleanArray(isNullables);
 		hasSequentialSelects = hasDeferred;
 
 		// DISCRIMINATOR
 
 		if ( persistentClass.isPolymorphic() ) {
 			Value discrimValue = persistentClass.getDiscriminator();
 			if (discrimValue==null) {
 				throw new MappingException("discriminator mapping required for single table polymorphic persistence");
 			}
 			forceDiscriminator = persistentClass.isForceDiscriminator();
 			Selectable selectable = (Selectable) discrimValue.getColumnIterator().next();
 			if ( discrimValue.hasFormula() ) {
 				Formula formula = (Formula) selectable;
 				discriminatorFormula = formula.getFormula();
 				discriminatorFormulaTemplate = formula.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 				discriminatorColumnName = null;
 				discriminatorColumnReaders = null;
 				discriminatorColumnReaderTemplate = null;
 				discriminatorAlias = "clazz_";
 			}
 			else {
 				Column column = (Column) selectable;
 				discriminatorColumnName = column.getQuotedName( factory.getDialect() );
 				discriminatorColumnReaders = column.getReadExpr( factory.getDialect() );
 				discriminatorColumnReaderTemplate = column.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 				discriminatorAlias = column.getAlias( factory.getDialect(), persistentClass.getRootTable() );
 				discriminatorFormula = null;
 				discriminatorFormulaTemplate = null;
 			}
 			discriminatorType = persistentClass.getDiscriminator().getType();
 			if ( persistentClass.isDiscriminatorValueNull() ) {
 				discriminatorValue = NULL_DISCRIMINATOR;
 				discriminatorSQLValue = InFragment.NULL;
 				discriminatorInsertable = false;
 			}
 			else if ( persistentClass.isDiscriminatorValueNotNull() ) {
 				discriminatorValue = NOT_NULL_DISCRIMINATOR;
 				discriminatorSQLValue = InFragment.NOT_NULL;
 				discriminatorInsertable = false;
 			}
 			else {
 				discriminatorInsertable = persistentClass.isDiscriminatorInsertable() && !discrimValue.hasFormula();
 				try {
 					DiscriminatorType dtype = (DiscriminatorType) discriminatorType;
 					discriminatorValue = dtype.stringToObject( persistentClass.getDiscriminatorValue() );
 					discriminatorSQLValue = dtype.objectToSQLString( discriminatorValue, factory.getDialect() );
 				}
 				catch (ClassCastException cce) {
 					throw new MappingException("Illegal discriminator type: " + discriminatorType.getName() );
 				}
 				catch (Exception e) {
 					throw new MappingException("Could not format discriminator value to SQL string", e);
 				}
 			}
 		}
 		else {
 			forceDiscriminator = false;
 			discriminatorInsertable = false;
 			discriminatorColumnName = null;
 			discriminatorColumnReaders = null;
 			discriminatorColumnReaderTemplate = null;
 			discriminatorAlias = null;
 			discriminatorType = null;
 			discriminatorValue = null;
 			discriminatorSQLValue = null;
 			discriminatorFormula = null;
 			discriminatorFormulaTemplate = null;
 		}
 
 		// PROPERTIES
 
 		propertyTableNumbers = new int[ getPropertySpan() ];
 		Iterator iter = persistentClass.getPropertyClosureIterator();
 		int i=0;
 		while( iter.hasNext() ) {
 			Property prop = (Property) iter.next();
 			propertyTableNumbers[i++] = persistentClass.getJoinNumber(prop);
 
 		}
 
 		//TODO: code duplication with JoinedSubclassEntityPersister
 		
 		ArrayList columnJoinNumbers = new ArrayList();
 		ArrayList formulaJoinedNumbers = new ArrayList();
 		ArrayList propertyJoinNumbers = new ArrayList();
 		
 		iter = persistentClass.getSubclassPropertyClosureIterator();
 		while ( iter.hasNext() ) {
 			Property prop = (Property) iter.next();
 			Integer join = persistentClass.getJoinNumber(prop);
 			propertyJoinNumbers.add(join);
 
 			//propertyTableNumbersByName.put( prop.getName(), join );
 			propertyTableNumbersByNameAndSubclass.put( 
 					prop.getPersistentClass().getEntityName() + '.' + prop.getName(), 
 					join 
 			);
 
 			Iterator citer = prop.getColumnIterator();
 			while ( citer.hasNext() ) {
 				Selectable thing = (Selectable) citer.next();
 				if ( thing.isFormula() ) {
 					formulaJoinedNumbers.add(join);
 				}
 				else {
 					columnJoinNumbers.add(join);
 				}
 			}
 		}
 		subclassColumnTableNumberClosure = ArrayHelper.toIntArray(columnJoinNumbers);
 		subclassFormulaTableNumberClosure = ArrayHelper.toIntArray(formulaJoinedNumbers);
 		subclassPropertyTableNumberClosure = ArrayHelper.toIntArray(propertyJoinNumbers);
 
 		int subclassSpan = persistentClass.getSubclassSpan() + 1;
 		subclassClosure = new String[subclassSpan];
 		subclassClosure[0] = getEntityName();
 		if ( persistentClass.isPolymorphic() ) {
 			addSubclassByDiscriminatorValue( discriminatorValue, getEntityName() );
 		}
 
 		// SUBCLASSES
 		if ( persistentClass.isPolymorphic() ) {
 			iter = persistentClass.getSubclassIterator();
 			int k=1;
 			while ( iter.hasNext() ) {
 				Subclass sc = (Subclass) iter.next();
 				subclassClosure[k++] = sc.getEntityName();
 				if ( sc.isDiscriminatorValueNull() ) {
 					addSubclassByDiscriminatorValue( NULL_DISCRIMINATOR, sc.getEntityName() );
 				}
 				else if ( sc.isDiscriminatorValueNotNull() ) {
 					addSubclassByDiscriminatorValue( NOT_NULL_DISCRIMINATOR, sc.getEntityName() );
 				}
 				else {
 					try {
 						DiscriminatorType dtype = (DiscriminatorType) discriminatorType;
 						addSubclassByDiscriminatorValue(
 							dtype.stringToObject( sc.getDiscriminatorValue() ),
 							sc.getEntityName()
 						);
 					}
 					catch (ClassCastException cce) {
 						throw new MappingException("Illegal discriminator type: " + discriminatorType.getName() );
 					}
 					catch (Exception e) {
 						throw new MappingException("Error parsing discriminator value", e);
 					}
 				}
 			}
 		}
 
 		initLockers();
 
 		initSubclassPropertyAliasesMap(persistentClass);
 		
 		postConstruct(mapping);
 
 	}
 
 	private void addSubclassByDiscriminatorValue(Object discriminatorValue, String entityName) {
 		String mappedEntityName = (String) subclassesByDiscriminatorValue.put( discriminatorValue, entityName );
 		if ( mappedEntityName != null ) {
 			throw new MappingException(
 					"Entities [" + entityName + "] and [" + mappedEntityName
 							+ "] are mapped with the same discriminator value '" + discriminatorValue + "'."
 			);
 		}
 	}
 
 	public SingleTableEntityPersister(
 			final EntityBinding entityBinding,
 			final EntityRegionAccessStrategy cacheAccessStrategy,
 			final NaturalIdRegionAccessStrategy naturalIdRegionAccessStrategy,
 			final SessionFactoryImplementor factory,
 			final Mapping mapping) throws HibernateException {
 
 		super( entityBinding, cacheAccessStrategy, naturalIdRegionAccessStrategy, factory );
 
 		// CLASS + TABLE
 
 		// TODO: fix when joins are working (HHH-6391)
 		//joinSpan = entityBinding.getJoinClosureSpan() + 1;
 		joinSpan = 1;
 		qualifiedTableNames = new String[joinSpan];
 		isInverseTable = new boolean[joinSpan];
 		isNullableTable = new boolean[joinSpan];
 		keyColumnNames = new String[joinSpan][];
 
 		final TableSpecification table = entityBinding.getPrimaryTable();
 		qualifiedTableNames[0] = table.getQualifiedName( factory.getDialect() );
 		isInverseTable[0] = false;
 		isNullableTable[0] = false;
 		keyColumnNames[0] = getIdentifierColumnNames();
 		cascadeDeleteEnabled = new boolean[joinSpan];
 
 		// Custom sql
 		customSQLInsert = new String[joinSpan];
 		customSQLUpdate = new String[joinSpan];
 		customSQLDelete = new String[joinSpan];
 		insertCallable = new boolean[joinSpan];
 		updateCallable = new boolean[joinSpan];
 		deleteCallable = new boolean[joinSpan];
 		insertResultCheckStyles = new ExecuteUpdateResultCheckStyle[joinSpan];
 		updateResultCheckStyles = new ExecuteUpdateResultCheckStyle[joinSpan];
 		deleteResultCheckStyles = new ExecuteUpdateResultCheckStyle[joinSpan];
 
 		initializeCustomSql( entityBinding.getCustomInsert(), 0, customSQLInsert, insertCallable, insertResultCheckStyles );
 		initializeCustomSql( entityBinding.getCustomUpdate(), 0, customSQLUpdate, updateCallable, updateResultCheckStyles );
 		initializeCustomSql( entityBinding.getCustomDelete(), 0, customSQLDelete, deleteCallable, deleteResultCheckStyles );
 
 		// JOINS
 
 		// TODO: add join stuff when HHH-6391 is working
 
 		constraintOrderedTableNames = new String[qualifiedTableNames.length];
 		constraintOrderedKeyColumnNames = new String[qualifiedTableNames.length][];
 		for ( int i = qualifiedTableNames.length - 1, position = 0; i >= 0; i--, position++ ) {
 			constraintOrderedTableNames[position] = qualifiedTableNames[i];
 			constraintOrderedKeyColumnNames[position] = keyColumnNames[i];
 		}
 
 		spaces = ArrayHelper.join(
 				qualifiedTableNames,
 				ArrayHelper.toStringArray( entityBinding.getSynchronizedTableNames() )
 		);
 
 		final boolean lazyAvailable = isInstrumented();
 
 		boolean hasDeferred = false;
 		ArrayList subclassTables = new ArrayList();
 		ArrayList joinKeyColumns = new ArrayList();
 		ArrayList<Boolean> isConcretes = new ArrayList<Boolean>();
 		ArrayList<Boolean> isDeferreds = new ArrayList<Boolean>();
 		ArrayList<Boolean> isInverses = new ArrayList<Boolean>();
 		ArrayList<Boolean> isNullables = new ArrayList<Boolean>();
 		ArrayList<Boolean> isLazies = new ArrayList<Boolean>();
 		subclassTables.add( qualifiedTableNames[0] );
 		joinKeyColumns.add( getIdentifierColumnNames() );
 		isConcretes.add(Boolean.TRUE);
 		isDeferreds.add(Boolean.FALSE);
 		isInverses.add(Boolean.FALSE);
 		isNullables.add(Boolean.FALSE);
 		isLazies.add(Boolean.FALSE);
 
 		// TODO: add join stuff when HHH-6391 is working
 
 
 		subclassTableSequentialSelect = ArrayHelper.toBooleanArray(isDeferreds);
 		subclassTableNameClosure = ArrayHelper.toStringArray(subclassTables);
 		subclassTableIsLazyClosure = ArrayHelper.toBooleanArray(isLazies);
 		subclassTableKeyColumnClosure = ArrayHelper.to2DStringArray( joinKeyColumns );
 		isClassOrSuperclassTable = ArrayHelper.toBooleanArray(isConcretes);
 		isInverseSubclassTable = ArrayHelper.toBooleanArray(isInverses);
 		isNullableSubclassTable = ArrayHelper.toBooleanArray(isNullables);
 		hasSequentialSelects = hasDeferred;
 
 		// DISCRIMINATOR
 
 		if ( entityBinding.isPolymorphic() ) {
 			SimpleValue discriminatorRelationalValue = entityBinding.getHierarchyDetails().getEntityDiscriminator().getBoundValue();
 			if ( discriminatorRelationalValue == null ) {
 				throw new MappingException("discriminator mapping required for single table polymorphic persistence");
 			}
 			forceDiscriminator = entityBinding.getHierarchyDetails().getEntityDiscriminator().isForced();
 			if ( DerivedValue.class.isInstance( discriminatorRelationalValue ) ) {
 				DerivedValue formula = ( DerivedValue ) discriminatorRelationalValue;
 				discriminatorFormula = formula.getExpression();
 				discriminatorFormulaTemplate = getTemplateFromString( formula.getExpression(), factory );
 				discriminatorColumnName = null;
 				discriminatorColumnReaders = null;
 				discriminatorColumnReaderTemplate = null;
 				discriminatorAlias = "clazz_";
 			}
 			else {
 				org.hibernate.metamodel.relational.Column column = ( org.hibernate.metamodel.relational.Column ) discriminatorRelationalValue;
 				discriminatorColumnName = column.getColumnName().encloseInQuotesIfQuoted( factory.getDialect() );
 				discriminatorColumnReaders =
 						column.getReadFragment() == null ?
 								column.getColumnName().encloseInQuotesIfQuoted( factory.getDialect() ) :
 								column.getReadFragment();
 				discriminatorColumnReaderTemplate = getTemplateFromColumn( column, factory );
 				discriminatorAlias = column.getAlias( factory.getDialect() );
 				discriminatorFormula = null;
 				discriminatorFormulaTemplate = null;
 			}
 
 			discriminatorType = entityBinding.getHierarchyDetails()
 					.getEntityDiscriminator()
 					.getExplicitHibernateTypeDescriptor()
 					.getResolvedTypeMapping();
 			if ( entityBinding.getDiscriminatorMatchValue() == null ) {
 				discriminatorValue = NULL_DISCRIMINATOR;
 				discriminatorSQLValue = InFragment.NULL;
 				discriminatorInsertable = false;
 			}
 			else if ( entityBinding.getDiscriminatorMatchValue().equals( NULL_STRING ) ) {
 				discriminatorValue = NOT_NULL_DISCRIMINATOR;
 				discriminatorSQLValue = InFragment.NOT_NULL;
 				discriminatorInsertable = false;
 			}
 			else if ( entityBinding.getDiscriminatorMatchValue().equals( NOT_NULL_STRING ) ) {
 				discriminatorValue = NOT_NULL_DISCRIMINATOR;
 				discriminatorSQLValue = InFragment.NOT_NULL;
 				discriminatorInsertable = false;
 			}
 			else {
 				discriminatorInsertable = entityBinding.getHierarchyDetails().getEntityDiscriminator().isInserted()
 						&& ! DerivedValue.class.isInstance( discriminatorRelationalValue );
 				try {
 					DiscriminatorType dtype = ( DiscriminatorType ) discriminatorType;
 					discriminatorValue = dtype.stringToObject( entityBinding.getDiscriminatorMatchValue() );
 					discriminatorSQLValue = dtype.objectToSQLString( discriminatorValue, factory.getDialect() );
 				}
 				catch (ClassCastException cce) {
 					throw new MappingException("Illegal discriminator type: " + discriminatorType.getName() );
 				}
 				catch (Exception e) {
 					throw new MappingException("Could not format discriminator value to SQL string", e);
 				}
 			}
 		}
 		else {
 			forceDiscriminator = false;
 			discriminatorInsertable = false;
 			discriminatorColumnName = null;
 			discriminatorColumnReaders = null;
 			discriminatorColumnReaderTemplate = null;
 			discriminatorAlias = null;
 			discriminatorType = null;
 			discriminatorValue = null;
 			discriminatorSQLValue = null;
 			discriminatorFormula = null;
 			discriminatorFormulaTemplate = null;
 		}
 
 		// PROPERTIES
 
 		propertyTableNumbers = new int[ getPropertySpan() ];
 		int i=0;
 		for( AttributeBinding attributeBinding : entityBinding.getAttributeBindingClosure() ) {
 			// TODO: fix when joins are working (HHH-6391)
 			//propertyTableNumbers[i++] = entityBinding.getJoinNumber( attributeBinding);
 			if ( attributeBinding == entityBinding.getHierarchyDetails().getEntityIdentifier().getValueBinding() ) {
 				continue; // skip identifier binding
 			}
 			if ( ! attributeBinding.getAttribute().isSingular() ) {
 				continue;
 			}
 			propertyTableNumbers[ i++ ] = 0;
 		}
 
 		//TODO: code duplication with JoinedSubclassEntityPersister
 
 		ArrayList columnJoinNumbers = new ArrayList();
 		ArrayList formulaJoinedNumbers = new ArrayList();
 		ArrayList propertyJoinNumbers = new ArrayList();
 
 		for ( AttributeBinding attributeBinding : entityBinding.getSubEntityAttributeBindingClosure() ) {
 			if ( ! attributeBinding.getAttribute().isSingular() ) {
 				continue;
 			}
 			SingularAttributeBinding singularAttributeBinding = (SingularAttributeBinding) attributeBinding;
 
 			// TODO: fix when joins are working (HHH-6391)
 			//int join = entityBinding.getJoinNumber(singularAttributeBinding);
 			int join = 0;
 			propertyJoinNumbers.add(join);
 
 			//propertyTableNumbersByName.put( singularAttributeBinding.getName(), join );
 			propertyTableNumbersByNameAndSubclass.put(
 					singularAttributeBinding.getContainer().getPathBase() + '.' + singularAttributeBinding.getAttribute().getName(),
 					join
 			);
 
 			for ( SimpleValueBinding simpleValueBinding : singularAttributeBinding.getSimpleValueBindings() ) {
 				if ( DerivedValue.class.isInstance( simpleValueBinding.getSimpleValue() ) ) {
 					formulaJoinedNumbers.add( join );
 				}
 				else {
 					columnJoinNumbers.add( join );
 				}
 			}
 		}
 		subclassColumnTableNumberClosure = ArrayHelper.toIntArray(columnJoinNumbers);
 		subclassFormulaTableNumberClosure = ArrayHelper.toIntArray(formulaJoinedNumbers);
 		subclassPropertyTableNumberClosure = ArrayHelper.toIntArray(propertyJoinNumbers);
 
 		int subclassSpan = entityBinding.getSubEntityBindingClosureSpan() + 1;
 		subclassClosure = new String[subclassSpan];
 		subclassClosure[0] = getEntityName();
 		if ( entityBinding.isPolymorphic() ) {
 			addSubclassByDiscriminatorValue( discriminatorValue, getEntityName() );
 		}
 
 		// SUBCLASSES
 		if ( entityBinding.isPolymorphic() ) {
 			int k=1;
 			for ( EntityBinding subEntityBinding : entityBinding.getPostOrderSubEntityBindingClosure() ) {
 				subclassClosure[k++] = subEntityBinding.getEntity().getName();
 				if ( subEntityBinding.isDiscriminatorMatchValueNull() ) {
 					addSubclassByDiscriminatorValue( NULL_DISCRIMINATOR, subEntityBinding.getEntity().getName() );
 				}
 				else if ( subEntityBinding.isDiscriminatorMatchValueNotNull() ) {
 					addSubclassByDiscriminatorValue( NOT_NULL_DISCRIMINATOR, subEntityBinding.getEntity().getName() );
 				}
 				else {
 					try {
 						DiscriminatorType dtype = (DiscriminatorType) discriminatorType;
 						addSubclassByDiscriminatorValue(
 							dtype.stringToObject( subEntityBinding.getDiscriminatorMatchValue() ),
 							subEntityBinding.getEntity().getName()
 						);
 					}
 					catch (ClassCastException cce) {
 						throw new MappingException("Illegal discriminator type: " + discriminatorType.getName() );
 					}
 					catch (Exception e) {
 						throw new MappingException("Error parsing discriminator value", e);
 					}
 				}
 			}
 		}
 
 		initLockers();
 
 		initSubclassPropertyAliasesMap( entityBinding );
 
 		postConstruct( mapping );
 	}
 
 	private static void initializeCustomSql(
 			CustomSQL customSql,
 			int i,
 			String[] sqlStrings,
 			boolean[] callable,
 			ExecuteUpdateResultCheckStyle[] checkStyles) {
 		sqlStrings[i] = customSql != null ?  customSql.getSql(): null;
 		callable[i] = sqlStrings[i] != null && customSql.isCallable();
 		checkStyles[i] = customSql != null && customSql.getCheckStyle() != null ?
 				customSql.getCheckStyle() :
 				ExecuteUpdateResultCheckStyle.determineDefault( sqlStrings[i], callable[i] );
 	}
 
 	protected boolean isInverseTable(int j) {
 		return isInverseTable[j];
 	}
 
 	protected boolean isInverseSubclassTable(int j) {
 		return isInverseSubclassTable[j];
 	}
 
 	public String getDiscriminatorColumnName() {
 		return discriminatorColumnName;
 	}
 
 	public String getDiscriminatorColumnReaders() {
 		return discriminatorColumnReaders;
 	}			
 	
 	public String getDiscriminatorColumnReaderTemplate() {
 		return discriminatorColumnReaderTemplate;
 	}	
 	
 	protected String getDiscriminatorAlias() {
 		return discriminatorAlias;
 	}
 
 	protected String getDiscriminatorFormulaTemplate() {
 		return discriminatorFormulaTemplate;
 	}
 
 	public String getTableName() {
 		return qualifiedTableNames[0];
 	}
 
 	public Type getDiscriminatorType() {
 		return discriminatorType;
 	}
 
 	public Object getDiscriminatorValue() {
 		return discriminatorValue;
 	}
 
 	public String getDiscriminatorSQLValue() {
 		return discriminatorSQLValue;
 	}
 
 	public String[] getSubclassClosure() {
 		return subclassClosure;
 	}
 
 	public String getSubclassForDiscriminatorValue(Object value) {
 		if (value==null) {
 			return (String) subclassesByDiscriminatorValue.get(NULL_DISCRIMINATOR);
 		}
 		else {
 			String result = (String) subclassesByDiscriminatorValue.get(value);
 			if (result==null) result = (String) subclassesByDiscriminatorValue.get(NOT_NULL_DISCRIMINATOR);
 			return result;
 		}
 	}
 
 	public Serializable[] getPropertySpaces() {
 		return spaces;
 	}
 
 	//Access cached SQL
 
 	protected boolean isDiscriminatorFormula() {
 		return discriminatorColumnName==null;
 	}
 
 	protected String getDiscriminatorFormula() {
 		return discriminatorFormula;
 	}
 
 	protected String getTableName(int j) {
 		return qualifiedTableNames[j];
 	}
 	
 	protected String[] getKeyColumns(int j) {
 		return keyColumnNames[j];
 	}
 	
 	protected boolean isTableCascadeDeleteEnabled(int j) {
 		return cascadeDeleteEnabled[j];
 	}
 	
 	protected boolean isPropertyOfTable(int property, int j) {
 		return propertyTableNumbers[property]==j;
 	}
 
 	protected boolean isSubclassTableSequentialSelect(int j) {
 		return subclassTableSequentialSelect[j] && !isClassOrSuperclassTable[j];
 	}
 	
 	// Execute the SQL:
 
 	public String fromTableFragment(String name) {
 		return getTableName() + ' ' + name;
 	}
 
 	public String filterFragment(String alias) throws MappingException {
 		String result = discriminatorFilterFragment(alias);
 		if ( hasWhere() ) result += " and " + getSQLWhereString(alias);
 		return result;
 	}
 	
 	public String oneToManyFilterFragment(String alias) throws MappingException {
 		return forceDiscriminator ?
 			discriminatorFilterFragment(alias) :
 			"";
 	}
 
 	private String discriminatorFilterFragment(String alias) throws MappingException {
 		if ( needsDiscriminator() ) {
 			InFragment frag = new InFragment();
 
 			if ( isDiscriminatorFormula() ) {
 				frag.setFormula( alias, getDiscriminatorFormulaTemplate() );
 			}
 			else {
 				frag.setColumn( alias, getDiscriminatorColumnName() );
 			}
 
 			String[] subclasses = getSubclassClosure();
 			for ( int i=0; i<subclasses.length; i++ ) {
 				final Queryable queryable = (Queryable) getFactory().getEntityPersister( subclasses[i] );
 				if ( !queryable.isAbstract() ) frag.addValue( queryable.getDiscriminatorSQLValue() );
 			}
 
 			StringBuilder buf = new StringBuilder(50)
 				.append(" and ")
 				.append( frag.toFragmentString() );
 
 			return buf.toString();
 		}
 		else {
 			return "";
 		}
 	}
 
 	private boolean needsDiscriminator() {
 		return forceDiscriminator || isInherited();
 	}
 
 	public String getSubclassPropertyTableName(int i) {
 		return subclassTableNameClosure[ subclassPropertyTableNumberClosure[i] ];
 	}
 
 	protected void addDiscriminatorToSelect(SelectFragment select, String name, String suffix) {
 		if ( isDiscriminatorFormula() ) {
 			select.addFormula( name, getDiscriminatorFormulaTemplate(), getDiscriminatorAlias() );
 		}
 		else {
 			select.addColumn( name, getDiscriminatorColumnName(),  getDiscriminatorAlias() );
 		}
 	}
 	
 	protected int[] getPropertyTableNumbersInSelect() {
 		return propertyTableNumbers;
 	}
 
 	protected int getSubclassPropertyTableNumber(int i) {
 		return subclassPropertyTableNumberClosure[i];
 	}
 
 	public int getTableSpan() {
 		return joinSpan;
 	}
 
 	protected void addDiscriminatorToInsert(Insert insert) {
 
 		if (discriminatorInsertable) {
 			insert.addColumn( getDiscriminatorColumnName(), discriminatorSQLValue );
 		}
 
 	}
 
 	protected int[] getSubclassColumnTableNumberClosure() {
 		return subclassColumnTableNumberClosure;
 	}
 
 	protected int[] getSubclassFormulaTableNumberClosure() {
 		return subclassFormulaTableNumberClosure;
 	}
 
 	protected int[] getPropertyTableNumbers() {
 		return propertyTableNumbers;
 	}
 		
 	protected boolean isSubclassPropertyDeferred(String propertyName, String entityName) {
 		return hasSequentialSelects && 
 			isSubclassTableSequentialSelect( getSubclassPropertyTableNumber(propertyName, entityName) );
 	}
 	
 	public boolean hasSequentialSelect() {
 		return hasSequentialSelects;
 	}
 	
 	private int getSubclassPropertyTableNumber(String propertyName, String entityName) {
 		Type type = propertyMapping.toType(propertyName);
 		if ( type.isAssociationType() && ( (AssociationType) type ).useLHSPrimaryKey() ) return 0;
 		final Integer tabnum = (Integer) propertyTableNumbersByNameAndSubclass.get(entityName + '.' + propertyName);
 		return tabnum==null ? 0 : tabnum;
 	}
 	
 	protected String getSequentialSelect(String entityName) {
 		return (String) sequentialSelectStringsByEntityName.get(entityName);
 	}
 
 	private String generateSequentialSelect(Loadable persister) {
 		//if ( this==persister || !hasSequentialSelects ) return null;
 
 		//note that this method could easily be moved up to BasicEntityPersister,
 		//if we ever needed to reuse it from other subclasses
 		
 		//figure out which tables need to be fetched
 		AbstractEntityPersister subclassPersister = (AbstractEntityPersister) persister;
 		HashSet tableNumbers = new HashSet();
 		String[] props = subclassPersister.getPropertyNames();
 		String[] classes = subclassPersister.getPropertySubclassNames();
 		for ( int i=0; i<props.length; i++ ) {
 			int propTableNumber = getSubclassPropertyTableNumber( props[i], classes[i] );
 			if ( isSubclassTableSequentialSelect(propTableNumber) && !isSubclassTableLazy(propTableNumber) ) {
 				tableNumbers.add( propTableNumber);
 			}
 		}
 		if ( tableNumbers.isEmpty() ) return null;
 		
 		//figure out which columns are needed
 		ArrayList columnNumbers = new ArrayList();
 		final int[] columnTableNumbers = getSubclassColumnTableNumberClosure();
 		for ( int i=0; i<getSubclassColumnClosure().length; i++ ) {
 			if ( tableNumbers.contains( columnTableNumbers[i] ) ) {
 				columnNumbers.add( i );
 			}
 		}
 		
 		//figure out which formulas are needed
 		ArrayList formulaNumbers = new ArrayList();
 		final int[] formulaTableNumbers = getSubclassColumnTableNumberClosure();
 		for ( int i=0; i<getSubclassFormulaTemplateClosure().length; i++ ) {
 			if ( tableNumbers.contains( formulaTableNumbers[i] ) ) {
 				formulaNumbers.add( i );
 			}
 		}
 		
 		//render the SQL
 		return renderSelect( 
 			ArrayHelper.toIntArray(tableNumbers),
 			ArrayHelper.toIntArray(columnNumbers),
 			ArrayHelper.toIntArray(formulaNumbers)
 		);
 	}
 		
 		
 	protected String[] getSubclassTableKeyColumns(int j) {
 		return subclassTableKeyColumnClosure[j];
 	}
 
 	public String getSubclassTableName(int j) {
 		return subclassTableNameClosure[j];
 	}
 
 	public int getSubclassTableSpan() {
 		return subclassTableNameClosure.length;
 	}
 
 	protected boolean isClassOrSuperclassTable(int j) {
 		return isClassOrSuperclassTable[j];
 	}
 
 	protected boolean isSubclassTableLazy(int j) {
 		return subclassTableIsLazyClosure[j];
 	}
 	
 	protected boolean isNullableTable(int j) {
 		return isNullableTable[j];
 	}
 	
 	protected boolean isNullableSubclassTable(int j) {
 		return isNullableSubclassTable[j];
 	}
 
 	public String getPropertyTableName(String propertyName) {
 		Integer index = getEntityMetamodel().getPropertyIndexOrNull(propertyName);
 		if (index==null) return null;
 		return qualifiedTableNames[ propertyTableNumbers[index] ];
 	}
 	
-	public void postInstantiate() {
+	protected void doPostInstantiate() {
 		super.postInstantiate();
 		if (hasSequentialSelects) {
 			String[] entityNames = getSubclassClosure();
 			for ( int i=1; i<entityNames.length; i++ ) {
 				Loadable loadable = (Loadable) getFactory().getEntityPersister( entityNames[i] );
 				if ( !loadable.isAbstract() ) { //perhaps not really necessary...
 					String sequentialSelect = generateSequentialSelect(loadable);
 					sequentialSelectStringsByEntityName.put( entityNames[i], sequentialSelect );
 				}
 			}
 		}
 	}
 
 	public boolean isMultiTable() {
 		return getTableSpan() > 1;
 	}
 
 	public String[] getConstraintOrderedTableNameClosure() {
 		return constraintOrderedTableNames;
 	}
 
 	public String[][] getContraintOrderedTableKeyColumnClosure() {
 		return constraintOrderedKeyColumnNames;
 	}
 
 	@Override
 	public FilterAliasGenerator getFilterAliasGenerator(String rootAlias) {
 		return new DynamicFilterAliasGenerator(qualifiedTableNames, rootAlias);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/CompositionSingularSubAttributesHelper.java b/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/CompositionSingularSubAttributesHelper.java
index 3a68c09b7b..f3b80c14f6 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/CompositionSingularSubAttributesHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/CompositionSingularSubAttributesHelper.java
@@ -1,252 +1,287 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.walking.internal;
 
 import java.util.Iterator;
 
+import org.hibernate.FetchMode;
 import org.hibernate.engine.FetchStrategy;
 import org.hibernate.engine.FetchStyle;
 import org.hibernate.engine.FetchTiming;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.engine.spi.CascadeStyles;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.loader.PropertyPath;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.AbstractEntityPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.persister.spi.HydratedCompoundValueHandler;
+import org.hibernate.persister.walking.spi.AnyMappingDefinition;
 import org.hibernate.persister.walking.spi.AssociationAttributeDefinition;
 import org.hibernate.persister.walking.spi.AssociationKey;
 import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.persister.walking.spi.AttributeSource;
 import org.hibernate.persister.walking.spi.CollectionDefinition;
 import org.hibernate.persister.walking.spi.CompositeCollectionElementDefinition;
 import org.hibernate.persister.walking.spi.CompositionDefinition;
 import org.hibernate.persister.walking.spi.EntityDefinition;
 import org.hibernate.persister.walking.spi.WalkingException;
+import org.hibernate.type.AnyType;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.Type;
 
 /**
  * A helper for getting attributes from a composition that is known
  * to have only singular attributes; for example, sub-attributes of a
  * composite ID or a composite collection element.
  *
  * TODO: This should be refactored into a delegate and renamed.
  *
  * @author Gail Badner
  */
 public class CompositionSingularSubAttributesHelper {
 
 	/**
 	 * Get composite ID sub-attribute definitions.
 	 *
 	 * @param entityPersister - the entity persister.
 	 * @return composite ID sub-attribute definitions.
 	 */
 	public static Iterable<AttributeDefinition> getIdentifierSubAttributes(
 			final AbstractEntityPersister entityPersister) {
 		return getSingularSubAttributes(
 				entityPersister,
 				entityPersister,
 				(CompositeType) entityPersister.getIdentifierType(),
 				entityPersister.getTableName(),
 				entityPersister.getRootTableIdentifierColumnNames()
 		);
 	}
 
 	/**
 	 * Get sub-attribute definitions for a composite collection element.
 	 * @param compositionElementDefinition - composite collection element definition.
 	 * @return sub-attribute definitions for a composite collection element.
 	 */
 	public static Iterable<AttributeDefinition> getCompositeCollectionElementSubAttributes(
 			CompositeCollectionElementDefinition compositionElementDefinition) {
 		final QueryableCollection collectionPersister =
 				(QueryableCollection) compositionElementDefinition.getCollectionDefinition().getCollectionPersister();
 		return getSingularSubAttributes(
 				compositionElementDefinition.getSource(),
 				(OuterJoinLoadable) collectionPersister.getOwnerEntityPersister(),
 				(CompositeType) collectionPersister.getElementType(),
 				collectionPersister.getTableName(),
 				collectionPersister.getElementColumnNames()
 		);
 	}
 
 	private static Iterable<AttributeDefinition> getSingularSubAttributes(
 			final AttributeSource source,
 			final OuterJoinLoadable ownerEntityPersister,
 			final CompositeType compositeType,
 			final String lhsTableName,
 			final String[] lhsColumns) {
 		return new Iterable<AttributeDefinition>() {
 			@Override
 			public Iterator<AttributeDefinition> iterator() {
 				return new Iterator<AttributeDefinition>() {
 					private final int numberOfAttributes = compositeType.getSubtypes().length;
 					private int currentSubAttributeNumber = 0;
 					private int currentColumnPosition = 0;
 
 					@Override
 					public boolean hasNext() {
 						return currentSubAttributeNumber < numberOfAttributes;
 					}
 
 					@Override
 					public AttributeDefinition next() {
 						final int subAttributeNumber = currentSubAttributeNumber;
 						currentSubAttributeNumber++;
 
 						final String name = compositeType.getPropertyNames()[subAttributeNumber];
 						final Type type = compositeType.getSubtypes()[subAttributeNumber];
 
 						final int columnPosition = currentColumnPosition;
 						final int columnSpan = type.getColumnSpan( ownerEntityPersister.getFactory() );
 						final String[] subAttributeLhsColumns = ArrayHelper.slice( lhsColumns, columnPosition, columnSpan );
 
+						final boolean nullable = compositeType.getPropertyNullability()[subAttributeNumber];
+
 						currentColumnPosition += columnSpan;
 
 						if ( type.isAssociationType() ) {
 							final AssociationType aType = (AssociationType) type;
 							return new AssociationAttributeDefinition() {
 								@Override
 								public AssociationKey getAssociationKey() {
-									/* TODO: is this always correct? */
-									//return new AssociationKey(
-									//		joinable.getTableName(),
-									//		JoinHelper.getRHSColumnNames( aType, getEntityPersister().getFactory() )
-									//);
-									return new AssociationKey(
-											lhsTableName,
-											subAttributeLhsColumns
-									);
+									return new AssociationKey( lhsTableName, subAttributeLhsColumns );
 								}
 
+
 								@Override
-								public boolean isCollection() {
-									return false;
+								public AssociationNature getAssociationNature() {
+									if ( type.isAnyType() ) {
+										return AssociationNature.ANY;
+									}
+									else {
+										// cannot be a collection
+										return AssociationNature.ENTITY;
+									}
 								}
 
 								@Override
 								public EntityDefinition toEntityDefinition() {
+									if ( getAssociationNature() != AssociationNature.ENTITY ) {
+										throw new WalkingException(
+												"Cannot build EntityDefinition from non-entity-typed attribute"
+										);
+									}
 									return (EntityPersister) aType.getAssociatedJoinable( ownerEntityPersister.getFactory() );
 								}
 
 								@Override
+								public AnyMappingDefinition toAnyDefinition() {
+									if ( getAssociationNature() != AssociationNature.ANY ) {
+										throw new WalkingException(
+												"Cannot build AnyMappingDefinition from non-any-typed attribute"
+										);
+									}
+									// todo : not sure how lazy is propogated into the component for a subattribute of type any
+									return new StandardAnyTypeDefinition( (AnyType) aType, false );
+								}
+
+								@Override
 								public CollectionDefinition toCollectionDefinition() {
 									throw new WalkingException( "A collection cannot be mapped to a composite ID sub-attribute." );
 								}
 
 								@Override
 								public FetchStrategy determineFetchPlan(LoadQueryInfluencers loadQueryInfluencers, PropertyPath propertyPath) {
 									return new FetchStrategy( FetchTiming.IMMEDIATE, FetchStyle.JOIN );
 								}
 
 								@Override
 								public CascadeStyle determineCascadeStyle() {
 									return CascadeStyles.NONE;
 								}
 
 								@Override
 								public HydratedCompoundValueHandler getHydratedCompoundValueExtractor() {
 									return null;
 								}
 
 								@Override
 								public String getName() {
 									return name;
 								}
 
 								@Override
-								public Type getType() {
-									return type;
+								public AssociationType getType() {
+									return aType;
+								}
+
+								@Override
+								public boolean isNullable() {
+									return nullable;
 								}
 
 								@Override
 								public AttributeSource getSource() {
 									return source;
 								}
 							};
 						}
 						else if ( type.isComponentType() ) {
 							return new CompositionDefinition() {
 								@Override
 								public String getName() {
 									return name;
 								}
 
 								@Override
 								public Type getType() {
 									return type;
 								}
 
 								@Override
+								public boolean isNullable() {
+									return nullable;
+								}
+
+								@Override
 								public AttributeSource getSource() {
 									return this;
 								}
 
 								@Override
 								public Iterable<AttributeDefinition> getAttributes() {
 									return CompositionSingularSubAttributesHelper.getSingularSubAttributes(
 											this,
 											ownerEntityPersister,
 											(CompositeType) type,
 											lhsTableName,
 											subAttributeLhsColumns
 									);
 								}
 							};
 						}
 						else {
 							return new AttributeDefinition() {
 								@Override
 								public String getName() {
 									return name;
 								}
 
 								@Override
 								public Type getType() {
 									return type;
 								}
 
 								@Override
+								public boolean isNullable() {
+									return nullable;
+								}
+
+								@Override
 								public AttributeSource getSource() {
 									return source;
 								}
 							};
 						}
 					}
 
 					@Override
 					public void remove() {
 						throw new UnsupportedOperationException( "Remove operation not supported here" );
 					}
 				};
 			}
 		};
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/EntityIdentifierDefinitionHelper.java b/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/EntityIdentifierDefinitionHelper.java
index 6e6e7f5a2f..3a3aba11b4 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/EntityIdentifierDefinitionHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/EntityIdentifierDefinitionHelper.java
@@ -1,153 +1,157 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.walking.internal;
 
 import org.hibernate.persister.entity.AbstractEntityPersister;
 import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.persister.walking.spi.AttributeSource;
 import org.hibernate.persister.walking.spi.CompositionDefinition;
 import org.hibernate.persister.walking.spi.EncapsulatedEntityIdentifierDefinition;
 import org.hibernate.persister.walking.spi.EntityDefinition;
 import org.hibernate.persister.walking.spi.EntityIdentifierDefinition;
 import org.hibernate.persister.walking.spi.NonEncapsulatedEntityIdentifierDefinition;
 import org.hibernate.type.Type;
 
 /**
  * @author Gail Badner
  */
 public class EntityIdentifierDefinitionHelper {
 
 	public static EntityIdentifierDefinition buildSimpleEncapsulatedIdentifierDefinition(final AbstractEntityPersister entityPersister) {
 		return new EncapsulatedEntityIdentifierDefinition() {
 			@Override
 			public AttributeDefinition getAttributeDefinition() {
 				return new AttributeDefinitionAdapter( entityPersister);
 			}
 
 			@Override
 			public boolean isEncapsulated() {
 				return true;
 			}
 
 			@Override
 			public EntityDefinition getEntityDefinition() {
 				return entityPersister;
 			}
 		};
 	}
 
 	public static EntityIdentifierDefinition buildEncapsulatedCompositeIdentifierDefinition(
 			final AbstractEntityPersister entityPersister) {
 
 		return new EncapsulatedEntityIdentifierDefinition() {
 			@Override
 			public AttributeDefinition getAttributeDefinition() {
 				return new CompositionDefinitionAdapter( entityPersister );
 			}
 
 			@Override
 			public boolean isEncapsulated() {
 				return true;
 			}
 
 			@Override
 			public EntityDefinition getEntityDefinition() {
 				return entityPersister;
 			}
 		};
 	}
 
 	public static EntityIdentifierDefinition buildNonEncapsulatedCompositeIdentifierDefinition(final AbstractEntityPersister entityPersister) {
 		return new NonEncapsulatedEntityIdentifierDefinition() {
 			@Override
 			public Iterable<AttributeDefinition> getAttributes() {
 				return CompositionSingularSubAttributesHelper.getIdentifierSubAttributes( entityPersister );
 			}
 
 			@Override
 			public Class getSeparateIdentifierMappingClass() {
 				return entityPersister.getEntityMetamodel().getIdentifierProperty().getType().getReturnedClass();
 			}
 
 			@Override
 			public boolean isEncapsulated() {
 				return false;
 			}
 
 			@Override
 			public EntityDefinition getEntityDefinition() {
 				return entityPersister;
 			}
 		};
 	}
 
 	private static class AttributeDefinitionAdapter implements AttributeDefinition {
 		private final AbstractEntityPersister entityPersister;
 
 		AttributeDefinitionAdapter(AbstractEntityPersister entityPersister) {
 			this.entityPersister = entityPersister;
 		}
 
 		@Override
 		public String getName() {
 			return entityPersister.getEntityMetamodel().getIdentifierProperty().getName();
 		}
 
 		@Override
 		public Type getType() {
 			return entityPersister.getEntityMetamodel().getIdentifierProperty().getType();
 		}
 
 		@Override
+		public boolean isNullable() {
+			return false;
+		}
+
+		@Override
 		public AttributeSource getSource() {
 			return entityPersister;
 		}
 
 		@Override
 		public String toString() {
 			return "<identifier-property:" + getName() + ">";
 		}
 
 		protected AbstractEntityPersister getEntityPersister() {
 			return entityPersister;
 		}
 	}
 
 	private static class CompositionDefinitionAdapter extends AttributeDefinitionAdapter implements CompositionDefinition {
-
 		CompositionDefinitionAdapter(AbstractEntityPersister entityPersister) {
 			super( entityPersister );
 		}
 
 		@Override
 		public String toString() {
 			return "<identifier-property:" + getName() + ">";
 		}
 
 		@Override
 		public Iterable<AttributeDefinition> getAttributes() {
 			return  CompositionSingularSubAttributesHelper.getIdentifierSubAttributes( getEntityPersister() );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/FetchStrategyHelper.java b/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/FetchStrategyHelper.java
index 7d6cf84335..9ddba820c2 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/FetchStrategyHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/FetchStrategyHelper.java
@@ -1,160 +1,170 @@
 /*
  * jDocBook, processing of DocBook sources
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.walking.internal;
 
 import java.util.Iterator;
 
 import org.hibernate.FetchMode;
+import org.hibernate.engine.FetchStrategy;
 import org.hibernate.engine.FetchStyle;
 import org.hibernate.engine.FetchTiming;
 import org.hibernate.engine.profile.Fetch;
 import org.hibernate.engine.profile.FetchProfile;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.loader.PropertyPath;
 import org.hibernate.persister.collection.AbstractCollectionPersister;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.type.AssociationType;
 
 /**
  * @author Steve Ebersole
  */
 public class FetchStrategyHelper {
 	/**
 	 * Determine the fetch-style (if one) explicitly set for this association via fetch profiles.
 	 * <p/>
 	 * Note that currently fetch profiles only allow specifying join fetching, so this method currently
 	 * returns either (a) FetchStyle.JOIN or (b) null
 	 *
 	 * @param loadQueryInfluencers
 	 * @param persister
 	 * @param path
 	 * @param propertyNumber
 	 *
 	 * @return
 	 */
 	public static FetchStyle determineFetchStyleByProfile(
 			LoadQueryInfluencers loadQueryInfluencers,
 			EntityPersister persister,
 			PropertyPath path,
 			int propertyNumber) {
 		if ( !loadQueryInfluencers.hasEnabledFetchProfiles() ) {
 			// perf optimization
 			return null;
 		}
 
 		// ugh, this stuff has to be made easier...
 		final String fullPath = path.getFullPath();
 		final String rootPropertyName = ( (OuterJoinLoadable) persister ).getSubclassPropertyName( propertyNumber );
 		int pos = fullPath.lastIndexOf( rootPropertyName );
 		final String relativePropertyPath = pos >= 0
 				? fullPath.substring( pos )
 				: rootPropertyName;
 		final String fetchRole = persister.getEntityName() + "." + relativePropertyPath;
 
 		Iterator profiles = loadQueryInfluencers.getEnabledFetchProfileNames().iterator();
 		while ( profiles.hasNext() ) {
 			final String profileName = ( String ) profiles.next();
 			final FetchProfile profile = loadQueryInfluencers.getSessionFactory().getFetchProfile( profileName );
 			final Fetch fetch = profile.getFetchByRole( fetchRole );
 			if ( fetch != null && Fetch.Style.JOIN == fetch.getStyle() ) {
 				return FetchStyle.JOIN;
 			}
 		}
 		return null;
 	}
 
 	/**
 	 *
 	 * @param mappingFetchMode The mapping defined fetch mode
 	 * @param type The association type
 	 * @param sessionFactory The session factory
 	 *
 	 * @return
 	 */
 	public static FetchStyle determineFetchStyleByMetadata(
 			FetchMode mappingFetchMode,
 			AssociationType type,
 			SessionFactoryImplementor sessionFactory) {
 		if ( !type.isEntityType() && !type.isCollectionType() ) {
 			return FetchStyle.SELECT;
 		}
 
 		if ( mappingFetchMode == FetchMode.JOIN ) {
 			return FetchStyle.JOIN;
 		}
 
 		if ( type.isEntityType() ) {
 			EntityPersister persister = (EntityPersister) type.getAssociatedJoinable( sessionFactory );
 			if ( persister.isBatchLoadable() ) {
 				return FetchStyle.BATCH;
 			}
 		}
 		else {
 			CollectionPersister persister = (CollectionPersister) type.getAssociatedJoinable( sessionFactory );
 			if ( persister instanceof AbstractCollectionPersister
 					&& ( (AbstractCollectionPersister) persister ).isSubselectLoadable() ) {
 				return FetchStyle.SUBSELECT;
 			}
 			else if ( persister.getBatchSize() > 0 ) {
 				return FetchStyle.BATCH;
 			}
 		}
 
 		return FetchStyle.SELECT;
 	}
 
 	public static FetchTiming determineFetchTiming(
 			FetchStyle style,
 			AssociationType type,
 			SessionFactoryImplementor sessionFactory) {
 		switch ( style ) {
 			case JOIN: {
 				return FetchTiming.IMMEDIATE;
 			}
 			case BATCH:
 			case SUBSELECT: {
 				return FetchTiming.DELAYED;
 			}
 			default: {
 				// SELECT case, can be either
 				return isSubsequentSelectDelayed( type, sessionFactory )
 						? FetchTiming.DELAYED
 						: FetchTiming.IMMEDIATE;
 			}
 		}
 	}
 
 	private static boolean isSubsequentSelectDelayed(AssociationType type, SessionFactoryImplementor sessionFactory) {
-		if ( type.isEntityType() ) {
+		if ( type.isAnyType() ) {
+			// we'd need more context here.  this is only kept as part of the property state on the owning entity
+			return false;
+		}
+		else if ( type.isEntityType() ) {
 			return ( (EntityPersister) type.getAssociatedJoinable( sessionFactory ) ).hasProxy();
 		}
 		else {
 			final CollectionPersister cp = ( (CollectionPersister) type.getAssociatedJoinable( sessionFactory ) );
 			return cp.isLazy() || cp.isExtraLazy();
 		}
 	}
+
+	public static boolean isJoinFetched(FetchStrategy fetchStrategy) {
+		return fetchStrategy.getTiming() == FetchTiming.IMMEDIATE
+				&& fetchStrategy.getStyle() == FetchStyle.JOIN;
+	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/StandardAnyTypeDefinition.java b/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/StandardAnyTypeDefinition.java
new file mode 100644
index 0000000000..790c8f6ffe
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/StandardAnyTypeDefinition.java
@@ -0,0 +1,103 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.persister.walking.internal;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.Map;
+
+import org.hibernate.persister.walking.spi.AnyMappingDefinition;
+import org.hibernate.type.AnyType;
+import org.hibernate.type.MetaType;
+import org.hibernate.type.Type;
+
+/**
+ * @author Steve Ebersole
+ */
+public class StandardAnyTypeDefinition implements AnyMappingDefinition {
+	private final AnyType anyType;
+	private final boolean definedAsLazy;
+	private final List<DiscriminatorMapping> discriminatorMappings;
+
+	public StandardAnyTypeDefinition(AnyType anyType, boolean definedAsLazy) {
+		this.anyType = anyType;
+		this.definedAsLazy = definedAsLazy;
+		this.discriminatorMappings = interpretDiscriminatorMappings( anyType );
+	}
+
+	private static List<DiscriminatorMapping> interpretDiscriminatorMappings(AnyType anyType) {
+		final Type discriminatorType = anyType.getDiscriminatorType();
+		if ( ! MetaType.class.isInstance( discriminatorType ) ) {
+			return Collections.emptyList();
+		}
+
+		final MetaType metaType = (MetaType) discriminatorType;
+		final List<DiscriminatorMapping> discriminatorMappings = new ArrayList<DiscriminatorMapping>();
+		for ( final Map.Entry<Object,String> entry : metaType.getDiscriminatorValuesToEntityNameMap().entrySet() ) {
+			discriminatorMappings.add(
+					new DiscriminatorMapping() {
+						private final Object discriminatorValue = entry.getKey();
+						private final String entityName = entry.getValue();
+
+						@Override
+						public Object getDiscriminatorValue() {
+							return discriminatorValue;
+						}
+
+						@Override
+						public String getEntityName() {
+							return entityName;
+						}
+					}
+			);
+		}
+		return discriminatorMappings;
+	}
+
+	@Override
+	public AnyType getType() {
+		return anyType;
+	}
+
+	@Override
+	public boolean isLazy() {
+		return definedAsLazy;
+	}
+
+	@Override
+	public Type getIdentifierType() {
+		return anyType.getIdentifierType();
+	}
+
+	@Override
+	public Type getDiscriminatorType() {
+		return anyType.getDiscriminatorType();
+	}
+
+	@Override
+	public Iterable<DiscriminatorMapping> getMappingDefinedDiscriminatorMappings() {
+		return discriminatorMappings;
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/walking/spi/AnyMappingDefinition.java b/hibernate-core/src/main/java/org/hibernate/persister/walking/spi/AnyMappingDefinition.java
new file mode 100644
index 0000000000..99fb3f2a9c
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/persister/walking/spi/AnyMappingDefinition.java
@@ -0,0 +1,110 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.persister.walking.spi;
+
+import org.hibernate.type.AnyType;
+import org.hibernate.type.Type;
+
+/**
+ * Describes an ANY mapping
+ *
+ * @author Steve Ebersole
+ */
+public interface AnyMappingDefinition {
+	/**
+	 * Access to the mapping's AnyType
+	 *
+	 * @return The AnyType
+	 */
+	public AnyType getType();
+
+	/**
+	 * Was the mapping defined as lazy?
+	 *
+	 * @return true/false
+	 */
+	public boolean isLazy();
+
+	/**
+	 * Access to the type of the value that makes up the identifier portion of the AnyType.
+	 *
+	 * @return The identifier type
+	 *
+	 * @see org.hibernate.annotations.AnyMetaDef#idType()
+	 */
+	public Type getIdentifierType();
+
+	/**
+	 * Access to the type of the value that makes up the discriminator portion of the AnyType.  The discriminator is
+	 * historically called the "meta".
+	 * <p/>
+	 * NOTE : If explicit discriminator mappings are given, the type here will be a {@link org.hibernate.type.MetaType}.
+	 *
+	 * @return The discriminator type
+	 *
+	 * @see org.hibernate.annotations.Any#metaColumn()
+	 * @see org.hibernate.annotations.AnyMetaDef#metaType()
+	 */
+	public Type getDiscriminatorType();
+
+	/**
+	 * Access to discriminator mappings explicitly defined in the mapping metadata.
+	 *
+	 * There are 2 flavors of discrimination:<ol>
+	 *     <li>
+	 *         The database holds the concrete entity names.  This is an implicit form, meaning that the discriminator
+	 *         mappings do not have to be defined in the mapping metadata.  In this case, an empty iterable is returned
+	 *         here
+	 *     </li>
+	 *     <li>
+	 *         The database holds discriminator values that are interpreted to corresponding entity names based on
+	 *         discriminator mappings explicitly supplied in the mapping metadata (see
+	 *         {@link org.hibernate.annotations.AnyMetaDef#metaValues()}).  In this case, this method gives access
+	 *         to those explicitly defined mappings.
+	 *     </li>
+	 * </ol>
+	 *
+	 * @return The explicitly defined discriminator value mappings.
+	 */
+	public Iterable<DiscriminatorMapping> getMappingDefinedDiscriminatorMappings();
+
+	/**
+	 * Models a single discriminator mapping definition
+	 */
+	public static interface DiscriminatorMapping {
+		/**
+		 * Access to the defined discriminator value (the database value) being mapped.
+		 *
+		 * @return The defined discriminator value
+		 */
+		public Object getDiscriminatorValue();
+
+		/**
+		 * Access to the defined entity name corresponding to the defined {@link #getDiscriminatorValue()}
+		 *
+		 * @return The defined entity name
+		 */
+		public String getEntityName();
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/walking/spi/AssociationAttributeDefinition.java b/hibernate-core/src/main/java/org/hibernate/persister/walking/spi/AssociationAttributeDefinition.java
index 719eb51803..f851640b06 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/walking/spi/AssociationAttributeDefinition.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/walking/spi/AssociationAttributeDefinition.java
@@ -1,49 +1,61 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.walking.spi;
 
 import org.hibernate.engine.FetchStrategy;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.loader.PropertyPath;
 import org.hibernate.persister.spi.HydratedCompoundValueHandler;
+import org.hibernate.type.AssociationType;
 
 /**
  * @author Steve Ebersole
  */
 public interface AssociationAttributeDefinition extends AttributeDefinition {
+	@Override
+	AssociationType getType();
+
 	public AssociationKey getAssociationKey();
 
-	public boolean isCollection();
+	public static enum AssociationNature {
+		ANY,
+		ENTITY,
+		COLLECTION
+	}
+
+	public AssociationNature getAssociationNature();
 
 	public EntityDefinition toEntityDefinition();
 
 	public CollectionDefinition toCollectionDefinition();
 
+	public AnyMappingDefinition toAnyDefinition();
+
 	public FetchStrategy determineFetchPlan(LoadQueryInfluencers loadQueryInfluencers, PropertyPath propertyPath);
 
 	public CascadeStyle determineCascadeStyle();
 
 	public HydratedCompoundValueHandler getHydratedCompoundValueExtractor();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/walking/spi/AssociationVisitationStrategy.java b/hibernate-core/src/main/java/org/hibernate/persister/walking/spi/AssociationVisitationStrategy.java
index d9d475a445..26a8a5c098 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/walking/spi/AssociationVisitationStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/walking/spi/AssociationVisitationStrategy.java
@@ -1,63 +1,65 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.walking.spi;
 
 /**
  * @author Steve Ebersole
  */
 public interface AssociationVisitationStrategy {
 	/**
 	 * Notification we are preparing to start visitation.
 	 */
 	public void start();
 
 	/**
 	 * Notification we are finished visitation.
 	 */
 	public void finish();
 
 	public void startingEntity(EntityDefinition entityDefinition);
 	public void finishingEntity(EntityDefinition entityDefinition);
 
 	public void startingEntityIdentifier(EntityIdentifierDefinition entityIdentifierDefinition);
 	public void finishingEntityIdentifier(EntityIdentifierDefinition entityIdentifierDefinition);
 
 	public void startingCollection(CollectionDefinition collectionDefinition);
 	public void finishingCollection(CollectionDefinition collectionDefinition);
 
 	public void startingCollectionIndex(CollectionIndexDefinition collectionIndexDefinition);
 	public void finishingCollectionIndex(CollectionIndexDefinition collectionIndexDefinition);
 
 	public void startingCollectionElements(CollectionElementDefinition elementDefinition);
 	public void finishingCollectionElements(CollectionElementDefinition elementDefinition);
 
 	public void startingComposite(CompositionDefinition compositionDefinition);
 	public void finishingComposite(CompositionDefinition compositionDefinition);
 
 	public void startingCompositeCollectionElement(CompositeCollectionElementDefinition compositionElementDefinition);
 	public void finishingCompositeCollectionElement(CompositeCollectionElementDefinition compositionElementDefinition);
 
 	public boolean startingAttribute(AttributeDefinition attributeDefinition);
 	public void finishingAttribute(AttributeDefinition attributeDefinition);
+
+	public void foundAny(AssociationAttributeDefinition attributeDefinition, AnyMappingDefinition anyDefinition);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/walking/spi/AttributeDefinition.java b/hibernate-core/src/main/java/org/hibernate/persister/walking/spi/AttributeDefinition.java
index ed58612671..ecea94881c 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/walking/spi/AttributeDefinition.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/walking/spi/AttributeDefinition.java
@@ -1,35 +1,36 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.walking.spi;
 
 import org.hibernate.type.Type;
 
 /**
  * @author Steve Ebersole
  */
 public interface AttributeDefinition {
+	public AttributeSource getSource();
 	public String getName();
 	public Type getType();
-	public AttributeSource getSource();
+	public boolean isNullable();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/walking/spi/CollectionElementDefinition.java b/hibernate-core/src/main/java/org/hibernate/persister/walking/spi/CollectionElementDefinition.java
index 94e05cc242..bb685d1816 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/walking/spi/CollectionElementDefinition.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/walking/spi/CollectionElementDefinition.java
@@ -1,74 +1,88 @@
 /*
  * jDocBook, processing of DocBook sources
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.walking.spi;
 
 import org.hibernate.type.Type;
 
 /**
  * Represents a collection element.
  *
  * @author Steve Ebersole
  */
 public interface CollectionElementDefinition {
 
 	/**
 	 * Returns the collection definition.
 	 * @return  the collection definition.
 	 */
 	public CollectionDefinition getCollectionDefinition();
 
 	/**
 	 * Returns the collection element type.
 	 * @return the collection element type
 	 */
 	public Type getType();
 
 	/**
 	 * If the element type returned by {@link #getType()} is an
 	 * {@link org.hibernate.type.EntityType}, then the entity
 	 * definition for the collection element is returned;
 	 * otherwise, IllegalStateException is thrown.
 	 *
 	 * @return the entity definition for the collection element.
 	 *
 	 * @throws IllegalStateException if the collection element type
 	 * returned by {@link #getType()} is not of type
 	 * {@link org.hibernate.type.EntityType}.
 	 */
+	public AnyMappingDefinition toAnyMappingDefinition();
+
+	/**
+	 * If the element type returned by {@link #getType()} is an
+	 * {@link org.hibernate.type.EntityType}, then the entity
+	 * definition for the collection element is returned;
+	 * otherwise, IllegalStateException is thrown.
+	 *
+	 * @return the entity definition for the collection element.
+	 *
+	 * @throws IllegalStateException if the collection element type
+	 * returned by {@link #getType()} is not of type
+	 * {@link org.hibernate.type.EntityType}.
+	 */
 	public EntityDefinition toEntityDefinition();
 
 	/**
 	 * If the element type returned by {@link #getType()} is a
 	 * {@link org.hibernate.type.CompositeType}, then the composite
 	 * element definition for the collection element is returned;
 	 * otherwise, IllegalStateException is thrown.
 	 *
 	 * @return the composite element definition for the collection element.
 	 *
 	 * @throws IllegalStateException if the collection element type
 	 * returned by {@link #getType()} is not of type
 	 * {@link org.hibernate.type.CompositeType}.
 	 */
 	public CompositeCollectionElementDefinition toCompositeElementDefinition();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/walking/spi/MetadataDrivenModelGraphVisitor.java b/hibernate-core/src/main/java/org/hibernate/persister/walking/spi/MetadataDrivenModelGraphVisitor.java
index ee6e494d8a..89453781b8 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/walking/spi/MetadataDrivenModelGraphVisitor.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/walking/spi/MetadataDrivenModelGraphVisitor.java
@@ -1,247 +1,261 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.walking.spi;
 
 import java.util.HashSet;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
+import org.hibernate.cfg.NotYetImplementedException;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.loader.PropertyPath;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.type.Type;
 
 /**
  * Provides model graph visitation based on the defined metadata (as opposed to based on the incoming graph
  * as we see in cascade processing).  In layman terms, we are walking the graph of the users model as defined by
  * mapped associations.
  * <p/>
  * Re-implementation of the legacy {@link org.hibernate.loader.JoinWalker} contract to leverage load plans.
  *
  * @author Steve Ebersole
  */
 public class MetadataDrivenModelGraphVisitor {
 	private static final Logger log = Logger.getLogger( MetadataDrivenModelGraphVisitor.class );
 
 	public static void visitEntity(AssociationVisitationStrategy strategy, EntityPersister persister) {
 		strategy.start();
 		try {
 			new MetadataDrivenModelGraphVisitor( strategy, persister.getFactory() )
 					.visitEntityDefinition( persister );
 		}
 		finally {
 			strategy.finish();
 		}
 	}
 
 	public static void visitCollection(AssociationVisitationStrategy strategy, CollectionPersister persister) {
 		strategy.start();
 		try {
 			new MetadataDrivenModelGraphVisitor( strategy, persister.getFactory() )
 					.visitCollectionDefinition( persister );
 		}
 		finally {
 			strategy.finish();
 		}
 	}
 
 	private final AssociationVisitationStrategy strategy;
 	private final SessionFactoryImplementor factory;
 
 	// todo : add a getDepth() method to PropertyPath
 	private PropertyPath currentPropertyPath = new PropertyPath();
 
 	public MetadataDrivenModelGraphVisitor(AssociationVisitationStrategy strategy, SessionFactoryImplementor factory) {
 		this.strategy = strategy;
 		this.factory = factory;
 	}
 
 	private void visitEntityDefinition(EntityDefinition entityDefinition) {
 		strategy.startingEntity( entityDefinition );
 
 		visitAttributes( entityDefinition );
 		visitIdentifierDefinition( entityDefinition.getEntityKeyDefinition() );
 
 		strategy.finishingEntity( entityDefinition );
 	}
 
 	private void visitIdentifierDefinition(EntityIdentifierDefinition entityIdentifierDefinition) {
 		strategy.startingEntityIdentifier( entityIdentifierDefinition );
 
 		if ( entityIdentifierDefinition.isEncapsulated() ) {
 			visitAttributeDefinition( ( (EncapsulatedEntityIdentifierDefinition) entityIdentifierDefinition).getAttributeDefinition() );
 		}
 		else {
 			for ( AttributeDefinition attributeDefinition : ( (NonEncapsulatedEntityIdentifierDefinition) entityIdentifierDefinition).getAttributes() ) {
 				visitAttributeDefinition( attributeDefinition );
 			}
 		}
 
 		strategy.finishingEntityIdentifier( entityIdentifierDefinition );
 	}
 
 	private void visitAttributes(AttributeSource attributeSource) {
+		final Iterable<AttributeDefinition> attributeDefinitions = attributeSource.getAttributes();
+		if ( attributeDefinitions == null ) {
+			return;
+		}
 		for ( AttributeDefinition attributeDefinition : attributeSource.getAttributes() ) {
 			visitAttributeDefinition( attributeDefinition );
 		}
 	}
 
 	private void visitAttributeDefinition(AttributeDefinition attributeDefinition) {
 		final PropertyPath subPath = currentPropertyPath.append( attributeDefinition.getName() );
 		log.debug( "Visiting attribute path : " + subPath.getFullPath() );
 
 		final boolean continueWalk;
 		if ( attributeDefinition.getType().isAssociationType() &&
 				isDuplicateAssociationKey( ( (AssociationAttributeDefinition) attributeDefinition ).getAssociationKey() ) ) {
 			log.debug( "Property path deemed to be circular : " + subPath.getFullPath() );
 			continueWalk = false;
 		}
 		else {
 			continueWalk = strategy.startingAttribute( attributeDefinition );
 		}
 		if ( continueWalk ) {
 			final PropertyPath old = currentPropertyPath;
 			currentPropertyPath = subPath;
 			try {
-				if ( attributeDefinition.getType().isAssociationType() ) {
+				final Type attributeType = attributeDefinition.getType();
+				if ( attributeType.isAssociationType() ) {
 					visitAssociation( (AssociationAttributeDefinition) attributeDefinition );
 				}
-				else if ( attributeDefinition.getType().isComponentType() ) {
+				else if ( attributeType.isComponentType() ) {
 					visitCompositeDefinition( (CompositionDefinition) attributeDefinition );
 				}
 			}
 			finally {
 				currentPropertyPath = old;
 			}
 		}
 		strategy.finishingAttribute( attributeDefinition );
 	}
 
 	private void visitAssociation(AssociationAttributeDefinition attribute) {
 		// todo : do "too deep" checks; but see note about adding depth to PropertyPath
 
 		addAssociationKey( attribute.getAssociationKey() );
 
-		if ( attribute.isCollection() ) {
+		final AssociationAttributeDefinition.AssociationNature nature = attribute.getAssociationNature();
+		if ( nature == AssociationAttributeDefinition.AssociationNature.ANY ) {
+			visitAnyDefinition( attribute, attribute.toAnyDefinition() );
+		}
+		else if ( nature == AssociationAttributeDefinition.AssociationNature.COLLECTION ) {
 			visitCollectionDefinition( attribute.toCollectionDefinition() );
 		}
 		else {
 			visitEntityDefinition( attribute.toEntityDefinition() );
 		}
 	}
 
+	private void visitAnyDefinition(AssociationAttributeDefinition attributeDefinition, AnyMappingDefinition anyDefinition) {
+		strategy.foundAny( attributeDefinition, anyDefinition );
+	}
+
 	private void visitCompositeDefinition(CompositionDefinition compositionDefinition) {
 		strategy.startingComposite( compositionDefinition );
 
 		visitAttributes( compositionDefinition );
 
 		strategy.finishingComposite( compositionDefinition );
 	}
 
 	private void visitCollectionDefinition(CollectionDefinition collectionDefinition) {
 		strategy.startingCollection( collectionDefinition );
 
 		visitCollectionIndex( collectionDefinition );
 		visitCollectionElements( collectionDefinition );
 
 		strategy.finishingCollection( collectionDefinition );
 	}
 
 	private void visitCollectionIndex(CollectionDefinition collectionDefinition) {
 		final CollectionIndexDefinition collectionIndexDefinition = collectionDefinition.getIndexDefinition();
 		if ( collectionIndexDefinition == null ) {
 			return;
 		}
 
 		strategy.startingCollectionIndex( collectionIndexDefinition );
 
 		log.debug( "Visiting index for collection :  " + currentPropertyPath.getFullPath() );
 		currentPropertyPath = currentPropertyPath.append( "<index>" );
 
 		try {
 			final Type collectionIndexType = collectionIndexDefinition.getType();
 			if ( collectionIndexType.isComponentType() ) {
 				visitCompositeDefinition( collectionIndexDefinition.toCompositeDefinition() );
 			}
 			else if ( collectionIndexType.isAssociationType() ) {
 				visitEntityDefinition( collectionIndexDefinition.toEntityDefinition() );
 			}
 		}
 		finally {
 			currentPropertyPath = currentPropertyPath.getParent();
 		}
 
 		strategy.finishingCollectionIndex( collectionIndexDefinition );
 	}
 
 	private void visitCollectionElements(CollectionDefinition collectionDefinition) {
 		final CollectionElementDefinition elementDefinition = collectionDefinition.getElementDefinition();
 		strategy.startingCollectionElements( elementDefinition );
 
 		if ( elementDefinition.getType().isComponentType() ) {
 			visitCompositeCollectionElementDefinition( elementDefinition.toCompositeElementDefinition() );
 		}
 		else if ( elementDefinition.getType().isEntityType() ) {
 			visitEntityDefinition( elementDefinition.toEntityDefinition() );
 		}
 
 		strategy.finishingCollectionElements( elementDefinition );
 	}
 
 	private void visitCompositeCollectionElementDefinition(CompositeCollectionElementDefinition compositionElementDefinition) {
 		strategy.startingCompositeCollectionElement( compositionElementDefinition );
 
 		visitAttributes( compositionElementDefinition );
 
 		strategy.finishingCompositeCollectionElement( compositionElementDefinition );
 	}
 
 	private final Set<AssociationKey> visitedAssociationKeys = new HashSet<AssociationKey>();
 
 	/**
 	 * Add association key to indicate the association is being visited.
 	 * @param associationKey - the association key.
 	 * @throws WalkingException if the association with the specified association key
 	 *                          has already been visited.
 	 */
 	protected void addAssociationKey(AssociationKey associationKey) {
 		if ( ! visitedAssociationKeys.add( associationKey ) ) {
 			throw new WalkingException(
 					String.format( "Association has already been visited: %s", associationKey )
 			);
 		}
 	}
 
 	/**
 	 * Has an association with the specified key been visited already?
 	 * @param associationKey - the association key.
 	 * @return true, if the association with the specified association key has already been visited;
 	 *         false, otherwise.
 	 */
 	protected boolean isDuplicateAssociationKey(AssociationKey associationKey) {
 		return visitedAssociationKeys.contains( associationKey );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/property/BasicPropertyAccessor.java b/hibernate-core/src/main/java/org/hibernate/property/BasicPropertyAccessor.java
index 15523c2437..89237cf61f 100644
--- a/hibernate-core/src/main/java/org/hibernate/property/BasicPropertyAccessor.java
+++ b/hibernate-core/src/main/java/org/hibernate/property/BasicPropertyAccessor.java
@@ -1,386 +1,389 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.property;
 import java.beans.Introspector;
 import java.lang.reflect.InvocationTargetException;
 import java.lang.reflect.Member;
 import java.lang.reflect.Method;
 import java.util.Map;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
 import org.hibernate.PropertyAccessException;
 import org.hibernate.PropertyNotFoundException;
+import org.hibernate.PropertySetterAccessException;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 
 /**
  * Accesses property values via a get/set pair, which may be nonpublic.
  * The default (and recommended strategy).
  *
  * @author Gavin King
  */
 public class BasicPropertyAccessor implements PropertyAccessor {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, BasicPropertyAccessor.class.getName());
 
 	public static final class BasicSetter implements Setter {
 		private Class clazz;
 		private final transient Method method;
 		private final String propertyName;
 
 		private BasicSetter(Class clazz, Method method, String propertyName) {
 			this.clazz=clazz;
 			this.method=method;
 			this.propertyName=propertyName;
 		}
 
 		public void set(Object target, Object value, SessionFactoryImplementor factory)
 		throws HibernateException {
 			try {
 				method.invoke( target, value );
 			}
 			catch (NullPointerException npe) {
 				if ( value==null && method.getParameterTypes()[0].isPrimitive() ) {
 					throw new PropertyAccessException(
 							npe,
 							"Null value was assigned to a property of primitive type",
 							true,
 							clazz,
 							propertyName
 						);
 				}
 				else {
 					throw new PropertyAccessException(
 							npe,
 							"NullPointerException occurred while calling",
 							true,
 							clazz,
 							propertyName
 						);
 				}
 			}
 			catch (InvocationTargetException ite) {
 				throw new PropertyAccessException(
 						ite,
 						"Exception occurred inside",
 						true,
 						clazz,
 						propertyName
 					);
 			}
 			catch (IllegalAccessException iae) {
 				throw new PropertyAccessException(
 						iae,
 						"IllegalAccessException occurred while calling",
 						true,
 						clazz,
 						propertyName
 					);
 				//cannot occur
 			}
 			catch (IllegalArgumentException iae) {
 				if ( value==null && method.getParameterTypes()[0].isPrimitive() ) {
 					throw new PropertyAccessException(
 							iae,
 							"Null value was assigned to a property of primitive type",
 							true,
 							clazz,
 							propertyName
 						);
 				}
 				else {
-                    LOG.illegalPropertySetterArgument(clazz.getName(), propertyName);
-                    LOG.expectedType(method.getParameterTypes()[0].getName(), value == null ? null : value.getClass().getName());
-					throw new PropertyAccessException(
+					final Class expectedType = method.getParameterTypes()[0];
+					LOG.illegalPropertySetterArgument( clazz.getName(), propertyName );
+					LOG.expectedType( expectedType.getName(), value == null ? null : value.getClass().getName() );
+					throw new PropertySetterAccessException(
 							iae,
-							"IllegalArgumentException occurred while calling",
-							true,
 							clazz,
-							propertyName
+							propertyName,
+							expectedType,
+							target,
+							value
 						);
 				}
 			}
 		}
 
 		public Method getMethod() {
 			return method;
 		}
 
 		public String getMethodName() {
 			return method.getName();
 		}
 
 		Object readResolve() {
 			return createSetter(clazz, propertyName);
 		}
 
 		@Override
         public String toString() {
 			return "BasicSetter(" + clazz.getName() + '.' + propertyName + ')';
 		}
 	}
 
 	public static final class BasicGetter implements Getter {
 		private Class clazz;
 		private final transient Method method;
 		private final String propertyName;
 
 		private BasicGetter(Class clazz, Method method, String propertyName) {
 			this.clazz=clazz;
 			this.method=method;
 			this.propertyName=propertyName;
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		public Object get(Object target) throws HibernateException {
 			try {
 				return method.invoke( target, (Object[]) null );
 			}
 			catch (InvocationTargetException ite) {
 				throw new PropertyAccessException(
 						ite,
 						"Exception occurred inside",
 						false,
 						clazz,
 						propertyName
 					);
 			}
 			catch (IllegalAccessException iae) {
 				throw new PropertyAccessException(
 						iae,
 						"IllegalAccessException occurred while calling",
 						false,
 						clazz,
 						propertyName
 					);
 				//cannot occur
 			}
 			catch (IllegalArgumentException iae) {
                 LOG.illegalPropertyGetterArgument(clazz.getName(), propertyName);
 				throw new PropertyAccessException(
 						iae,
 						"IllegalArgumentException occurred calling",
 						false,
 						clazz,
 						propertyName
 					);
 			}
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		public Object getForInsert(Object target, Map mergeMap, SessionImplementor session) {
 			return get( target );
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		public Class getReturnType() {
 			return method.getReturnType();
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		public Member getMember() {
 			return method;
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		public Method getMethod() {
 			return method;
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		public String getMethodName() {
 			return method.getName();
 		}
 
 		@Override
         public String toString() {
 			return "BasicGetter(" + clazz.getName() + '.' + propertyName + ')';
 		}
 
 		Object readResolve() {
 			return createGetter(clazz, propertyName);
 		}
 	}
 
 
 	public Setter getSetter(Class theClass, String propertyName)
 	throws PropertyNotFoundException {
 		return createSetter(theClass, propertyName);
 	}
 
 	private static Setter createSetter(Class theClass, String propertyName)
 	throws PropertyNotFoundException {
 		BasicSetter result = getSetterOrNull(theClass, propertyName);
 		if (result==null) {
 			throw new PropertyNotFoundException(
 					"Could not find a setter for property " +
 					propertyName +
 					" in class " +
 					theClass.getName()
 				);
 		}
 		return result;
 	}
 
 	private static BasicSetter getSetterOrNull(Class theClass, String propertyName) {
 
 		if (theClass==Object.class || theClass==null) return null;
 
 		Method method = setterMethod(theClass, propertyName);
 
 		if (method!=null) {
 			if ( !ReflectHelper.isPublic(theClass, method) ) method.setAccessible(true);
 			return new BasicSetter(theClass, method, propertyName);
 		}
 		else {
 			BasicSetter setter = getSetterOrNull( theClass.getSuperclass(), propertyName );
 			if (setter==null) {
 				Class[] interfaces = theClass.getInterfaces();
 				for ( int i=0; setter==null && i<interfaces.length; i++ ) {
 					setter=getSetterOrNull( interfaces[i], propertyName );
 				}
 			}
 			return setter;
 		}
 
 	}
 
 	private static Method setterMethod(Class theClass, String propertyName) {
 
 		BasicGetter getter = getGetterOrNull(theClass, propertyName);
 		Class returnType = (getter==null) ? null : getter.getReturnType();
 
 		Method[] methods = theClass.getDeclaredMethods();
 		Method potentialSetter = null;
 		for ( Method method : methods ) {
 			final String methodName = method.getName();
 
 			if ( method.getParameterTypes().length == 1 && methodName.startsWith( "set" ) ) {
 				String testStdMethod = Introspector.decapitalize( methodName.substring( 3 ) );
 				String testOldMethod = methodName.substring( 3 );
 				if ( testStdMethod.equals( propertyName ) || testOldMethod.equals( propertyName ) ) {
 					potentialSetter = method;
 					if ( returnType == null || method.getParameterTypes()[0].equals( returnType ) ) {
 						return potentialSetter;
 					}
 				}
 			}
 		}
 		return potentialSetter;
 	}
 
 	public Getter getGetter(Class theClass, String propertyName) throws PropertyNotFoundException {
 		return createGetter(theClass, propertyName);
 	}
 
 	public static Getter createGetter(Class theClass, String propertyName) throws PropertyNotFoundException {
 		BasicGetter result = getGetterOrNull(theClass, propertyName);
 		if (result==null) {
 			throw new PropertyNotFoundException(
 					"Could not find a getter for " +
 					propertyName +
 					" in class " +
 					theClass.getName()
 			);
 		}
 		return result;
 	}
 
 	private static BasicGetter getGetterOrNull(Class theClass, String propertyName) {
 		if (theClass==Object.class || theClass==null) {
 			return null;
 		}
 
 		Method method = getterMethod(theClass, propertyName);
 
 		if (method!=null) {
 			if ( !ReflectHelper.isPublic( theClass, method ) ) {
 				method.setAccessible(true);
 			}
 			return new BasicGetter(theClass, method, propertyName);
 		}
 		else {
 			BasicGetter getter = getGetterOrNull( theClass.getSuperclass(), propertyName );
 			if (getter==null) {
 				Class[] interfaces = theClass.getInterfaces();
 				for ( int i=0; getter==null && i<interfaces.length; i++ ) {
 					getter=getGetterOrNull( interfaces[i], propertyName );
 				}
 			}
 			return getter;
 		}
 	}
 
 	private static Method getterMethod(Class theClass, String propertyName) {
 		Method[] methods = theClass.getDeclaredMethods();
 		for ( Method method : methods ) {
 			// if the method has parameters, skip it
 			if ( method.getParameterTypes().length != 0 ) {
 				continue;
 			}
 			// if the method is a "bridge", skip it
 			if ( method.isBridge() ) {
 				continue;
 			}
 
 			final String methodName = method.getName();
 
 			// try "get"
 			if ( methodName.startsWith( "get" ) ) {
 				String testStdMethod = Introspector.decapitalize( methodName.substring( 3 ) );
 				String testOldMethod = methodName.substring( 3 );
 				if ( testStdMethod.equals( propertyName ) || testOldMethod.equals( propertyName ) ) {
 					return method;
 				}
 			}
 
 			// if not "get", then try "is"
 			if ( methodName.startsWith( "is" ) ) {
 				String testStdMethod = Introspector.decapitalize( methodName.substring( 2 ) );
 				String testOldMethod = methodName.substring( 2 );
 				if ( testStdMethod.equals( propertyName ) || testOldMethod.equals( propertyName ) ) {
 					return method;
 				}
 			}
 		}
 
 		return null;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/ANSIJoinFragment.java b/hibernate-core/src/main/java/org/hibernate/sql/ANSIJoinFragment.java
index baf2bb7315..3544ed67e7 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/ANSIJoinFragment.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/ANSIJoinFragment.java
@@ -1,170 +1,178 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.sql;
 
 import org.hibernate.AssertionFailure;
 
 /**
  * An ANSI-style join.
  *
  * @author Gavin King
  */
 public class ANSIJoinFragment extends JoinFragment {
 	private StringBuilder buffer = new StringBuilder();
 	private StringBuilder conditions = new StringBuilder();
 
 	/**
 	 * Adds a join, represented by the given information, to the fragment.
 	 *
 	 * @param tableName The name of the table being joined.
 	 * @param alias The alias applied to the table being joined.
 	 * @param fkColumns The columns (from the table being joined) used to define the join-restriction (the ON)
 	 * @param pkColumns The columns (from the table being joined to) used to define the join-restriction (the ON)
 	 * @param joinType The type of join to produce (INNER, etc).
 	 */
 	public void addJoin(String tableName, String alias, String[] fkColumns, String[] pkColumns, JoinType joinType) {
 		addJoin( tableName, alias, fkColumns, pkColumns, joinType, null );
 	}
 
 	/**
 	 * Adds a join, represented by the given information, to the fragment.
 	 *
-	 * @param tableName The name of the table being joined.
-	 * @param alias The alias applied to the table being joined.
-	 * @param fkColumns The columns (from the table being joined) used to define the join-restriction (the ON)
-	 * @param pkColumns The columns (from the table being joined to) used to define the join-restriction (the ON)
+	 * @param rhsTableName The name of the table being joined (the RHS table).
+	 * @param rhsAlias The alias applied to the table being joined (the alias for the RHS table).
+	 * @param lhsColumns The columns (from the table being joined) used to define the join-restriction (the ON).  These
+	 * are the LHS columns, and are expected to be qualified.
+	 * @param rhsColumns The columns (from the table being joined to) used to define the join-restriction (the ON).  These
+	 * are the RHS columns and are expected to *not* be qualified.
 	 * @param joinType The type of join to produce (INNER, etc).
 	 * @param on Any extra join restrictions
 	 */
-	public void addJoin(String tableName, String alias, String[] fkColumns, String[] pkColumns, JoinType joinType, String on) {
+	public void addJoin(
+			String rhsTableName,
+			String rhsAlias,
+			String[] lhsColumns,
+			String[] rhsColumns,
+			JoinType joinType,
+			String on) {
 		final String joinString;
 		switch (joinType) {
 			case INNER_JOIN:
 				joinString = " inner join ";
 				break;
 			case LEFT_OUTER_JOIN:
 				joinString = " left outer join ";
 				break;
 			case RIGHT_OUTER_JOIN:
 				joinString = " right outer join ";
 				break;
 			case FULL_JOIN:
 				joinString = " full outer join ";
 				break;
 			default:
 				throw new AssertionFailure("undefined join type");
 		}
 
 		this.buffer.append(joinString)
-			.append(tableName)
+			.append(rhsTableName)
 			.append(' ')
-			.append(alias)
+			.append(rhsAlias)
 			.append(" on ");
 
 
-		for ( int j=0; j<fkColumns.length; j++) {
-			this.buffer.append( fkColumns[j] )
+		for ( int j=0; j<lhsColumns.length; j++) {
+			this.buffer.append( lhsColumns[j] )
 				.append('=')
-				.append(alias)
+				.append(rhsAlias)
 				.append('.')
-				.append( pkColumns[j] );
-			if ( j < fkColumns.length-1 ) {
+				.append( rhsColumns[j] );
+			if ( j < lhsColumns.length-1 ) {
 				this.buffer.append( " and " );
 			}
 		}
 
 		addCondition( buffer, on );
 
 	}
 
 	@Override
 	public String toFromFragmentString() {
 		return this.buffer.toString();
 	}
 
 	@Override
 	public String toWhereFragmentString() {
 		return this.conditions.toString();
 	}
 
 	@Override
 	public void addJoins(String fromFragment, String whereFragment) {
 		this.buffer.append( fromFragment );
 		//where fragment must be empty!
 	}
 
 	@Override
 	public JoinFragment copy() {
 		final ANSIJoinFragment copy = new ANSIJoinFragment();
 		copy.buffer = new StringBuilder( this.buffer.toString() );
 		return copy;
 	}
 
 	/**
 	 * Adds a condition to the join fragment.  For each given column a predicate is built in the form:
 	 * {@code [alias.[column] = [condition]}
 	 *
 	 * @param alias The alias to apply to column(s)
 	 * @param columns The columns to apply restriction
 	 * @param condition The restriction condition
 	 */
 	public void addCondition(String alias, String[] columns, String condition) {
 		for ( String column : columns ) {
 			this.conditions.append( " and " )
 					.append( alias )
 					.append( '.' )
 					.append( column )
 					.append( condition );
 		}
 	}
 
 	@Override
 	public void addCrossJoin(String tableName, String alias) {
 		this.buffer.append(", ")
 			.append(tableName)
 			.append(' ')
 			.append(alias);
 	}
 
 	@Override
 	public void addCondition(String alias, String[] fkColumns, String[] pkColumns) {
 		throw new UnsupportedOperationException();
 
 	}
 
 	@Override
 	public boolean addCondition(String condition) {
 		return addCondition(conditions, condition);
 	}
 
 	/**
 	 * Adds an externally built join fragment.
 	 *
 	 * @param fromFragmentString The join fragment string
 	 */
 	public void addFromFragmentString(String fromFragmentString) {
 		this.buffer.append(fromFragmentString);
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/CacheJoinFragment.java b/hibernate-core/src/main/java/org/hibernate/sql/CacheJoinFragment.java
index 2470c0f9af..4af4208776 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/CacheJoinFragment.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/CacheJoinFragment.java
@@ -1,44 +1,44 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.sql;
 import org.hibernate.AssertionFailure;
 
 /**
  * A Cach&eacute; dialect join.  Differs from ANSI only in that full outer join
  * is not supported.
  *
  * @author Jeff Miller
  * @author Jonathan Levinson
  */
 public class CacheJoinFragment extends ANSIJoinFragment {
 
-	public void addJoin(String tableName, String alias, String[] fkColumns, String[] pkColumns, JoinType joinType, String on) {
+	public void addJoin(String rhsTableName, String rhsAlias, String[] lhsColumns, String[] rhsColumns, JoinType joinType, String on) {
 		if ( joinType == JoinType.FULL_JOIN ) {
 			throw new AssertionFailure( "Cache does not support full outer joins" );
 		}
-		super.addJoin( tableName, alias, fkColumns, pkColumns, joinType, on );
+		super.addJoin( rhsTableName, rhsAlias, lhsColumns, rhsColumns, joinType, on );
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/DisjunctionFragment.java b/hibernate-core/src/main/java/org/hibernate/sql/DisjunctionFragment.java
index cb4ea0b8b8..89b2a92682 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/DisjunctionFragment.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/DisjunctionFragment.java
@@ -1,47 +1,53 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.sql;
 
 
 /**
  * A disjunctive string of conditions
  * @author Gavin King
  */
 public class DisjunctionFragment {
-
 	private StringBuilder buffer = new StringBuilder();
 
 	public DisjunctionFragment addCondition(ConditionFragment fragment) {
-		if ( buffer.length()>0 ) buffer.append(" or ");
-		buffer.append("(")
-			.append( fragment.toFragmentString() )
-			.append(")");
+		addCondition( fragment.toFragmentString() );
+		return this;
+	}
+
+	public DisjunctionFragment addCondition(String fragment) {
+		if ( buffer.length() > 0 ) {
+			buffer.append(" or ");
+		}
+		buffer.append( '(' )
+				.append( fragment )
+				.append( ')' );
 		return this;
 	}
 
 	public String toFragmentString() {
 		return buffer.toString();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/component/AbstractCompositionAttribute.java b/hibernate-core/src/main/java/org/hibernate/tuple/component/AbstractCompositionAttribute.java
index d2bf2c4526..bceaf833af 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/component/AbstractCompositionAttribute.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/component/AbstractCompositionAttribute.java
@@ -1,210 +1,254 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tuple.component;
 
 import java.util.Iterator;
 
+import org.hibernate.engine.internal.JoinHelper;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
+import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.persister.walking.spi.AssociationKey;
 import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.persister.walking.spi.AttributeSource;
 import org.hibernate.persister.walking.spi.CompositionDefinition;
 import org.hibernate.persister.walking.spi.EntityDefinition;
 import org.hibernate.tuple.AbstractNonIdentifierAttribute;
 import org.hibernate.tuple.BaselineAttributeInformation;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.ForeignKeyDirection;
 import org.hibernate.type.Type;
 
 import static org.hibernate.engine.internal.JoinHelper.getLHSColumnNames;
 import static org.hibernate.engine.internal.JoinHelper.getLHSTableName;
 import static org.hibernate.engine.internal.JoinHelper.getRHSColumnNames;
 
 /**
  * A base class for a composite, non-identifier attribute.
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractCompositionAttribute extends AbstractNonIdentifierAttribute implements
 																						   CompositionDefinition {
 	protected AbstractCompositionAttribute(
 			AttributeSource source,
 			SessionFactoryImplementor sessionFactory,
 			int attributeNumber,
 			String attributeName,
 			CompositeType attributeType,
 			BaselineAttributeInformation baselineInfo) {
 		super( source, sessionFactory, attributeNumber, attributeName, attributeType, baselineInfo );
 	}
 
 	@Override
 	public CompositeType getType() {
 		return (CompositeType) super.getType();
 	}
 
 	@Override
 	public Iterable<AttributeDefinition> getAttributes() {
 		return new Iterable<AttributeDefinition>() {
 			@Override
 			public Iterator<AttributeDefinition> iterator() {
 				return new Iterator<AttributeDefinition>() {
 					private final int numberOfAttributes = getType().getSubtypes().length;
 					private int currentSubAttributeNumber = 0;
 					private int currentColumnPosition = 0;
 
 					@Override
 					public boolean hasNext() {
 						return currentSubAttributeNumber < numberOfAttributes;
 					}
 
 					@Override
 					public AttributeDefinition next() {
 						final int subAttributeNumber = currentSubAttributeNumber;
 						currentSubAttributeNumber++;
 
 						final String name = getType().getPropertyNames()[subAttributeNumber];
 						final Type type = getType().getSubtypes()[subAttributeNumber];
 
 						int columnPosition = currentColumnPosition;
 						currentColumnPosition += type.getColumnSpan( sessionFactory() );
 
 						if ( type.isAssociationType() ) {
 							// we build the association-key here because of the "goofiness" with 'currentColumnPosition'
 							final AssociationKey associationKey;
 							final AssociationType aType = (AssociationType) type;
 							final Joinable joinable = aType.getAssociatedJoinable( sessionFactory() );
-							if ( aType.getForeignKeyDirection() == ForeignKeyDirection.FOREIGN_KEY_FROM_PARENT ) {
+
+							if ( aType.isAnyType() ) {
 								associationKey = new AssociationKey(
-										getLHSTableName(
+										JoinHelper.getLHSTableName(
 												aType,
 												attributeNumber(),
-												(OuterJoinLoadable) locateOwningPersister()
+												(OuterJoinLoadable) getSource()
 										),
-										getLHSColumnNames(
+										JoinHelper.getLHSColumnNames(
 												aType,
 												attributeNumber(),
-												columnPosition,
-												(OuterJoinLoadable) locateOwningPersister(),
+												0,
+												(OuterJoinLoadable) getSource(),
 												sessionFactory()
 										)
 								);
 							}
+							else if ( aType.getForeignKeyDirection() == ForeignKeyDirection.FOREIGN_KEY_FROM_PARENT ) {
+								final String lhsTableName;
+								final String[] lhsColumnNames;
+
+								if ( joinable.isCollection() ) {
+									final QueryableCollection collectionPersister = (QueryableCollection) joinable;
+									lhsTableName = collectionPersister.getTableName();
+									lhsColumnNames = collectionPersister.getElementColumnNames();
+								}
+								else {
+									final OuterJoinLoadable entityPersister = (OuterJoinLoadable) locateOwningPersister();
+									lhsTableName = getLHSTableName( aType, attributeNumber(), entityPersister );
+									lhsColumnNames = getLHSColumnNames( aType, attributeNumber(), entityPersister, sessionFactory() );
+								}
+								associationKey = new AssociationKey( lhsTableName, lhsColumnNames );
+
+//								associationKey = new AssociationKey(
+//										getLHSTableName(
+//												aType,
+//												attributeNumber(),
+//												(OuterJoinLoadable) locateOwningPersister()
+//										),
+//										getLHSColumnNames(
+//												aType,
+//												attributeNumber(),
+//												columnPosition,
+//												(OuterJoinLoadable) locateOwningPersister(),
+//												sessionFactory()
+//										)
+//								);
+							}
 							else {
 								associationKey = new AssociationKey(
 										joinable.getTableName(),
 										getRHSColumnNames( aType, sessionFactory() )
 								);
 							}
 
+							final CompositeType cType = getType();
+							final boolean nullable = cType.getPropertyNullability() == null
+									? true
+									: cType.getPropertyNullability()[ subAttributeNumber ];
+
 							return new CompositeBasedAssociationAttribute(
 									AbstractCompositionAttribute.this,
 									sessionFactory(),
 									subAttributeNumber,
 									name,
 									(AssociationType) type,
 									new BaselineAttributeInformation.Builder()
 											.setInsertable( AbstractCompositionAttribute.this.isInsertable() )
 											.setUpdateable( AbstractCompositionAttribute.this.isUpdateable() )
 											.setInsertGenerated( AbstractCompositionAttribute.this.isInsertGenerated() )
 											.setUpdateGenerated( AbstractCompositionAttribute.this.isUpdateGenerated() )
-											.setNullable( getType().getPropertyNullability()[subAttributeNumber] )
+											.setNullable( nullable )
 											.setDirtyCheckable( true )
 											.setVersionable( AbstractCompositionAttribute.this.isVersionable() )
 											.setCascadeStyle( getType().getCascadeStyle( subAttributeNumber ) )
 											.setFetchMode( getType().getFetchMode( subAttributeNumber ) )
 											.createInformation(),
 									AbstractCompositionAttribute.this.attributeNumber(),
 									associationKey
 							);
 						}
 						else if ( type.isComponentType() ) {
 							return new CompositionBasedCompositionAttribute(
 									AbstractCompositionAttribute.this,
 									sessionFactory(),
 									subAttributeNumber,
 									name,
 									(CompositeType) type,
 									new BaselineAttributeInformation.Builder()
 											.setInsertable( AbstractCompositionAttribute.this.isInsertable() )
 											.setUpdateable( AbstractCompositionAttribute.this.isUpdateable() )
 											.setInsertGenerated( AbstractCompositionAttribute.this.isInsertGenerated() )
 											.setUpdateGenerated( AbstractCompositionAttribute.this.isUpdateGenerated() )
 											.setNullable( getType().getPropertyNullability()[subAttributeNumber] )
 											.setDirtyCheckable( true )
 											.setVersionable( AbstractCompositionAttribute.this.isVersionable() )
 											.setCascadeStyle( getType().getCascadeStyle( subAttributeNumber ) )
 											.setFetchMode( getType().getFetchMode( subAttributeNumber ) )
 											.createInformation()
 							);
 						}
 						else {
+							final CompositeType cType = getType();
+							final boolean nullable = cType.getPropertyNullability() == null
+									? true
+									: cType.getPropertyNullability()[ subAttributeNumber ];
+
 							return new CompositeBasedBasicAttribute(
 									AbstractCompositionAttribute.this,
 									sessionFactory(),
 									subAttributeNumber,
 									name,
 									type,
 									new BaselineAttributeInformation.Builder()
 											.setInsertable( AbstractCompositionAttribute.this.isInsertable() )
 											.setUpdateable( AbstractCompositionAttribute.this.isUpdateable() )
 											.setInsertGenerated( AbstractCompositionAttribute.this.isInsertGenerated() )
 											.setUpdateGenerated( AbstractCompositionAttribute.this.isUpdateGenerated() )
-											.setNullable( getType().getPropertyNullability()[subAttributeNumber] )
+											.setNullable( nullable )
 											.setDirtyCheckable( true )
 											.setVersionable( AbstractCompositionAttribute.this.isVersionable() )
 											.setCascadeStyle( getType().getCascadeStyle( subAttributeNumber ) )
 											.setFetchMode( getType().getFetchMode( subAttributeNumber ) )
 											.createInformation()
 							);
 						}
 					}
 
 					@Override
 					public void remove() {
 						throw new UnsupportedOperationException( "Remove operation not supported here" );
 					}
 				};
 			}
 		};
 	}
 
 	public EntityPersister locateOwningPersister() {
 		if ( EntityDefinition.class.isInstance( getSource() ) ) {
 			return ( (EntityDefinition) getSource() ).getEntityPersister();
 		}
 		else {
 			return ( (AbstractCompositionAttribute) getSource() ).locateOwningPersister();
 		}
 	}
 
 	@Override
 	protected String loggableMetadata() {
 		return super.loggableMetadata() + ",composition";
 	}
 }
 
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/component/CompositeBasedAssociationAttribute.java b/hibernate-core/src/main/java/org/hibernate/tuple/component/CompositeBasedAssociationAttribute.java
index 72eb5eac0b..d3d52ecc3c 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/component/CompositeBasedAssociationAttribute.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/component/CompositeBasedAssociationAttribute.java
@@ -1,183 +1,224 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tuple.component;
 
 import org.hibernate.FetchMode;
 import org.hibernate.engine.FetchStrategy;
 import org.hibernate.engine.FetchStyle;
 import org.hibernate.engine.FetchTiming;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.loader.PropertyPath;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.persister.spi.HydratedCompoundValueHandler;
 import org.hibernate.persister.walking.internal.FetchStrategyHelper;
+import org.hibernate.persister.walking.internal.StandardAnyTypeDefinition;
+import org.hibernate.persister.walking.spi.AnyMappingDefinition;
 import org.hibernate.persister.walking.spi.AssociationAttributeDefinition;
 import org.hibernate.persister.walking.spi.AssociationKey;
 import org.hibernate.persister.walking.spi.CollectionDefinition;
 import org.hibernate.persister.walking.spi.EntityDefinition;
+import org.hibernate.persister.walking.spi.WalkingException;
 import org.hibernate.tuple.BaselineAttributeInformation;
+import org.hibernate.type.AnyType;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CompositeType;
 
 /**
  * @author Steve Ebersole
  */
 public class CompositeBasedAssociationAttribute
 		extends AbstractCompositeBasedAttribute
 		implements AssociationAttributeDefinition {
 
 	private final AssociationKey associationKey;
 	private Joinable joinable;
 
 	public CompositeBasedAssociationAttribute(
 			AbstractCompositionAttribute source,
 			SessionFactoryImplementor factory,
 			int attributeNumber,
 			String attributeName,
 			AssociationType attributeType,
 			BaselineAttributeInformation baselineInfo,
 			int ownerAttributeNumber,
 			AssociationKey associationKey) {
 		super( source, factory, attributeNumber, attributeName, attributeType, baselineInfo, ownerAttributeNumber );
 		this.associationKey = associationKey;
 	}
 
 	@Override
 	public AssociationType getType() {
 		return (AssociationType) super.getType();
 	}
 
 	protected Joinable getJoinable() {
 		if ( joinable == null ) {
 			joinable = getType().getAssociatedJoinable( sessionFactory() );
 		}
 		return joinable;
 	}
 
 	@Override
 	public AssociationKey getAssociationKey() {
 		return associationKey;
 	}
 
 	@Override
-	public boolean isCollection() {
-		return getJoinable().isCollection();
+	public AssociationNature getAssociationNature() {
+		if ( getType().isAnyType() ) {
+			return AssociationNature.ANY;
+		}
+		else {
+			if ( getJoinable().isCollection() ) {
+				return AssociationNature.COLLECTION;
+			}
+			else {
+				return AssociationNature.ENTITY;
+			}
+		}
+	}
+
+	private boolean isAnyType() {
+		return getAssociationNature() == AssociationNature.ANY;
+	}
+
+	private boolean isEntityType() {
+		return getAssociationNature() == AssociationNature.ENTITY;
+	}
+
+	private boolean isCollection() {
+		return getAssociationNature() == AssociationNature.COLLECTION;
+	}
+
+	@Override
+	public AnyMappingDefinition toAnyDefinition() {
+		if ( !isAnyType() ) {
+			throw new WalkingException( "Cannot build AnyMappingDefinition from non-any-typed attribute" );
+		}
+		// todo : not sure how lazy is propogated into the component for a subattribute of type any
+		return new StandardAnyTypeDefinition( (AnyType) getType(), false );
 	}
 
 	@Override
 	public EntityDefinition toEntityDefinition() {
 		if ( isCollection() ) {
 			throw new IllegalStateException( "Cannot treat collection attribute as entity type" );
 		}
+		if ( isAnyType() ) {
+			throw new IllegalStateException( "Cannot treat any-type attribute as entity type" );
+		}
 		return (EntityPersister) getJoinable();
 	}
 
 	@Override
 	public CollectionDefinition toCollectionDefinition() {
-		if ( isCollection() ) {
+		if ( isEntityType() ) {
 			throw new IllegalStateException( "Cannot treat entity attribute as collection type" );
 		}
+		if ( isAnyType() ) {
+			throw new IllegalStateException( "Cannot treat any-type attribute as collection type" );
+		}
 		return (CollectionPersister) getJoinable();
 	}
 
 	@Override
 	public FetchStrategy determineFetchPlan(LoadQueryInfluencers loadQueryInfluencers, PropertyPath propertyPath) {
 		final EntityPersister owningPersister = locateOwningPersister();
 
 		FetchStyle style = determineFetchStyleByProfile(
 				loadQueryInfluencers,
 				owningPersister,
 				propertyPath,
 				ownerAttributeNumber()
 		);
 		if ( style == null ) {
 			style = determineFetchStyleByMetadata(
 					getSource().getType().getFetchMode( attributeNumber() ),
 					getType()
 			);
 		}
 
 		return new FetchStrategy( determineFetchTiming( style ), style );
 	}
 
 	protected FetchStyle determineFetchStyleByProfile(
 			LoadQueryInfluencers loadQueryInfluencers,
 			EntityPersister owningPersister,
 			PropertyPath propertyPath,
 			int ownerAttributeNumber) {
 		return FetchStrategyHelper.determineFetchStyleByProfile(
 				loadQueryInfluencers,
 				owningPersister,
 				propertyPath,
 				ownerAttributeNumber
 		);
 	}
 
 	protected FetchStyle determineFetchStyleByMetadata(FetchMode fetchMode, AssociationType type) {
 		return FetchStrategyHelper.determineFetchStyleByMetadata( fetchMode, type, sessionFactory() );
 	}
 
 	private FetchTiming determineFetchTiming(FetchStyle style) {
 		return FetchStrategyHelper.determineFetchTiming( style, getType(), sessionFactory() );
 	}
 
 	private EntityPersister locateOwningPersister() {
 		return getSource().locateOwningPersister();
 	}
 
 	@Override
 	public CascadeStyle determineCascadeStyle() {
 		final CompositeType compositeType = (CompositeType) locateOwningPersister().getPropertyType( getName() );
 		return compositeType.getCascadeStyle( attributeNumber() );
 	}
 
 	private HydratedCompoundValueHandler hydratedCompoundValueHandler;
 
 	@Override
 	public HydratedCompoundValueHandler getHydratedCompoundValueExtractor() {
 		if ( hydratedCompoundValueHandler == null ) {
 			hydratedCompoundValueHandler = new HydratedCompoundValueHandler() {
 				@Override
 				public Object extract(Object hydratedState) {
 					return ( (Object[] ) hydratedState )[ attributeNumber() ];
 				}
 
 				@Override
 				public void inject(Object hydratedState, Object value) {
 					( (Object[] ) hydratedState )[ attributeNumber() ] = value;
 				}
 			};
 		}
 		return hydratedCompoundValueHandler;
 	}
 
 	@Override
 	protected String loggableMetadata() {
 		return super.loggableMetadata() + ",association";
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/entity/EntityBasedAssociationAttribute.java b/hibernate-core/src/main/java/org/hibernate/tuple/entity/EntityBasedAssociationAttribute.java
index 78d803e43b..3e1092e387 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/entity/EntityBasedAssociationAttribute.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/entity/EntityBasedAssociationAttribute.java
@@ -1,181 +1,228 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tuple.entity;
 
 import org.hibernate.engine.FetchStrategy;
 import org.hibernate.engine.FetchStyle;
+import org.hibernate.engine.internal.JoinHelper;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.loader.PropertyPath;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.persister.spi.HydratedCompoundValueHandler;
 import org.hibernate.persister.walking.internal.FetchStrategyHelper;
+import org.hibernate.persister.walking.internal.StandardAnyTypeDefinition;
+import org.hibernate.persister.walking.spi.AnyMappingDefinition;
 import org.hibernate.persister.walking.spi.AssociationAttributeDefinition;
 import org.hibernate.persister.walking.spi.AssociationKey;
 import org.hibernate.persister.walking.spi.CollectionDefinition;
 import org.hibernate.persister.walking.spi.EntityDefinition;
+import org.hibernate.persister.walking.spi.WalkingException;
 import org.hibernate.tuple.BaselineAttributeInformation;
+import org.hibernate.type.AnyType;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.ForeignKeyDirection;
 
 import static org.hibernate.engine.internal.JoinHelper.getLHSColumnNames;
 import static org.hibernate.engine.internal.JoinHelper.getLHSTableName;
 import static org.hibernate.engine.internal.JoinHelper.getRHSColumnNames;
 
 /**
 * @author Steve Ebersole
 */
 public class EntityBasedAssociationAttribute
 		extends AbstractEntityBasedAttribute
 		implements AssociationAttributeDefinition {
 
-	private Joinable joinable;
 
 	public EntityBasedAssociationAttribute(
 			EntityPersister source,
 			SessionFactoryImplementor sessionFactory,
 			int attributeNumber,
 			String attributeName,
 			AssociationType attributeType,
 			BaselineAttributeInformation baselineInfo) {
 		super( source, sessionFactory, attributeNumber, attributeName, attributeType, baselineInfo );
 	}
 
 	@Override
 	public AssociationType getType() {
 		return (AssociationType) super.getType();
 	}
-
-	protected Joinable getJoinable() {
-		if ( joinable == null ) {
-			joinable = getType().getAssociatedJoinable( sessionFactory() );
-		}
-		return joinable;
-	}
-
 	@Override
 	public AssociationKey getAssociationKey() {
 		final AssociationType type = getType();
+
+		if ( type.isAnyType() ) {
+			return new AssociationKey(
+					JoinHelper.getLHSTableName( type, attributeNumber(), (OuterJoinLoadable) getSource() ),
+					JoinHelper.getLHSColumnNames(
+							type,
+							attributeNumber(),
+							0,
+							(OuterJoinLoadable) getSource(),
+							sessionFactory()
+					)
+			);
+		}
+
 		final Joinable joinable = type.getAssociatedJoinable( sessionFactory() );
 
 		if ( type.getForeignKeyDirection() == ForeignKeyDirection.FOREIGN_KEY_FROM_PARENT ) {
 			final String lhsTableName;
 			final String[] lhsColumnNames;
 
 			if ( joinable.isCollection() ) {
 				final QueryableCollection collectionPersister = (QueryableCollection) joinable;
 				lhsTableName = collectionPersister.getTableName();
 				lhsColumnNames = collectionPersister.getElementColumnNames();
 			}
 			else {
 				final OuterJoinLoadable entityPersister = (OuterJoinLoadable) source();
 				lhsTableName = getLHSTableName( type, attributeNumber(), entityPersister );
 				lhsColumnNames = getLHSColumnNames( type, attributeNumber(), entityPersister, sessionFactory() );
 			}
 			return new AssociationKey( lhsTableName, lhsColumnNames );
 		}
 		else {
 			return new AssociationKey( joinable.getTableName(), getRHSColumnNames( type, sessionFactory() ) );
 		}
 	}
 
 	@Override
-	public boolean isCollection() {
-		return getJoinable().isCollection();
+	public AssociationNature getAssociationNature() {
+		if ( getType().isAnyType() ) {
+			return AssociationNature.ANY;
+		}
+		else {
+			if ( getType().isCollectionType() ) {
+				return AssociationNature.COLLECTION;
+			}
+			else {
+				return AssociationNature.ENTITY;
+			}
+		}
+	}
+
+	@Override
+	public AnyMappingDefinition toAnyDefinition() {
+		return new StandardAnyTypeDefinition(
+				(AnyType) getType(),
+				getSource().getEntityMetamodel().getProperties()[ attributeNumber() ].isLazy()
+		);
+	}
+
+	private Joinable joinable;
+
+	protected Joinable getJoinable() {
+		if ( getAssociationNature() == AssociationNature.ANY ) {
+			throw new WalkingException( "Cannot resolve AnyType to a Joinable" );
+		}
+
+		if ( joinable == null ) {
+			joinable = getType().getAssociatedJoinable( sessionFactory() );
+		}
+		return joinable;
 	}
 
 	@Override
 	public EntityDefinition toEntityDefinition() {
-		if ( isCollection() ) {
+		if ( getAssociationNature() == AssociationNature.ANY ) {
+			throw new WalkingException( "Cannot treat any-type attribute as an entity type" );
+		}
+		if ( getAssociationNature() == AssociationNature.COLLECTION ) {
 			throw new IllegalStateException( "Cannot treat collection-valued attribute as entity type" );
 		}
 		return (EntityPersister) getJoinable();
 	}
 
 	@Override
 	public CollectionDefinition toCollectionDefinition() {
-		if ( ! isCollection() ) {
+		if ( getAssociationNature() == AssociationNature.ANY ) {
+			throw new WalkingException( "Cannot treat any-type attribute as a collection type" );
+		}
+		if ( getAssociationNature() == AssociationNature.ENTITY ) {
 			throw new IllegalStateException( "Cannot treat entity-valued attribute as collection type" );
 		}
 		return (QueryableCollection) getJoinable();
 	}
 
 	@Override
 	public FetchStrategy determineFetchPlan(LoadQueryInfluencers loadQueryInfluencers, PropertyPath propertyPath) {
 		final EntityPersister owningPersister = getSource().getEntityPersister();
 
 		FetchStyle style = FetchStrategyHelper.determineFetchStyleByProfile(
 				loadQueryInfluencers,
 				owningPersister,
 				propertyPath,
 				attributeNumber()
 		);
 		if ( style == null ) {
 			style = FetchStrategyHelper.determineFetchStyleByMetadata(
 					( (OuterJoinLoadable) getSource().getEntityPersister() ).getFetchMode( attributeNumber() ),
 					getType(),
 					sessionFactory()
 			);
 		}
 
 		return new FetchStrategy(
 				FetchStrategyHelper.determineFetchTiming( style, getType(), sessionFactory() ),
 				style
 		);
 	}
 
 	@Override
 	public CascadeStyle determineCascadeStyle() {
 		return getSource().getEntityPersister().getPropertyCascadeStyles()[attributeNumber()];
 	}
 
 	private HydratedCompoundValueHandler hydratedCompoundValueHandler;
 
 	@Override
 	public HydratedCompoundValueHandler getHydratedCompoundValueExtractor() {
 		if ( hydratedCompoundValueHandler == null ) {
 			hydratedCompoundValueHandler = new HydratedCompoundValueHandler() {
 				@Override
 				public Object extract(Object hydratedState) {
 					return ( (Object[] ) hydratedState )[ attributeNumber() ];
 				}
 
 				@Override
 				public void inject(Object hydratedState, Object value) {
 					( (Object[] ) hydratedState )[ attributeNumber() ] = value;
 				}
 			};
 		}
 		return hydratedCompoundValueHandler;
 	}
 
 	@Override
 	protected String loggableMetadata() {
 		return super.loggableMetadata() + ",association";
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/AnyType.java b/hibernate-core/src/main/java/org/hibernate/type/AnyType.java
index 33a9bec9e0..b8a25c54ab 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/AnyType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/AnyType.java
@@ -1,406 +1,527 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.io.Serializable;
 import java.lang.reflect.Method;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Arrays;
 import java.util.Map;
 
 import org.dom4j.Node;
 
 import org.hibernate.EntityMode;
+import org.hibernate.EntityNameResolver;
 import org.hibernate.FetchMode;
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.TransientObjectException;
 import org.hibernate.engine.internal.ForeignKeys;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.engine.spi.CascadeStyles;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.metamodel.relational.Size;
+import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Joinable;
+import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.proxy.HibernateProxyHelper;
+import org.hibernate.proxy.LazyInitializer;
 
 /**
  * Handles "any" mappings
  * 
  * @author Gavin King
  */
 public class AnyType extends AbstractType implements CompositeType, AssociationType {
+	private final TypeFactory.TypeScope scope;
 	private final Type identifierType;
-	private final Type metaType;
+	private final Type discriminatorType;
 
-	public AnyType(Type metaType, Type identifierType) {
+	/**
+	 * Intended for use only from legacy {@link ObjectType} type definition
+	 *
+	 * @param discriminatorType
+	 * @param identifierType
+	 */
+	protected AnyType(Type discriminatorType, Type identifierType) {
+		this( null, discriminatorType, identifierType );
+	}
+
+	public AnyType(TypeFactory.TypeScope scope, Type discriminatorType, Type identifierType) {
+		this.scope = scope;
+		this.discriminatorType = discriminatorType;
 		this.identifierType = identifierType;
-		this.metaType = metaType;
 	}
 
-	public Object deepCopy(Object value, SessionFactoryImplementor factory)
-	throws HibernateException {
-		return value;
+	public Type getIdentifierType() {
+		return identifierType;
 	}
-	
-	public boolean isMethodOf(Method method) {
-		return false;
+
+	public Type getDiscriminatorType() {
+		return discriminatorType;
 	}
 
-	public boolean isSame(Object x, Object y) throws HibernateException {
-		return x==y;
+
+	// general Type metadata ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+	@Override
+	public String getName() {
+		return "object";
 	}
 
-	public int compare(Object x, Object y) {
-		return 0; //TODO: entities CAN be compared, by PK and entity name, fix this!
+	@Override
+	public Class getReturnedClass() {
+		return Object.class;
 	}
 
-	public int getColumnSpan(Mapping session)
-	throws MappingException {
-		return 2;
+	@Override
+	public int[] sqlTypes(Mapping mapping) throws MappingException {
+		return ArrayHelper.join( discriminatorType.sqlTypes( mapping ), identifierType.sqlTypes( mapping ) );
 	}
 
-	public String getName() {
-		return "object";
+	@Override
+	public Size[] dictatedSizes(Mapping mapping) throws MappingException {
+		return ArrayHelper.join( discriminatorType.dictatedSizes( mapping ), identifierType.dictatedSizes( mapping ) );
 	}
 
-	public boolean isMutable() {
-		return false;
+	@Override
+	public Size[] defaultSizes(Mapping mapping) throws MappingException {
+		return ArrayHelper.join( discriminatorType.defaultSizes( mapping ), identifierType.defaultSizes( mapping ) );
 	}
 
-	public Object nullSafeGet(ResultSet rs,	String name, SessionImplementor session, Object owner)
-	throws HibernateException, SQLException {
+	@Override
+	public Object[] getPropertyValues(Object component, EntityMode entityMode) {
+		throw new UnsupportedOperationException();
+	}
 
-		throw new UnsupportedOperationException("object is a multicolumn type");
+	@Override
+	public boolean isAnyType() {
+		return true;
 	}
 
-	public Object nullSafeGet(ResultSet rs,	String[] names,	SessionImplementor session,	Object owner)
-	throws HibernateException, SQLException {
-		return resolveAny(
-				(String) metaType.nullSafeGet(rs, names[0], session, owner),
-				(Serializable) identifierType.nullSafeGet(rs, names[1], session, owner),
-				session
-			);
+	@Override
+	public boolean isAssociationType() {
+		return true;
 	}
 
-	public Object hydrate(ResultSet rs,	String[] names,	SessionImplementor session,	Object owner)
-	throws HibernateException, SQLException {
-		String entityName = (String) metaType.nullSafeGet(rs, names[0], session, owner);
-		Serializable id = (Serializable) identifierType.nullSafeGet(rs, names[1], session, owner);
-		return new ObjectTypeCacheEntry(entityName, id);
+	@Override
+	public boolean isComponentType() {
+		return true;
 	}
 
-	public Object resolve(Object value, SessionImplementor session, Object owner)
-	throws HibernateException {
-		ObjectTypeCacheEntry holder = (ObjectTypeCacheEntry) value;
-		return resolveAny(holder.entityName, holder.id, session);
+	@Override
+	public boolean isEmbedded() {
+		return false;
 	}
 
-	public Object semiResolve(Object value, SessionImplementor session, Object owner)
-	throws HibernateException {
-		throw new UnsupportedOperationException("any mappings may not form part of a property-ref");
+	@Override
+	public boolean isMutable() {
+		return false;
 	}
-	
-	private Object resolveAny(String entityName, Serializable id, SessionImplementor session)
-	throws HibernateException {
-		return entityName==null || id==null ?
-				null : session.internalLoad( entityName, id, false, false );
+
+	@Override
+	public Object deepCopy(Object value, SessionFactoryImplementor factory) {
+		return value;
 	}
 
-	public void nullSafeSet(PreparedStatement st, Object value,	int index, SessionImplementor session)
-	throws HibernateException, SQLException {
-		nullSafeSet(st, value, index, null, session);
+
+	// general Type functionality ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+	@Override
+	public int compare(Object x, Object y) {
+		if ( x == null ) {
+			// if y is also null, return that they are the same (no option for "UNKNOWN")
+			// if y is not null, return that y is "greater" (-1 because the result is from the perspective of
+			// 		the first arg: x)
+			return y == null ? 0 : -1;
+		}
+		else if ( y == null ) {
+			// x is not null, but y is.  return that x is "greater"
+			return 1;
+		}
+
+		// At this point we know both are non-null.
+		final Object xId = extractIdentifier( x );
+		final Object yId = extractIdentifier( y );
+
+		return getIdentifierType().compare( xId, yId );
 	}
-	
-	public void nullSafeSet(PreparedStatement st, Object value,	int index, boolean[] settable, SessionImplementor session)
-	throws HibernateException, SQLException {
 
-		Serializable id;
-		String entityName;
-		if (value==null) {
-			id=null;
-			entityName=null;
+	private Object extractIdentifier(Object entity) {
+		final EntityPersister concretePersister = guessEntityPersister( entity );
+		return concretePersister == null
+				? null
+				: concretePersister.getEntityTuplizer().getIdentifier( entity, null );
+	}
+
+	private EntityPersister guessEntityPersister(Object object) {
+		if ( scope == null ) {
+			return null;
 		}
-		else {
-			entityName = session.bestGuessEntityName(value);
-			id = ForeignKeys.getEntityIdentifierIfNotUnsaved(entityName, value, session);
+
+		String entityName = null;
+
+		// this code is largely copied from Session's bestGuessEntityName
+		Object entity = object;
+		if ( entity instanceof HibernateProxy ) {
+			final LazyInitializer initializer = ( (HibernateProxy) entity ).getHibernateLazyInitializer();
+			if ( initializer.isUninitialized() ) {
+				entityName = initializer.getEntityName();
+			}
+			entity = initializer.getImplementation();
 		}
-		
-		// metaType is assumed to be single-column type
-		if ( settable==null || settable[0] ) {
-			metaType.nullSafeSet(st, entityName, index, session);
+
+		if ( entityName == null ) {
+			for ( EntityNameResolver resolver : scope.resolveFactory().iterateEntityNameResolvers() ) {
+				entityName = resolver.resolveEntityName( entity );
+				if ( entityName != null ) {
+					break;
+				}
+			}
 		}
-		if (settable==null) {
-			identifierType.nullSafeSet(st, id, index+1, session);
+
+		if ( entityName == null ) {
+			// the old-time stand-by...
+			entityName = object.getClass().getName();
 		}
-		else {
-			boolean[] idsettable = new boolean[ settable.length-1 ];
-			System.arraycopy(settable, 1, idsettable, 0, idsettable.length);
-			identifierType.nullSafeSet(st, id, index+1, idsettable, session);
+
+		return scope.resolveFactory().getEntityPersister( entityName );
+	}
+
+	@Override
+	public boolean isSame(Object x, Object y) throws HibernateException {
+		return x == y;
+	}
+
+	@Override
+	public boolean isModified(Object old, Object current, boolean[] checkable, SessionImplementor session)
+			throws HibernateException {
+		if ( current == null ) {
+			return old != null;
 		}
+		else if ( old == null ) {
+			return true;
+		}
+
+		final ObjectTypeCacheEntry holder = (ObjectTypeCacheEntry) old;
+		final boolean[] idCheckable = new boolean[checkable.length-1];
+		System.arraycopy( checkable, 1, idCheckable, 0, idCheckable.length );
+		return ( checkable[0] && !holder.entityName.equals( session.bestGuessEntityName( current ) ) )
+				|| identifierType.isModified( holder.id, getIdentifier( current, session ), idCheckable, session );
 	}
 
-	public Class getReturnedClass() {
-		return Object.class;
+	@Override
+	public boolean[] toColumnNullness(Object value, Mapping mapping) {
+		final boolean[] result = new boolean[ getColumnSpan( mapping ) ];
+		if ( value != null ) {
+			Arrays.fill( result, true );
+		}
+		return result;
 	}
 
-	public int[] sqlTypes(Mapping mapping) throws MappingException {
-		return ArrayHelper.join(
-				metaType.sqlTypes( mapping ),
-				identifierType.sqlTypes( mapping )
-		);
+	@Override
+	public boolean isDirty(Object old, Object current, boolean[] checkable, SessionImplementor session)
+			throws HibernateException {
+		return isDirty( old, current, session );
 	}
 
 	@Override
-	public Size[] dictatedSizes(Mapping mapping) throws MappingException {
-		return ArrayHelper.join(
-				metaType.dictatedSizes( mapping ),
-				identifierType.dictatedSizes( mapping )
-		);
+	public int getColumnSpan(Mapping session) {
+		return 2;
 	}
 
 	@Override
-	public Size[] defaultSizes(Mapping mapping) throws MappingException {
-		return ArrayHelper.join(
-				metaType.defaultSizes( mapping ),
-				identifierType.defaultSizes( mapping )
+	public Object nullSafeGet(ResultSet rs,	String[] names,	SessionImplementor session,	Object owner)
+			throws HibernateException, SQLException {
+		return resolveAny(
+				(String) discriminatorType.nullSafeGet( rs, names[0], session, owner ),
+				(Serializable) identifierType.nullSafeGet( rs, names[1], session, owner ),
+				session
 		);
 	}
 
-	public void setToXMLNode(Node xml, Object value, SessionFactoryImplementor factory) {
-		throw new UnsupportedOperationException("any types cannot be stringified");
+	@Override
+	public Object hydrate(ResultSet rs,	String[] names,	SessionImplementor session,	Object owner)
+			throws HibernateException, SQLException {
+		final String entityName = (String) discriminatorType.nullSafeGet( rs, names[0], session, owner );
+		final Serializable id = (Serializable) identifierType.nullSafeGet( rs, names[1], session, owner );
+		return new ObjectTypeCacheEntry( entityName, id );
 	}
 
-	public String toLoggableString(Object value, SessionFactoryImplementor factory) 
-	throws HibernateException {
-		//TODO: terrible implementation!
-		return value == null
-				? "null"
-				: factory.getTypeHelper()
-						.entity( HibernateProxyHelper.getClassWithoutInitializingProxy( value ) )
-						.toLoggableString( value, factory );
+	@Override
+	public Object resolve(Object value, SessionImplementor session, Object owner) throws HibernateException {
+		final ObjectTypeCacheEntry holder = (ObjectTypeCacheEntry) value;
+		return resolveAny( holder.entityName, holder.id, session );
 	}
 
-	public Object fromXMLNode(Node xml, Mapping factory) throws HibernateException {
-		throw new UnsupportedOperationException(); //TODO: is this right??
+	private Object resolveAny(String entityName, Serializable id, SessionImplementor session)
+			throws HibernateException {
+		return entityName==null || id==null
+				? null
+				: session.internalLoad( entityName, id, false, false );
 	}
 
-	public static final class ObjectTypeCacheEntry implements Serializable {
-		String entityName;
-		Serializable id;
-		ObjectTypeCacheEntry(String entityName, Serializable id) {
-			this.entityName = entityName;
-			this.id = id;
-		}
+	@Override
+	public void nullSafeSet(PreparedStatement st, Object value,	int index, SessionImplementor session)
+			throws HibernateException, SQLException {
+		nullSafeSet( st, value, index, null, session );
 	}
 
-	public Object assemble(
-		Serializable cached,
-		SessionImplementor session,
-		Object owner)
-	throws HibernateException {
+	@Override
+	public void nullSafeSet(PreparedStatement st, Object value,	int index, boolean[] settable, SessionImplementor session)
+			throws HibernateException, SQLException {
+		Serializable id;
+		String entityName;
+		if ( value == null ) {
+			id = null;
+			entityName = null;
+		}
+		else {
+			entityName = session.bestGuessEntityName( value );
+			id = ForeignKeys.getEntityIdentifierIfNotUnsaved( entityName, value, session );
+		}
 
-		ObjectTypeCacheEntry e = (ObjectTypeCacheEntry) cached;
-		return e==null ? null : session.internalLoad(e.entityName, e.id, false, false);
+		// discriminatorType is assumed to be single-column type
+		if ( settable == null || settable[0] ) {
+			discriminatorType.nullSafeSet( st, entityName, index, session );
+		}
+		if ( settable == null ) {
+			identifierType.nullSafeSet( st, id, index+1, session );
+		}
+		else {
+			final boolean[] idSettable = new boolean[ settable.length-1 ];
+			System.arraycopy( settable, 1, idSettable, 0, idSettable.length );
+			identifierType.nullSafeSet( st, id, index+1, idSettable, session );
+		}
 	}
 
-	public Serializable disassemble(Object value, SessionImplementor session, Object owner)
-	throws HibernateException {
-		return value==null ?
-			null :
-			new ObjectTypeCacheEntry(
-						session.bestGuessEntityName(value),
-						ForeignKeys.getEntityIdentifierIfNotUnsaved( 
-								session.bestGuessEntityName(value), value, session 
-							)
-					);
+	@Override
+	public String toLoggableString(Object value, SessionFactoryImplementor factory) throws HibernateException {
+		//TODO: terrible implementation!
+		return value == null
+				? "null"
+				: factory.getTypeHelper()
+				.entity( HibernateProxyHelper.getClassWithoutInitializingProxy( value ) )
+				.toLoggableString( value, factory );
 	}
 
-	public boolean isAnyType() {
-		return true;
+	@Override
+	public Object assemble(Serializable cached, SessionImplementor session, Object owner) throws HibernateException {
+		final ObjectTypeCacheEntry e = (ObjectTypeCacheEntry) cached;
+		return e == null ? null : session.internalLoad( e.entityName, e.id, false, false );
 	}
 
-	public Object replace(
-			Object original, 
-			Object target,
-			SessionImplementor session, 
-			Object owner, 
-			Map copyCache)
-	throws HibernateException {
-		if (original==null) {
+	@Override
+	public Serializable disassemble(Object value, SessionImplementor session, Object owner) throws HibernateException {
+		if ( value == null ) {
 			return null;
 		}
 		else {
-			String entityName = session.bestGuessEntityName(original);
-			Serializable id = ForeignKeys.getEntityIdentifierIfNotUnsaved(
-					entityName,
-					original,
-					session
+			return new ObjectTypeCacheEntry(
+					session.bestGuessEntityName( value ),
+					ForeignKeys.getEntityIdentifierIfNotUnsaved(
+							session.bestGuessEntityName( value ),
+							value,
+							session
+					)
 			);
-			return session.internalLoad( 
-					entityName, 
-					id, 
-					false, 
-					false
-				);
 		}
 	}
-	public CascadeStyle getCascadeStyle(int i) {
-		return CascadeStyles.NONE;
+
+	@Override
+	public Object replace(Object original, Object target, SessionImplementor session, Object owner, Map copyCache)
+			throws HibernateException {
+		if ( original == null ) {
+			return null;
+		}
+		else {
+			final String entityName = session.bestGuessEntityName( original );
+			final Serializable id = ForeignKeys.getEntityIdentifierIfNotUnsaved( entityName, original, session );
+			return session.internalLoad( entityName, id, false, false );
+		}
 	}
 
-	public FetchMode getFetchMode(int i) {
-		return FetchMode.SELECT;
+	@Override
+	public Object nullSafeGet(ResultSet rs,	String name, SessionImplementor session, Object owner) {
+		throw new UnsupportedOperationException( "object is a multicolumn type" );
+	}
+
+	@Override
+	public Object semiResolve(Object value, SessionImplementor session, Object owner) {
+		throw new UnsupportedOperationException( "any mappings may not form part of a property-ref" );
+	}
+
+	@Override
+	public void setToXMLNode(Node xml, Object value, SessionFactoryImplementor factory) {
+		throw new UnsupportedOperationException("any types cannot be stringified");
+	}
+
+	@Override
+	public Object fromXMLNode(Node xml, Mapping factory) throws HibernateException {
+		throw new UnsupportedOperationException();
+	}
+
+
+
+	// CompositeType implementation ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+	@Override
+	public boolean isMethodOf(Method method) {
+		return false;
 	}
 
 	private static final String[] PROPERTY_NAMES = new String[] { "class", "id" };
 
+	@Override
 	public String[] getPropertyNames() {
 		return PROPERTY_NAMES;
 	}
 
-	public Object getPropertyValue(Object component, int i, SessionImplementor session)
-		throws HibernateException {
-
-		return i==0 ?
-				session.bestGuessEntityName(component) :
-				getIdentifier(component, session);
+	@Override
+	public Object getPropertyValue(Object component, int i, SessionImplementor session) throws HibernateException {
+		return i==0
+				? session.bestGuessEntityName( component )
+				: getIdentifier( component, session );
 	}
 
-	public Object[] getPropertyValues(Object component, SessionImplementor session)
-		throws HibernateException {
-
-		return new Object[] { session.bestGuessEntityName(component), getIdentifier(component, session) };
+	@Override
+	public Object[] getPropertyValues(Object component, SessionImplementor session) throws HibernateException {
+		return new Object[] {
+				session.bestGuessEntityName( component ),
+				getIdentifier( component, session )
+		};
 	}
 
 	private Serializable getIdentifier(Object value, SessionImplementor session) throws HibernateException {
 		try {
-			return ForeignKeys.getEntityIdentifierIfNotUnsaved( session.bestGuessEntityName(value), value, session );
+			return ForeignKeys.getEntityIdentifierIfNotUnsaved(
+					session.bestGuessEntityName( value ),
+					value,
+					session
+			);
 		}
 		catch (TransientObjectException toe) {
 			return null;
 		}
 	}
 
-	public Type[] getSubtypes() {
-		return new Type[] { metaType, identifierType };
+	@Override
+	public void setPropertyValues(Object component, Object[] values, EntityMode entityMode) {
+		throw new UnsupportedOperationException();
 	}
 
-	public void setPropertyValues(Object component, Object[] values, EntityMode entityMode)
-		throws HibernateException {
+	private static final boolean[] NULLABILITY = new boolean[] { false, false };
 
-		throw new UnsupportedOperationException();
+	@Override
+	public boolean[] getPropertyNullability() {
+		return NULLABILITY;
+	}
 
+	@Override
+	public Type[] getSubtypes() {
+		return new Type[] {discriminatorType, identifierType };
 	}
 
-	public Object[] getPropertyValues(Object component, EntityMode entityMode) {
-		throw new UnsupportedOperationException();
+	@Override
+	public CascadeStyle getCascadeStyle(int i) {
+		return CascadeStyles.NONE;
 	}
 
-	public boolean isComponentType() {
-		return true;
+	@Override
+	public FetchMode getFetchMode(int i) {
+		return FetchMode.SELECT;
 	}
 
+
+	// AssociationType implementation ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+	@Override
 	public ForeignKeyDirection getForeignKeyDirection() {
-		//return AssociationType.FOREIGN_KEY_TO_PARENT; //this is better but causes a transient object exception...
 		return ForeignKeyDirection.FOREIGN_KEY_FROM_PARENT;
 	}
 
-	public boolean isAssociationType() {
-		return true;
-	}
-
+	@Override
 	public boolean useLHSPrimaryKey() {
 		return false;
 	}
 
-	public Joinable getAssociatedJoinable(SessionFactoryImplementor factory) {
-		throw new UnsupportedOperationException("any types do not have a unique referenced persister");
-	}
-
-	public boolean isModified(Object old, Object current, boolean[] checkable, SessionImplementor session)
-	throws HibernateException {
-		if (current==null) return old!=null;
-		if (old==null) return current!=null;
-		ObjectTypeCacheEntry holder = (ObjectTypeCacheEntry) old;
-		boolean[] idcheckable = new boolean[checkable.length-1];
-		System.arraycopy(checkable, 1, idcheckable, 0, idcheckable.length);
-		return ( checkable[0] && !holder.entityName.equals( session.bestGuessEntityName(current) ) ) ||
-				identifierType.isModified(holder.id, getIdentifier(current, session), idcheckable, session);
-	}
-
-	public String getAssociatedEntityName(SessionFactoryImplementor factory)
-		throws MappingException {
-		throw new UnsupportedOperationException("any types do not have a unique referenced persister");
-	}
-	
-	public boolean[] getPropertyNullability() {
+	@Override
+	public String getLHSPropertyName() {
 		return null;
 	}
 
-	public String getOnCondition(String alias, SessionFactoryImplementor factory, Map enabledFilters)
-	throws MappingException {
-		throw new UnsupportedOperationException();
-	}
-	
 	public boolean isReferenceToPrimaryKey() {
 		return true;
 	}
-	
-	public String getRHSUniqueKeyPropertyName() {
-		return null;
-	}
 
-	public String getLHSPropertyName() {
+	@Override
+	public String getRHSUniqueKeyPropertyName() {
 		return null;
 	}
 
+	@Override
 	public boolean isAlwaysDirtyChecked() {
 		return false;
 	}
 
+	@Override
 	public boolean isEmbeddedInXML() {
 		return false;
 	}
-	
-	public boolean[] toColumnNullness(Object value, Mapping mapping) {
-		boolean[] result = new boolean[ getColumnSpan(mapping) ];
-		if (value!=null) Arrays.fill(result, true);
-		return result;
+
+	@Override
+	public Joinable getAssociatedJoinable(SessionFactoryImplementor factory) {
+		throw new UnsupportedOperationException("any types do not have a unique referenced persister");
 	}
 
-	public boolean isDirty(Object old, Object current, boolean[] checkable, SessionImplementor session) 
-	throws HibernateException {
-		//TODO!!!
-		return isDirty(old, current, session);
+	@Override
+	public String getAssociatedEntityName(SessionFactoryImplementor factory) {
+		throw new UnsupportedOperationException("any types do not have a unique referenced persister");
 	}
 
-	public boolean isEmbedded() {
-		return false;
+	@Override
+	public String getOnCondition(String alias, SessionFactoryImplementor factory, Map enabledFilters) {
+		throw new UnsupportedOperationException();
+	}
+
+
+	/**
+	 * Used to externalize discrimination per a given identifier.  For example, when writing to
+	 * second level cache we write the discrimination resolved concrete type for each entity written.
+	 */
+	public static final class ObjectTypeCacheEntry implements Serializable {
+		final String entityName;
+		final Serializable id;
+
+		ObjectTypeCacheEntry(String entityName, Serializable id) {
+			this.entityName = entityName;
+			this.id = id;
+		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/MetaType.java b/hibernate-core/src/main/java/org/hibernate/type/MetaType.java
index 14bc66d508..fcabf01874 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/MetaType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/MetaType.java
@@ -1,177 +1,179 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Map;
 
 import org.dom4j.Node;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.metamodel.relational.Size;
 
 /**
  * @author Gavin King
  */
 public class MetaType extends AbstractType {
 	public static final String[] REGISTRATION_KEYS = new String[0];
 
-	private final Map values;
-	private final Map keys;
 	private final Type baseType;
+	private final Map<Object,String> discriminatorValuesToEntityNameMap;
+	private final Map<String,Object> entityNameToDiscriminatorValueMap;
 
-	public MetaType(Map values, Type baseType) {
+	public MetaType(Map<Object,String> discriminatorValuesToEntityNameMap, Type baseType) {
 		this.baseType = baseType;
-		this.values = values;
-		keys = new HashMap();
-		Iterator iter = values.entrySet().iterator();
-		while ( iter.hasNext() ) {
-			Map.Entry me = (Map.Entry) iter.next();
-			keys.put( me.getValue(), me.getKey() );
+		this.discriminatorValuesToEntityNameMap = discriminatorValuesToEntityNameMap;
+		this.entityNameToDiscriminatorValueMap = new HashMap<String,Object>();
+		for ( Map.Entry<Object,String> entry : discriminatorValuesToEntityNameMap.entrySet() ) {
+			entityNameToDiscriminatorValueMap.put( entry.getValue(), entry.getKey() );
 		}
 	}
 
 	public String[] getRegistrationKeys() {
 		return REGISTRATION_KEYS;
 	}
 
+	public Map<Object, String> getDiscriminatorValuesToEntityNameMap() {
+		return discriminatorValuesToEntityNameMap;
+	}
+
 	public int[] sqlTypes(Mapping mapping) throws MappingException {
 		return baseType.sqlTypes(mapping);
 	}
 
 	@Override
 	public Size[] dictatedSizes(Mapping mapping) throws MappingException {
 		return baseType.dictatedSizes( mapping );
 	}
 
 	@Override
 	public Size[] defaultSizes(Mapping mapping) throws MappingException {
 		return baseType.defaultSizes( mapping );
 	}
 
 	public int getColumnSpan(Mapping mapping) throws MappingException {
 		return baseType.getColumnSpan(mapping);
 	}
 
 	public Class getReturnedClass() {
 		return String.class;
 	}
 
 	public Object nullSafeGet(
 		ResultSet rs,
 		String[] names,
 		SessionImplementor session,
 		Object owner)
 	throws HibernateException, SQLException {
 		Object key = baseType.nullSafeGet(rs, names, session, owner);
-		return key==null ? null : values.get(key);
+		return key==null ? null : discriminatorValuesToEntityNameMap.get(key);
 	}
 
 	public Object nullSafeGet(
 		ResultSet rs,
 		String name,
 		SessionImplementor session,
 		Object owner)
 	throws HibernateException, SQLException {
 		Object key = baseType.nullSafeGet(rs, name, session, owner);
-		return key==null ? null : values.get(key);
+		return key==null ? null : discriminatorValuesToEntityNameMap.get(key);
 	}
 
 	public void nullSafeSet(PreparedStatement st, Object value, int index, SessionImplementor session)
 	throws HibernateException, SQLException {
-		baseType.nullSafeSet(st, value==null ? null : keys.get(value), index, session);
+		baseType.nullSafeSet(st, value==null ? null : entityNameToDiscriminatorValueMap.get(value), index, session);
 	}
 	
 	public void nullSafeSet(
 			PreparedStatement st,
 			Object value,
 			int index,
 			boolean[] settable, 
 			SessionImplementor session)
 	throws HibernateException, SQLException {
 		if ( settable[0] ) nullSafeSet(st, value, index, session);
 	}
 
 	public String toLoggableString(Object value, SessionFactoryImplementor factory) throws HibernateException {
 		return toXMLString(value, factory);
 	}
 	
 	public String toXMLString(Object value, SessionFactoryImplementor factory)
 		throws HibernateException {
 		return (String) value; //value is the entity name
 	}
 
 	public Object fromXMLString(String xml, Mapping factory)
 		throws HibernateException {
 		return xml; //xml is the entity name
 	}
 
 	public String getName() {
 		return baseType.getName(); //TODO!
 	}
 
 	public Object deepCopy(Object value, SessionFactoryImplementor factory)
 	throws HibernateException {
 		return value;
 	}
 
 	public Object replace(
 			Object original, 
 			Object target,
 			SessionImplementor session, 
 			Object owner, 
 			Map copyCache
 	) {
 		return original;
 	}
 	
 	public boolean isMutable() {
 		return false;
 	}
 
 	public Object fromXMLNode(Node xml, Mapping factory) throws HibernateException {
 		return fromXMLString( xml.getText(), factory );
 	}
 
 	public void setToXMLNode(Node node, Object value, SessionFactoryImplementor factory) throws HibernateException {
 		node.setText( toXMLString(value, factory) );
 	}
 
 	public boolean[] toColumnNullness(Object value, Mapping mapping) {
 		throw new UnsupportedOperationException();
 	}
 
 	public boolean isDirty(Object old, Object current, boolean[] checkable, SessionImplementor session) throws HibernateException {
 		return checkable[0] && isDirty(old, current, session);
 	}
 	
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/ObjectType.java b/hibernate-core/src/main/java/org/hibernate/type/ObjectType.java
index 4ce68e86a4..83bd3876da 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/ObjectType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/ObjectType.java
@@ -1,47 +1,50 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 
 /**
  * Specific adaptation of the "any" type to the old deprecated "object" type
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class ObjectType extends AnyType implements BasicType {
+	/**
+	 * Singleton access
+	 */
 	public static final ObjectType INSTANCE = new ObjectType();
 
-	public ObjectType() {
+	private ObjectType() {
 		super( StringType.INSTANCE, SerializableType.INSTANCE );
 	}
 
 	public String getName() {
 		return "object";
 	}
 
 	public String[] getRegistrationKeys() {
 		return new String[] { getName(), Object.class.getName() };
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/TypeFactory.java b/hibernate-core/src/main/java/org/hibernate/type/TypeFactory.java
index 60c8427551..0d6606e486 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/TypeFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/TypeFactory.java
@@ -1,523 +1,523 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.io.Serializable;
 import java.util.Comparator;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.classic.Lifecycle;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.tuple.component.ComponentMetamodel;
 import org.hibernate.usertype.CompositeUserType;
 import org.hibernate.usertype.ParameterizedType;
 import org.hibernate.usertype.UserType;
 import org.jboss.logging.Logger;
 
 /**
  * Used internally to build instances of {@link Type}, specifically it builds instances of
  *
  *
  * Used internally to obtain instances of <tt>Type</tt>. Applications should use static methods
  * and constants on <tt>org.hibernate.Hibernate</tt>.
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 @SuppressWarnings({ "unchecked" })
 public final class TypeFactory implements Serializable {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, TypeFactory.class.getName());
 
 	private final TypeScopeImpl typeScope = new TypeScopeImpl();
 
 	public static interface TypeScope extends Serializable {
 		public SessionFactoryImplementor resolveFactory();
 	}
 
 	private static class TypeScopeImpl implements TypeFactory.TypeScope {
 		private SessionFactoryImplementor factory;
 
 		public void injectSessionFactory(SessionFactoryImplementor factory) {
 			if ( this.factory != null ) {
 				LOG.scopingTypesToSessionFactoryAfterAlreadyScoped( this.factory, factory );
 			}
 			else {
 				LOG.tracev( "Scoping types to session factory {0}", factory );
 			}
 			this.factory = factory;
 		}
 
 		public SessionFactoryImplementor resolveFactory() {
 			if ( factory == null ) {
 				throw new HibernateException( "SessionFactory for type scoping not yet known" );
 			}
 			return factory;
 		}
 	}
 
 	public void injectSessionFactory(SessionFactoryImplementor factory) {
 		typeScope.injectSessionFactory( factory );
 	}
 
 	public SessionFactoryImplementor resolveSessionFactory() {
 		return typeScope.resolveFactory();
 	}
 
 	public Type byClass(Class clazz, Properties parameters) {
 		if ( Type.class.isAssignableFrom( clazz ) ) {
 			return type( clazz, parameters );
 		}
 
 		if ( CompositeUserType.class.isAssignableFrom( clazz ) ) {
 			return customComponent( clazz, parameters );
 		}
 
 		if ( UserType.class.isAssignableFrom( clazz ) ) {
 			return custom( clazz, parameters );
 		}
 
 		if ( Lifecycle.class.isAssignableFrom( clazz ) ) {
 			// not really a many-to-one association *necessarily*
 			return manyToOne( clazz.getName() );
 		}
 
 		if ( Serializable.class.isAssignableFrom( clazz ) ) {
 			return serializable( clazz );
 		}
 
 		return null;
 	}
 
 	public Type type(Class<Type> typeClass, Properties parameters) {
 		try {
 			Type type = typeClass.newInstance();
 			injectParameters( type, parameters );
 			return type;
 		}
 		catch (Exception e) {
 			throw new MappingException( "Could not instantiate Type: " + typeClass.getName(), e );
 		}
 	}
 
 	public static void injectParameters(Object type, Properties parameters) {
 		if ( ParameterizedType.class.isInstance( type ) ) {
 			( (ParameterizedType) type ).setParameterValues(parameters);
 		}
 		else if ( parameters!=null && !parameters.isEmpty() ) {
 			throw new MappingException( "type is not parameterized: " + type.getClass().getName() );
 		}
 	}
 
 	public CompositeCustomType customComponent(Class<CompositeUserType> typeClass, Properties parameters) {
 		return customComponent( typeClass, parameters, typeScope );
 	}
 
 	/**
 	 * @deprecated Only for use temporary use by {@link org.hibernate.Hibernate}
 	 */
 	@Deprecated
     @SuppressWarnings({ "JavaDoc" })
 	public static CompositeCustomType customComponent(Class<CompositeUserType> typeClass, Properties parameters, TypeScope scope) {
 		try {
 			CompositeUserType userType = typeClass.newInstance();
 			injectParameters( userType, parameters );
 			return new CompositeCustomType( userType );
 		}
 		catch ( Exception e ) {
 			throw new MappingException( "Unable to instantiate custom type: " + typeClass.getName(), e );
 		}
 	}
 
 	/**
 	 * @deprecated Use {@link #customCollection(String, java.util.Properties, String, String)}
 	 * instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public CollectionType customCollection(
 			String typeName,
 			Properties typeParameters,
 			String role,
 			String propertyRef,
 			boolean embedded) {
 		Class typeClass;
 		try {
 			typeClass = ReflectHelper.classForName( typeName );
 		}
 		catch ( ClassNotFoundException cnfe ) {
 			throw new MappingException( "user collection type class not found: " + typeName, cnfe );
 		}
 		CustomCollectionType result = new CustomCollectionType( typeScope, typeClass, role, propertyRef, embedded );
 		if ( typeParameters != null ) {
 			injectParameters( result.getUserType(), typeParameters );
 		}
 		return result;
 	}
 
 	public CollectionType customCollection(
 			String typeName,
 			Properties typeParameters,
 			String role,
 			String propertyRef) {
 		Class typeClass;
 		try {
 			typeClass = ReflectHelper.classForName( typeName );
 		}
 		catch ( ClassNotFoundException cnfe ) {
 			throw new MappingException( "user collection type class not found: " + typeName, cnfe );
 		}
 		CustomCollectionType result = new CustomCollectionType( typeScope, typeClass, role, propertyRef );
 		if ( typeParameters != null ) {
 			injectParameters( result.getUserType(), typeParameters );
 		}
 		return result;
 	}
 
 	public CustomType custom(Class<UserType> typeClass, Properties parameters) {
 		return custom( typeClass, parameters, typeScope );
 	}
 
 	/**
 	 * @deprecated Only for use temporary use by {@link org.hibernate.Hibernate}
 	 */
 	@Deprecated
     public static CustomType custom(Class<UserType> typeClass, Properties parameters, TypeScope scope) {
 		try {
 			UserType userType = typeClass.newInstance();
 			injectParameters( userType, parameters );
 			return new CustomType( userType );
 		}
 		catch ( Exception e ) {
 			throw new MappingException( "Unable to instantiate custom type: " + typeClass.getName(), e );
 		}
 	}
 
 	/**
 	 * Build a {@link SerializableType} from the given {@link Serializable} class.
 	 *
 	 * @param serializableClass The {@link Serializable} class.
 	 * @param <T> The actual class type (extends Serializable)
 	 *
 	 * @return The built {@link SerializableType}
 	 */
 	public static <T extends Serializable> SerializableType<T> serializable(Class<T> serializableClass) {
 		return new SerializableType<T>( serializableClass );
 	}
 
 
 	// one-to-one type builders ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * @deprecated Use {@link #oneToOne(String, ForeignKeyDirection, String, boolean, boolean, String, String, boolean)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public EntityType oneToOne(
 			String persistentClass,
 			ForeignKeyDirection foreignKeyType,
 			String uniqueKeyPropertyName,
 			boolean lazy,
 			boolean unwrapProxy,
 			boolean isEmbeddedInXML,
 			String entityName,
 			String propertyName) {
 		return oneToOne( persistentClass, foreignKeyType, uniqueKeyPropertyName == null, uniqueKeyPropertyName, lazy, unwrapProxy, entityName,
 				propertyName );
 	}
 
 	/**
 	 * @deprecated Use {@link #oneToOne(String, ForeignKeyDirection, String, boolean, boolean, String, String, boolean)} instead.
 	 */
 	@Deprecated
 	public EntityType oneToOne(
 			String persistentClass,
 			ForeignKeyDirection foreignKeyType,
 			String uniqueKeyPropertyName,
 			boolean lazy,
 			boolean unwrapProxy,
 			String entityName,
 			String propertyName) {
 		return oneToOne( persistentClass, foreignKeyType, uniqueKeyPropertyName == null, uniqueKeyPropertyName, lazy, unwrapProxy, entityName,
 				propertyName );
 	}
 
 	public EntityType oneToOne(
 			String persistentClass,
 			ForeignKeyDirection foreignKeyType,
 			boolean referenceToPrimaryKey,
 			String uniqueKeyPropertyName,
 			boolean lazy,
 			boolean unwrapProxy,
 			String entityName,
 			String propertyName) {
 		return new OneToOneType( typeScope, persistentClass, foreignKeyType, referenceToPrimaryKey,
 				uniqueKeyPropertyName, lazy, unwrapProxy, entityName, propertyName );
 	}
 	
 	/**
 	 * @deprecated Use {@link #specialOneToOne(String, ForeignKeyDirection, String, boolean, boolean, String, String, boolean)} instead.
 	 */
 	@Deprecated
 	public EntityType specialOneToOne(
 			String persistentClass,
 			ForeignKeyDirection foreignKeyType,
 			String uniqueKeyPropertyName,
 			boolean lazy,
 			boolean unwrapProxy,
 			String entityName,
 			String propertyName) {
 		return specialOneToOne( persistentClass, foreignKeyType, uniqueKeyPropertyName == null, uniqueKeyPropertyName, lazy, unwrapProxy,
 				entityName, propertyName );
 	}
 
 	public EntityType specialOneToOne(
 			String persistentClass,
 			ForeignKeyDirection foreignKeyType,
 			boolean referenceToPrimaryKey,
 			String uniqueKeyPropertyName,
 			boolean lazy,
 			boolean unwrapProxy,
 			String entityName,
 			String propertyName) {
 		return new SpecialOneToOneType( typeScope, persistentClass, foreignKeyType, referenceToPrimaryKey,
 				uniqueKeyPropertyName, lazy, unwrapProxy, entityName, propertyName );
 	}
 
 
 	// many-to-one type builders ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public EntityType manyToOne(String persistentClass) {
 		return new ManyToOneType( typeScope, persistentClass );
 	}
 
 	public EntityType manyToOne(String persistentClass, boolean lazy) {
 		return new ManyToOneType( typeScope, persistentClass, lazy );
 	}
 
 	/**
 	 * @deprecated Use {@link #manyToOne(String, boolean, String, boolean, boolean, boolean, boolean)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public EntityType manyToOne(
 			String persistentClass,
 			String uniqueKeyPropertyName,
 			boolean lazy,
 			boolean unwrapProxy,
 			boolean isEmbeddedInXML,
 			boolean ignoreNotFound,
 			boolean isLogicalOneToOne) {
 		return manyToOne( persistentClass, uniqueKeyPropertyName == null, uniqueKeyPropertyName, lazy, unwrapProxy, ignoreNotFound,
 				isLogicalOneToOne );
 	}
 
 	/**
 	 * @deprecated Use {@link #manyToOne(String, boolean, String, boolean, boolean, boolean, boolean)} instead.
 	 */
 	@Deprecated
 	public EntityType manyToOne(
 			String persistentClass,
 			String uniqueKeyPropertyName,
 			boolean lazy,
 			boolean unwrapProxy,
 			boolean ignoreNotFound,
 			boolean isLogicalOneToOne) {
 		return manyToOne( persistentClass, uniqueKeyPropertyName == null, uniqueKeyPropertyName, lazy, unwrapProxy, ignoreNotFound,
 				isLogicalOneToOne );
 	}
 
 	public EntityType manyToOne(
 			String persistentClass,
 			boolean referenceToPrimaryKey,
 			String uniqueKeyPropertyName,
 			boolean lazy,
 			boolean unwrapProxy,
 			boolean ignoreNotFound,
 			boolean isLogicalOneToOne) {
 		return new ManyToOneType(
 				typeScope,
 				persistentClass,
 				referenceToPrimaryKey,
 				uniqueKeyPropertyName,
 				lazy,
 				unwrapProxy,
 				ignoreNotFound,
 				isLogicalOneToOne
 		);
 	}
 
 	// collection type builders ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * @deprecated Use {@link #array(String, String, Class)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public CollectionType array(String role, String propertyRef, boolean embedded, Class elementClass) {
 		return new ArrayType( typeScope, role, propertyRef, elementClass, embedded );
 	}
 
 	public CollectionType array(String role, String propertyRef, Class elementClass) {
 		return new ArrayType( typeScope, role, propertyRef, elementClass );
 	}
 
 	/**
 	 * @deprecated Use {@link #list(String, String)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public CollectionType list(String role, String propertyRef, boolean embedded) {
 		return new ListType( typeScope, role, propertyRef, embedded );
 	}
 
 	public CollectionType list(String role, String propertyRef) {
 		return new ListType( typeScope, role, propertyRef );
 	}
 
 	/**
 	 * @deprecated Use {@link #bag(String, String)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public CollectionType bag(String role, String propertyRef, boolean embedded) {
 		return new BagType( typeScope, role, propertyRef, embedded );
 	}
 
 	public CollectionType bag(String role, String propertyRef) {
 		return new BagType( typeScope, role, propertyRef );
 	}
 
 	/**
 	 * @deprecated Use {@link #idbag(String, String)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public CollectionType idbag(String role, String propertyRef, boolean embedded) {
 		return new IdentifierBagType( typeScope, role, propertyRef, embedded );
 	}
 
 	public CollectionType idbag(String role, String propertyRef) {
 		return new IdentifierBagType( typeScope, role, propertyRef );
 	}
 
 	/**
 	 * @deprecated Use {@link #map(String, String)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public CollectionType map(String role, String propertyRef, boolean embedded) {
 		return new MapType( typeScope, role, propertyRef, embedded );
 	}
 
 	public CollectionType map(String role, String propertyRef) {
 		return new MapType( typeScope, role, propertyRef );
 	}
 
 	/**
 	 * @deprecated Use {@link #orderedMap(String, String)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public CollectionType orderedMap(String role, String propertyRef, boolean embedded) {
 		return new OrderedMapType( typeScope, role, propertyRef, embedded );
 	}
 
 	public CollectionType orderedMap(String role, String propertyRef) {
 		return new OrderedMapType( typeScope, role, propertyRef );
 	}
 
 	/**
 	 * @deprecated Use {@link #sortedMap(String, String, java.util.Comparator)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public CollectionType sortedMap(String role, String propertyRef, boolean embedded, Comparator comparator) {
 		return new SortedMapType( typeScope, role, propertyRef, comparator, embedded );
 	}
 
 	public CollectionType sortedMap(String role, String propertyRef, Comparator comparator) {
 		return new SortedMapType( typeScope, role, propertyRef, comparator );
 	}
 
 	/**
 	 * @deprecated Use {@link #set(String, String)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public CollectionType set(String role, String propertyRef, boolean embedded) {
 		return new SetType( typeScope, role, propertyRef, embedded );
 	}
 
 	public CollectionType set(String role, String propertyRef) {
 		return new SetType( typeScope, role, propertyRef );
 	}
 
 	/**
 	 * @deprecated Use {@link #orderedSet(String, String)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public CollectionType orderedSet(String role, String propertyRef, boolean embedded) {
 		return new OrderedSetType( typeScope, role, propertyRef, embedded );
 	}
 
 	public CollectionType orderedSet(String role, String propertyRef) {
 		return new OrderedSetType( typeScope, role, propertyRef );
 	}
 
 	/**
 	 * @deprecated Use {@link #sortedSet(String, String, java.util.Comparator)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public CollectionType sortedSet(String role, String propertyRef, boolean embedded, Comparator comparator) {
 		return new SortedSetType( typeScope, role, propertyRef, comparator, embedded );
 	}
 
 	public CollectionType sortedSet(String role, String propertyRef, Comparator comparator) {
 		return new SortedSetType( typeScope, role, propertyRef, comparator );
 	}
 
 	// component type builders ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public ComponentType component(ComponentMetamodel metamodel) {
 		return new ComponentType( typeScope, metamodel );
 	}
 
 	public EmbeddedComponentType embeddedComponent(ComponentMetamodel metamodel) {
 		return new EmbeddedComponentType( typeScope, metamodel );
 	}
 
 
 	// any type builder ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public Type any(Type metaType, Type identifierType) {
-		return new AnyType( metaType, identifierType );
+		return new AnyType( typeScope, metaType, identifierType );
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/loader/EncapsulatedCompositeAttributeResultSetProcessorTest.java b/hibernate-core/src/test/java/org/hibernate/loader/EncapsulatedCompositeAttributeResultSetProcessorTest.java
index 7c1a12db66..a8285a674c 100644
--- a/hibernate-core/src/test/java/org/hibernate/loader/EncapsulatedCompositeAttributeResultSetProcessorTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/loader/EncapsulatedCompositeAttributeResultSetProcessorTest.java
@@ -1,355 +1,417 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader;
 
-import java.io.Serializable;
-import java.math.BigDecimal;
-import java.sql.Connection;
-import java.sql.PreparedStatement;
-import java.sql.ResultSet;
-import java.sql.SQLException;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.Date;
-import java.util.List;
-
 import javax.persistence.CollectionTable;
 import javax.persistence.Column;
 import javax.persistence.ElementCollection;
 import javax.persistence.Embeddable;
 import javax.persistence.Embedded;
 import javax.persistence.Entity;
 import javax.persistence.EnumType;
 import javax.persistence.Enumerated;
 import javax.persistence.FetchType;
 import javax.persistence.Id;
+import javax.persistence.JoinColumn;
 import javax.persistence.ManyToOne;
+import java.io.Serializable;
+import java.math.BigDecimal;
+import java.sql.Connection;
+import java.sql.PreparedStatement;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+import java.util.ArrayList;
+import java.util.Date;
+import java.util.List;
 
-import org.junit.Test;
-
+import org.hibernate.LockMode;
+import org.hibernate.LockOptions;
 import org.hibernate.Session;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.QueryParameters;
+import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.jdbc.Work;
-import org.hibernate.loader.internal.EntityLoadQueryBuilderImpl;
-import org.hibernate.loader.internal.LoadQueryAliasResolutionContextImpl;
-import org.hibernate.loader.internal.ResultSetProcessorImpl;
+import org.hibernate.loader.entity.EntityJoinWalker;
+import org.hibernate.loader.plan.exec.process.internal.ResultSetProcessorImpl;
+import org.hibernate.loader.plan.exec.internal.AliasResolutionContextImpl;
+import org.hibernate.loader.plan.exec.query.spi.NamedParameterContext;
+import org.hibernate.loader.plan.exec.query.spi.QueryBuildingParameters;
+import org.hibernate.loader.plan.exec.spi.AliasResolutionContext;
+import org.hibernate.loader.plan.exec.spi.LoadQueryDetails;
 import org.hibernate.loader.plan.internal.SingleRootReturnLoadPlanBuilderStrategy;
 import org.hibernate.loader.plan.spi.LoadPlan;
 import org.hibernate.loader.plan.spi.build.LoadPlanBuilder;
-import org.hibernate.loader.spi.LoadQueryAliasResolutionContext;
-import org.hibernate.loader.spi.NamedParameterContext;
 import org.hibernate.loader.spi.NoOpLoadPlanAdvisor;
 import org.hibernate.persister.entity.EntityPersister;
-import org.hibernate.test.component.cascading.toone.PersonalInfo;
-import org.hibernate.testing.FailureExpected;
+import org.hibernate.persister.entity.OuterJoinLoadable;
+
+import org.junit.Test;
+
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.hibernate.testing.junit4.ExtraAssertions;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertSame;
 
 /**
  * @author Gail Badner
  */
 public class EncapsulatedCompositeAttributeResultSetProcessorTest extends BaseCoreFunctionalTestCase {
 
 	@Override
 	protected Class<?>[] getAnnotatedClasses() {
 		return new Class[] { Person.class, Customer.class };
 	}
 
 	@Test
 	public void testSimpleNestedCompositeAttributeProcessing() throws Exception {
 		// create some test data
 		Session session = openSession();
 		session.beginTransaction();
 		Person person = new Person();
 		person.id = 1;
 		person.name = "Joe Blow";
 		person.address = new Address();
 		person.address.address1 = "1313 Mockingbird Lane";
 		person.address.city = "Pleasantville";
 		person.address.country = "USA";
 		AddressType addressType = new AddressType();
 		addressType.typeName = "snail mail";
 		person.address.type = addressType;
 		session.save( person );
 		session.getTransaction().commit();
 		session.close();
 
 		session = openSession();
 		session.beginTransaction();
 		Person personGotten = (Person) session.get( Person.class, person.id );
 		assertEquals( person.id, personGotten.id );
 		assertEquals( person.address.address1, personGotten.address.address1 );
 		assertEquals( person.address.city, personGotten.address.city );
 		assertEquals( person.address.country, personGotten.address.country );
 		assertEquals( person.address.type.typeName, personGotten.address.type.typeName );
 		session.getTransaction().commit();
 		session.close();
 
 		List results = getResults( sessionFactory().getEntityPersister( Person.class.getName() ) );
 		assertEquals( 1, results.size() );
 		Object result = results.get( 0 );
 		assertNotNull( result );
 
 		Person personWork = ExtraAssertions.assertTyping( Person.class, result );
 		assertEquals( person.id, personWork.id );
 		assertEquals( person.address.address1, personWork.address.address1 );
 		assertEquals( person.address.city, personWork.address.city );
 		assertEquals( person.address.country, personWork.address.country );
 		assertEquals( person.address.type.typeName, personGotten.address.type.typeName );
 
 		// clean up test data
 		session = openSession();
 		session.beginTransaction();
 		session.createQuery( "delete Person" ).executeUpdate();
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	@Test
+	public void testNestedCompositeElementCollectionQueryBuilding() {
+		doCompare(
+				sessionFactory(),
+				(OuterJoinLoadable) sessionFactory().getClassMetadata( Customer.class )
+		);
+	}
+
+	private void doCompare(SessionFactoryImplementor sf, OuterJoinLoadable persister) {
+		final LoadQueryInfluencers influencers = LoadQueryInfluencers.NONE;
+		final LockMode lockMode = LockMode.NONE;
+		final int batchSize = 1;
+
+		final EntityJoinWalker walker = new EntityJoinWalker(
+				persister,
+				persister.getKeyColumnNames(),
+				batchSize,
+				lockMode,
+				sf,
+				influencers
+		);
+
+
+		SingleRootReturnLoadPlanBuilderStrategy strategy = new SingleRootReturnLoadPlanBuilderStrategy( sf, influencers );
+		LoadPlan plan = LoadPlanBuilder.buildRootEntityLoadPlan( strategy, persister );
+		LoadQueryDetails details = LoadQueryDetails.makeForBatching(
+				persister.getKeyColumnNames(),
+				plan,
+				sf,
+				new QueryBuildingParameters() {
+					@Override
+					public LoadQueryInfluencers getQueryInfluencers() {
+						return influencers;
+					}
+
+					@Override
+					public int getBatchSize() {
+						return batchSize;
+					}
+
+					@Override
+					public LockMode getLockMode() {
+						return null;
+					}
+
+					@Override
+					public LockOptions getLockOptions() {
+						return null;
+					}
+				}
+		);
+
+		compare( walker, details );
+	}
+
+	private void compare(JoinWalker walker, LoadQueryDetails details) {
+		System.out.println( "WALKER    : " + walker.getSQLString() );
+		System.out.println( "LOAD-PLAN : " + details.getSqlStatement() );
+		System.out.println();
+	}
+
+	@Test
 	public void testNestedCompositeElementCollectionProcessing() throws Exception {
 		// create some test data
 		Session session = openSession();
 		session.beginTransaction();
 		Person person = new Person();
 		person.id = 1;
 		person.name = "Joe Blow";
 		session.save( person );
 		Customer customer = new Customer();
 		customer.id = 1L;
 		Investment investment1 = new Investment();
 		investment1.description = "stock";
 		investment1.date = new Date();
 		investment1.monetaryAmount = new MonetaryAmount();
 		investment1.monetaryAmount.currency = MonetaryAmount.CurrencyCode.USD;
 		investment1.monetaryAmount.amount = BigDecimal.valueOf( 1234, 2 );
 		investment1.performedBy = person;
 		Investment investment2 = new Investment();
 		investment2.description = "bond";
 		investment2.date = new Date();
 		investment2.monetaryAmount = new MonetaryAmount();
 		investment2.monetaryAmount.currency = MonetaryAmount.CurrencyCode.EUR;
 		investment2.monetaryAmount.amount = BigDecimal.valueOf( 98176, 1 );
 		customer.investments.add( investment1 );
 		customer.investments.add( investment2 );
 		session.save( customer );
 		session.getTransaction().commit();
 		session.close();
 
 		session = openSession();
 		session.beginTransaction();
 		Customer customerGotten = (Customer) session.get( Customer.class, customer.id );
 		assertEquals( customer.id, customerGotten.id );
 		session.getTransaction().commit();
 		session.close();
 
 		List results = getResults( sessionFactory().getEntityPersister( Customer.class.getName() ) );
 
 		assertEquals( 2, results.size() );
 		assertSame( results.get( 0 ), results.get( 1 ) );
 		Object result = results.get( 0 );
 		assertNotNull( result );
 
 		Customer customerWork = ExtraAssertions.assertTyping( Customer.class, result );
 
 		// clean up test data
 		session = openSession();
 		session.beginTransaction();
 		session.delete( customerWork.investments.get( 0 ).performedBy );
 		session.delete( customerWork );
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	private List<?> getResults(EntityPersister entityPersister ) {
-			final SingleRootReturnLoadPlanBuilderStrategy strategy = new SingleRootReturnLoadPlanBuilderStrategy(
-					sessionFactory(),
-					LoadQueryInfluencers.NONE
-			);
-			final LoadPlan plan = LoadPlanBuilder.buildRootEntityLoadPlan( strategy, entityPersister );
-			final LoadQueryAliasResolutionContext aliasResolutionContext =
-					new LoadQueryAliasResolutionContextImpl(
-							sessionFactory(),
-							0,
-							Collections.singletonMap( plan.getReturns().get( 0 ), new String[] { "abc" } )
-					);
-			final EntityLoadQueryBuilderImpl queryBuilder = new EntityLoadQueryBuilderImpl(
-					LoadQueryInfluencers.NONE,
-					plan
-			);
-			final String sql = queryBuilder.generateSql( 1, sessionFactory(), aliasResolutionContext );
-
-			final ResultSetProcessorImpl resultSetProcessor = new ResultSetProcessorImpl( plan );
-			final List results = new ArrayList();
-
-			final Session workSession = openSession();
-			workSession.beginTransaction();
-			workSession.doWork(
-					new Work() {
-						@Override
-						public void execute(Connection connection) throws SQLException {
-							PreparedStatement ps = connection.prepareStatement( sql );
-							ps.setInt( 1, 1 );
-							ResultSet resultSet = ps.executeQuery();
-							results.addAll(
-									resultSetProcessor.extractResults(
-											NoOpLoadPlanAdvisor.INSTANCE,
-											resultSet,
-											(SessionImplementor) workSession,
-											new QueryParameters(),
-											new NamedParameterContext() {
-												@Override
-												public int[] getNamedParameterLocations(String name) {
-													return new int[0];
-												}
-											},
-											aliasResolutionContext,
-											true,
-											false,
-											null,
-											null
-									)
-							);
-							resultSet.close();
-							ps.close();
-						}
+		final LoadPlan plan = Helper.INSTANCE.buildLoadPlan( sessionFactory(), entityPersister );
+
+		// ultimately, using a LoadPlan requires that it be interpreted into 2 pieces of information:
+		//		1) The query to execute
+		//		2) The ResultSetProcessor to use.
+		//
+		// Those 2 pieces of information share some common context:
+		//		1) alias resolution context
+		//
+
+		final AliasResolutionContext aliasResolutionContext = new AliasResolutionContextImpl( sessionFactory() );
+
+		final String sql = Helper.INSTANCE.generateSql( sessionFactory(), plan, aliasResolutionContext );
+
+		final ResultSetProcessorImpl resultSetProcessor = new ResultSetProcessorImpl( plan, true );
+		final List results = new ArrayList();
+
+		final Session workSession = openSession();
+		workSession.beginTransaction();
+		workSession.doWork(
+				new Work() {
+					@Override
+					public void execute(Connection connection) throws SQLException {
+						PreparedStatement ps = connection.prepareStatement( sql );
+						ps.setInt( 1, 1 );
+						ResultSet resultSet = ps.executeQuery();
+						results.addAll(
+								resultSetProcessor.extractResults(
+										NoOpLoadPlanAdvisor.INSTANCE,
+										resultSet,
+										(SessionImplementor) workSession,
+										new QueryParameters(),
+										new NamedParameterContext() {
+											@Override
+											public int[] getNamedParameterLocations(String name) {
+												return new int[0];
+											}
+										},
+										aliasResolutionContext,
+										true,
+										false,
+										null,
+										null
+								)
+						);
+						resultSet.close();
+						ps.close();
 					}
-			);
-			workSession.getTransaction().commit();
-			workSession.close();
-			return results;
-		}
+				}
+		);
+		workSession.getTransaction().commit();
+		workSession.close();
+		return results;
+	}
 
 	@Entity( name = "Person" )
 	public static class Person implements Serializable {
 		@Id
 		Integer id;
 		String name;
 
 		@Embedded
 		Address address;
 	}
 
 	@Embeddable
 	public static class Address implements Serializable {
 		String address1;
 		String city;
 		String country;
 		AddressType type;
 	}
 
 	@Embeddable
 	public static class AddressType {
 		String typeName;
 	}
 
 	@Entity( name = "Customer" )
 	public static class Customer {
 		private Long id;
 		private List<Investment> investments = new ArrayList<Investment>();
 
 		@Id
 		public Long getId() {
 			return id;
 		}
 		public void setId(Long id) {
 			this.id = id;
 		}
 
 		@ElementCollection(fetch = FetchType.EAGER)
-		@CollectionTable( name = "Investments" )
+		@CollectionTable( name = "investments", joinColumns = @JoinColumn( name = "customer_id" ) )
 		public List<Investment> getInvestments() {
 			return investments;
 		}
 		public void setInvestments(List<Investment> investments) {
 			this.investments = investments;
 		}
 	}
 
 	@Embeddable
 	public static class Investment {
 		private MonetaryAmount monetaryAmount;
 		private String description;
 		private Date date;
 		private Person performedBy;
 
 		@Embedded
 		public MonetaryAmount getMonetaryAmount() {
 			return monetaryAmount;
 		}
 		public void setMonetaryAmount(MonetaryAmount monetaryAmount) {
 			this.monetaryAmount = monetaryAmount;
 		}
 		public String getDescription() {
 			return description;
 		}
 		public void setDescription(String description) {
 			this.description = description;
 		}
 		public Date getDate() {
 			return date;
 		}
 		public void setDate(Date date) {
 			this.date = date;
 		}
 		@ManyToOne
 		public Person getPerformedBy() {
 			return performedBy;
 		}
 		public void setPerformedBy(Person performedBy) {
 			this.performedBy = performedBy;
 		}
 	}
 
 	@Embeddable
 	public static class MonetaryAmount {
 		public static enum CurrencyCode {
 			USD,
 			EUR
 		}
 		private BigDecimal amount;
 		@Column(length = 3)
 		@Enumerated(EnumType.STRING)
 		private CurrencyCode currency;
 
 		public BigDecimal getAmount() {
 			return amount;
 		}
 		public void setAmount(BigDecimal amount) {
 			this.amount = amount;
 		}
 
 		public CurrencyCode getCurrency() {
 			return currency;
 		}
 		public void setCurrency(CurrencyCode currency) {
 			this.currency = currency;
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/loader/EncapsulatedCompositeIdResultSetProcessorTest.java b/hibernate-core/src/test/java/org/hibernate/loader/EncapsulatedCompositeIdResultSetProcessorTest.java
index 2482fcf4ca..69026877f5 100644
--- a/hibernate-core/src/test/java/org/hibernate/loader/EncapsulatedCompositeIdResultSetProcessorTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/loader/EncapsulatedCompositeIdResultSetProcessorTest.java
@@ -1,434 +1,439 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader;
 
+import javax.persistence.Embeddable;
+import javax.persistence.EmbeddedId;
+import javax.persistence.Entity;
+import javax.persistence.Id;
+import javax.persistence.ManyToOne;
 import java.io.Serializable;
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
-import java.util.Collections;
 import java.util.List;
-import javax.persistence.Embeddable;
-import javax.persistence.EmbeddedId;
-import javax.persistence.Entity;
-import javax.persistence.Id;
-import javax.persistence.ManyToOne;
-
-import org.junit.Test;
 
 import org.hibernate.LockOptions;
 import org.hibernate.Session;
-import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.jdbc.Work;
-import org.hibernate.loader.internal.EntityLoadQueryBuilderImpl;
-import org.hibernate.loader.internal.LoadQueryAliasResolutionContextImpl;
-import org.hibernate.loader.internal.ResultSetProcessorImpl;
-import org.hibernate.loader.plan.internal.SingleRootReturnLoadPlanBuilderStrategy;
+import org.hibernate.loader.plan.exec.process.internal.ResultSetProcessorImpl;
+import org.hibernate.loader.plan.exec.internal.AliasResolutionContextImpl;
+import org.hibernate.loader.plan.exec.query.spi.NamedParameterContext;
+import org.hibernate.loader.plan.exec.spi.AliasResolutionContext;
 import org.hibernate.loader.plan.spi.LoadPlan;
-import org.hibernate.loader.plan.spi.build.LoadPlanBuilder;
-import org.hibernate.loader.spi.LoadQueryAliasResolutionContext;
-import org.hibernate.loader.spi.NamedParameterContext;
 import org.hibernate.loader.spi.NoOpLoadPlanAdvisor;
 import org.hibernate.persister.entity.EntityPersister;
+import org.hibernate.type.Type;
+
+import org.junit.Test;
+
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.hibernate.testing.junit4.ExtraAssertions;
-import org.hibernate.type.Type;
 
 import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNotNull;
-import static org.junit.Assert.assertSame;
-import static org.junit.Assert.assertTrue;
 
 /**
  * @author Gail Badner
  */
 public class EncapsulatedCompositeIdResultSetProcessorTest extends BaseCoreFunctionalTestCase {
 
 	@Override
 	protected Class<?>[] getAnnotatedClasses() {
 		return new Class[] { Parent.class, CardField.class, Card.class };
 	}
 
 	@Test
 	public void testSimpleCompositeId() throws Exception {
 
 		// create some test data
 		Session session = openSession();
 		session.beginTransaction();
 		Parent parent = new Parent();
 		parent.id = new ParentPK();
 		parent.id.firstName = "Joe";
 		parent.id.lastName = "Blow";
 		session.save( parent );
 		session.getTransaction().commit();
 		session.close();
 
 		session = openSession();
 		session.beginTransaction();
 		Parent parentGotten = (Parent) session.get( Parent.class, parent.id );
 		assertEquals( parent, parentGotten );
 		session.getTransaction().commit();
 		session.close();
 
 		final List results = getResults(
 				sessionFactory().getEntityPersister( Parent.class.getName() ),
 				new Callback() {
 					@Override
 					public void bind(PreparedStatement ps) throws SQLException {
 						ps.setString( 1, "Joe" );
 						ps.setString( 2, "Blow" );
 					}
 
 					@Override
 					public QueryParameters getQueryParameters() {
 						return new QueryParameters();
 					}
 
 				}
 		);
 		assertEquals( 1, results.size() );
 		Object result = results.get( 0 );
 		assertNotNull( result );
 
 		Parent parentWork = ExtraAssertions.assertTyping( Parent.class, result );
 		assertEquals( parent, parentWork );
 
 		// clean up test data
 		session = openSession();
 		session.beginTransaction();
 		session.createQuery( "delete Parent" ).executeUpdate();
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	@Test
 	public void testCompositeIdWithKeyManyToOne() throws Exception {
 		final String cardId = "ace-of-spades";
 
 		// create some test data
 		Session session = openSession();
 		session.beginTransaction();
 		Card card = new Card( cardId );
 		final CardField cardField = new CardField( card, 1 );
 		session.persist( card );
 		session.persist( cardField );
 		session.getTransaction().commit();
 		session.close();
 
 		session = openSession();
 		session.beginTransaction();
 		Card cardProxy = (Card) session.load( Card.class, cardId );
 		final CardFieldPK cardFieldPK = new CardFieldPK( cardProxy, 1 );
 		CardField cardFieldGotten = (CardField) session.get( CardField.class, cardFieldPK );
 
 		//assertEquals( card, cardGotten );
 		session.getTransaction().commit();
 		session.close();
 
 		final EntityPersister entityPersister = sessionFactory().getEntityPersister( CardField.class.getName() );
 
 		final List results = getResults(
 				entityPersister,
 				new Callback() {
 					@Override
 					public void bind(PreparedStatement ps) throws SQLException {
 						ps.setString( 1, cardField.primaryKey.card.id );
 						ps.setInt( 2, cardField.primaryKey.fieldNumber );
 					}
 
 					@Override
 					public QueryParameters getQueryParameters() {
 						QueryParameters qp = new QueryParameters();
 						qp.setPositionalParameterTypes( new Type[] { entityPersister.getIdentifierType() } );
 						qp.setPositionalParameterValues( new Object[] { cardFieldPK } );
 						qp.setOptionalObject( null );
 						qp.setOptionalEntityName( entityPersister.getEntityName() );
 						qp.setOptionalId( cardFieldPK );
 						qp.setLockOptions( LockOptions.NONE );
 						return qp;
 					}
 
 				}
 		);
 		assertEquals( 1, results.size() );
 		Object result = results.get( 0 );
 		assertNotNull( result );
 
 		CardField cardFieldWork = ExtraAssertions.assertTyping( CardField.class, result );
 		assertEquals( cardFieldGotten, cardFieldWork );
 
 		// clean up test data
 		session = openSession();
 		session.beginTransaction();
 		session.createQuery( "delete CardField" ).executeUpdate();
 		session.createQuery( "delete Card" ).executeUpdate();
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	private List getResults(final EntityPersister entityPersister, final Callback callback) {
-		final SingleRootReturnLoadPlanBuilderStrategy strategy = new SingleRootReturnLoadPlanBuilderStrategy(
-				sessionFactory(),
-				LoadQueryInfluencers.NONE
-		);
-		final LoadPlan plan = LoadPlanBuilder.buildRootEntityLoadPlan( strategy, entityPersister );
-		final LoadQueryAliasResolutionContext aliasResolutionContext =
-				new LoadQueryAliasResolutionContextImpl(
-						sessionFactory(),
-						0,
-						Collections.singletonMap( plan.getReturns().get( 0 ), new String[] { "abc" } )
-				);
-		final EntityLoadQueryBuilderImpl queryBuilder = new EntityLoadQueryBuilderImpl(
-				LoadQueryInfluencers.NONE,
-				plan
-		);
-		final String sql = queryBuilder.generateSql( 1, sessionFactory(), aliasResolutionContext );
+		final LoadPlan plan = Helper.INSTANCE.buildLoadPlan( sessionFactory(), entityPersister );
+		final AliasResolutionContext aliasResolutionContext = new AliasResolutionContextImpl( sessionFactory(), 0 );
+
+		final String sql = Helper.INSTANCE.generateSql( sessionFactory(), plan, aliasResolutionContext );
+
+		final ResultSetProcessorImpl resultSetProcessor = new ResultSetProcessorImpl( plan, true );
 
-		final ResultSetProcessorImpl resultSetProcessor = new ResultSetProcessorImpl( plan );
 		final List results = new ArrayList();
 
 		final Session workSession = openSession();
 		workSession.beginTransaction();
 		workSession.doWork(
 				new Work() {
 					@Override
 					public void execute(Connection connection) throws SQLException {
 						PreparedStatement ps = connection.prepareStatement( sql );
 						callback.bind( ps );
 						ResultSet resultSet = ps.executeQuery();
 						//callback.beforeExtractResults( workSession );
 						results.addAll(
 								resultSetProcessor.extractResults(
 										NoOpLoadPlanAdvisor.INSTANCE,
 										resultSet,
 										(SessionImplementor) workSession,
 										callback.getQueryParameters(),
 										new NamedParameterContext() {
 											@Override
 											public int[] getNamedParameterLocations(String name) {
 												return new int[0];
 											}
 										},
 										aliasResolutionContext,
 										true,
 										false,
 										null,
 										null
 								)
 						);
 						resultSet.close();
 						ps.close();
 					}
 				}
 		);
 		workSession.getTransaction().commit();
 		workSession.close();
 
 		return results;
 	}
 
 
 	private interface Callback {
 		void bind(PreparedStatement ps) throws SQLException;
 		QueryParameters getQueryParameters ();
 	}
 
 	@Entity ( name = "Parent" )
 	public static class Parent {
 		@EmbeddedId
 		public ParentPK id;
 
 		public boolean equals(Object o) {
 			if ( this == o ) return true;
 			if ( !( o instanceof Parent ) ) return false;
 
 			final Parent parent = (Parent) o;
 
 			if ( !id.equals( parent.id ) ) return false;
 
 			return true;
 		}
 
 		public int hashCode() {
 			return id.hashCode();
 		}
 	}
 
 	@Embeddable
 	public static class ParentPK implements Serializable {
 		private String firstName;
 		private String lastName;
 
 		public boolean equals(Object o) {
 			if ( this == o ) return true;
 			if ( !( o instanceof ParentPK ) ) return false;
 
 			final ParentPK parentPk = (ParentPK) o;
 
 			if ( !firstName.equals( parentPk.firstName ) ) return false;
 			if ( !lastName.equals( parentPk.lastName ) ) return false;
 
 			return true;
 		}
 
 		public int hashCode() {
 			int result;
 			result = firstName.hashCode();
 			result = 29 * result + lastName.hashCode();
 			return result;
 		}
 	}
 
 	@Entity ( name = "CardField" )
 	public static class CardField implements Serializable {
 
 		@EmbeddedId
 		private CardFieldPK primaryKey;
 
 		CardField(Card card, int fieldNumber) {
 			this.primaryKey = new CardFieldPK(card, fieldNumber);
 		}
 
 		CardField() {
 		}
 
 		public CardFieldPK getPrimaryKey() {
 			return primaryKey;
 		}
 
 		public void setPrimaryKey(CardFieldPK primaryKey) {
 			this.primaryKey = primaryKey;
 		}
 
 		@Override
 		public boolean equals(Object o) {
 			if ( this == o ) {
 				return true;
 			}
 			if ( o == null || getClass() != o.getClass() ) {
 				return false;
 			}
 
 			CardField cardField = (CardField) o;
 
 			if ( primaryKey != null ? !primaryKey.equals( cardField.primaryKey ) : cardField.primaryKey != null ) {
 				return false;
 			}
 
 			return true;
 		}
 
 		@Override
 		public int hashCode() {
 			return primaryKey != null ? primaryKey.hashCode() : 0;
 		}
 	}
 
 	@Embeddable
 	public static class CardFieldPK implements Serializable {
 		@ManyToOne(optional = false)
 		private Card card;
 
 		private int fieldNumber;
 
 		public CardFieldPK(Card card, int fieldNumber) {
 			this.card = card;
 			this.fieldNumber = fieldNumber;
 		}
 
 		CardFieldPK() {
 		}
 
 		public Card getCard() {
 			return card;
 		}
 
 		public void setCard(Card card) {
 			this.card = card;
 		}
 
 		public int getFieldNumber() {
 			return fieldNumber;
 		}
 
 		public void setFieldNumber(int fieldNumber) {
 			this.fieldNumber = fieldNumber;
 		}
 
 		@Override
 		public boolean equals(Object o) {
 			if ( this == o ) {
 				return true;
 			}
 			if ( o == null || getClass() != o.getClass() ) {
 				return false;
 			}
 
 			CardFieldPK that = (CardFieldPK) o;
 
 			if ( fieldNumber != that.fieldNumber ) {
 				return false;
 			}
 			if ( card != null ? !card.equals( that.card ) : that.card != null ) {
 				return false;
 			}
 
 			return true;
 		}
 
 		@Override
 		public int hashCode() {
 			int result = card != null ? card.hashCode() : 0;
 			result = 31 * result + fieldNumber;
 			return result;
 		}
 	}
 
 	@Entity ( name = "Card" )
 	public static class Card implements Serializable {
 		@Id
 		private String id;
 
 		public Card(String id) {
 			this();
 			this.id = id;
 		}
 
 		Card() {
 		}
 
 		public String getId() {
 			return id;
 		}
 
 		public void setId(String id) {
 			this.id = id;
 		}
+
+		@Override
+		public boolean equals(Object o) {
+			if ( this == o ) {
+				return true;
+			}
+			if ( o == null || getClass() != o.getClass() ) {
+				return false;
+			}
+
+			Card card = (Card) o;
+
+			if ( !id.equals( card.id ) ) {
+				return false;
+			}
+
+			return true;
+		}
+
+		@Override
+		public int hashCode() {
+			return id.hashCode();
+		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/loader/EntityAssociationResultSetProcessorTest.java b/hibernate-core/src/test/java/org/hibernate/loader/EntityAssociationResultSetProcessorTest.java
index 33c32e0504..bccdcf5584 100644
--- a/hibernate-core/src/test/java/org/hibernate/loader/EntityAssociationResultSetProcessorTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/loader/EntityAssociationResultSetProcessorTest.java
@@ -1,326 +1,298 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader;
 
-import java.sql.Connection;
-import java.sql.PreparedStatement;
-import java.sql.ResultSet;
-import java.sql.SQLException;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.List;
 import javax.persistence.CascadeType;
 import javax.persistence.Entity;
 import javax.persistence.Id;
 import javax.persistence.JoinColumn;
 import javax.persistence.ManyToOne;
 import javax.persistence.OneToMany;
-
-import org.junit.Test;
+import java.sql.Connection;
+import java.sql.PreparedStatement;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+import java.util.ArrayList;
+import java.util.List;
 
 import org.hibernate.Hibernate;
 import org.hibernate.Session;
-import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.jdbc.Work;
-import org.hibernate.loader.internal.EntityLoadQueryBuilderImpl;
-import org.hibernate.loader.internal.LoadQueryAliasResolutionContextImpl;
-import org.hibernate.loader.internal.ResultSetProcessorImpl;
-import org.hibernate.loader.plan.internal.SingleRootReturnLoadPlanBuilderStrategy;
+import org.hibernate.loader.plan.exec.process.internal.ResultSetProcessorImpl;
+import org.hibernate.loader.plan.exec.internal.AliasResolutionContextImpl;
+import org.hibernate.loader.plan.exec.query.spi.NamedParameterContext;
+import org.hibernate.loader.plan.exec.spi.AliasResolutionContext;
 import org.hibernate.loader.plan.spi.LoadPlan;
-import org.hibernate.loader.plan.spi.build.LoadPlanBuilder;
-import org.hibernate.loader.spi.LoadQueryAliasResolutionContext;
-import org.hibernate.loader.spi.NamedParameterContext;
 import org.hibernate.loader.spi.NoOpLoadPlanAdvisor;
 import org.hibernate.persister.entity.EntityPersister;
+
+import org.junit.Test;
+
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.hibernate.testing.junit4.ExtraAssertions;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertTrue;
 
 /**
  * @author Gail Badner
  */
 public class EntityAssociationResultSetProcessorTest extends BaseCoreFunctionalTestCase {
 
 	@Override
 	protected Class<?>[] getAnnotatedClasses() {
 		return new Class[] { Message.class, Poster.class, ReportedMessage.class };
 	}
 
 	@Test
 	public void testManyToOneEntityProcessing() throws Exception {
 		final EntityPersister entityPersister = sessionFactory().getEntityPersister( Message.class.getName() );
 
 		// create some test data
 		Session session = openSession();
 		session.beginTransaction();
 		Message message = new Message( 1, "the message" );
 		Poster poster = new Poster( 2, "the poster" );
 		session.save( message );
 		session.save( poster );
 		message.poster = poster;
 		poster.messages.add( message );
 		session.getTransaction().commit();
 		session.close();
 
 		{
-			final SingleRootReturnLoadPlanBuilderStrategy strategy = new SingleRootReturnLoadPlanBuilderStrategy(
-					sessionFactory(),
-					LoadQueryInfluencers.NONE
-			);
-			final LoadPlan plan = LoadPlanBuilder.buildRootEntityLoadPlan( strategy, entityPersister );
-			final LoadQueryAliasResolutionContext aliasResolutionContext =
-					new LoadQueryAliasResolutionContextImpl(
-							sessionFactory(),
-							0,
-							Collections.singletonMap( plan.getReturns().get( 0 ), new String[] { "abc" } )
-					);
-			final EntityLoadQueryBuilderImpl queryBuilder = new EntityLoadQueryBuilderImpl(
-					LoadQueryInfluencers.NONE,
-					plan
-			);
-			final String sql = queryBuilder.generateSql( 1, sessionFactory(), aliasResolutionContext );
+			final LoadPlan plan = Helper.INSTANCE.buildLoadPlan( sessionFactory(), entityPersister );
+			final AliasResolutionContext aliasResolutionContext = new AliasResolutionContextImpl( sessionFactory(), 0 );
+
+			final String sql = Helper.INSTANCE.generateSql( sessionFactory(), plan, aliasResolutionContext );
 
-			final ResultSetProcessorImpl resultSetProcessor = new ResultSetProcessorImpl( plan );
+			final ResultSetProcessorImpl resultSetProcessor = new ResultSetProcessorImpl( plan, true );
 			final List results = new ArrayList();
 
 			final Session workSession = openSession();
 			workSession.beginTransaction();
 			workSession.doWork(
 					new Work() {
 						@Override
 						public void execute(Connection connection) throws SQLException {
 							PreparedStatement ps = connection.prepareStatement( sql );
 							ps.setInt( 1, 1 );
 							ResultSet resultSet = ps.executeQuery();
 							results.addAll(
 									resultSetProcessor.extractResults(
 											NoOpLoadPlanAdvisor.INSTANCE,
 											resultSet,
 											(SessionImplementor) workSession,
 											new QueryParameters(),
 											new NamedParameterContext() {
 												@Override
 												public int[] getNamedParameterLocations(String name) {
 													return new int[0];
 												}
 											},
 											aliasResolutionContext,
 											true,
 											false,
 											null,
 											null
 									)
 							);
 							resultSet.close();
 							ps.close();
 						}
 					}
 			);
 			assertEquals( 1, results.size() );
 			Object result = results.get( 0 );
 			assertNotNull( result );
 
 			Message workMessage = ExtraAssertions.assertTyping( Message.class, result );
 			assertEquals( 1, workMessage.mid.intValue() );
 			assertEquals( "the message", workMessage.msgTxt );
 			assertTrue( Hibernate.isInitialized( workMessage.poster ) );
 			Poster workPoster = workMessage.poster;
 			assertEquals( 2, workPoster.pid.intValue() );
 			assertEquals( "the poster", workPoster.name );
 			assertFalse( Hibernate.isInitialized( workPoster.messages ) );
 
 			workSession.getTransaction().commit();
 			workSession.close();
 		}
 
 		// clean up test data
 		session = openSession();
 		session.beginTransaction();
 		session.createQuery( "delete Message" ).executeUpdate();
 		session.createQuery( "delete Poster" ).executeUpdate();
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	@Test
 	public void testNestedManyToOneEntityProcessing() throws Exception {
 		final EntityPersister entityPersister = sessionFactory().getEntityPersister( ReportedMessage.class.getName() );
 
 		// create some test data
 		Session session = openSession();
 		session.beginTransaction();
 		Message message = new Message( 1, "the message" );
 		Poster poster = new Poster( 2, "the poster" );
 		session.save( message );
 		session.save( poster );
 		message.poster = poster;
 		poster.messages.add( message );
 		ReportedMessage reportedMessage = new ReportedMessage( 0, "inappropriate", message );
 		session.save( reportedMessage );
 		session.getTransaction().commit();
 		session.close();
 
 		{
-			final SingleRootReturnLoadPlanBuilderStrategy strategy = new SingleRootReturnLoadPlanBuilderStrategy(
-					sessionFactory(),
-					LoadQueryInfluencers.NONE
-			);
-			final LoadPlan plan = LoadPlanBuilder.buildRootEntityLoadPlan( strategy, entityPersister );
-			final LoadQueryAliasResolutionContext aliasResolutionContext =
-					new LoadQueryAliasResolutionContextImpl(
-							sessionFactory(),
-							0,
-							Collections.singletonMap( plan.getReturns().get( 0 ), new String[] { "abc" } )
-					);
-			final EntityLoadQueryBuilderImpl queryBuilder = new EntityLoadQueryBuilderImpl(
-					LoadQueryInfluencers.NONE,
-					plan
-			);
-			final String sql = queryBuilder.generateSql( 1, sessionFactory(), aliasResolutionContext );
+			final LoadPlan plan = Helper.INSTANCE.buildLoadPlan( sessionFactory(), entityPersister );
+			final AliasResolutionContext aliasResolutionContext = new AliasResolutionContextImpl( sessionFactory(), 0 );
+
+			final String sql = Helper.INSTANCE.generateSql( sessionFactory(), plan, aliasResolutionContext );
 
-			final ResultSetProcessorImpl resultSetProcessor = new ResultSetProcessorImpl( plan );
+			final ResultSetProcessorImpl resultSetProcessor = new ResultSetProcessorImpl( plan, true );
 			final List results = new ArrayList();
 
 			final Session workSession = openSession();
 			workSession.beginTransaction();
 			workSession.doWork(
 					new Work() {
 						@Override
 						public void execute(Connection connection) throws SQLException {
 							PreparedStatement ps = connection.prepareStatement( sql );
 							ps.setInt( 1, 0 );
 							ResultSet resultSet = ps.executeQuery();
 							results.addAll(
 									resultSetProcessor.extractResults(
 											NoOpLoadPlanAdvisor.INSTANCE,
 											resultSet,
 											(SessionImplementor) workSession,
 											new QueryParameters(),
 											new NamedParameterContext() {
 												@Override
 												public int[] getNamedParameterLocations(String name) {
 													return new int[0];
 												}
 											},
 											aliasResolutionContext,
 											true,
 											false,
 											null,
 											null
 									)
 							);
 							resultSet.close();
 							ps.close();
 						}
 					}
 			);
 			assertEquals( 1, results.size() );
 			Object result = results.get( 0 );
 			assertNotNull( result );
 
 			ReportedMessage workReportedMessage = ExtraAssertions.assertTyping( ReportedMessage.class, result );
 			assertEquals( 0, workReportedMessage.id.intValue() );
 			assertEquals( "inappropriate", workReportedMessage.reason );
 			Message workMessage = workReportedMessage.message;
 			assertNotNull( workMessage );
 			assertTrue( Hibernate.isInitialized( workMessage ) );
 			assertEquals( 1, workMessage.mid.intValue() );
 			assertEquals( "the message", workMessage.msgTxt );
 			assertTrue( Hibernate.isInitialized( workMessage.poster ) );
 			Poster workPoster = workMessage.poster;
 			assertEquals( 2, workPoster.pid.intValue() );
 			assertEquals( "the poster", workPoster.name );
 			assertFalse( Hibernate.isInitialized( workPoster.messages ) );
 
 			workSession.getTransaction().commit();
 			workSession.close();
 		}
 
 		// clean up test data
 		session = openSession();
 		session.beginTransaction();
 		session.createQuery( "delete ReportedMessage" ).executeUpdate();
 		session.createQuery( "delete Message" ).executeUpdate();
 		session.createQuery( "delete Poster" ).executeUpdate();
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	@Entity( name = "ReportedMessage" )
 	public static class ReportedMessage {
 		@Id
 		private Integer id;
 		private String reason;
 		@ManyToOne
 		@JoinColumn
 		private Message message;
 
 		public ReportedMessage() {}
 
 		public ReportedMessage(Integer id, String reason, Message message) {
 			this.id = id;
 			this.reason = reason;
 			this.message = message;
 		}
 	}
 
 	@Entity( name = "Message" )
 	public static class Message {
 		@Id
 		private Integer mid;
 		private String msgTxt;
 		@ManyToOne( cascade = CascadeType.MERGE )
 		@JoinColumn
 		private Poster poster;
 
 		public Message() {}
 
 		public Message(Integer mid, String msgTxt) {
 			this.mid = mid;
 			this.msgTxt = msgTxt;
 		}
 	}
 
 	@Entity( name = "Poster" )
 	public static class Poster {
 		@Id
 		private Integer pid;
 		private String name;
 		@OneToMany(mappedBy = "poster")
 		private List<Message> messages = new ArrayList<Message>();
 
 		public Poster() {}
 
 		public Poster(Integer pid, String name) {
 			this.pid = pid;
 			this.name = name;
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/loader/EntityWithNonLazyCollectionResultSetProcessorTest.java b/hibernate-core/src/test/java/org/hibernate/loader/EntityWithNonLazyCollectionResultSetProcessorTest.java
index bd6a8d5a70..5fc9a90b82 100644
--- a/hibernate-core/src/test/java/org/hibernate/loader/EntityWithNonLazyCollectionResultSetProcessorTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/loader/EntityWithNonLazyCollectionResultSetProcessorTest.java
@@ -1,179 +1,166 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader;
 
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertNotNull;
-import static org.junit.Assert.assertSame;
-import static org.junit.Assert.assertTrue;
-
+import javax.persistence.CollectionTable;
+import javax.persistence.Column;
+import javax.persistence.ElementCollection;
+import javax.persistence.Entity;
+import javax.persistence.FetchType;
+import javax.persistence.Id;
+import javax.persistence.JoinColumn;
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
-import java.util.Collections;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
 
-import javax.persistence.CollectionTable;
-import javax.persistence.ElementCollection;
-import javax.persistence.Entity;
-import javax.persistence.FetchType;
-import javax.persistence.Id;
-
 import org.hibernate.Hibernate;
 import org.hibernate.Session;
-import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.jdbc.Work;
-import org.hibernate.loader.internal.EntityLoadQueryBuilderImpl;
-import org.hibernate.loader.internal.LoadQueryAliasResolutionContextImpl;
-import org.hibernate.loader.internal.ResultSetProcessorImpl;
-import org.hibernate.loader.plan.internal.SingleRootReturnLoadPlanBuilderStrategy;
+import org.hibernate.loader.plan.exec.process.internal.ResultSetProcessorImpl;
+import org.hibernate.loader.plan.exec.internal.AliasResolutionContextImpl;
+import org.hibernate.loader.plan.exec.query.spi.NamedParameterContext;
+import org.hibernate.loader.plan.exec.spi.AliasResolutionContext;
 import org.hibernate.loader.plan.spi.LoadPlan;
-import org.hibernate.loader.plan.spi.build.LoadPlanBuilder;
-import org.hibernate.loader.spi.LoadQueryAliasResolutionContext;
-import org.hibernate.loader.spi.NamedParameterContext;
 import org.hibernate.loader.spi.NoOpLoadPlanAdvisor;
 import org.hibernate.persister.entity.EntityPersister;
+
+import org.junit.Test;
+
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.hibernate.testing.junit4.ExtraAssertions;
-import org.junit.Test;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.assertSame;
+import static org.junit.Assert.assertTrue;
 
 /**
  * @author Gail Badner
  */
 public class EntityWithNonLazyCollectionResultSetProcessorTest extends BaseCoreFunctionalTestCase {
 
 	@Override
 	protected Class<?>[] getAnnotatedClasses() {
 		return new Class[] { Person.class };
 	}
 
 	@Test
 	public void testEntityWithSet() throws Exception {
 		final EntityPersister entityPersister = sessionFactory().getEntityPersister( Person.class.getName() );
 
 		// create some test data
 		Session session = openSession();
 		session.beginTransaction();
 		Person person = new Person();
 		person.id = 1;
 		person.name = "John Doe";
 		person.nickNames.add( "Jack" );
 		person.nickNames.add( "Johnny" );
 		session.save( person );
 		session.getTransaction().commit();
 		session.close();
 
 		{
-			final SingleRootReturnLoadPlanBuilderStrategy strategy = new SingleRootReturnLoadPlanBuilderStrategy(
-					sessionFactory(),
-					LoadQueryInfluencers.NONE
-			);
-			final LoadPlan plan = LoadPlanBuilder.buildRootEntityLoadPlan( strategy, entityPersister );
-			final LoadQueryAliasResolutionContext aliasResolutionContext =
-					new LoadQueryAliasResolutionContextImpl(
-							sessionFactory(),
-							0,
-							Collections.singletonMap( plan.getReturns().get( 0 ), new String[] { "abc" } )
-					);
-			final EntityLoadQueryBuilderImpl queryBuilder = new EntityLoadQueryBuilderImpl(
-					LoadQueryInfluencers.NONE,
-					plan
-			);
-			final String sql = queryBuilder.generateSql( 1, sessionFactory(), aliasResolutionContext );
+			final LoadPlan plan = Helper.INSTANCE.buildLoadPlan( sessionFactory(), entityPersister );
+			final AliasResolutionContext aliasResolutionContext = new AliasResolutionContextImpl( sessionFactory(), 0 );
+
+			final String sql = Helper.INSTANCE.generateSql( sessionFactory(), plan, aliasResolutionContext );
 
-			final ResultSetProcessorImpl resultSetProcessor = new ResultSetProcessorImpl( plan );
+			final ResultSetProcessorImpl resultSetProcessor = new ResultSetProcessorImpl( plan, true );
 			final List results = new ArrayList();
 
 			final Session workSession = openSession();
 			workSession.beginTransaction();
 			workSession.doWork(
 					new Work() {
 						@Override
 						public void execute(Connection connection) throws SQLException {
 							PreparedStatement ps = connection.prepareStatement( sql );
 							ps.setInt( 1, 1 );
 							ResultSet resultSet = ps.executeQuery();
 							results.addAll(
 									resultSetProcessor.extractResults(
 											NoOpLoadPlanAdvisor.INSTANCE,
 											resultSet,
 											(SessionImplementor) workSession,
 											new QueryParameters(),
 											new NamedParameterContext() {
 												@Override
 												public int[] getNamedParameterLocations(String name) {
 													return new int[0];
 												}
 											},
 											aliasResolutionContext,
 											true,
 											false,
 											null,
 											null
 									)
 							);
 							resultSet.close();
 							ps.close();
 						}
 					}
 			);
 			assertEquals( 2, results.size() );
 			Object result1 = results.get( 0 );
 			assertSame( result1, results.get( 1 ) );
 			assertNotNull( result1 );
 
 			Person workPerson = ExtraAssertions.assertTyping( Person.class, result1 );
 			assertEquals( 1, workPerson.id.intValue() );
 			assertEquals( person.name, workPerson.name );
 			assertTrue( Hibernate.isInitialized( workPerson.nickNames ) );
 			assertEquals( 2, workPerson.nickNames.size() );
 			assertEquals( person.nickNames, workPerson.nickNames );
 			workSession.getTransaction().commit();
 			workSession.close();
 		}
 
 		// clean up test data
 		session = openSession();
 		session.beginTransaction();
 		session.delete( person );
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	@Entity( name = "Person" )
 	public static class Person {
 		@Id
 		private Integer id;
 		private String name;
 		@ElementCollection( fetch = FetchType.EAGER )
-		@CollectionTable( name = "NickNames" )
+		@CollectionTable( name = "nick_names", joinColumns = @JoinColumn( name = "pid" ) )
+		@Column( name = "nick" )
 		private Set<String> nickNames = new HashSet<String>();
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/loader/EntityWithNonLazyOneToManyListResultSetProcessorTest.java b/hibernate-core/src/test/java/org/hibernate/loader/EntityWithNonLazyOneToManyListResultSetProcessorTest.java
index abd4dadf7f..a061775a74 100644
--- a/hibernate-core/src/test/java/org/hibernate/loader/EntityWithNonLazyOneToManyListResultSetProcessorTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/loader/EntityWithNonLazyOneToManyListResultSetProcessorTest.java
@@ -1,215 +1,199 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader;
 
-import java.sql.Connection;
-import java.sql.PreparedStatement;
-import java.sql.ResultSet;
-import java.sql.SQLException;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.List;
 import javax.persistence.CascadeType;
 import javax.persistence.Entity;
 import javax.persistence.FetchType;
 import javax.persistence.Id;
 import javax.persistence.JoinColumn;
 import javax.persistence.ManyToOne;
 import javax.persistence.OneToMany;
-
-import org.junit.Test;
+import java.sql.Connection;
+import java.sql.PreparedStatement;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+import java.util.ArrayList;
+import java.util.List;
 
 import org.hibernate.Hibernate;
 import org.hibernate.Session;
-import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.jdbc.Work;
-import org.hibernate.loader.internal.EntityLoadQueryBuilderImpl;
-import org.hibernate.loader.internal.LoadQueryAliasResolutionContextImpl;
-import org.hibernate.loader.internal.ResultSetProcessorImpl;
-import org.hibernate.loader.plan.internal.SingleRootReturnLoadPlanBuilderStrategy;
+import org.hibernate.loader.plan.exec.process.internal.ResultSetProcessorImpl;
+import org.hibernate.loader.plan.exec.internal.AliasResolutionContextImpl;
+import org.hibernate.loader.plan.exec.query.spi.NamedParameterContext;
+import org.hibernate.loader.plan.exec.spi.AliasResolutionContext;
 import org.hibernate.loader.plan.spi.LoadPlan;
-import org.hibernate.loader.plan.spi.build.LoadPlanBuilder;
-import org.hibernate.loader.spi.LoadQueryAliasResolutionContext;
-import org.hibernate.loader.spi.NamedParameterContext;
 import org.hibernate.loader.spi.NoOpLoadPlanAdvisor;
 import org.hibernate.persister.entity.EntityPersister;
+
+import org.junit.Test;
+
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.hibernate.testing.junit4.ExtraAssertions;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertSame;
 import static org.junit.Assert.assertTrue;
 
 /**
  * @author Gail Badner
  */
 public class EntityWithNonLazyOneToManyListResultSetProcessorTest extends BaseCoreFunctionalTestCase {
 
 	@Override
 	protected Class<?>[] getAnnotatedClasses() {
 		return new Class[] { Poster.class, Message.class };
 	}
 
 	@Test
 	public void testEntityWithList() throws Exception {
 		final EntityPersister entityPersister = sessionFactory().getEntityPersister( Poster.class.getName() );
 
 		// create some test data
 		Session session = openSession();
 		session.beginTransaction();
 		Poster poster = new Poster();
 		poster.pid = 0;
 		poster.name = "John Doe";
 		Message message1 = new Message();
 		message1.mid = 1;
 		message1.msgTxt = "Howdy!";
 		message1.poster = poster;
 		poster.messages.add( message1 );
 		Message message2 = new Message();
 		message2.mid = 2;
 		message2.msgTxt = "Bye!";
 		message2.poster = poster;
 		poster.messages.add( message2 );
 		session.save( poster );
 		session.getTransaction().commit();
 		session.close();
 
 		session = openSession();
 		session.beginTransaction();
 		Poster posterGotten = (Poster) session.get( Poster.class, poster.pid );
 		assertEquals( 0, posterGotten.pid.intValue() );
 		assertEquals( poster.name, posterGotten.name );
 		assertTrue( Hibernate.isInitialized( posterGotten.messages ) );
 		assertEquals( 2, posterGotten.messages.size() );
 		assertEquals( message1.msgTxt, posterGotten.messages.get( 0 ).msgTxt );
 		assertEquals( message2.msgTxt, posterGotten.messages.get( 1 ).msgTxt );
 		assertSame( posterGotten, posterGotten.messages.get( 0 ).poster );
 		assertSame( posterGotten, posterGotten.messages.get( 1 ).poster );
 		session.getTransaction().commit();
 		session.close();
 
 		{
-			final SingleRootReturnLoadPlanBuilderStrategy strategy = new SingleRootReturnLoadPlanBuilderStrategy(
-					sessionFactory(),
-					LoadQueryInfluencers.NONE
-			);
-			final LoadPlan plan = LoadPlanBuilder.buildRootEntityLoadPlan( strategy, entityPersister );
-			final LoadQueryAliasResolutionContext aliasResolutionContext =
-					new LoadQueryAliasResolutionContextImpl(
-							sessionFactory(),
-							0,
-							Collections.singletonMap( plan.getReturns().get( 0 ), new String[] { "abc" } )
-					);
-			final EntityLoadQueryBuilderImpl queryBuilder = new EntityLoadQueryBuilderImpl(
-					LoadQueryInfluencers.NONE,
-					plan
-			);
-			final String sql = queryBuilder.generateSql( 1, sessionFactory(), aliasResolutionContext );
+			final LoadPlan plan = Helper.INSTANCE.buildLoadPlan( sessionFactory(), entityPersister );
+			final AliasResolutionContext aliasResolutionContext = new AliasResolutionContextImpl( sessionFactory(), 0 );
+
+			final String sql = Helper.INSTANCE.generateSql( sessionFactory(), plan, aliasResolutionContext );
 
-			final ResultSetProcessorImpl resultSetProcessor = new ResultSetProcessorImpl( plan );
+			final ResultSetProcessorImpl resultSetProcessor = new ResultSetProcessorImpl( plan, true );
 			final List results = new ArrayList();
 
 			final Session workSession = openSession();
 			workSession.beginTransaction();
 			workSession.doWork(
 					new Work() {
 						@Override
 						public void execute(Connection connection) throws SQLException {
 							PreparedStatement ps = connection.prepareStatement( sql );
 							ps.setInt( 1, 0 );
 							ResultSet resultSet = ps.executeQuery();
 							results.addAll(
 									resultSetProcessor.extractResults(
 											NoOpLoadPlanAdvisor.INSTANCE,
 											resultSet,
 											(SessionImplementor) workSession,
 											new QueryParameters(),
 											new NamedParameterContext() {
 												@Override
 												public int[] getNamedParameterLocations(String name) {
 													return new int[0];
 												}
 											},
 											aliasResolutionContext,
 											true,
 											false,
 											null,
 											null
 									)
 							);
 							resultSet.close();
 							ps.close();
 						}
 					}
 			);
 			assertEquals( 2, results.size() );
 			Object result1 = results.get( 0 );
 			assertNotNull( result1 );
 			assertSame( result1, results.get( 1 ) );
 
 			Poster workPoster = ExtraAssertions.assertTyping( Poster.class, result1 );
 			assertEquals( 0, workPoster.pid.intValue() );
 			assertEquals( poster.name, workPoster.name );
 			assertTrue( Hibernate.isInitialized( workPoster.messages ) );
 			assertEquals( 2, workPoster.messages.size() );
 			assertTrue( Hibernate.isInitialized( posterGotten.messages ) );
 			assertEquals( 2, workPoster.messages.size() );
 			assertEquals( message1.msgTxt, workPoster.messages.get( 0 ).msgTxt );
 			assertEquals( message2.msgTxt, workPoster.messages.get( 1 ).msgTxt );
 			assertSame( workPoster, workPoster.messages.get( 0 ).poster );
 			assertSame( workPoster, workPoster.messages.get( 1 ).poster );
 			workSession.getTransaction().commit();
 			workSession.close();
 		}
 
 		// clean up test data
 		session = openSession();
 		session.beginTransaction();
 		session.delete( poster );
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	@Entity( name = "Message" )
 	public static class Message {
 		@Id
 		private Integer mid;
 		private String msgTxt;
 		@ManyToOne
 		@JoinColumn
 		private Poster poster;
 	}
 
 	@Entity( name = "Poster" )
 	public static class Poster {
 		@Id
 		private Integer pid;
 		private String name;
 		@OneToMany(mappedBy = "poster", fetch = FetchType.EAGER, cascade = CascadeType.ALL )
 		private List<Message> messages = new ArrayList<Message>();
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/loader/EntityWithNonLazyOneToManySetResultSetProcessorTest.java b/hibernate-core/src/test/java/org/hibernate/loader/EntityWithNonLazyOneToManySetResultSetProcessorTest.java
index eee117e602..5a84e8a3a4 100644
--- a/hibernate-core/src/test/java/org/hibernate/loader/EntityWithNonLazyOneToManySetResultSetProcessorTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/loader/EntityWithNonLazyOneToManySetResultSetProcessorTest.java
@@ -1,234 +1,218 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader;
 
+import javax.persistence.CascadeType;
+import javax.persistence.Entity;
+import javax.persistence.FetchType;
+import javax.persistence.Id;
+import javax.persistence.JoinColumn;
+import javax.persistence.ManyToOne;
+import javax.persistence.OneToMany;
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
-import java.util.Collections;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
-import javax.persistence.CascadeType;
-import javax.persistence.Entity;
-import javax.persistence.FetchType;
-import javax.persistence.Id;
-import javax.persistence.JoinColumn;
-import javax.persistence.ManyToOne;
-import javax.persistence.OneToMany;
-
-import org.junit.Test;
 
 import org.hibernate.Hibernate;
 import org.hibernate.Session;
-import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.jdbc.Work;
-import org.hibernate.loader.internal.EntityLoadQueryBuilderImpl;
-import org.hibernate.loader.internal.LoadQueryAliasResolutionContextImpl;
-import org.hibernate.loader.internal.ResultSetProcessorImpl;
-import org.hibernate.loader.plan.internal.SingleRootReturnLoadPlanBuilderStrategy;
+import org.hibernate.loader.plan.exec.process.internal.ResultSetProcessorImpl;
+import org.hibernate.loader.plan.exec.internal.AliasResolutionContextImpl;
+import org.hibernate.loader.plan.exec.query.spi.NamedParameterContext;
+import org.hibernate.loader.plan.exec.spi.AliasResolutionContext;
 import org.hibernate.loader.plan.spi.LoadPlan;
-import org.hibernate.loader.plan.spi.build.LoadPlanBuilder;
-import org.hibernate.loader.spi.LoadQueryAliasResolutionContext;
-import org.hibernate.loader.spi.NamedParameterContext;
 import org.hibernate.loader.spi.NoOpLoadPlanAdvisor;
 import org.hibernate.persister.entity.EntityPersister;
+
+import org.junit.Test;
+
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.hibernate.testing.junit4.ExtraAssertions;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertSame;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * @author Gail Badner
  */
 public class EntityWithNonLazyOneToManySetResultSetProcessorTest extends BaseCoreFunctionalTestCase {
 
 	@Override
 	protected Class<?>[] getAnnotatedClasses() {
 		return new Class[] { Poster.class, Message.class };
 	}
 
 	@Test
 	public void testEntityWithSet() throws Exception {
 		final EntityPersister entityPersister = sessionFactory().getEntityPersister( Poster.class.getName() );
 
 		// create some test data
 		Session session = openSession();
 		session.beginTransaction();
 		Poster poster = new Poster();
 		poster.pid = 0;
 		poster.name = "John Doe";
 		Message message1 = new Message();
 		message1.mid = 1;
 		message1.msgTxt = "Howdy!";
 		message1.poster = poster;
 		poster.messages.add( message1 );
 		Message message2 = new Message();
 		message2.mid = 2;
 		message2.msgTxt = "Bye!";
 		message2.poster = poster;
 		poster.messages.add( message2 );
 		session.save( poster );
 		session.getTransaction().commit();
 		session.close();
 
 		session = openSession();
 		session.beginTransaction();
 		Poster posterGotten = (Poster) session.get( Poster.class, poster.pid );
 		assertEquals( 0, posterGotten.pid.intValue() );
 		assertEquals( poster.name, posterGotten.name );
 		assertTrue( Hibernate.isInitialized( posterGotten.messages ) );
 		assertEquals( 2, posterGotten.messages.size() );
 		for ( Message message : posterGotten.messages ) {
 			if ( message.mid == 1 ) {
 				assertEquals( message1.msgTxt, message.msgTxt );
 			}
 			else if ( message.mid == 2 ) {
 				assertEquals( message2.msgTxt, message.msgTxt );
 			}
 			else {
 				fail( "unexpected message id." );
 			}
 			assertSame( posterGotten, message.poster );
 		}
 		session.getTransaction().commit();
 		session.close();
 
 		{
-			final SingleRootReturnLoadPlanBuilderStrategy strategy = new SingleRootReturnLoadPlanBuilderStrategy(
-					sessionFactory(),
-					LoadQueryInfluencers.NONE
-			);
-			final LoadPlan plan = LoadPlanBuilder.buildRootEntityLoadPlan( strategy, entityPersister );
-			final LoadQueryAliasResolutionContext aliasResolutionContext =
-					new LoadQueryAliasResolutionContextImpl(
-							sessionFactory(),
-							0,
-							Collections.singletonMap( plan.getReturns().get( 0 ), new String[] { "abc" } )
-					);
-			final EntityLoadQueryBuilderImpl queryBuilder = new EntityLoadQueryBuilderImpl(
-					LoadQueryInfluencers.NONE,
-					plan
-			);
-			final String sql = queryBuilder.generateSql( 1, sessionFactory(), aliasResolutionContext );
+			final LoadPlan plan = Helper.INSTANCE.buildLoadPlan( sessionFactory(), entityPersister );
+			final AliasResolutionContext aliasResolutionContext = new AliasResolutionContextImpl( sessionFactory(), 0 );
+
+			final String sql = Helper.INSTANCE.generateSql( sessionFactory(), plan, aliasResolutionContext );
 
-			final ResultSetProcessorImpl resultSetProcessor = new ResultSetProcessorImpl( plan );
+			final ResultSetProcessorImpl resultSetProcessor = new ResultSetProcessorImpl( plan, true );
 			final List results = new ArrayList();
 
 			final Session workSession = openSession();
 			workSession.beginTransaction();
 			workSession.doWork(
 					new Work() {
 						@Override
 						public void execute(Connection connection) throws SQLException {
 							PreparedStatement ps = connection.prepareStatement( sql );
 							ps.setInt( 1, 0 );
 							ResultSet resultSet = ps.executeQuery();
 							results.addAll(
 									resultSetProcessor.extractResults(
 											NoOpLoadPlanAdvisor.INSTANCE,
 											resultSet,
 											(SessionImplementor) workSession,
 											new QueryParameters(),
 											new NamedParameterContext() {
 												@Override
 												public int[] getNamedParameterLocations(String name) {
 													return new int[0];
 												}
 											},
 											aliasResolutionContext,
 											true,
 											false,
 											null,
 											null
 									)
 							);
 							resultSet.close();
 							ps.close();
 						}
 					}
 			);
 			assertEquals( 2, results.size() );
 			Object result1 = results.get( 0 );
 			assertNotNull( result1 );
 			assertSame( result1, results.get( 1 ) );
 
 			Poster workPoster = ExtraAssertions.assertTyping( Poster.class, result1 );
 			assertEquals( 0, workPoster.pid.intValue() );
 			assertEquals( poster.name, workPoster.name );
 			assertTrue( Hibernate.isInitialized( workPoster.messages ) );
 			assertEquals( 2, workPoster.messages.size() );
 			assertTrue( Hibernate.isInitialized( posterGotten.messages ) );
 			assertEquals( 2, workPoster.messages.size() );
 			for ( Message message : workPoster.messages ) {
 				if ( message.mid == 1 ) {
 					assertEquals( message1.msgTxt, message.msgTxt );
 				}
 				else if ( message.mid == 2 ) {
 					assertEquals( message2.msgTxt, message.msgTxt );
 				}
 				else {
 					fail( "unexpected message id." );
 				}
 				assertSame( workPoster, message.poster );
 			}
 			workSession.getTransaction().commit();
 			workSession.close();
 		}
 
 		// clean up test data
 		session = openSession();
 		session.beginTransaction();
 		session.delete( poster );
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	@Entity( name = "Message" )
 	public static class Message {
 		@Id
 		private Integer mid;
 		private String msgTxt;
 		@ManyToOne
 		@JoinColumn
 		private Poster poster;
 	}
 
 	@Entity( name = "Poster" )
 	public static class Poster {
 		@Id
 		private Integer pid;
 		private String name;
 		@OneToMany(mappedBy = "poster", fetch = FetchType.EAGER, cascade = CascadeType.ALL )
 		private Set<Message> messages = new HashSet<Message>();
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/loader/Helper.java b/hibernate-core/src/test/java/org/hibernate/loader/Helper.java
new file mode 100644
index 0000000000..257b899b15
--- /dev/null
+++ b/hibernate-core/src/test/java/org/hibernate/loader/Helper.java
@@ -0,0 +1,86 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader;
+
+import org.hibernate.LockMode;
+import org.hibernate.LockOptions;
+import org.hibernate.engine.spi.LoadQueryInfluencers;
+import org.hibernate.engine.spi.SessionFactoryImplementor;
+import org.hibernate.loader.plan.exec.query.internal.EntityLoadQueryBuilderImpl;
+import org.hibernate.loader.plan.exec.query.spi.QueryBuildingParameters;
+import org.hibernate.loader.plan.exec.spi.AliasResolutionContext;
+import org.hibernate.loader.plan.internal.SingleRootReturnLoadPlanBuilderStrategy;
+import org.hibernate.loader.plan.spi.LoadPlan;
+import org.hibernate.loader.plan.spi.build.LoadPlanBuilder;
+import org.hibernate.persister.entity.EntityPersister;
+
+/**
+ * @author Steve Ebersole
+ */
+public class Helper implements QueryBuildingParameters {
+	/**
+	 * Singleton access
+	 */
+	public static final Helper INSTANCE = new Helper();
+
+	private Helper() {
+	}
+
+	public LoadPlan buildLoadPlan(SessionFactoryImplementor sf, EntityPersister entityPersister) {
+		final SingleRootReturnLoadPlanBuilderStrategy strategy = new SingleRootReturnLoadPlanBuilderStrategy(
+				sf,
+				LoadQueryInfluencers.NONE
+		);
+		return LoadPlanBuilder.buildRootEntityLoadPlan( strategy, entityPersister );
+	}
+
+	public String generateSql(SessionFactoryImplementor sf, LoadPlan plan, AliasResolutionContext aliasResolutionContext) {
+		return EntityLoadQueryBuilderImpl.INSTANCE.generateSql(
+				plan,
+				sf,
+				this,
+				aliasResolutionContext
+		);
+	}
+
+	@Override
+	public LoadQueryInfluencers getQueryInfluencers() {
+		return LoadQueryInfluencers.NONE;
+	}
+
+	@Override
+	public int getBatchSize() {
+		return 1;
+	}
+
+	@Override
+	public LockMode getLockMode() {
+		return null;
+	}
+
+	@Override
+	public LockOptions getLockOptions() {
+		return null;
+	}
+}
diff --git a/hibernate-core/src/test/java/org/hibernate/loader/NonEncapsulatedCompositeIdResultSetProcessorTest.java b/hibernate-core/src/test/java/org/hibernate/loader/NonEncapsulatedCompositeIdResultSetProcessorTest.java
index bd05014d50..81c2833de9 100644
--- a/hibernate-core/src/test/java/org/hibernate/loader/NonEncapsulatedCompositeIdResultSetProcessorTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/loader/NonEncapsulatedCompositeIdResultSetProcessorTest.java
@@ -1,232 +1,215 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader;
 
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
-import java.util.Collections;
 import java.util.List;
 
 import org.hibernate.LockOptions;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
-import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.jdbc.Work;
-import org.hibernate.loader.internal.EntityLoadQueryBuilderImpl;
-import org.hibernate.loader.internal.LoadQueryAliasResolutionContextImpl;
-import org.hibernate.loader.internal.ResultSetProcessorImpl;
-import org.hibernate.loader.plan.internal.SingleRootReturnLoadPlanBuilderStrategy;
+import org.hibernate.loader.plan.exec.process.internal.ResultSetProcessorImpl;
+import org.hibernate.loader.plan.exec.internal.AliasResolutionContextImpl;
+import org.hibernate.loader.plan.exec.query.spi.NamedParameterContext;
+import org.hibernate.loader.plan.exec.spi.AliasResolutionContext;
 import org.hibernate.loader.plan.spi.LoadPlan;
-import org.hibernate.loader.plan.spi.build.LoadPlanBuilder;
-import org.hibernate.loader.spi.LoadQueryAliasResolutionContext;
-import org.hibernate.loader.spi.NamedParameterContext;
 import org.hibernate.loader.spi.NoOpLoadPlanAdvisor;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.type.Type;
 
 import org.junit.Test;
 
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.hibernate.test.onetoone.formula.Address;
 import org.hibernate.test.onetoone.formula.Person;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 
 /**
  * @author Steve Ebersole
  */
 public class NonEncapsulatedCompositeIdResultSetProcessorTest extends BaseCoreFunctionalTestCase {
 
 	@Override
 	protected String[] getMappings() {
 		return new String[] { "onetoone/formula/Person.hbm.xml" };
 	}
 
 	@Test
 	public void testCompositeIdWithKeyManyToOne() throws Exception {
 		final String personId = "John Doe";
 
 		Person p = new Person();
 		p.setName( personId );
 		final Address a = new Address();
 		a.setPerson( p );
 		p.setAddress( a );
 		a.setType( "HOME" );
 		a.setStreet( "Main St" );
 		a.setState( "Sweet Home Alabama" );
 		a.setZip( "3181" );
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( p );
 		t.commit();
 		s.close();
 
 		final EntityPersister personPersister = sessionFactory().getEntityPersister( Person.class.getName() );
 		final EntityPersister addressPersister = sessionFactory().getEntityPersister( Address.class.getName() );
 
 		{
 			final List results = getResults(
 					addressPersister,
 					new Callback() {
 						@Override
 						public void bind(PreparedStatement ps) throws SQLException {
 							ps.setString( 1, personId );
 							ps.setString( 2, "HOME" );
 						}
 
 						@Override
 						public QueryParameters getQueryParameters() {
 							QueryParameters qp = new QueryParameters();
 							qp.setPositionalParameterTypes( new Type[] { addressPersister.getIdentifierType() } );
 							qp.setPositionalParameterValues( new Object[] { a } );
 							qp.setOptionalObject( a );
 							qp.setOptionalEntityName( addressPersister.getEntityName() );
 							qp.setOptionalId( a );
 							qp.setLockOptions( LockOptions.NONE );
 							return qp;
 						}
 
 					}
 			);
 			assertEquals( 1, results.size() );
 			Object result = results.get( 0 );
 			assertNotNull( result );
 		}
 
 		// test loading the Person (the entity with normal id def, but mixed composite fk to Address)
 		{
 			final List results = getResults(
 					personPersister,
 					new Callback() {
 						@Override
 						public void bind(PreparedStatement ps) throws SQLException {
 							ps.setString( 1, personId );
 						}
 
 						@Override
 						public QueryParameters getQueryParameters() {
 							QueryParameters qp = new QueryParameters();
 							qp.setPositionalParameterTypes( new Type[] { personPersister.getIdentifierType() } );
 							qp.setPositionalParameterValues( new Object[] { personId } );
 							qp.setOptionalObject( null );
 							qp.setOptionalEntityName( personPersister.getEntityName() );
 							qp.setOptionalId( personId );
 							qp.setLockOptions( LockOptions.NONE );
 							return qp;
 						}
 
 					}
 			);
 			assertEquals( 1, results.size() );
 			Object result = results.get( 0 );
 			assertNotNull( result );
 		}
 
 //		CardField cardFieldWork = ExtraAssertions.assertTyping( CardField.class, result );
 //		assertEquals( cardFieldGotten, cardFieldWork );
 
 		// clean up test data
 		s = openSession();
 		s.beginTransaction();
 		s.createQuery( "delete Address" ).executeUpdate();
 		s.createQuery( "delete Person" ).executeUpdate();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	private List getResults(final EntityPersister entityPersister, final Callback callback) {
-		final SingleRootReturnLoadPlanBuilderStrategy strategy = new SingleRootReturnLoadPlanBuilderStrategy(
-				sessionFactory(),
-				LoadQueryInfluencers.NONE
-		);
-		final LoadPlan plan = LoadPlanBuilder.buildRootEntityLoadPlan( strategy, entityPersister );
-		final LoadQueryAliasResolutionContext aliasResolutionContext =
-				new LoadQueryAliasResolutionContextImpl(
-						sessionFactory(),
-						0,
-						Collections.singletonMap( plan.getReturns().get( 0 ), new String[] { "abc" } )
-				);
-		final EntityLoadQueryBuilderImpl queryBuilder = new EntityLoadQueryBuilderImpl(
-				LoadQueryInfluencers.NONE,
-				plan
-		);
-		final String sql = queryBuilder.generateSql( 1, sessionFactory(), aliasResolutionContext );
+		final LoadPlan plan = Helper.INSTANCE.buildLoadPlan( sessionFactory(), entityPersister );
+		final AliasResolutionContext aliasResolutionContext = new AliasResolutionContextImpl( sessionFactory(), 0 );
+
+		final String sql = Helper.INSTANCE.generateSql( sessionFactory(), plan, aliasResolutionContext );
 
-		final ResultSetProcessorImpl resultSetProcessor = new ResultSetProcessorImpl( plan );
+		final ResultSetProcessorImpl resultSetProcessor = new ResultSetProcessorImpl( plan, true );
 		final List results = new ArrayList();
 
 		final Session workSession = openSession();
 		workSession.beginTransaction();
 		workSession.doWork(
 				new Work() {
 					@Override
 					public void execute(Connection connection) throws SQLException {
 						System.out.println( "SQL : " + sql );
 						PreparedStatement ps = connection.prepareStatement( sql );
 						callback.bind( ps );
 						ResultSet resultSet = ps.executeQuery();
 						//callback.beforeExtractResults( workSession );
 						results.addAll(
 								resultSetProcessor.extractResults(
 										NoOpLoadPlanAdvisor.INSTANCE,
 										resultSet,
 										(SessionImplementor) workSession,
 										callback.getQueryParameters(),
 										new NamedParameterContext() {
 											@Override
 											public int[] getNamedParameterLocations(String name) {
 												return new int[0];
 											}
 										},
 										aliasResolutionContext,
 										true,
 										false,
 										null,
 										null
 								)
 						);
 						resultSet.close();
 						ps.close();
 					}
 				}
 		);
 		workSession.getTransaction().commit();
 		workSession.close();
 
 		return results;
 	}
 
 
 	private interface Callback {
 		void bind(PreparedStatement ps) throws SQLException;
 		QueryParameters getQueryParameters();
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/loader/SimpleResultSetProcessorTest.java b/hibernate-core/src/test/java/org/hibernate/loader/SimpleResultSetProcessorTest.java
index 2256b881c1..e0cdd76818 100644
--- a/hibernate-core/src/test/java/org/hibernate/loader/SimpleResultSetProcessorTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/loader/SimpleResultSetProcessorTest.java
@@ -1,168 +1,151 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader;
 
 import javax.persistence.Entity;
 import javax.persistence.Id;
-
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
-import java.util.Collections;
 import java.util.List;
 
 import org.hibernate.Session;
-import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.jdbc.Work;
-import org.hibernate.loader.internal.EntityLoadQueryBuilderImpl;
-import org.hibernate.loader.internal.LoadQueryAliasResolutionContextImpl;
-import org.hibernate.loader.internal.ResultSetProcessorImpl;
-import org.hibernate.loader.plan.internal.SingleRootReturnLoadPlanBuilderStrategy;
+import org.hibernate.loader.plan.exec.process.internal.ResultSetProcessorImpl;
+import org.hibernate.loader.plan.exec.internal.AliasResolutionContextImpl;
+import org.hibernate.loader.plan.exec.query.spi.NamedParameterContext;
+import org.hibernate.loader.plan.exec.spi.AliasResolutionContext;
 import org.hibernate.loader.plan.spi.LoadPlan;
-import org.hibernate.loader.plan.spi.build.LoadPlanBuilder;
-import org.hibernate.loader.spi.LoadQueryAliasResolutionContext;
-import org.hibernate.loader.spi.NamedParameterContext;
 import org.hibernate.loader.spi.NoOpLoadPlanAdvisor;
 import org.hibernate.persister.entity.EntityPersister;
 
 import org.junit.Test;
 
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.hibernate.testing.junit4.ExtraAssertions;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 
 /**
  * @author Steve Ebersole
  */
 public class SimpleResultSetProcessorTest extends BaseCoreFunctionalTestCase {
 
 	@Override
 	protected Class<?>[] getAnnotatedClasses() {
 		return new Class[] { SimpleEntity.class };
 	}
 
 	@Test
 	public void testSimpleEntityProcessing() throws Exception {
 		final EntityPersister entityPersister = sessionFactory().getEntityPersister( SimpleEntity.class.getName() );
 
 		// create some test data
 		Session session = openSession();
 		session.beginTransaction();
 		session.save( new SimpleEntity( 1, "the only" ) );
 		session.getTransaction().commit();
 		session.close();
 
 		{
-			final SingleRootReturnLoadPlanBuilderStrategy strategy = new SingleRootReturnLoadPlanBuilderStrategy(
-					sessionFactory(),
-					LoadQueryInfluencers.NONE
-			);
-			final LoadPlan plan = LoadPlanBuilder.buildRootEntityLoadPlan( strategy, entityPersister );
-			final LoadQueryAliasResolutionContext aliasResolutionContext =
-					new LoadQueryAliasResolutionContextImpl(
-							sessionFactory(),
-							0,
-							Collections.singletonMap( plan.getReturns().get( 0 ), new String[] { "abc" } )
-					);
-			final EntityLoadQueryBuilderImpl queryBuilder = new EntityLoadQueryBuilderImpl(
-					LoadQueryInfluencers.NONE,
-					plan
-			);
-			final String sql = queryBuilder.generateSql( 1, sessionFactory(), aliasResolutionContext );
+			final LoadPlan plan = Helper.INSTANCE.buildLoadPlan( sessionFactory(), entityPersister );
+			final AliasResolutionContext aliasResolutionContext = new AliasResolutionContextImpl( sessionFactory(), 0 );
+
+			final String sql = Helper.INSTANCE.generateSql( sessionFactory(), plan, aliasResolutionContext );
 
-			final ResultSetProcessorImpl resultSetProcessor = new ResultSetProcessorImpl( plan );
+			final ResultSetProcessorImpl resultSetProcessor = new ResultSetProcessorImpl( plan, true );
 			final List results = new ArrayList();
 
 			final Session workSession = openSession();
 			workSession.beginTransaction();
 			workSession.doWork(
 					new Work() {
 						@Override
 						public void execute(Connection connection) throws SQLException {
+							( (SessionImplementor) workSession ).getFactory().getJdbcServices().getSqlStatementLogger().logStatement( sql );
 							PreparedStatement ps = connection.prepareStatement( sql );
 							ps.setInt( 1, 1 );
 							ResultSet resultSet = ps.executeQuery();
 							results.addAll(
 									resultSetProcessor.extractResults(
 											NoOpLoadPlanAdvisor.INSTANCE,
 											resultSet,
 											(SessionImplementor) workSession,
 											new QueryParameters(),
 											new NamedParameterContext() {
 												@Override
 												public int[] getNamedParameterLocations(String name) {
 													return new int[0];
 												}
 											},
 											aliasResolutionContext,
 											true,
 											false,
 											null,
 											null
 									)
 							);
 							resultSet.close();
 							ps.close();
 						}
 					}
 			);
 			assertEquals( 1, results.size() );
 			Object result = results.get( 0 );
 			assertNotNull( result );
 
 			SimpleEntity workEntity = ExtraAssertions.assertTyping( SimpleEntity.class, result );
 			assertEquals( 1, workEntity.id.intValue() );
 			assertEquals( "the only", workEntity.name );
 			workSession.getTransaction().commit();
 			workSession.close();
 		}
 
 		// clean up test data
 		session = openSession();
 		session.beginTransaction();
 		session.createQuery( "delete SimpleEntity" ).executeUpdate();
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	@Entity(name = "SimpleEntity")
 	public static class SimpleEntity {
 		@Id public Integer id;
 		public String name;
 
 		public SimpleEntity() {
 		}
 
 		public SimpleEntity(Integer id, String name) {
 			this.id = id;
 			this.name = name;
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/loader/plan/spi/LoadPlanStructureAssertionHelper.java b/hibernate-core/src/test/java/org/hibernate/loader/plan/spi/LoadPlanStructureAssertionHelper.java
new file mode 100644
index 0000000000..a828a7a784
--- /dev/null
+++ b/hibernate-core/src/test/java/org/hibernate/loader/plan/spi/LoadPlanStructureAssertionHelper.java
@@ -0,0 +1,125 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.spi;
+
+import org.hibernate.LockMode;
+import org.hibernate.LockOptions;
+import org.hibernate.engine.spi.LoadQueryInfluencers;
+import org.hibernate.engine.spi.SessionFactoryImplementor;
+import org.hibernate.internal.util.StringHelper;
+import org.hibernate.loader.JoinWalker;
+import org.hibernate.loader.entity.EntityJoinWalker;
+import org.hibernate.loader.entity.EntityLoader;
+import org.hibernate.loader.plan.exec.query.spi.QueryBuildingParameters;
+import org.hibernate.loader.plan.exec.spi.LoadQueryDetails;
+import org.hibernate.loader.plan.internal.SingleRootReturnLoadPlanBuilderStrategy;
+import org.hibernate.loader.plan.spi.build.LoadPlanBuilder;
+import org.hibernate.persister.entity.OuterJoinLoadable;
+
+/**
+ * Perform assertions based on a LoadPlan, specifically against the outputs/expectations of the legacy Loader approach.
+ * <p/>
+ * Mainly this is intended to be a transitory set of help since it is expected that Loader will go away replaced by
+ * LoadPlans, QueryBuilders and ResultSetProcessors.  For now I want to make sure that the outputs (e.g., the SQL,
+ * the extraction aliases) are the same given the same input.  That makes sure we have the best possibility of success
+ * in designing and implementing the "replacement parts".
+ *
+ * @author Steve Ebersole
+ */
+public class LoadPlanStructureAssertionHelper {
+	/**
+	 * Singleton access to the helper
+	 */
+	public static final LoadPlanStructureAssertionHelper INSTANCE = new LoadPlanStructureAssertionHelper();
+
+	/**
+	 * Performs a basic comparison.  Builds a LoadPlan for the given persister and compares it against the
+	 * expectations according to the Loader/Walker corollary.
+	 *
+	 * @param sf The SessionFactory
+	 * @param persister The entity persister for which to build a LoadPlan and compare against the Loader/Walker
+	 * expectations.
+	 */
+	public void performBasicComparison(SessionFactoryImplementor sf, OuterJoinLoadable persister) {
+		// todo : allow these to be passed in by tests?
+		final LoadQueryInfluencers influencers = LoadQueryInfluencers.NONE;
+		final LockMode lockMode = LockMode.NONE;
+		final int batchSize = 1;
+
+		// legacy Loader-based contracts...
+		final EntityJoinWalker walker = new EntityJoinWalker(
+				persister,
+				persister.getKeyColumnNames(),
+				batchSize,
+				lockMode,
+				sf,
+				influencers
+		);
+//		final EntityLoader loader = new EntityLoader( persister, lockMode, sf, influencers );
+
+		SingleRootReturnLoadPlanBuilderStrategy strategy = new SingleRootReturnLoadPlanBuilderStrategy( sf, influencers );
+		LoadPlan plan = LoadPlanBuilder.buildRootEntityLoadPlan( strategy, persister );
+		LoadQueryDetails details = LoadQueryDetails.makeForBatching(
+				persister.getKeyColumnNames(),
+				plan,
+				sf,
+				new QueryBuildingParameters() {
+					@Override
+					public LoadQueryInfluencers getQueryInfluencers() {
+						return influencers;
+					}
+
+					@Override
+					public int getBatchSize() {
+						return batchSize;
+					}
+
+					@Override
+					public LockMode getLockMode() {
+						return lockMode;
+					}
+
+					@Override
+					public LockOptions getLockOptions() {
+						return null;
+					}
+				}
+		);
+
+		compare( walker, details );
+	}
+
+	private void compare(JoinWalker walker, LoadQueryDetails details) {
+		System.out.println( "------ SQL -----------------------------------------------------------------" );
+		System.out.println( "WALKER    : " + walker.getSQLString() );
+		System.out.println( "LOAD-PLAN : " + details.getSqlStatement() );
+		System.out.println( "----------------------------------------------------------------------------" );
+		System.out.println( );
+		System.out.println( "------ SUFFIXES ------------------------------------------------------------" );
+		System.out.println( "WALKER    : " + StringHelper.join( ", ",  walker.getSuffixes() ) + " : "
+									+ StringHelper.join( ", ", walker.getCollectionSuffixes() ) );
+		System.out.println( "----------------------------------------------------------------------------" );
+		System.out.println( );
+	}
+}
diff --git a/hibernate-core/src/test/java/org/hibernate/loader/plan/spi/LoadPlanStructureAssertionTest.java b/hibernate-core/src/test/java/org/hibernate/loader/plan/spi/LoadPlanStructureAssertionTest.java
new file mode 100644
index 0000000000..83d71adc35
--- /dev/null
+++ b/hibernate-core/src/test/java/org/hibernate/loader/plan/spi/LoadPlanStructureAssertionTest.java
@@ -0,0 +1,86 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.loader.plan.spi;
+
+import org.hibernate.cfg.Configuration;
+import org.hibernate.engine.spi.SessionFactoryImplementor;
+import org.hibernate.loader.EncapsulatedCompositeIdResultSetProcessorTest;
+import org.hibernate.persister.entity.OuterJoinLoadable;
+
+import org.junit.Test;
+
+import org.hibernate.testing.junit4.BaseUnitTestCase;
+
+/**
+ * Used to assert that "fetch graphs" between JoinWalker and LoadPlan are same.
+ *
+ * @author Steve Ebersole
+ */
+public class LoadPlanStructureAssertionTest extends BaseUnitTestCase {
+	@Test
+	public void testJoinedOneToOne() {
+		// tests the mappings defined in org.hibernate.test.onetoone.joined.JoinedSubclassOneToOneTest
+		Configuration cfg = new Configuration();
+		cfg.addResource( "org/hibernate/test/onetoone/joined/Person.hbm.xml" );
+		SessionFactoryImplementor sf = (SessionFactoryImplementor) cfg.buildSessionFactory();
+
+//		doCompare( sf, (OuterJoinLoadable) sf.getClassMetadata( org.hibernate.test.onetoone.joined.Person.class ) );
+		doCompare( sf, (OuterJoinLoadable) sf.getClassMetadata( org.hibernate.test.onetoone.joined.Entity.class ) );
+
+//		doCompare( sf, (OuterJoinLoadable) sf.getClassMetadata( org.hibernate.test.onetoone.joined.Address.class ) );
+	}
+
+	@Test
+	public void testSpecialOneToOne() {
+		// tests the mappings defined in org.hibernate.test.onetoone.joined.JoinedSubclassOneToOneTest
+		Configuration cfg = new Configuration();
+		cfg.addResource( "org/hibernate/test/onetoone/formula/Person.hbm.xml" );
+		SessionFactoryImplementor sf = (SessionFactoryImplementor) cfg.buildSessionFactory();
+
+		doCompare( sf, (OuterJoinLoadable) sf.getClassMetadata( org.hibernate.test.onetoone.formula.Person.class ) );
+	}
+
+	@Test
+	public void testEncapsulatedCompositeId() {
+		Configuration cfg = new Configuration();
+		cfg.addAnnotatedClass( EncapsulatedCompositeIdResultSetProcessorTest.Parent.class );
+		cfg.addAnnotatedClass( EncapsulatedCompositeIdResultSetProcessorTest.CardField.class );
+		cfg.addAnnotatedClass( EncapsulatedCompositeIdResultSetProcessorTest.Card.class );
+		SessionFactoryImplementor sf = (SessionFactoryImplementor) cfg.buildSessionFactory();
+		doCompare( sf, (OuterJoinLoadable) sf.getClassMetadata( EncapsulatedCompositeIdResultSetProcessorTest.CardField.class ) );
+	}
+
+	@Test
+	public void testManyToMany() {
+		Configuration cfg = new Configuration();
+		cfg.addResource( "org/hibernate/test/immutable/entitywithmutablecollection/inverse/ContractVariation.hbm.xml" );
+		SessionFactoryImplementor sf = (SessionFactoryImplementor) cfg.buildSessionFactory();
+		doCompare( sf, (OuterJoinLoadable) sf.getClassMetadata( org.hibernate.test.immutable.entitywithmutablecollection.Contract.class ) );
+
+	}
+
+	private void doCompare(SessionFactoryImplementor sf, OuterJoinLoadable persister) {
+		LoadPlanStructureAssertionHelper.INSTANCE.performBasicComparison( sf, persister );
+	}
+}
diff --git a/hibernate-core/src/test/java/org/hibernate/persister/walking/BasicWalkingTest.java b/hibernate-core/src/test/java/org/hibernate/persister/walking/BasicWalkingTest.java
index 90788b3911..5a7ef43eeb 100644
--- a/hibernate-core/src/test/java/org/hibernate/persister/walking/BasicWalkingTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/persister/walking/BasicWalkingTest.java
@@ -1,233 +1,239 @@
 /*
  * jDocBook, processing of DocBook sources
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.walking;
 
 import javax.persistence.Entity;
 import javax.persistence.Id;
 import javax.persistence.JoinColumn;
 import javax.persistence.ManyToOne;
 import javax.persistence.OneToMany;
 import java.util.List;
 
 import org.hibernate.annotations.common.util.StringHelper;
 import org.hibernate.persister.entity.EntityPersister;
+import org.hibernate.persister.walking.spi.AnyMappingDefinition;
+import org.hibernate.persister.walking.spi.AssociationAttributeDefinition;
 import org.hibernate.persister.walking.spi.AssociationVisitationStrategy;
 import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.persister.walking.spi.CollectionDefinition;
 import org.hibernate.persister.walking.spi.CollectionElementDefinition;
 import org.hibernate.persister.walking.spi.CollectionIndexDefinition;
 import org.hibernate.persister.walking.spi.CompositeCollectionElementDefinition;
 import org.hibernate.persister.walking.spi.CompositionDefinition;
 import org.hibernate.persister.walking.spi.EntityDefinition;
 import org.hibernate.persister.walking.spi.EntityIdentifierDefinition;
 import org.hibernate.persister.walking.spi.MetadataDrivenModelGraphVisitor;
 
 import org.junit.Test;
 
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
 /**
  * @author Steve Ebersole
  */
 public class BasicWalkingTest extends BaseCoreFunctionalTestCase {
 	@Override
 	protected Class<?>[] getAnnotatedClasses() {
 		return new Class[] { Message.class, Poster.class };
 	}
 
 	@Test
 	public void testIt() {
 		EntityPersister ep = (EntityPersister) sessionFactory().getClassMetadata(Message.class);
 		MetadataDrivenModelGraphVisitor.visitEntity(
 				new AssociationVisitationStrategy() {
 					private int depth = 0;
 
 					@Override
 					public void start() {
 						System.out.println( ">> Start" );
 					}
 
 					@Override
 					public void finish() {
 						System.out.println( "<< Finish" );
 					}
 
 					@Override
 					public void startingEntity(EntityDefinition entityDefinition) {
 						System.out.println(
 								String.format(
 										"%s Starting entity (%s)",
 										StringHelper.repeat( ">>", ++depth ),
 										entityDefinition.toString()
 								)
 						);
 					}
 
 					@Override
 					public void finishingEntity(EntityDefinition entityDefinition) {
 						System.out.println(
 								String.format(
 										"%s Finishing entity (%s)",
 										StringHelper.repeat( "<<", depth-- ),
 										entityDefinition.toString()
 								)
 						);
 					}
 
 					@Override
 					public void startingEntityIdentifier(EntityIdentifierDefinition entityIdentifierDefinition) {
 						//To change body of implemented methods use File | Settings | File Templates.
 					}
 
 					@Override
 					public void finishingEntityIdentifier(EntityIdentifierDefinition entityIdentifierDefinition) {
 						//To change body of implemented methods use File | Settings | File Templates.
 					}
 
 					@Override
 					public void startingCollection(CollectionDefinition collectionDefinition) {
 						System.out.println(
 								String.format(
 										"%s Starting collection (%s)",
 										StringHelper.repeat( ">>", ++depth ),
 										collectionDefinition.toString()
 								)
 						);
 					}
 
 					@Override
 					public void finishingCollection(CollectionDefinition collectionDefinition) {
 						System.out.println(
 								String.format(
 										"%s Finishing collection (%s)",
 										StringHelper.repeat( ">>", depth-- ),
 										collectionDefinition.toString()
 								)
 						);
 					}
 
 					@Override
 					public void startingCollectionIndex(CollectionIndexDefinition collectionIndexDefinition) {
 						//To change body of implemented methods use File | Settings | File Templates.
 					}
 
 					@Override
 					public void finishingCollectionIndex(CollectionIndexDefinition collectionIndexDefinition) {
 						//To change body of implemented methods use File | Settings | File Templates.
 					}
 
 					@Override
 					public void startingCollectionElements(CollectionElementDefinition elementDefinition) {
 						//To change body of implemented methods use File | Settings | File Templates.
 					}
 
 					@Override
 					public void finishingCollectionElements(CollectionElementDefinition elementDefinition) {
 						//To change body of implemented methods use File | Settings | File Templates.
 					}
 
 					@Override
 					public void startingComposite(CompositionDefinition compositionDefinition) {
 						System.out.println(
 								String.format(
 										"%s Starting composite (%s)",
 										StringHelper.repeat( ">>", ++depth ),
 										compositionDefinition.toString()
 								)
 						);
 					}
 
 					@Override
 					public void finishingComposite(CompositionDefinition compositionDefinition) {
 						System.out.println(
 								String.format(
 										"%s Finishing composite (%s)",
 										StringHelper.repeat( ">>", depth-- ),
 										compositionDefinition.toString()
 								)
 						);
 					}
 
 					@Override
 					public void startingCompositeCollectionElement(CompositeCollectionElementDefinition compositionElementDefinition) {
 						System.out.println(
 								String.format(
 										"%s Starting composite (%s)",
 										StringHelper.repeat( ">>", ++depth ),
 										compositionElementDefinition.toString()
 								)
 						);
 					}
 
 					@Override
 					public void finishingCompositeCollectionElement(CompositeCollectionElementDefinition compositionElementDefinition) {
 						System.out.println(
 								String.format(
 										"%s Finishing composite (%s)",
 										StringHelper.repeat( ">>", depth-- ),
 										compositionElementDefinition.toString()
 								)
 						);
 					}
 
 					@Override
 					public boolean startingAttribute(AttributeDefinition attributeDefinition) {
 						System.out.println(
 								String.format(
 										"%s Handling attribute (%s)",
 										StringHelper.repeat( ">>", depth + 1 ),
 										attributeDefinition.toString()
 								)
 						);
 						return true;
 					}
 
 					@Override
 					public void finishingAttribute(AttributeDefinition attributeDefinition) {
 						// nothing to do
 					}
+
+					@Override
+					public void foundAny(AssociationAttributeDefinition attributeDefinition, AnyMappingDefinition anyDefinition) {
+					}
 				},
 				ep
 		);
 	}
 
 	@Entity( name = "Message" )
 	public static class Message {
 		@Id
 		private Integer id;
 		private String name;
 		@ManyToOne
 		@JoinColumn
 		private Poster poster;
 	}
 
 	@Entity( name = "Poster" )
 	public static class Poster {
 		@Id
 		private Integer id;
 		private String name;
 		@OneToMany(mappedBy = "poster")
 		private List<Message> messages;
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/collectionelement/CollectionElementTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/collectionelement/CollectionElementTest.java
index 0f69d745dd..196173fb91 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/collectionelement/CollectionElementTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/collectionelement/CollectionElementTest.java
@@ -1,291 +1,292 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.annotations.collectionelement;
 
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Locale;
 
 import org.junit.Test;
 
 import org.hibernate.Filter;
 import org.hibernate.Query;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.Column;
 import org.hibernate.test.annotations.Country;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertTrue;
 
 /**
  * @author Emmanuel Bernard
  * @author Hardy Ferentschik
  */
 @SuppressWarnings("unchecked")
 public class CollectionElementTest extends BaseCoreFunctionalTestCase {
 	@Test
 	public void testSimpleElement() throws Exception {
 		assertEquals(
 				"BoyFavoriteNumbers",
 				configuration().getCollectionMapping( Boy.class.getName() + '.' + "favoriteNumbers" )
 						.getCollectionTable().getName()
 		);
 		Session s = openSession();
 		s.getTransaction().begin();
 		Boy boy = new Boy();
 		boy.setFirstName( "John" );
 		boy.setLastName( "Doe" );
 		boy.getNickNames().add( "Johnny" );
 		boy.getNickNames().add( "Thing" );
 		boy.getScorePerNickName().put( "Johnny", Integer.valueOf( 3 ) );
 		boy.getScorePerNickName().put( "Thing", Integer.valueOf( 5 ) );
 		int[] favNbrs = new int[4];
 		for (int index = 0; index < favNbrs.length - 1; index++) {
 			favNbrs[index] = index * 3;
 		}
 		boy.setFavoriteNumbers( favNbrs );
 		boy.getCharacters().add( Character.GENTLE );
 		boy.getCharacters().add( Character.CRAFTY );
 
 		HashMap<String,FavoriteFood> foods = new HashMap<String,FavoriteFood>();
 		foods.put( "breakfast", FavoriteFood.PIZZA);
 		foods.put( "lunch", FavoriteFood.KUNGPAOCHICKEN);
 		foods.put( "dinner", FavoriteFood.SUSHI);
 		boy.setFavoriteFood(foods);
 		s.persist( boy );
 		s.getTransaction().commit();
 		s.clear();
 		Transaction tx = s.beginTransaction();
 		boy = (Boy) s.get( Boy.class, boy.getId() );
 		assertNotNull( boy.getNickNames() );
 		assertTrue( boy.getNickNames().contains( "Thing" ) );
 		assertNotNull( boy.getScorePerNickName() );
 		assertTrue( boy.getScorePerNickName().containsKey( "Thing" ) );
 		assertEquals( Integer.valueOf( 5 ), boy.getScorePerNickName().get( "Thing" ) );
 		assertNotNull( boy.getFavoriteNumbers() );
 		assertEquals( 3, boy.getFavoriteNumbers()[1] );
 		assertTrue( boy.getCharacters().contains( Character.CRAFTY ) );
 		assertTrue( boy.getFavoriteFood().get("dinner").equals(FavoriteFood.SUSHI));
 		assertTrue( boy.getFavoriteFood().get("lunch").equals(FavoriteFood.KUNGPAOCHICKEN));
 		assertTrue( boy.getFavoriteFood().get("breakfast").equals(FavoriteFood.PIZZA));
 		List result = s.createQuery( "select boy from Boy boy join boy.nickNames names where names = :name" )
 				.setParameter( "name", "Thing" ).list();
 		assertEquals( 1, result.size() );
 		s.delete( boy );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testCompositeElement() throws Exception {
 		Session s = openSession();
 		s.getTransaction().begin();
 		Boy boy = new Boy();
 		boy.setFirstName( "John" );
 		boy.setLastName( "Doe" );
 		Toy toy = new Toy();
 		toy.setName( "Balloon" );
 		toy.setSerial( "serial001" );
 		toy.setBrand( new Brand() );
 		toy.getBrand().setName( "Bandai" );
 		boy.getFavoriteToys().add( toy );
 		s.persist( boy );
 		s.getTransaction().commit();
 		s.clear();
 		Transaction tx = s.beginTransaction();
 		boy = (Boy) s.get( Boy.class, boy.getId() );
+		assertNotNull( boy );
 		assertNotNull( boy.getFavoriteToys() );
 		assertTrue( boy.getFavoriteToys().contains( toy ) );
 		assertEquals( "@Parent is failing", boy, boy.getFavoriteToys().iterator().next().getOwner() );
 		s.delete( boy );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testAttributedJoin() throws Exception {
 		Session s = openSession();
 		s.getTransaction().begin();
 		Country country = new Country();
 		country.setName( "Australia" );
 		s.persist( country );
 
 		Boy boy = new Boy();
 		boy.setFirstName( "John" );
 		boy.setLastName( "Doe" );
 		CountryAttitude attitude = new CountryAttitude();
 		// TODO: doesn't work
 		attitude.setBoy( boy );
 		attitude.setCountry( country );
 		attitude.setLikes( true );
 		boy.getCountryAttitudes().add( attitude );
 		s.persist( boy );
 		s.getTransaction().commit();
 		s.clear();
 
 		Transaction tx = s.beginTransaction();
 		boy = (Boy) s.get( Boy.class, boy.getId() );
 		assertTrue( boy.getCountryAttitudes().contains( attitude ) );
 		s.delete( boy );
 		s.delete( s.get( Country.class, country.getId() ) );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testLazyCollectionofElements() throws Exception {
 		assertEquals(
 				"BoyFavoriteNumbers",
 				configuration().getCollectionMapping( Boy.class.getName() + '.' + "favoriteNumbers" )
 						.getCollectionTable().getName()
 		);
 		Session s = openSession();
 		s.getTransaction().begin();
 		Boy boy = new Boy();
 		boy.setFirstName( "John" );
 		boy.setLastName( "Doe" );
 		boy.getNickNames().add( "Johnny" );
 		boy.getNickNames().add( "Thing" );
 		boy.getScorePerNickName().put( "Johnny", new Integer( 3 ) );
 		boy.getScorePerNickName().put( "Thing", new Integer( 5 ) );
 		int[] favNbrs = new int[4];
 		for (int index = 0; index < favNbrs.length - 1; index++) {
 			favNbrs[index] = index * 3;
 		}
 		boy.setFavoriteNumbers( favNbrs );
 		boy.getCharacters().add( Character.GENTLE );
 		boy.getCharacters().add( Character.CRAFTY );
 		s.persist( boy );
 		s.getTransaction().commit();
 		s.clear();
 		Transaction tx = s.beginTransaction();
 		boy = (Boy) s.get( Boy.class, boy.getId() );
 		assertNotNull( boy.getNickNames() );
 		assertTrue( boy.getNickNames().contains( "Thing" ) );
 		assertNotNull( boy.getScorePerNickName() );
 		assertTrue( boy.getScorePerNickName().containsKey( "Thing" ) );
 		assertEquals( new Integer( 5 ), boy.getScorePerNickName().get( "Thing" ) );
 		assertNotNull( boy.getFavoriteNumbers() );
 		assertEquals( 3, boy.getFavoriteNumbers()[1] );
 		assertTrue( boy.getCharacters().contains( Character.CRAFTY ) );
 		List result = s.createQuery( "select boy from Boy boy join boy.nickNames names where names = :name" )
 				.setParameter( "name", "Thing" ).list();
 		assertEquals( 1, result.size() );
 		s.delete( boy );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testFetchEagerAndFilter() throws Exception {
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 
 		TestCourse test = new TestCourse();
 
 		LocalizedString title = new LocalizedString( "title in english" );
 		title.getVariations().put( Locale.FRENCH.getLanguage(), "title en francais" );
 		test.setTitle( title );
 		s.save( test );
 
 		s.flush();
 		s.clear();
 
 		Filter filter = s.enableFilter( "selectedLocale" );
 		filter.setParameter( "param", "fr" );
 
 		Query q = s.createQuery( "from TestCourse t" );
 		List l = q.list();
 		assertEquals( 1, l.size() );
 
 		TestCourse t = (TestCourse) s.get( TestCourse.class, test.getTestCourseId() );
 		assertEquals( 1, t.getTitle().getVariations().size() );
 
 		tx.rollback();
 
 		s.close();
 	}
 
 	@Test
 	public void testMapKeyType() throws Exception {
 		Matrix m = new Matrix();
 		m.getMvalues().put( 1, 1.1f );
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		s.persist( m );
 		s.flush();
 		s.clear();
 		m = (Matrix) s.get( Matrix.class, m.getId() );
 		assertEquals( 1.1f, m.getMvalues().get( 1 ), 0.01f );
 		tx.rollback();
 		s.close();
 	}
 
 	@Test
 	public void testDefaultValueColumnForBasic() throws Exception {
 		isDefaultValueCollectionColumnPresent( Boy.class.getName(), "hatedNames" );
 		isDefaultValueCollectionColumnPresent( Boy.class.getName(), "preferredNames" );
 		isCollectionColumnPresent( Boy.class.getName(), "nickNames", "nickNames" );
 		isDefaultValueCollectionColumnPresent( Boy.class.getName(), "scorePerPreferredName");
 	}
 
 	@Test
 	public void testDefaultFKNameForElementCollection() throws Exception {
 		isCollectionColumnPresent( Boy.class.getName(), "hatedNames", "Boy_id" );
 	}
 
 	private void isLegacyValueCollectionColumnPresent(String collectionHolder, String propertyName) {
 
 	}
 
 	private void isDefaultValueCollectionColumnPresent(String collectionOwner, String propertyName) {
 		isCollectionColumnPresent( collectionOwner, propertyName, propertyName );
 	}
 
 	private void isCollectionColumnPresent(String collectionOwner, String propertyName, String columnName) {
 		final Collection collection = configuration().getCollectionMapping( collectionOwner + "." + propertyName );
 		final Iterator columnIterator = collection.getCollectionTable().getColumnIterator();
 		boolean hasDefault = false;
 		while ( columnIterator.hasNext() ) {
 			Column column = (Column) columnIterator.next();
 			if ( columnName.equals( column.getName() ) ) hasDefault = true;
 		}
 		assertTrue( "Could not find " + columnName, hasDefault );
 	}
 
 	@Override
 	protected Class[] getAnnotatedClasses() {
 		return new Class[] {
 				Boy.class,
 				Country.class,
 				TestCourse.class,
 				Matrix.class
 		};
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/any/AnyTypeTest.java b/hibernate-core/src/test/java/org/hibernate/test/any/AnyTypeTest.java
index 3c7a4966de..06b93d6f66 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/any/AnyTypeTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/any/AnyTypeTest.java
@@ -1,73 +1,85 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.any;
 
 import org.junit.Test;
 
 import org.hibernate.Session;
+import org.hibernate.hql.internal.ast.QuerySyntaxException;
+
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
 /**
  * @author Steve Ebersole
  */
 @TestForIssue( jiraKey = "HHH-1663" )
 public class AnyTypeTest extends BaseCoreFunctionalTestCase {
 	@Override
 	public String[] getMappings() {
 		return new String[] { "any/Person.hbm.xml" };
 	}
 
 	@Override
 	public String getCacheConcurrencyStrategy() {
 		// having second level cache causes a condition whereby the original test case would not fail...
 		return null;
 	}
 
 	@Test
 	public void testFlushProcessing() {
 		Session session = openSession();
 		session.beginTransaction();
 		Person person = new Person();
 		Address address = new Address();
 		person.setData( address );
 		session.saveOrUpdate(person);
 		session.saveOrUpdate(address);
 		session.getTransaction().commit();
 		session.close();
 
 		session = openSession();
 		session.beginTransaction();
         person = (Person) session.load( Person.class, person.getId() );
         person.setName("makingpersondirty");
 		session.getTransaction().commit();
 		session.close();
 
 		session = openSession();
 		session.beginTransaction();
 		session.delete( person );
 		session.getTransaction().commit();
 		session.close();
 	}
+
+	@Test( expected = QuerySyntaxException.class )
+	public void testJoinFetchOfAnAnyTypeAttribute() {
+		// Query translator should dis-allow join fetching of an <any/> mapping.  Let's make sure it does...
+		Session session = openSession();
+		session.beginTransaction();
+		session.createQuery( "select p from Person p join fetch p.data" ).list();
+		session.getTransaction().commit();
+		session.close();
+	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/lazyonetoone/LazyOneToOneTest.java b/hibernate-core/src/test/java/org/hibernate/test/lazyonetoone/LazyOneToOneTest.java
index e70c47e126..e7bb2490a4 100755
--- a/hibernate-core/src/test/java/org/hibernate/test/lazyonetoone/LazyOneToOneTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/lazyonetoone/LazyOneToOneTest.java
@@ -1,110 +1,111 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2006-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.lazyonetoone;
 import java.util.Date;
 
 import org.junit.Test;
 
 import org.hibernate.Hibernate;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.bytecode.instrumentation.internal.FieldInterceptionHelper;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.testing.Skip;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertSame;
 import static org.junit.Assert.assertTrue;
 
 /**
  * @author Gavin King
  */
 @Skip(
 		condition = LazyOneToOneTest.DomainClassesInstrumentedMatcher.class,
 		message = "Test domain classes were not instrumented"
 )
 public class LazyOneToOneTest extends BaseCoreFunctionalTestCase {
 	public String[] getMappings() {
 		return new String[] { "lazyonetoone/Person.hbm.xml" };
 	}
 
 	public void configure(Configuration cfg) {
 		cfg.setProperty(Environment.MAX_FETCH_DEPTH, "2");
 		cfg.setProperty(Environment.USE_SECOND_LEVEL_CACHE, "false");
 	}
 
 	@Test
 	public void testLazy() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Person p = new Person("Gavin");
 		Person p2 = new Person("Emmanuel");
 		Employee e = new Employee(p);
 		new Employment(e, "JBoss");
 		Employment old = new Employment(e, "IFA");
 		old.setEndDate( new Date() );
 		s.persist(p);
 		s.persist(p2);
 		t.commit();
 		s.close();
 		
 		s = openSession();
 		t = s.beginTransaction();
 		p = (Person) s.createQuery("from Person where name='Gavin'").uniqueResult();
 		//assertFalse( Hibernate.isPropertyInitialized(p, "employee") );
 		assertSame( p.getEmployee().getPerson(), p );
 		assertTrue( Hibernate.isInitialized( p.getEmployee().getEmployments() ) );
 		assertEquals( p.getEmployee().getEmployments().size(), 1 );
 		p2 = (Person) s.createQuery("from Person where name='Emmanuel'").uniqueResult();
 		assertNull( p2.getEmployee() );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = (Person) s.get(Person.class, "Gavin");
 		//assertFalse( Hibernate.isPropertyInitialized(p, "employee") );
 		assertSame( p.getEmployee().getPerson(), p );
 		assertTrue( Hibernate.isInitialized( p.getEmployee().getEmployments() ) );
 		assertEquals( p.getEmployee().getEmployments().size(), 1 );
 		p2 = (Person) s.get(Person.class, "Emmanuel");
 		assertNull( p2.getEmployee() );
 		s.delete(p2);
 		s.delete(old);
 		s.delete(p);
 		t.commit();
 		s.close();
 	}
 
 	public static class DomainClassesInstrumentedMatcher implements Skip.Matcher {
 		@Override
 		public boolean isMatch() {
-			return FieldInterceptionHelper.isInstrumented( Person.class );
+			// we match (to skip) when the classes are *not* instrumented...
+			return ! FieldInterceptionHelper.isInstrumented( Person.class );
 		}
 	}
 }
 
diff --git a/hibernate-core/src/test/java/org/hibernate/test/legacy/FooBarTest.java b/hibernate-core/src/test/java/org/hibernate/test/legacy/FooBarTest.java
index 006c6fcaaa..377a6e722e 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/legacy/FooBarTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/legacy/FooBarTest.java
@@ -1846,2000 +1846,2024 @@ public class FooBarTest extends LegacyTestCase {
 			Query q = s.createQuery("select bar from Bar as bar where bar.x > ?");
 			q.list();
 			fail("Should throw QueryException for missing ?");
 		}
 		catch (QueryException iae) {
 			// should happen
 		}
 		finally {
 			s.close();
 		}
 
 		s = openSession();
 		try {
 			Query q = s.createQuery("select bar from Bar as bar where bar.x > ? or bar.short = 1 or bar.string = 'ff ? bb'");
 			q.setInteger(0, 1);
 			q.list();
 		}
 		catch (QueryException iae) {
 			fail("Should not throw QueryException for missing ?");
 		}
 		finally {
 			s.close();
 		}
 
 		s = openSession();
 		try {
 			Query q = s.createQuery("select bar from Bar as bar where bar.string = ' ? ' or bar.string = '?'");
 			q.list();
 		}
 		catch (QueryException iae) {
 			fail("Should not throw QueryException for ? in quotes");
 		}
 		finally {
 			s.close();
 		}
 
 		s = openSession();
 		try {
 			Query q = s.createQuery("select bar from Bar as bar where bar.string = ? or bar.string = ? or bar.string = ?");
 			q.setParameter(0, "bull");
 			q.setParameter(2, "shit");
 			q.list();
 			fail("should throw exception telling me i have not set parameter 1");
 		}
 		catch (QueryException iae) {
 			// should happen!
 		}
 		finally {
 			s.close();
 		}
 	}
 
 	@Test
 	public void testDyna() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		GlarchProxy g = new Glarch();
 		g.setName("G");
 		Serializable id = s.save(g);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, id);
 		assertTrue( g.getName().equals("G") );
 		assertTrue( g.getDynaBean().get("foo").equals("foo") && g.getDynaBean().get("bar").equals( new Integer(66) ) );
 		assertTrue( ! (g instanceof Glarch) );
 		g.getDynaBean().put("foo", "bar");
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, id);
 		assertTrue( g.getDynaBean().get("foo").equals("bar") && g.getDynaBean().get("bar").equals( new Integer(66) ) );
 		g.setDynaBean(null);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, id);
 		assertTrue( g.getDynaBean()==null );
 		s.delete(g);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testFindByCriteria() throws Exception {
 		if ( getDialect() instanceof DB2Dialect ) {
 			return;
 		}
 
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		Foo f = new Foo();
 		s.save( f );
 		s.flush();
 
 		List list = s.createCriteria(Foo.class)
 			.add( Restrictions.eq( "integer", f.getInteger() ) )
 			.add( Restrictions.eqProperty("integer", "integer") )
 			.add( Restrictions.like( "string", f.getString().toUpperCase() ).ignoreCase() )
 			.add( Restrictions.in( "boolean", new Boolean[] { f.getBoolean(), f.getBoolean() } ) )
 			.setFetchMode("foo", FetchMode.JOIN)
 			.setFetchMode("baz", FetchMode.SELECT)
 			.setFetchMode("abstracts", FetchMode.JOIN)
 			.list();
 		assertTrue( list.size() == 1 && list.get( 0 ) == f );
 
 		list = s.createCriteria(Foo.class).add(
 				Restrictions.disjunction()
 					.add( Restrictions.eq( "integer", f.getInteger() ) )
 					.add( Restrictions.like( "string", f.getString() ) )
 					.add( Restrictions.eq( "boolean", f.getBoolean() ) )
 			)
 			.add( Restrictions.isNotNull("boolean") )
 			.list();
 		assertTrue( list.size() == 1 && list.get( 0 ) == f );
 
 		Foo example = new Foo();
 		example.setString("a STRing");
 		list = s.createCriteria(Foo.class).add(
 			Example.create(example)
 				.excludeZeroes()
 				.ignoreCase()
 				.excludeProperty("bool")
 				.excludeProperty("char")
 				.excludeProperty("yesno")
 			)
 			.list();
 		assertTrue(
 				"Example API without like did not work correctly, size was " + list.size(),
 				list.size() == 1 && list.get( 0 ) == f
 		);
 		example.setString("rin");
 
 		list = s.createCriteria(Foo.class).add(
 			Example.create(example)
 				.excludeZeroes()
 				.enableLike(MatchMode.ANYWHERE)
 				.excludeProperty("bool")
 				.excludeProperty("char")
 				.excludeProperty("yesno")
 			)
 			.list();
 		assertTrue( "Example API without like did not work correctly, size was " + list.size(), list.size()==1 && list.get(0)==f );
 
 		list = s.createCriteria(Foo.class)
 			.add( Restrictions.or(
 					Restrictions.and(
 					Restrictions.eq( "integer", f.getInteger() ),
 					Restrictions.like( "string", f.getString() )
 				),
 				Restrictions.eq( "boolean", f.getBoolean() )
 			) )
 			.list();
 		assertTrue( list.size()==1 && list.get(0)==f );
 		list = s.createCriteria(Foo.class)
 			.setMaxResults(5)
 			.addOrder( Order.asc("date") )
 			.list();
 		assertTrue( list.size()==1 && list.get(0)==f );
 		list = s.createCriteria(Foo.class)
 			.setFirstResult(1)
 			.addOrder( Order.asc("date") )
 			.addOrder( Order.desc("string") )
 			.list();
 		assertTrue( list.size() == 0 );
 		list = s.createCriteria(Foo.class)
 			.setFetchMode( "component.importantDates", FetchMode.JOIN )
 			.list();
 		assertTrue( list.size() == 3 );
 
 		list = s.createCriteria(Foo.class)
 			.setFetchMode( "component.importantDates", FetchMode.JOIN )
 			.setResultTransformer(Criteria.DISTINCT_ROOT_ENTITY)
 			.list();
 		assertTrue( list.size()==1 );
 
 		f.setFoo( new Foo() );
 		s.save( f.getFoo() );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		list = s.createCriteria(Foo.class)
 			.add( Restrictions.eq( "integer", f.getInteger() ) )
 			.add( Restrictions.like( "string", f.getString() ) )
 			.add( Restrictions.in( "boolean", new Boolean[] { f.getBoolean(), f.getBoolean() } ) )
 			.add( Restrictions.isNotNull("foo") )
 			.setFetchMode( "foo", FetchMode.JOIN )
 			.setFetchMode( "baz", FetchMode.SELECT )
 			.setFetchMode( "component.glarch", FetchMode.SELECT )
 			.setFetchMode( "foo.baz", FetchMode.SELECT )
 			.setFetchMode( "foo.component.glarch", FetchMode.SELECT )
 			.list();
 		f = (Foo) list.get(0);
 		assertTrue( Hibernate.isInitialized( f.getFoo() ) );
 		assertTrue( !Hibernate.isInitialized( f.getComponent().getGlarch() ) );
 
 		s.save( new Bar() );
 		list = s.createCriteria(Bar.class)
 			.list();
 		assertTrue( list.size() == 1 );
 		assertTrue( s.createCriteria(Foo.class).list().size()==3 );
 		s.delete( list.get( 0 ) );
 
 		s.delete( f.getFoo() );
 		s.delete(f);
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testAfterDelete() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo foo = new Foo();
 		s.save(foo);
 		s.flush();
 		s.delete(foo);
 		s.save(foo);
 		s.delete(foo);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testCollectionWhere() throws Exception {
 		Foo foo1 = new Foo();
 		Foo foo2 = new Foo();
 		Baz baz = new Baz();
 		Foo[] arr = new Foo[10];
 		arr[0] = foo1;
 		arr[9] = foo2;
 
 		Session s = openSession();
 		s.beginTransaction();
 		s.save( foo1 );
 		s.save(foo2);
 		baz.setFooArray( arr );
 		s.save( baz );
 		s.getTransaction().commit();
 		s.close();
 
 		final Session s2 = openSession();
 		s2.beginTransaction();
 		baz = (Baz) s2.load( Baz.class, baz.getCode() );
 		assertTrue( baz.getFooArray().length == 1 );
 		assertTrue( s2.createQuery( "from Baz baz join baz.fooArray foo" ).list().size()==1 );
 		assertTrue( s2.createQuery( "from Foo foo" ).list().size()==2 );
 		assertTrue( s2.createFilter( baz.getFooArray(), "" ).list().size() == 1 );
 		//assertTrue( s.delete("from java.lang.Object o")==9 );
 		doDelete( s2, "from Foo foo" );
 		final String bazid = baz.getCode();
 		s2.delete( baz );
 		int rows = s2.doReturningWork(
 				new AbstractReturningWork<Integer>() {
 					@Override
 					public Integer execute(Connection connection) throws SQLException {
 						Statement st = connection.createStatement();
 						return st.executeUpdate( "delete from FOO_ARRAY where id_='" + bazid + "' and i>=8" );
 					}
 				}
 		);
 		assertTrue( rows == 1 );
 		s2.getTransaction().commit();
 		s2.close();
 	}
 
 	@Test
 	public void testComponentParent() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		BarProxy bar = new Bar();
 		bar.setBarComponent( new FooComponent() );
 		Baz baz = new Baz();
 		baz.setComponents( new FooComponent[] { new FooComponent(), new FooComponent() } );
 		s.save(bar);
 		s.save(baz);
 		t.commit();
 		s.close();
 		s = openSession();
 		t = s.beginTransaction();
 		bar = (BarProxy) s.load(Bar.class, bar.getKey());
 		s.load(baz, baz.getCode());
 		assertTrue( bar.getBarComponent().getParent()==bar );
 		assertTrue( baz.getComponents()[0].getBaz()==baz && baz.getComponents()[1].getBaz()==baz );
 		s.delete(baz);
 		s.delete(bar);
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testCollectionCache() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		s.save(baz);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.load( Baz.class, baz.getCode() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void ntestAssociationId() throws Exception {
 		// IMPL NOTE : previously not being run due to the name
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Bar bar = new Bar();
 		String id = (String) s.save(bar);
 		MoreStuff more = new MoreStuff();
 		more.setName("More Stuff");
 		more.setIntId(12);
 		more.setStringId("id");
 		Stuff stuf = new Stuff();
 		stuf.setMoreStuff(more);
 		more.setStuffs( new ArrayList() );
 		more.getStuffs().add(stuf);
 		stuf.setFoo(bar);
 		stuf.setId(1234);
 		stuf.setProperty( TimeZone.getDefault() );
 		s.save(more);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		List results = s.createQuery(
 				"from Stuff as s where s.foo.id = ? and s.id.id = ? and s.moreStuff.id.intId = ? and s.moreStuff.id.stringId = ?"
 		)
 				.setParameter( 0, bar, s.getTypeHelper().entity(Foo.class) )
 				.setParameter( 1, new Long(1234), StandardBasicTypes.LONG )
 				.setParameter( 2, new Integer(12), StandardBasicTypes.INTEGER )
 				.setParameter( 3, "id", StandardBasicTypes.STRING )
 				.list();
 		assertEquals( 1, results.size() );
 		results = s.createQuery( "from Stuff as s where s.foo.id = ? and s.id.id = ? and s.moreStuff.name = ?" )
 				.setParameter( 0, bar, s.getTypeHelper().entity(Foo.class) )
 				.setParameter( 1, new Long(1234), StandardBasicTypes.LONG )
 				.setParameter( 2, "More Stuff", StandardBasicTypes.STRING )
 				.list();
 		assertEquals( 1, results.size() );
 		s.createQuery( "from Stuff as s where s.foo.string is not null" ).list();
 		assertTrue(
 				s.createQuery( "from Stuff as s where s.foo > '0' order by s.foo" ).list().size()==1
 		);
 		//s.createCriteria(Stuff.class).createCriteria("id.foo").add( Expression.isNull("foo") ).list();
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		FooProxy foo = (FooProxy) s.load(Foo.class, id);
 		s.load(more, more);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Stuff stuff = new Stuff();
 		stuff.setFoo(foo);
 		stuff.setId(1234);
 		stuff.setMoreStuff(more);
 		s.load(stuff, stuff);
 		assertTrue( stuff.getProperty().equals( TimeZone.getDefault() ) );
 		assertTrue( stuff.getMoreStuff().getName().equals("More Stuff") );
 		doDelete( s, "from MoreStuff" );
 		doDelete( s, "from Foo foo" );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testCascadeSave() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Baz baz = new Baz();
 		List list = new ArrayList();
 		list.add( new Fee() );
 		list.add( new Fee() );
 		baz.setFees( list );
 		s.save(baz);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		assertTrue( baz.getFees().size() == 2 );
 		s.delete(baz);
 		assertTrue( !s.createQuery( "from Fee fee" ).iterate().hasNext() );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testCollectionsInSelect() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Foo[] foos = new Foo[] { null, new Foo() };
 		s.save( foos[1] );
 		Baz baz = new Baz();
 		baz.setDefaults();
 		baz.setFooArray(foos);
 		s.save(baz);
 		Baz baz2 = new Baz();
 		baz2.setDefaults();
 		s.save(baz2);
 
 		Bar bar = new Bar();
 		bar.setBaz(baz);
 		s.save(bar);
 
 		List list = s.createQuery( "select new Result(foo.string, foo.long, foo.integer) from Foo foo" ).list();
 		assertTrue( list.size()==2 && ( list.get(0) instanceof Result ) && ( list.get(1) instanceof Result ) );
 		/*list = s.find("select new Result( baz.name, foo.long, count(elements(baz.fooArray)) ) from Baz baz join baz.fooArray foo group by baz.name, foo.long");
 		assertTrue( list.size()==1 && ( list.get(0) instanceof Result ) );
 		Result r = ((Result) list.get(0) );
 		assertEquals( r.getName(), baz.getName() );
 		assertEquals( r.getCount(), 1 );
 		assertEquals( r.getAmount(), foos[1].getLong().longValue() );*/
 		list = s.createQuery(
 				"select new Result( baz.name, max(foo.long), count(foo) ) from Baz baz join baz.fooArray foo group by baz.name"
 		).list();
 		assertTrue( list.size()==1 && ( list.get(0) instanceof Result ) );
 		Result r = ((Result) list.get(0) );
 		assertEquals( r.getName(), baz.getName() );
 		assertEquals( r.getCount(), 1 );
 		assertTrue( r.getAmount() > 696969696969696000l );
 
 
 		//s.find("select max( elements(bar.baz.fooArray) ) from Bar as bar");
 		//The following test is disabled for databases with no subselects...also for Interbase (not sure why).
 		if ( !(getDialect() instanceof MySQLDialect) && !(getDialect() instanceof HSQLDialect) /*&& !(dialect instanceof MckoiDialect)*/ && !(getDialect() instanceof SAPDBDialect) && !(getDialect() instanceof PointbaseDialect) )  {
 			s.createQuery( "select count(*) from Baz as baz where 1 in indices(baz.fooArray)" ).list();
 			s.createQuery( "select count(*) from Bar as bar where 'abc' in elements(bar.baz.fooArray)" ).list();
 			s.createQuery( "select count(*) from Bar as bar where 1 in indices(bar.baz.fooArray)" ).list();
 			if ( !(getDialect() instanceof DB2Dialect) &&  !(getDialect() instanceof Oracle8iDialect ) && !( getDialect() instanceof SybaseDialect ) && !( getDialect() instanceof Sybase11Dialect ) && !( getDialect() instanceof SybaseASE15Dialect ) && !( getDialect() instanceof PostgreSQLDialect ) && !(getDialect() instanceof PostgreSQL81Dialect)) {
 				// SybaseAnywhereDialect supports implicit conversions from strings to ints
 				s.createQuery(
 						"select count(*) from Bar as bar, bar.component.glarch.proxyArray as g where g.id in indices(bar.baz.fooArray)"
 				).list();
 				s.createQuery(
 						"select max( elements(bar.baz.fooArray) ) from Bar as bar, bar.component.glarch.proxyArray as g where g.id in indices(bar.baz.fooArray)"
 				).list();
 			}
 			s.createQuery(
 					"select count(*) from Bar as bar where '1' in (from bar.component.glarch.proxyArray g where g.name='foo')"
 			).list();
 			s.createQuery(
 					"select count(*) from Bar as bar where '1' in (from bar.component.glarch.proxyArray g where g.name='foo')"
 			).list();
 			s.createQuery(
 					"select count(*) from Bar as bar left outer join bar.component.glarch.proxyArray as pg where '1' in (from bar.component.glarch.proxyArray)"
 			).list();
 		}
 
 		list = s.createQuery(
 				"from Baz baz left join baz.fooToGlarch join fetch baz.fooArray foo left join fetch foo.foo"
 		).list();
 		assertTrue( list.size()==1 && ( (Object[]) list.get(0) ).length==2 );
 
 		s.createQuery(
 				"select baz.name from Bar bar inner join bar.baz baz inner join baz.fooSet foo where baz.name = bar.string"
 		).list();
 		s.createQuery(
 				"SELECT baz.name FROM Bar AS bar INNER JOIN bar.baz AS baz INNER JOIN baz.fooSet AS foo WHERE baz.name = bar.string"
 		).list();
 
 		if ( !( getDialect() instanceof HSQLDialect ) ) s.createQuery(
 				"select baz.name from Bar bar join bar.baz baz left outer join baz.fooSet foo where baz.name = bar.string"
 		).list();
 
 		s.createQuery( "select baz.name from Bar bar join bar.baz baz join baz.fooSet foo where baz.name = bar.string" )
 				.list();
 		s.createQuery(
 				"SELECT baz.name FROM Bar AS bar JOIN bar.baz AS baz JOIN baz.fooSet AS foo WHERE baz.name = bar.string"
 		).list();
 
 		if ( !( getDialect() instanceof HSQLDialect ) ) {
 			s.createQuery(
 					"select baz.name from Bar bar left join bar.baz baz left join baz.fooSet foo where baz.name = bar.string"
 			).list();
 			s.createQuery( "select foo.string from Bar bar left join bar.baz.fooSet foo where bar.string = foo.string" )
 					.list();
 		}
 
 		s.createQuery(
 				"select baz.name from Bar bar left join bar.baz baz left join baz.fooArray foo where baz.name = bar.string"
 		).list();
 		s.createQuery( "select foo.string from Bar bar left join bar.baz.fooArray foo where bar.string = foo.string" )
 				.list();
 
 		s.createQuery(
 				"select bar.string, foo.string from Bar bar inner join bar.baz as baz inner join baz.fooSet as foo where baz.name = 'name'"
 		).list();
 		s.createQuery( "select foo from Bar bar inner join bar.baz as baz inner join baz.fooSet as foo" ).list();
 		s.createQuery( "select foo from Bar bar inner join bar.baz.fooSet as foo" ).list();
 
 		s.createQuery(
 				"select bar.string, foo.string from Bar bar join bar.baz as baz join baz.fooSet as foo where baz.name = 'name'"
 		).list();
 		s.createQuery( "select foo from Bar bar join bar.baz as baz join baz.fooSet as foo" ).list();
 		s.createQuery( "select foo from Bar bar join bar.baz.fooSet as foo" ).list();
 
 		assertTrue( s.createQuery( "from Bar bar join bar.baz.fooArray foo" ).list().size()==1 );
 
 		assertTrue( s.createQuery( "from Bar bar join bar.baz.fooSet foo" ).list().size()==0 );
 		assertTrue( s.createQuery( "from Bar bar join bar.baz.fooArray foo" ).list().size()==1 );
 
 		s.delete(bar);
 
 		if ( getDialect() instanceof DB2Dialect || getDialect() instanceof PostgreSQLDialect || getDialect() instanceof PostgreSQL81Dialect ) {
 			s.createQuery( "select one from One one join one.manies many group by one order by count(many)" ).iterate();
 			s.createQuery( "select one from One one join one.manies many group by one having count(many) < 5" )
 					.iterate();
 		}
 
 		s.createQuery( "from One one join one.manies many where one.id = 1 and many.id = 1" ).list();
 		s.createQuery( "select one.id, elements(one.manies) from One one" ).iterate();
 		s.createQuery( "select max( elements(one.manies) ) from One one" ).iterate();
 		s.createQuery( "select one, elements(one.manies) from One one" ).list();
 		Iterator iter = s.createQuery( "select elements(baz.fooArray) from Baz baz where baz.id=?" )
 				.setParameter( 0, baz.getCode(), StandardBasicTypes.STRING )
 				.iterate();
 		assertTrue( iter.next()==foos[1] && !iter.hasNext() );
 		list = s.createQuery( "select elements(baz.fooArray) from Baz baz where baz.id=?" )
 				.setParameter( 0, baz.getCode(), StandardBasicTypes.STRING )
 				.list();
 		assertEquals( 1, list.size() );
 		iter = s.createQuery( "select indices(baz.fooArray) from Baz baz where baz.id=?" )
 				.setParameter( 0, baz.getCode(), StandardBasicTypes.STRING )
 				.iterate();
 		assertTrue( iter.next().equals( new Integer(1) ) && !iter.hasNext() );
 
 		iter = s.createQuery( "select size(baz.stringSet) from Baz baz where baz.id=?" )
 				.setParameter( 0, baz.getCode(), StandardBasicTypes.STRING )
 				.iterate();
 		assertEquals( new Integer(3), iter.next() );
 
 		s.createQuery( "from Foo foo where foo.component.glarch.id is not null" ).list();
 
 		iter = s.createQuery(
 				"select baz, size(baz.stringSet), count( distinct elements(baz.stringSet) ), max( elements(baz.stringSet) ) from Baz baz group by baz"
 		).iterate();
 		while ( iter.hasNext() ) {
 			Object[] arr = (Object[]) iter.next();
             log.info(arr[0] + " " + arr[1] + " " + arr[2] + " " + arr[3]);
 		}
 
 		s.delete(baz);
 		s.delete(baz2);
 		s.delete( foos[1] );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testNewFlushing() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		s.save(baz);
 		s.flush();
 		baz.getStringArray()[0] = "a new value";
 		Iterator iter = s.createQuery( "from Baz baz" ).iterate();//no flush
 		assertTrue( iter.next()==baz );
 		iter = s.createQuery( "select elements(baz.stringArray) from Baz baz" ).iterate();
 		boolean found = false;
 		while ( iter.hasNext() ) {
 			if ( iter.next().equals("a new value") ) found = true;
 		}
 		assertTrue( found );
 		baz.setStringArray( null );
 		s.createQuery( "from Baz baz" ).iterate(); //no flush
 		iter = s.createQuery( "select elements(baz.stringArray) from Baz baz" ).iterate();
 		assertTrue( !iter.hasNext() );
 		baz.getStringList().add( "1E1" );
 		iter = s.createQuery( "from Foo foo" ).iterate();//no flush
 		assertTrue( !iter.hasNext() );
 		iter = s.createQuery( "select elements(baz.stringList) from Baz baz" ).iterate();
 		found = false;
 		while ( iter.hasNext() ) {
 			if ( iter.next().equals("1E1") ) found = true;
 		}
 		assertTrue( found );
 		baz.getStringList().remove( "1E1" );
 		iter = s.createQuery( "select elements(baz.stringArray) from Baz baz" ).iterate(); //no flush
 		iter = s.createQuery( "select elements(baz.stringList) from Baz baz" ).iterate();
 		found = false;
 		while ( iter.hasNext() ) {
 			if ( iter.next().equals("1E1") ) found = true;
 		}
 		assertTrue(!found);
 
 		List newList = new ArrayList();
 		newList.add("value");
 		baz.setStringList( newList );
 		iter = s.createQuery( "from Foo foo" ).iterate();//no flush
 		baz.setStringList( null );
 		iter = s.createQuery( "select elements(baz.stringList) from Baz baz" ).iterate();
 		assertTrue( !iter.hasNext() );
 
 		baz.setStringList(newList);
 		iter = s.createQuery( "from Foo foo" ).iterate();//no flush
 		iter = s.createQuery( "select elements(baz.stringList) from Baz baz" ).iterate();
 		assertTrue( iter.hasNext() );
 
 		s.delete( baz );
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testPersistCollections() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		assertEquals( 0, ( (Long) s.createQuery( "select count(*) from Bar" ).iterate().next() ).longValue() );
 		assertTrue( s.createQuery( "select count(*) from Bar b" ).iterate().next().equals( new Long(0) ) );
 		assertFalse( s.createQuery( "from Glarch g" ).iterate().hasNext() );
 
 		Baz baz = new Baz();
 		s.save(baz);
 		baz.setDefaults();
 		baz.setStringArray( new String[] { "stuff" } );
 		Set bars = new HashSet();
 		bars.add( new Bar() );
 		baz.setCascadingBars(bars);
 		HashMap sgm = new HashMap();
 		sgm.put( "a", new Glarch() );
 		sgm.put( "b", new Glarch() );
 		baz.setStringGlarchMap(sgm);
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		assertEquals( 1L, ((Long) s.createQuery( "select count(*) from Bar" ).iterate().next()).longValue() );
 		baz = (Baz) ( (Object[]) s.createQuery( "select baz, baz from Baz baz" ).list().get(0) )[1];
 		assertTrue( baz.getCascadingBars().size()==1 );
 		//System.out.println( s.print(baz) );
 		Foo foo = new Foo();
 		s.save(foo);
 		Foo foo2 = new Foo() ;
 		s.save(foo2);
 		baz.setFooArray( new Foo[] { foo, foo, null, foo2 } );
 		baz.getFooSet().add(foo);
 		baz.getCustoms().add( new String[] { "new", "custom" } );
 		baz.setStringArray(null);
 		baz.getStringList().set(0, "new value");
 		baz.setStringSet( new TreeSet() );
 		Time time = new java.sql.Time(12345);
 		baz.getTimeArray()[2] = time;
 		//System.out.println(time);
 
 		assertTrue( baz.getStringGlarchMap().size()==1 );
 
 		//The following test is disabled databases with no subselects
 		if ( !(getDialect() instanceof MySQLDialect) && !(getDialect() instanceof HSQLDialect) && !(getDialect() instanceof PointbaseDialect) )  {
 			List list = s.createQuery(
 					"select foo from Foo foo, Baz baz where foo in elements(baz.fooArray) and 3 = some elements(baz.intArray) and 4 > all indices(baz.intArray)"
 			).list();
 			assertTrue( "collection.elements find", list.size()==2 );
 		}
 		if (!(getDialect() instanceof SAPDBDialect) ) { // SAPDB doesn't like distinct with binary type
 			List list = s.createQuery( "select distinct foo from Baz baz join baz.fooArray foo" ).list();
 			assertTrue( "collection.elements find", list.size()==2 );
 		}
 
 		List list = s.createQuery( "select foo from Baz baz join baz.fooSet foo" ).list();
 		assertTrue( "association.elements find", list.size()==1 );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		assertEquals( 1, ((Long) s.createQuery( "select count(*) from Bar" ).iterate().next()).longValue() );
 		baz = (Baz) s.createQuery( "select baz from Baz baz order by baz" ).list().get(0);
 		assertTrue( "collection of custom types - added element", baz.getCustoms().size()==4 && baz.getCustoms().get(0)!=null );
 		assertTrue ( "component of component in collection", baz.getComponents()[1].getSubcomponent()!=null );
 		assertTrue( baz.getComponents()[1].getBaz()==baz );
 		assertTrue( "set of objects", ( (FooProxy) baz.getFooSet().iterator().next() ).getKey().equals( foo.getKey() ));
 		assertTrue( "collection removed", baz.getStringArray().length==0 );
 		assertTrue( "changed element", baz.getStringList().get(0).equals("new value"));
 		assertTrue( "replaced set", baz.getStringSet().size()==0 );
 		assertTrue( "array element change", baz.getTimeArray()[2]!=null );
 		assertTrue( baz.getCascadingBars().size()==1 );
 		//System.out.println( s.print(baz) );
 		baz.getStringSet().add("two");
 		baz.getStringSet().add("one");
 		baz.getBag().add("three");
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		baz = (Baz) s.createQuery( "select baz from Baz baz order by baz" ).list().get(0);
 		assertTrue( baz.getStringSet().size()==2 );
 		assertTrue( baz.getStringSet().first().equals("one") );
 		assertTrue( baz.getStringSet().last().equals("two") );
 		assertTrue( baz.getBag().size()==5 );
 		baz.getStringSet().remove("two");
 		baz.getBag().remove("duplicate");
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		assertEquals( 1, ((Long) s.createQuery( "select count(*) from Bar" ).iterate().next()).longValue() );
 		baz = (Baz) s.load(Baz.class, baz.getCode());
 		assertTrue( baz.getCascadingBars().size()==1 );
 		Bar bar = new Bar();
 		Bar bar2 = new Bar();
 		s.save(bar); s.save(bar2);
 		baz.setTopFoos( new HashSet() );
 		baz.getTopFoos().add(bar);
 		baz.getTopFoos().add(bar2);
 		assertTrue( baz.getCascadingBars().size()==1 );
 		baz.setTopGlarchez( new TreeMap() );
 		GlarchProxy g = new Glarch();
 		s.save(g);
 		baz.getTopGlarchez().put( new Character('G'), g );
 		HashMap map = new HashMap();
 		map.put(bar, g);
 		map.put(bar2, g);
 		baz.setFooToGlarch(map);
 		map = new HashMap();
 		map.put( new FooComponent("name", 123, null, null), bar );
 		map.put( new FooComponent("nameName", 12, null, null), bar );
 		baz.setFooComponentToFoo(map);
 		map = new HashMap();
 		map.put(bar, g);
 		baz.setGlarchToFoo(map);
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		baz = (Baz) s.createQuery( "select baz from Baz baz order by baz" ).list().get(0);
 		assertTrue( baz.getCascadingBars().size()==1 );
 
 		Session s2 = openSession();
 		Transaction txn2 = s2.beginTransaction();
 		assertEquals( 3, ((Long) s2.createQuery( "select count(*) from Bar" ).iterate().next()).longValue() );
 		Baz baz2 = (Baz) s2.createQuery( "select baz from Baz baz order by baz" ).list().get(0);
 		Object o = baz2.getFooComponentToFoo().get( new FooComponent("name", 123, null, null) );
 		assertTrue(
 			o==baz2.getFooComponentToFoo().get( new FooComponent("nameName", 12, null, null) ) && o!=null
 		);
 		txn2.commit();
 		s2.close();
 
 		assertTrue( Hibernate.isInitialized( baz.getFooToGlarch() ) );
 		assertTrue( baz.getTopFoos().size()==2 );
 		assertTrue( baz.getTopGlarchez().size()==1 );
 		assertTrue( baz.getTopFoos().iterator().next()!=null );
 		assertTrue( baz.getStringSet().size()==1 );
 		assertTrue( baz.getBag().size()==4 );
 		assertTrue( baz.getFooToGlarch().size()==2 );
 		assertTrue( baz.getFooComponentToFoo().size()==2 );
 		assertTrue( baz.getGlarchToFoo().size()==1 );
 		Iterator iter = baz.getFooToGlarch().keySet().iterator();
 		for (int i=0; i<2; i++ ) assertTrue( iter.next() instanceof BarProxy );
 		FooComponent fooComp = (FooComponent) baz.getFooComponentToFoo().keySet().iterator().next();
 		assertTrue(
 			( (fooComp.getCount()==123 && fooComp.getName().equals("name"))
 			|| (fooComp.getCount()==12 && fooComp.getName().equals("nameName")) )
 			&& ( baz.getFooComponentToFoo().get(fooComp) instanceof BarProxy )
 		);
 		Glarch g2 = new Glarch();
 		s.save(g2);
 		g = (GlarchProxy) baz.getTopGlarchez().get( new Character('G') );
 		baz.getTopGlarchez().put( new Character('H'), g );
 		baz.getTopGlarchez().put( new Character('G'), g2 );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		baz = (Baz) s.load(Baz.class, baz.getCode());
 		assertTrue( baz.getTopGlarchez().size()==2 );
 		assertTrue( baz.getCascadingBars().size()==1 );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		assertEquals( 3, ((Long) s.createQuery( "select count(*) from Bar" ).iterate().next()).longValue() );
 		baz = (Baz) s.createQuery( "select baz from Baz baz order by baz" ).list().get(0);
 		assertTrue( baz.getTopGlarchez().size()==2 );
 		assertTrue( baz.getCascadingBars().size()==1 );
 		txn.commit();
 
 		final Session s3 = (Session) SerializationHelper.deserialize( SerializationHelper.serialize(s) );
 		s.close();
 
 		txn2 = s3.beginTransaction();
 		baz = (Baz) s3.load(Baz.class, baz.getCode());
 		assertEquals( 3, ((Long) s3.createQuery( "select count(*) from Bar" ).iterate().next()).longValue() );
 		s3.delete(baz);
 		s3.delete( baz.getTopGlarchez().get( Character.valueOf('G') ) );
 		s3.delete( baz.getTopGlarchez().get( Character.valueOf('H') ) );
 		int rows = s3.doReturningWork(
 				new AbstractReturningWork<Integer>() {
 					@Override
 					public Integer execute(Connection connection) throws SQLException {
 						final String sql = "update " + getDialect().openQuote() + "glarchez" + getDialect().closeQuote() + " set baz_map_id=null where baz_map_index='a'";
 						Statement st = connection.createStatement();
 						return st.executeUpdate( sql );
 					}
 				}
 		);
 		assertTrue(rows==1);
 		assertEquals( 2, doDelete( s3, "from Bar bar" ) );
 		FooProxy[] arr = baz.getFooArray();
 		assertTrue( "new array of objects", arr.length==4 && arr[1].getKey().equals( foo.getKey() ) );
 		for ( int i=1; i<arr.length; i++ ) {
 			if ( arr[i]!=null) s3.delete(arr[i]);
 		}
 
 		s3.load( Qux.class, new Long(666) ); //nonexistent
 
 		assertEquals( 1, doDelete( s3, "from Glarch g" ) );
 		txn2.commit();
 
 		s3.disconnect();
 
 		Session s4 = (Session) SerializationHelper.deserialize( SerializationHelper.serialize( s3 ) );
 		s3.close();
 		//s3.reconnect();
 		assertTrue( s4.load( Qux.class, new Long(666) )!=null ); //nonexistent
 		//s3.disconnect();
 		s4.close();
 	}
 
 	@Test
 	public void testSaveFlush() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Fee fee = new Fee();
 		s.save( fee );
 		fee.setFi( "blah" );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		fee = (Fee) s.load( Fee.class, fee.getKey() );
 		assertTrue( "blah".equals( fee.getFi() ) );
 		s.delete(fee);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testCreateUpdate() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo foo = new Foo();
 		s.save(foo);
 		foo.setString("dirty");
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Foo foo2 = new Foo();
 		s.load( foo2, foo.getKey() );
 		// There is an interbase bug that causes null integers to return as 0, also numeric precision is <= 15
 		assertTrue( "create-update", foo.equalsFoo(foo2) );
 		//System.out.println( s.print(foo2) );
 		s.delete(foo2);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		foo = new Foo();
 		s.save(foo);
 		foo.setString("dirty");
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.load(foo2, foo.getKey());
 		// There is an interbase bug that causes null integers to return as 0, also numeric precision is <= 15
 		assertTrue( "create-update", foo.equalsFoo(foo2) );
 		//System.out.println( s.print(foo2) );
 		s.delete(foo2);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	@SuppressWarnings( {"unchecked"})
 	public void testUpdateCollections() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Holder baz = new Holder();
 		baz.setName("123");
 		Foo f1 = new Foo();
 		Foo f2 = new Foo();
 		Foo f3 = new Foo();
 		One o = new One();
 		baz.setOnes( new ArrayList() );
 		baz.getOnes().add(o);
 		Foo[] foos = new Foo[] { f1, null, f2 };
 		baz.setFooArray(foos);
 		baz.setFoos( new HashSet() );
 		baz.getFoos().add(f1);
 		s.save(f1);
 		s.save(f2);
 		s.save(f3);
 		s.save(o);
 		s.save(baz);
 		s.getTransaction().commit();
 		s.close();
 
 		baz.getOnes().set(0, null);
 		baz.getOnes().add(o);
 		baz.getFoos().add(f2);
 		foos[0] = f3;
 		foos[1] = f1;
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(baz);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Holder h = (Holder) s.load(Holder.class, baz.getId());
 		assertTrue( h.getOnes().get(0)==null );
 		assertTrue( h.getOnes().get(1)!=null );
 		assertTrue( h.getFooArray()[0]!=null);
 		assertTrue( h.getFooArray()[1]!=null);
 		assertTrue( h.getFooArray()[2]!=null);
 		assertTrue( h.getFoos().size()==2 );
 		s.getTransaction().commit();
 		s.close();
 
 		baz.getFoos().remove(f1);
 		baz.getFoos().remove(f2);
 		baz.getFooArray()[0]=null;
 		baz.getFooArray()[0]=null;
 		baz.getFooArray()[0]=null;
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(baz);
 		doDelete( s, "from Foo" );
 		baz.getOnes().remove(o);
 		doDelete( s, "from One" );
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testCreate() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo foo = new Foo();
 		s.save(foo);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Foo foo2 = new Foo();
 		s.load( foo2, foo.getKey() );
 		// There is an interbase bug that causes null integers to return as 0, also numeric precision is <= 15
 		assertTrue( "create", foo.equalsFoo( foo2 ) );
 		s.delete(foo2);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
+	public void loadFoo() {
+		Session s = openSession();
+		s.beginTransaction();
+		FooProxy foo = new Foo();
+		s.save( foo );
+		s.getTransaction().commit();
+		s.close();
+
+		final String id = ( (Foo) foo ).key;
+
+		s = openSession();
+		s.beginTransaction();
+		foo = (FooProxy) s.load( Foo.class, id );
+		s.getTransaction().commit();
+		s.close();
+
+		s = openSession();
+		s.beginTransaction();
+		s.delete( foo );
+		s.getTransaction().commit();
+		s.close();
+	}
+
+	@Test
 	public void testCallback() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Qux q = new Qux("0");
 		s.save(q);
 		q.setChild( new Qux( "1" ) );
 		s.save( q.getChild() );
 		Qux q2 = new Qux("2");
 		q2.setChild( q.getChild() );
 		Qux q3 = new Qux("3");
 		q.getChild().setChild(q3);
 		s.save( q3 );
 		Qux q4 = new Qux("4");
 		q4.setChild( q3 );
 		s.save(q4);
 		s.save( q2 );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		List l = s.createQuery( "from Qux" ).list();
 		assertTrue( "", l.size() == 5 );
 		s.delete( l.get( 0 ) );
 		s.delete( l.get( 1 ) );
 		s.delete( l.get( 2 ) );
 		s.delete( l.get(3) );
 		s.delete( l.get(4) );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testPolymorphism() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Bar bar = new Bar();
 		s.save(bar);
 		bar.setBarString("bar bar");
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		FooProxy foo = (FooProxy) s.load( Foo.class, bar.getKey() );
 		assertTrue( "polymorphic", foo instanceof BarProxy );
 		assertTrue( "subclass property", ( (BarProxy) foo ).getBarString().equals( bar.getBarString() ) );
 		//System.out.println( s.print(foo) );
 		s.delete(foo);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testRemoveContains() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		s.save( baz );
 		s.flush();
 		assertTrue( s.contains(baz) );
 		s.evict( baz );
 		assertFalse( s.contains(baz) );
 		Baz baz2 = (Baz) s.load( Baz.class, baz.getCode() );
 		assertFalse( baz == baz2 );
 		s.delete(baz2);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	@SuppressWarnings( {"unchecked"})
 	public void testCollectionOfSelf() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Bar bar = new Bar();
 		s.save(bar);
 		bar.setAbstracts( new HashSet() );
 		bar.getAbstracts().add( bar );
 		Bar bar2 = new Bar();
 		bar.getAbstracts().add( bar2 );
 		bar.setFoo(bar);
 		s.save( bar2 );
 		s.getTransaction().commit();
 		s.close();
 
 		bar.setAbstracts( null );
 
 		s = openSession();
 		s.beginTransaction();
 		s.load( bar, bar.getKey() );
 		assertTrue( "collection contains self", bar.getAbstracts().size() == 2 && bar.getAbstracts().contains( bar ) );
 		assertTrue( "association to self", bar.getFoo()==bar );
 		for ( Object o : bar.getAbstracts() ) {
 			s.delete( o );
 		}
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testFind() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 
 		Bar bar = new Bar();
 		s.save(bar);
 		bar.setBarString("bar bar");
 		bar.setString("xxx");
 		Foo foo = new Foo();
 		s.save(foo);
 		foo.setString("foo bar");
 		s.save( new Foo() );
 		s.save( new Bar() );
 		List list1 = s.createQuery( "select foo from Foo foo where foo.string='foo bar'" ).list();
 		assertTrue( "find size", list1.size()==1 );
 		assertTrue( "find ==", list1.get(0)==foo );
 		List list2 = s.createQuery( "from Foo foo order by foo.string, foo.date" ).list();
 		assertTrue( "find size", list2.size()==4 );
 
 		list1 = s.createQuery( "from Foo foo where foo.class='B'" ).list();
 		assertTrue( "class special property", list1.size()==2);
 		list1 = s.createQuery( "from Foo foo where foo.class=Bar" ).list();
 		assertTrue( "class special property", list1.size()==2);
 		list1 = s.createQuery( "from Foo foo where foo.class=Bar" ).list();
 		list2 = s.createQuery( "select bar from Bar bar, Foo foo where bar.string = foo.string and not bar=foo" ).list();
 		assertTrue( "class special property", list1.size()==2);
 		assertTrue( "select from a subclass", list2.size()==1);
 		Trivial t = new Trivial();
 		s.save(t);
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		list1 = s.createQuery( "from Foo foo where foo.string='foo bar'" ).list();
 		assertTrue( "find size", list1.size()==1 );
 		// There is an interbase bug that causes null integers to return as 0, also numeric precision is <= 15
 		assertTrue( "find equals", ( (Foo) list1.get(0) ).equalsFoo(foo) );
 		list2 = s.createQuery( "select foo from Foo foo" ).list();
 		assertTrue( "find size", list2.size()==5 );
 		List list3 = s.createQuery( "from Bar bar where bar.barString='bar bar'" ).list();
 		assertTrue( "find size", list3.size()==1 );
 		assertTrue( "find same instance", list2.contains( list1.get(0) ) && list2.contains( list2.get(0) ) );
 		assertTrue( s.createQuery( "from Trivial" ).list().size()==1 );
 		doDelete( s, "from Trivial" );
 
 		list2 = s.createQuery( "from Foo foo where foo.date = ?" )
 				.setParameter( 0, new java.sql.Date(123), StandardBasicTypes.DATE )
 				.list();
 		assertTrue ( "find by date", list2.size()==4 );
 		Iterator iter = list2.iterator();
 		while ( iter.hasNext() ) {
 			s.delete( iter.next() );
 		}
 		list2 = s.createQuery( "from Foo foo" ).list();
 		assertTrue( "find deleted", list2.size()==0);
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testDeleteRecursive() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo x = new Foo();
 		Foo y = new Foo();
 		x.setFoo( y );
 		y.setFoo( x );
 		s.save( x );
 		s.save( y );
 		s.flush();
 		s.delete( y );
 		s.delete( x );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testReachability() throws Exception {
 		//first for unkeyed collections
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz1 = new Baz();
 		s.save(baz1);
 		Baz baz2 = new Baz();
 		s.save(baz2);
 		baz1.setIntArray( new int[] {1 ,2, 3, 4} );
 		baz1.setFooSet( new HashSet() );
 		Foo foo = new Foo();
 		s.save(foo);
 		baz1.getFooSet().add(foo);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		baz1 = (Baz) s.load( Baz.class, baz1.getCode() );
 		baz2.setFooSet( baz1.getFooSet() ); baz1.setFooSet(null);
 		baz2.setIntArray( baz1.getIntArray() ); baz1.setIntArray(null);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		baz1 = (Baz) s.load( Baz.class, baz1.getCode() );
 		assertTrue( "unkeyed reachability", baz2.getIntArray().length==4 );
 		assertTrue( "unkeyed reachability", baz2.getFooSet().size()==1 );
 		assertTrue( "unkeyed reachability", baz1.getIntArray().length==0 );
 		assertTrue( "unkeyed reachability", baz1.getFooSet().size()==0 );
 		//System.out.println( s.print(baz1) + s.print(baz2) );
 		FooProxy fp = (FooProxy) baz2.getFooSet().iterator().next();
 		s.delete(fp);
 		s.delete(baz1);
 		s.delete(baz2);
 		s.getTransaction().commit();
 		s.close();
 
 		//now for collections of collections
 		s = openSession();
 		s.beginTransaction();
 		baz1 = new Baz();
 		s.save(baz1);
 		baz2 = new Baz();
 		s.save(baz2);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		baz1 = (Baz) s.load( Baz.class, baz1.getCode() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		baz1 = (Baz) s.load( Baz.class, baz1.getCode() );
 		s.delete(baz1);
 		s.delete(baz2);
 		s.getTransaction().commit();
 		s.close();
 
 		//now for keyed collections
 		s = openSession();
 		s.beginTransaction();
 		baz1 = new Baz();
 		s.save(baz1);
 		baz2 = new Baz();
 		s.save(baz2);
 		Foo foo1 = new Foo();
 		Foo foo2 = new Foo();
 		s.save(foo1); s.save(foo2);
 		baz1.setFooArray( new Foo[] { foo1, null, foo2 } );
 		baz1.setStringDateMap( new TreeMap() );
 		baz1.getStringDateMap().put("today", new Date( System.currentTimeMillis() ) );
 		baz1.getStringDateMap().put("tomorrow", new Date( System.currentTimeMillis() + 86400000 ) );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		baz1 = (Baz) s.load( Baz.class, baz1.getCode() );
 		baz2.setFooArray( baz1.getFooArray() ); baz1.setFooArray(null);
 		baz2.setStringDateMap( baz1.getStringDateMap() ); baz1.setStringDateMap(null);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		baz1 = (Baz) s.load( Baz.class, baz1.getCode() );
 		assertTrue( "reachability", baz2.getStringDateMap().size()==2 );
 		assertTrue( "reachability", baz2.getFooArray().length==3 );
 		assertTrue( "reachability", baz1.getStringDateMap().size()==0 );
 		assertTrue( "reachability", baz1.getFooArray().length==0 );
 		assertTrue( "null element", baz2.getFooArray()[1]==null );
 		assertTrue( "non-null element", baz2.getStringDateMap().get("today")!=null );
 		assertTrue( "non-null element", baz2.getStringDateMap().get("tomorrow")!=null );
 		assertTrue( "null element", baz2.getStringDateMap().get("foo")==null );
 		s.delete( baz2.getFooArray()[0] );
 		s.delete( baz2.getFooArray()[2] );
 		s.delete(baz1);
 		s.delete(baz2);
 		s.flush();
 		assertTrue( s.createQuery( "from java.lang.Object" ).list().size()==0 );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testPersistentLifecycle() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Qux q = new Qux();
 		s.save(q);
 		q.setStuff("foo bar baz qux");
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		q = (Qux) s.load( Qux.class, q.getKey() );
 		assertTrue( "lifecycle create", q.getCreated() );
 		assertTrue( "lifecycle load", q.getLoaded() );
 		assertTrue( "lifecycle subobject", q.getFoo()!=null );
 		s.delete(q);
 		assertTrue( "lifecycle delete", q.getDeleted() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		assertTrue( "subdeletion", s.createQuery( "from Foo foo" ).list().size()==0);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testIterators() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		for ( int i=0; i<10; i++ ) {
 			Qux q = new Qux();
 			Object qid = s.save(q);
 			assertTrue("not null", qid!=null);
 		}
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Iterator iter = s.createQuery( "from Qux q where q.stuff is null" ).iterate();
 		int count=0;
 		while ( iter.hasNext() ) {
 			Qux q = (Qux) iter.next();
 			q.setStuff("foo");
 			if (count==0 || count==5) iter.remove();
 			count++;
 		}
 		assertTrue("iterate", count==10);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		assertEquals( 8, doDelete( s, "from Qux q where q.stuff=?", "foo", StandardBasicTypes.STRING ) );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		iter = s.createQuery( "from Qux q" ).iterate();
 		assertTrue( "empty iterator", !iter.hasNext() );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testVersioning() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		GlarchProxy g = new Glarch();
 		s.save(g);
 		GlarchProxy g2 = new Glarch();
 		s.save(g2);
 		Serializable gid = s.getIdentifier(g);
 		Serializable g2id = s.getIdentifier(g2);
 		g.setName("glarch");
 		txn.commit();
 		s.close();
 
 		sessionFactory().evict(Glarch.class);
 
 		s = openSession();
 		txn = s.beginTransaction();
 		g = (GlarchProxy) s.load( Glarch.class, gid );
 		s.lock(g, LockMode.UPGRADE);
 		g2 = (GlarchProxy) s.load( Glarch.class, g2id );
 		assertTrue( "version", g.getVersion()==1 );
 		assertTrue( "version", g.getDerivedVersion()==1 );
 		assertTrue( "version", g2.getVersion()==0 );
 		g.setName("foo");
 		assertTrue(
 			"find by version",
 				s.createQuery( "from Glarch g where g.version=2" ).list().size()==1
 		);
 		g.setName("bar");
 		txn.commit();
 		s.close();
 
 		sessionFactory().evict(Glarch.class);
 
 		s = openSession();
 		txn = s.beginTransaction();
 		g = (GlarchProxy) s.load( Glarch.class, gid );
 		g2 = (GlarchProxy) s.load( Glarch.class, g2id );
 		assertTrue( "version", g.getVersion()==3 );
 		assertTrue( "version", g.getDerivedVersion()==3 );
 		assertTrue( "version", g2.getVersion()==0 );
 		g.setNext(null);
 		g2.setNext(g);
 		s.delete(g2);
 		s.delete(g);
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testVersionedCollections() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		GlarchProxy g = new Glarch();
 		s.save(g);
 		g.setProxyArray( new GlarchProxy[] { g } );
 		String gid = (String) s.getIdentifier(g);
 		ArrayList list = new ArrayList();
 		list.add("foo");
 		g.setStrings(list);
 		HashSet set = new HashSet();
 		set.add( g );
 		g.setProxySet( set );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, gid);
 		assertTrue( g.getStrings().size()==1 );
 		assertTrue( g.getProxyArray().length==1 );
 		assertTrue( g.getProxySet().size()==1 );
 		assertTrue( "versioned collection before", g.getVersion() == 1 );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, gid);
 		assertTrue( g.getStrings().get(0).equals("foo") );
 		assertTrue( g.getProxyArray()[0]==g );
 		assertTrue( g.getProxySet().iterator().next()==g );
 		assertTrue( "versioned collection before", g.getVersion() == 1 );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, gid);
 		assertTrue( "versioned collection before", g.getVersion() == 1 );
 		g.getStrings().add( "bar" );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, gid);
 		assertTrue( "versioned collection after", g.getVersion()==2 );
 		assertTrue( "versioned collection after", g.getStrings().size() == 2 );
 		g.setProxyArray( null );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, gid);
 		assertTrue( "versioned collection after", g.getVersion()==3 );
 		assertTrue( "versioned collection after", g.getProxyArray().length == 0 );
 		g.setFooComponents( new ArrayList() );
 		g.setProxyArray( null );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, gid);
 		assertTrue( "versioned collection after", g.getVersion()==4 );
 		s.delete(g);
 		s.flush();
 		assertTrue( s.createQuery( "from java.lang.Object" ).list().size()==0 );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testRecursiveLoad() throws Exception {
 		//Non polymorphic class (there is an implementation optimization
 		//being tested here)
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		GlarchProxy last = new Glarch();
 		s.save(last);
 		last.setOrder( (short) 0 );
 		for (int i=0; i<5; i++) {
 			GlarchProxy next = new Glarch();
 			s.save(next);
 			last.setNext(next);
 			last = next;
 			last.setOrder( (short) (i+1) );
 		}
 		Iterator iter = s.createQuery( "from Glarch g" ).iterate();
 		while ( iter.hasNext() ) {
 			iter.next();
 		}
 		List list = s.createQuery( "from Glarch g" ).list();
 		assertTrue( "recursive find", list.size()==6 );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		list = s.createQuery( "from Glarch g" ).list();
 		assertTrue( "recursive iter", list.size()==6 );
 		list = s.createQuery( "from Glarch g where g.next is not null" ).list();
 		assertTrue( "recursive iter", list.size()==5 );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		iter = s.createQuery( "from Glarch g order by g.order asc" ).iterate();
 		while ( iter.hasNext() ) {
 			GlarchProxy g = (GlarchProxy) iter.next();
 			assertTrue( "not null", g!=null );
 			iter.remove();
 		}
 		txn.commit();
 		s.close();
 
 		//Same thing but using polymorphic class (no optimisation possible):
 		s = openSession();
 		txn = s.beginTransaction();
 		FooProxy flast = new Bar();
 		s.save(flast);
 		flast.setString( "foo0" );
 		for (int i=0; i<5; i++) {
 			FooProxy foo = new Bar();
 			s.save(foo);
 			flast.setFoo(foo);
 			flast = flast.getFoo();
 			flast.setString( "foo" + (i+1) );
 		}
 		iter = s.createQuery( "from Foo foo" ).iterate();
 		while ( iter.hasNext() ) {
 			iter.next();
 		}
 		list = s.createQuery( "from Foo foo" ).list();
 		assertTrue( "recursive find", list.size()==6 );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		list = s.createQuery( "from Foo foo" ).list();
 		assertTrue( "recursive iter", list.size()==6 );
 		iter = list.iterator();
 		while ( iter.hasNext() ) {
 			assertTrue( "polymorphic recursive load", iter.next() instanceof BarProxy );
 		}
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		iter = s.createQuery( "from Foo foo order by foo.string asc" ).iterate();
 		while ( iter.hasNext() ) {
 			BarProxy bar = (BarProxy) iter.next();
 			assertTrue( "not null", bar!=null );
 			iter.remove();
 		}
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testScrollableIterator() throws Exception {
 		// skip if not one of these named dialects
 		boolean match = getDialect() instanceof DB2Dialect
 				|| getDialect() instanceof SybaseDialect
 				|| getDialect() instanceof HSQLDialect
 				|| getDialect() instanceof Oracle8iDialect // 9i/10g too because of inheritence...
 				;
 		if ( ! match ) {
 			return;
 		}
 
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		s.save( new Foo() );
 		s.save( new Foo() );
 		s.save( new Foo() );
 		s.save( new Bar() );
 		Query query = s.createQuery("select f, f.integer from Foo f");
 		assertTrue( query.getReturnTypes().length==2 );
 		ScrollableResults iter = query.scroll();
 		assertTrue( iter.next() );
 		assertTrue( iter.scroll(1) );
 		FooProxy f2 = (FooProxy) iter.get()[0];
 		assertTrue( f2!=null );
 		assertTrue( iter.scroll(-1) );
 		Object f1 = iter.get(0);
 		iter.next();
 		assertTrue( f1!=null && iter.get(0)==f2 );
 		iter.getInteger(1);
 
 		assertTrue( !iter.scroll(100) );
 		assertTrue( iter.first() );
 		assertTrue( iter.scroll(3) );
 		Object f4 = iter.get(0);
 		assertTrue( f4!=null );
 		assertTrue( !iter.next() );
 		assertTrue( iter.first() );
 		assertTrue( iter.get(0)==f1 );
 		assertTrue( iter.last() );
 		assertTrue( iter.get(0)==f4 );
 		assertTrue( iter.previous() );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		query = s.createQuery("select f, f.integer from Foo f");
 		assertTrue( query.getReturnTypes().length==2 );
 		iter = query.scroll();
 		assertTrue( iter.next() );
 		assertTrue( iter.scroll(1) );
 		f2 = (FooProxy) iter.get()[0];
 		assertTrue( f2!=null );
 		assertTrue( f2.getString()!=null  && f2.getComponent().getImportantDates().length > 0 );
 		assertTrue( iter.scroll(-1) );
 		f1 = iter.get(0);
 		iter.next();
 		assertTrue( f1!=null && iter.get(0)==f2 );
 		iter.getInteger(1);
 
 		assertTrue( !iter.scroll(100) );
 		assertTrue( iter.first() );
 		assertTrue( iter.scroll(3) );
 		f4 = iter.get(0);
 		assertTrue( f4!=null );
 		assertTrue( !iter.next() );
 		assertTrue( iter.first() );
 		assertTrue( iter.get(0)==f1 );
 		assertTrue( iter.last() );
 		assertTrue( iter.get(0)==f4 );
 		assertTrue( iter.previous() );
 		int i = 0;
 		for ( Object entity : s.createQuery( "from Foo" ).list() ) {
 			i++;
 			s.delete( entity );
 		}
 		assertEquals( 4, i );
 		s.flush();
 		assertTrue( s.createQuery( "from java.lang.Object" ).list().size()==0 );
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testMultiColumnQueries() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		Foo foo = new Foo();
 		s.save(foo);
 		Foo foo1 = new Foo();
 		s.save(foo1);
 		foo.setFoo(foo1);
 		List l = s.createQuery( "select parent, child from Foo parent, Foo child where parent.foo = child" ).list();
 		assertTrue( "multi-column find", l.size()==1 );
 
 		Iterator rs = s.createQuery(
 				"select count(distinct child.id), count(distinct parent.id) from Foo parent, Foo child where parent.foo = child"
 		).iterate();
 		Object[] row = (Object[]) rs.next();
 		assertTrue( "multi-column count", ( (Long) row[0] ).intValue()==1 );
 		assertTrue( "multi-column count", ( (Long) row[1] ).intValue()==1 );
 		assertTrue( !rs.hasNext() );
 
 		rs = s.createQuery( "select child.id, parent.id, child.long from Foo parent, Foo child where parent.foo = child" )
 				.iterate();
 		row = (Object[]) rs.next();
 		assertTrue( "multi-column id", row[0].equals( foo.getFoo().getKey() ) );
 		assertTrue( "multi-column id", row[1].equals( foo.getKey() ) );
 		assertTrue( "multi-column property", row[2].equals( foo.getFoo().getLong() ) );
 		assertTrue( !rs.hasNext() );
 
 		rs = s.createQuery(
 				"select child.id, parent.id, child.long, child, parent.foo from Foo parent, Foo child where parent.foo = child"
 		).iterate();
 		row = (Object[]) rs.next();
 		assertTrue(
 			foo.getFoo().getKey().equals( row[0] ) &&
 			foo.getKey().equals( row[1] ) &&
 			foo.getFoo().getLong().equals( row[2] ) &&
 			row[3] == foo.getFoo() &&
 			row[3]==row[4]
 		);
 		assertTrue( !rs.hasNext() );
 
 		row = (Object[]) l.get(0);
 		assertTrue( "multi-column find", row[0]==foo && row[1]==foo.getFoo() );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		Iterator iter = s.createQuery(
 				"select parent, child from Foo parent, Foo child where parent.foo = child and parent.string='a string'"
 		).iterate();
 		int deletions=0;
 		while ( iter.hasNext() ) {
 			Object[] pnc = (Object[]) iter.next();
 			s.delete( pnc[0] );
 			s.delete( pnc[1] );
 			deletions++;
 		}
 		assertTrue("multi-column iterate", deletions==1);
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testDeleteTransient() throws Exception {
 		Fee fee = new Fee();
 		Fee fee2 = new Fee();
 		fee2.setAnotherFee(fee);
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		s.save(fee);
 		s.save(fee2);
 		s.flush();
 		fee.setCount(123);
 		tx.commit();
 		s.close();
 		s = openSession();
 		tx = s.beginTransaction();
 		s.delete(fee);
 		s.delete(fee2);
 		//foo.setAnotherFee(null);
 		tx.commit();
 		s.close();
 		s = openSession();
 		tx = s.beginTransaction();
 		assertTrue( s.createQuery( "from Fee fee" ).list().size()==0 );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testDeleteUpdatedTransient() throws Exception {
 		Fee fee = new Fee();
 		Fee fee2 = new Fee();
 		fee2.setAnotherFee(fee);
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		s.save(fee);
 		s.save(fee2);
 		s.flush();
 		fee.setCount(123);
 		tx.commit();
 		s.close();
 		s = openSession();
 		tx = s.beginTransaction();
 		s.update(fee);
 		//fee2.setAnotherFee(null);
 		s.update(fee2);
 		s.delete(fee);
 		s.delete(fee2);
 		tx.commit();
 		s.close();
 		s = openSession();
 		tx = s.beginTransaction();
 		assertTrue( s.createQuery( "from Fee fee" ).list().size()==0 );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testUpdateOrder() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Fee fee1 = new Fee();
 		s.save(fee1);
 		Fee fee2 = new Fee();
 		fee1.setFee(fee2);
 		fee2.setFee(fee1);
 		fee2.setFees( new HashSet() );
 		Fee fee3 = new Fee();
 		fee3.setFee(fee1);
 		fee3.setAnotherFee(fee2);
 		fee2.setAnotherFee(fee3);
 		s.save(fee3);
 		s.save(fee2);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		fee1.setCount(10);
 		fee2.setCount(20);
 		fee3.setCount(30);
 		s.update(fee1);
 		s.update(fee2);
 		s.update(fee3);
 		s.flush();
 		s.delete(fee1);
 		s.delete(fee2);
 		s.delete(fee3);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		assertTrue( s.createQuery( "from Fee fee" ).list().size()==0 );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testUpdateFromTransient() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Fee fee1 = new Fee();
 		s.save(fee1);
 		Fee fee2 = new Fee();
 		fee1.setFee(fee2);
 		fee2.setFee(fee1);
 		fee2.setFees( new HashSet() );
 		Fee fee3 = new Fee();
 		fee3.setFee(fee1);
 		fee3.setAnotherFee(fee2);
 		fee2.setAnotherFee(fee3);
 		s.save(fee3);
 		s.save(fee2);
 		s.getTransaction().commit();
 		s.close();
 
 		fee1.setFi("changed");
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(fee1);
 		s.getTransaction().commit();
 		s.close();
 
 		Qux q = new Qux("quxxy");
 		q.setTheKey(0);
 		fee1.setQux(q);
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(fee1);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		fee1 = (Fee) s.load( Fee.class, fee1.getKey() );
 		assertTrue( "updated from transient", fee1.getFi().equals("changed") );
 		assertTrue( "unsaved value", fee1.getQux()!=null );
 		s.delete( fee1.getQux() );
 		fee1.setQux(null);
 		s.getTransaction().commit();
 		s.close();
 
 		fee2.setFi("CHANGED");
 		fee2.getFees().add("an element");
 		fee1.setFi("changed again");
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(fee2);
 		s.update( fee1 );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Fee fee = new Fee();
 		s.load( fee, fee2.getKey() );
 		fee1 = (Fee) s.load( Fee.class, fee1.getKey() );
 		assertTrue( "updated from transient", fee1.getFi().equals("changed again") );
 		assertTrue( "updated from transient", fee.getFi().equals("CHANGED") );
 		assertTrue( "updated collection", fee.getFees().contains("an element") );
 		s.getTransaction().commit();
 		s.close();
 
 		fee.getFees().clear();
 		fee.getFees().add("new element");
 		fee1.setFee(null);
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(fee);
 		s.saveOrUpdate(fee1);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.load( fee, fee.getKey() );
 		assertTrue( "update", fee.getAnotherFee()!=null );
 		assertTrue( "update", fee.getFee()!=null );
 		assertTrue( "update", fee.getAnotherFee().getFee()==fee.getFee() );
 		assertTrue( "updated collection", fee.getFees().contains("new element") );
 		assertTrue( "updated collection", !fee.getFees().contains("an element") );
 		s.getTransaction().commit();
 		s.close();
 
 		fee.setQux( new Qux("quxy") );
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(fee);
 		s.getTransaction().commit();
 		s.close();
 
 		fee.getQux().setStuff("xxx");
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(fee);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.load( fee, fee.getKey() );
 		assertTrue( "cascade update", fee.getQux()!=null );
 		assertTrue( "cascade update", fee.getQux().getStuff().equals("xxx") );
 		assertTrue( "update", fee.getAnotherFee()!=null );
 		assertTrue( "update", fee.getFee()!=null );
 		assertTrue( "update", fee.getAnotherFee().getFee()==fee.getFee() );
 		fee.getAnotherFee().setAnotherFee(null);
 		s.delete(fee);
 		doDelete( s, "from Fee fee" );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		assertTrue( s.createQuery( "from Fee fee" ).list().size()==0 );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testArraysOfTimes() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz() ;
 		s.save(baz);
 		baz.setDefaults();
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz.getTimeArray()[2] = new Date(123);
 		baz.getTimeArray()[3] = new java.sql.Time(1234);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		s.delete( baz );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testComponents() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		Foo foo = new Foo();
 //		foo.setComponent( new FooComponent("foo", 69, null, new FooComponent("bar", 96, null, null) ) );
 		s.save(foo);
 		foo.getComponent().setName( "IFA" );
 		txn.commit();
 		s.close();
 
 		foo.setComponent( null );
 
 		s = openSession();
 		txn = s.beginTransaction();
 		s.load( foo, foo.getKey() );
 		assertTrue(
 			"save components",
 			foo.getComponent().getName().equals("IFA") &&
diff --git a/hibernate-core/src/test/java/org/hibernate/test/querycache/QueryCacheTest.java b/hibernate-core/src/test/java/org/hibernate/test/querycache/QueryCacheTest.java
index a33aa1cca0..04b87537d4 100755
--- a/hibernate-core/src/test/java/org/hibernate/test/querycache/QueryCacheTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/querycache/QueryCacheTest.java
@@ -1,498 +1,505 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2006-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.querycache;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.Criteria;
 import org.hibernate.Hibernate;
 import org.hibernate.Query;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.criterion.Restrictions;
 import org.hibernate.stat.EntityStatistics;
 import org.hibernate.stat.QueryStatistics;
 import org.hibernate.testing.DialectChecks;
 import org.hibernate.testing.RequiresDialectFeature;
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.hibernate.transform.Transformers;
 import org.junit.Test;
 
 /**
  * @author Gavin King
  * @author Brett Meyer
  */
 public class QueryCacheTest extends BaseCoreFunctionalTestCase {
 
 	private static final CompositeKey PK = new CompositeKey(1, 2);
 	
 	@Override
 	public String[] getMappings() {
 		return new String[] { "querycache/Item.hbm.xml" };
 	}
 
 	@Override
 	protected Class[] getAnnotatedClasses() {
 		return new Class[] { 
 				CompositeKey.class,
 				EntityWithCompositeKey.class,
 				StringCompositeKey.class,
 				EntityWithStringCompositeKey.class				
 		};
 	}
 
 	@Override
 	public void configure(Configuration cfg) {
 		super.configure( cfg );
 		cfg.setProperty( Environment.USE_QUERY_CACHE, "true" );
 		cfg.setProperty( Environment.CACHE_REGION_PREFIX, "foo" );
 		cfg.setProperty( Environment.USE_SECOND_LEVEL_CACHE, "true" );
 		cfg.setProperty( Environment.GENERATE_STATISTICS, "true" );
 	}
 
 	@Override
 	protected String getCacheConcurrencyStrategy() {
 		return "nonstrict-read-write";
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-5426" )
 	public void testInvalidationFromBulkHQL() {
 		sessionFactory().getCache().evictQueryRegions();
 		sessionFactory().getStatistics().clear();
 
 		Session s = openSession();
 		List list = new ArrayList();
 		s.beginTransaction();
 		for (int i = 0; i < 3; i++) {
 			Item a = new Item();
 			a.setName("a" + i);
 			a.setDescription("a" + i);
 			list.add(a);
 			s.persist(a);
 		}
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		String queryString = "select count(*) from Item";
 		// this query will hit the database and create the cache
 		Long result = (Long) s.createQuery(queryString).setCacheable(true).uniqueResult();
 		assertEquals(3, result.intValue());
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		String updateString = "delete from Item";
 		s.createQuery(updateString).executeUpdate();
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		// and this one SHOULD not be served by the cache
 		Number result2 = (Number) s.createQuery(queryString).setCacheable(true).uniqueResult();
 		assertEquals(0, result2.intValue());
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "JBPAPP-4224" )
 	public void testHitCacheInSameSession() {
 		sessionFactory().evictQueries();
 		sessionFactory().getStatistics().clear();
 		Session s = openSession();
 		List list = new ArrayList();
 		s.beginTransaction();
 		for ( int i = 0; i < 3; i++ ) {
 			Item a = new Item();
 			a.setName( "a" + i );
 			a.setDescription( "a" + i );
 			list.add( a );
 			s.persist( a );
 		}
 		s.getTransaction().commit();
 
 //		s.close();
 //		s=openSession();
 
 		s.beginTransaction();
 		String queryString = "from Item";
 		// this query will hit the database and create the cache
 		s.createQuery( queryString ).setCacheable( true ).list();
 		s.getTransaction().commit();
 
 		s.beginTransaction();
 		//and this one SHOULD served by the cache
 		s.createQuery( queryString ).setCacheable( true ).list();
 		s.getTransaction().commit();
 		QueryStatistics qs = s.getSessionFactory().getStatistics().getQueryStatistics( queryString );
 		assertEquals( 1, qs.getCacheHitCount() );
 		assertEquals( 1, qs.getCachePutCount() );
 		s.close();
 		s = openSession();
 		s.beginTransaction();
 		for(Object obj:list){
 			s.delete( obj );
 		}
 		s.getTransaction().commit();
 		s.close();
 
 	}
 
 	private static final String queryString = "from Item i where i.name='widget'";
 
 	@Test
 	public void testQueryCacheInvalidation() throws Exception {
 
 		sessionFactory().evictQueries();
 		sessionFactory().getStatistics().clear();
 
 		final String queryString = "from Item i where i.name='widget'";
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.createQuery( queryString ).setCacheable(true).list();
 		Item i = new Item();
 		i.setName("widget");
 		i.setDescription("A really top-quality, full-featured widget.");
 		s.save(i);
 		t.commit();
 		s.close();
 
 		QueryStatistics qs = s.getSessionFactory().getStatistics().getQueryStatistics( queryString );
 		EntityStatistics es = s.getSessionFactory().getStatistics().getEntityStatistics( Item.class.getName() );
 
 		Thread.sleep(200);
 
 		s = openSession();
 		t = s.beginTransaction();
 		List result = s.createQuery( queryString ).setCacheable(true).list();
 		assertEquals( result.size(), 1 );
 		t.commit();
 		s.close();
 
 		assertEquals( qs.getCacheHitCount(), 0 );
 
 		s = openSession();
 		t = s.beginTransaction();
 		result = s.createQuery( queryString ).setCacheable(true).list();
 		assertEquals( result.size(), 1 );
 		t.commit();
 		s.close();
 
 		assertEquals( qs.getCacheHitCount(), 1 );
 		assertEquals( s.getSessionFactory().getStatistics().getEntityFetchCount(), 0 );
 
 		s = openSession();
 		t = s.beginTransaction();
 		result = s.createQuery( queryString ).setCacheable(true).list();
 		assertEquals( result.size(), 1 );
 		assertTrue( Hibernate.isInitialized( result.get(0) ) );
 		i = (Item) result.get(0);
 		i.setName("Widget");
 		t.commit();
 		s.close();
 
 		assertEquals( qs.getCacheHitCount(), 2 );
 		assertEquals( qs.getCacheMissCount(), 2 );
 		assertEquals( s.getSessionFactory().getStatistics().getEntityFetchCount(), 0 );
 
 		Thread.sleep(200);
 
 		s = openSession();
 		t = s.beginTransaction();
 		result = s.createQuery( queryString ).setCacheable(true).list();
 		i = (Item) s.get( Item.class, new Long(i.getId()) );
 
 		s.delete(i);
 		t.commit();
 		s.close();
 
 		assertEquals( qs.getCacheHitCount(), 2 );
 		assertEquals( qs.getCacheMissCount(), 3 );
 		assertEquals( qs.getCachePutCount(), 3 );
 		assertEquals( qs.getExecutionCount(), 3 );
 		assertEquals( es.getFetchCount(), 0 ); //check that it was being cached
 
 	}
 
 	@Test
 	@RequiresDialectFeature(
 			value = DialectChecks.CaseSensitiveCheck.class,
 			comment = "i.name='widget' should not match on case sensitive database."
 	)
 	public void testCaseInsensitiveComparison() {
 		Session s = openSession();
 		s.beginTransaction();
 		Item i = new Item();
 		i.setName( "Widget" );
 		i.setDescription( "A really top-quality, full-featured widget." );
 		s.save( i );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		List result = s.createQuery( queryString ).list();
 		assertEquals(1, result.size());
 		i = (Item) s.get( Item.class, new Long(i.getId()) );
 		assertEquals( i.getName(), "Widget" );
 		s.delete(i);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testQueryCacheFetch() throws Exception {
 		sessionFactory().evictQueries();
 		sessionFactory().getStatistics().clear();
 
+		// persist our 2 items.  This saves them to the db, but also into the second level entity cache region
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Item i = new Item();
 		i.setName("widget");
 		i.setDescription("A really top-quality, full-featured widget.");
 		Item i2 = new Item();
 		i2.setName("other widget");
 		i2.setDescription("Another decent widget.");
 		s.persist(i);
 		s.persist(i2);
 		t.commit();
 		s.close();
 
 		final String queryString = "from Item i where i.name like '%widget'";
 
 		QueryStatistics qs = s.getSessionFactory().getStatistics().getQueryStatistics( queryString );
 
 		Thread.sleep(200);
 
+		// perform the cacheable query.  this will execute the query (no query cache hit), but the Items will be
+		// found in second level entity cache region
 		s = openSession();
 		t = s.beginTransaction();
-		List result = s.createQuery( queryString ).setCacheable(true).list();
+		List result = s.createQuery( queryString ).setCacheable( true ).list();
 		assertEquals( result.size(), 2 );
 		t.commit();
 		s.close();
-
 		assertEquals( qs.getCacheHitCount(), 0 );
 		assertEquals( s.getSessionFactory().getStatistics().getEntityFetchCount(), 0 );
 
+
+		// evict the Items from the second level entity cache region
 		sessionFactory().evict(Item.class);
 
+		// now, perform the cacheable query again.  this time we should not execute the query (query cache hit).
+		// However, the Items will not be found in second level entity cache region this time (we evicted them above)
+		// nor are they in associated with the session.
 		s = openSession();
 		t = s.beginTransaction();
 		result = s.createQuery( queryString ).setCacheable(true).list();
 		assertEquals( result.size(), 2 );
 		assertTrue( Hibernate.isInitialized( result.get(0) ) );
 		assertTrue( Hibernate.isInitialized( result.get(1) ) );
 		t.commit();
 		s.close();
 
 		assertEquals( qs.getCacheHitCount(), 1 );
 		assertEquals( s.getSessionFactory().getStatistics().getEntityFetchCount(), 1 );
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.createQuery("delete Item").executeUpdate();
 		t.commit();
 		s.close();
 
 	}
 
 	@Test
 	public void testProjectionCache() throws Exception {
 		sessionFactory().evictQueries();
         sessionFactory().getStatistics().clear();
 
 		final String queryString = "select i.description as desc from Item i where i.name='widget'";
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.createQuery( queryString ).setCacheable(true).list();
 		Item i = new Item();
 		i.setName("widget");
 		i.setDescription("A really top-quality, full-featured widget.");
 		s.save(i);
 		t.commit();
 		s.close();
 
         QueryStatistics qs = s.getSessionFactory().getStatistics().getQueryStatistics( queryString );
 		EntityStatistics es = s.getSessionFactory().getStatistics().getEntityStatistics( Item.class.getName() );
 
 		assertEquals( qs.getCacheHitCount(), 0 );
 		assertEquals( qs.getCacheMissCount(), 1 );
 		assertEquals( qs.getCachePutCount(), 1 );
 
 		Thread.sleep(200);
 
 		s = openSession();
 		t = s.beginTransaction();
 		List result = s.createQuery( queryString ).setCacheable(true).list();
 		assertEquals( result.size(), 1 );
 		assertEquals( i.getDescription(), ( result.get( 0 ) ) );
 		t.commit();
 		s.close();
 
 		assertEquals( qs.getCacheHitCount(), 0 );
 		assertEquals( qs.getCacheMissCount(), 2 );
 		assertEquals( qs.getCachePutCount(), 2 );
 
 		s = openSession();
 		t = s.beginTransaction();
 		result = s.createQuery( queryString ).setCacheable(true).list();
 		assertEquals( result.size(), 1 );
 		assertEquals( i.getDescription(), result.get( 0 ) );
 		t.commit();
 		s.close();
 
 		assertEquals( qs.getCacheHitCount(), 1 );
 		assertEquals( qs.getCacheMissCount(), 2 );
 		assertEquals( qs.getCachePutCount(), 2 );
 
 		s = openSession();
 		t = s.beginTransaction();
 		result = s.createQuery( queryString ).setCacheable(true).setResultTransformer(Transformers.ALIAS_TO_ENTITY_MAP).list();
 		assertEquals( result.size(), 1 );
 		Map m = (Map) result.get(0);
 		assertEquals( 1, m.size() );
 		assertEquals( i.getDescription(), m.get( "desc" ) );
 		t.commit();
 		s.close();
 
 		assertEquals( "hit count should go up since data is not transformed until after it is cached", qs.getCacheHitCount(), 2 );
 		assertEquals( qs.getCacheMissCount(), 2 );
 		assertEquals( qs.getCachePutCount(), 2 );
 
 		s = openSession();
 		t = s.beginTransaction();
 		result = s.createQuery( queryString ).setCacheable(true).setResultTransformer(Transformers.ALIAS_TO_ENTITY_MAP).list();
 		assertEquals( result.size(), 1 );
 		m = (Map) result.get(0);
 		assertEquals(1, m.size());
 		assertEquals( i.getDescription(), m.get( "desc" ) );
 		t.commit();
 		s.close();
 
 		assertEquals( "hit count should go up since data is not transformed until after it is cachedr", qs.getCacheHitCount(), 3 );
 		assertEquals( qs.getCacheMissCount(), 2 );
 		assertEquals( qs.getCachePutCount(), 2 );
 
 		s = openSession();
 		t = s.beginTransaction();
 		result = s.createQuery( queryString ).setCacheable(true).list();
 		assertEquals( result.size(), 1 );
 		assertTrue( Hibernate.isInitialized( result.get(0) ) );
 		i = (Item) s.get( Item.class, new Long(i.getId()) );
         i.setName("widget");
 		i.setDescription("A middle-quality widget.");
 		t.commit();
 		s.close();
 
 		assertEquals( qs.getCacheHitCount(), 4 );
 		assertEquals( qs.getCacheMissCount(), 2 );
 		assertEquals( qs.getCachePutCount(), 2 );
 
 		Thread.sleep(200);
 
 		s = openSession();
 		t = s.beginTransaction();
 		result = s.createQuery( queryString ).setCacheable(true).list();
 		assertEquals( result.size(), 1 );
 		i = (Item) s.get( Item.class, new Long(i.getId()) );
 		assertEquals( result.get(0), "A middle-quality widget." );
 
 		assertEquals( qs.getCacheHitCount(), 4 );
 		assertEquals( qs.getCacheMissCount(), 3 );
 		assertEquals( qs.getCachePutCount(), 3 );
 
 		s.delete(i);
 		t.commit();
 		s.close();
 
 		assertEquals( qs.getCacheHitCount(), 4 );
 		assertEquals( qs.getCacheMissCount(), 3 );
 		assertEquals( qs.getCachePutCount(), 3 );
 		assertEquals( qs.getExecutionCount(), 3 );
 		assertEquals( es.getFetchCount(), 0 ); //check that it was being cached
 	}
 	
 	@Test
 	@TestForIssue( jiraKey = "HHH-4459" )
 	public void testGetByCompositeId() {
 		Session s = openSession();
 		s.beginTransaction();
 		s.persist( new EntityWithCompositeKey( PK ) );
 		Query query = s.createQuery( "FROM EntityWithCompositeKey e WHERE e.pk = :pk" );
 		query.setCacheable( true );
 		query.setParameter( "pk", PK );
 		assertEquals(1, query.list().size( ));
 		s.getTransaction().rollback();
 		s.close();
 		
 		s = openSession();
 		s.beginTransaction();
 		EntityWithStringCompositeKey entity = new EntityWithStringCompositeKey();
 		StringCompositeKey key = new StringCompositeKey();
 		key.setAnalog( "foo1" );
 		key.setDevice( "foo2" );
 		key.setDeviceType( "foo3" );
 		key.setSubstation( "foo4" );
 		entity.setPk( key );
 		s.persist( entity );
 		Criteria c = s.createCriteria(
 				EntityWithStringCompositeKey.class ).add( Restrictions.eq( 
 						"pk", key ) );
 		c.setCacheable( true );
 		assertEquals( 1, c.list().size() );
 		s.getTransaction().rollback();
 		s.close();
 	}
 
 //	@Test
 //	public void testGetByCompositeIdNoCache() {
 //		Query query = em.createQuery("FROM EntityWithCompositeKey e WHERE e.pk = :pk");
 //		query.setParameter("pk", PK);
 //		assertEquals(1, query.getResultList().size());
 //	}
 //
 //	@Test
 //	public void testGetByEntityIself() {
 //		Query query = em.createQuery("FROM EntityWithCompositeKey e WHERE e = :ent");
 //		query.setParameter("ent", new EntityWithCompositeKey(PK));
 //		assertEquals(1, query.getResultList().size());
 //	}
 
 }
 
diff --git a/hibernate-core/src/test/resources/log4j.properties b/hibernate-core/src/test/resources/log4j.properties
index 51025a3b1e..bcbf2f632b 100644
--- a/hibernate-core/src/test/resources/log4j.properties
+++ b/hibernate-core/src/test/resources/log4j.properties
@@ -1,50 +1,50 @@
 #
 # Hibernate, Relational Persistence for Idiomatic Java
 #
 # Copyright (c) 2013, Red Hat Inc. or third-party contributors as
 # indicated by the @author tags or express copyright attribution
 # statements applied by the authors.  All third-party contributions are
 # distributed under license by Red Hat Inc.
 #
 # This copyrighted material is made available to anyone wishing to use, modify,
 # copy, or redistribute it subject to the terms and conditions of the GNU
 # Lesser General Public License, as published by the Free Software Foundation.
 #
 # This program is distributed in the hope that it will be useful,
 # but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
 # or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
 # for more details.
 #
 # You should have received a copy of the GNU Lesser General Public License
 # along with this distribution; if not, write to:
 # Free Software Foundation, Inc.
 # 51 Franklin Street, Fifth Floor
 # Boston, MA  02110-1301  USA
 #
 log4j.appender.stdout=org.apache.log4j.ConsoleAppender
 log4j.appender.stdout.Target=System.out
 log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
 log4j.appender.stdout.layout.ConversionPattern=%d{ABSOLUTE} %5p %c{1}:%L - %m%n
 #log4j.appender.stdout.layout.ConversionPattern=%d{ABSOLUTE} %5p %c{1}:%L (hibernateLoadPlanWalkPath->%X{hibernateLoadPlanWalkPath}) - %m%n
 
-log4j.appender.stdout-mdc=org.apache.log4j.ConsoleAppender
-log4j.appender.stdout-mdc.Target=System.out
-log4j.appender.stdout-mdc.layout=org.apache.log4j.PatternLayout
-log4j.appender.stdout-mdc.layout.ConversionPattern=%d{ABSOLUTE} %5p %c{1}:%L (walk path -> %X{hibernateLoadPlanWalkPath}) - %m%n
+#log4j.appender.stdout-mdc=org.apache.log4j.ConsoleAppender
+#log4j.appender.stdout-mdc.Target=System.out
+#log4j.appender.stdout-mdc.layout=org.apache.log4j.PatternLayout
+#log4j.appender.stdout-mdc.layout.ConversionPattern=%d{ABSOLUTE} %5p %c{1}:%L (walk path -> %X{hibernateLoadPlanWalkPath}) - %m%n
 
 log4j.rootLogger=info, stdout
 
-log4j.logger.org.hibernate.loader.plan=trace, stdout-mdc
-log4j.additivity.org.hibernate.loader.plan=false
-log4j.logger.org.hibernate.persister.walking=trace, stdout-mdc
-log4j.additivity.org.hibernate.persister.walking=false
+#log4j.logger.org.hibernate.loader.plan=trace, stdout-mdc
+#log4j.additivity.org.hibernate.loader.plan=false
+#log4j.logger.org.hibernate.persister.walking=trace, stdout-mdc
+#log4j.additivity.org.hibernate.persister.walking=false
 
 log4j.logger.org.hibernate.tool.hbm2ddl=trace
 log4j.logger.org.hibernate.testing.cache=debug
 
 # SQL Logging - HHH-6833
 log4j.logger.org.hibernate.SQL=debug
 
 log4j.logger.org.hibernate.hql.internal.ast=debug
 
 log4j.logger.org.hibernate.sql.ordering.antlr=debug
\ No newline at end of file
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/graph/internal/advisor/AdviceHelper.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/graph/internal/advisor/AdviceHelper.java
index 1e65c7a037..e11942e66e 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/graph/internal/advisor/AdviceHelper.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/graph/internal/advisor/AdviceHelper.java
@@ -1,76 +1,78 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.graph.internal.advisor;
 
 import org.hibernate.LockMode;
+import org.hibernate.cfg.NotYetImplementedException;
 import org.hibernate.engine.FetchStrategy;
 import org.hibernate.engine.FetchStyle;
 import org.hibernate.engine.FetchTiming;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.jpa.graph.spi.AttributeNodeImplementor;
 import org.hibernate.jpa.internal.metamodel.Helper;
 import org.hibernate.loader.plan.spi.CollectionFetch;
 import org.hibernate.loader.plan.spi.CompositeFetch;
 import org.hibernate.loader.plan.spi.EntityFetch;
 import org.hibernate.loader.plan.spi.Fetch;
 import org.hibernate.loader.plan.spi.FetchOwner;
 import org.hibernate.type.EntityType;
 
 /**
  * @author Steve Ebersole
  */
 public class AdviceHelper {
 	private AdviceHelper() {
 	}
 
 	static Fetch buildFetch(FetchOwner fetchOwner, AttributeNodeImplementor attributeNode) {
-		if ( attributeNode.getAttribute().isAssociation() ) {
-			if ( attributeNode.getAttribute().isCollection() ) {
-				return new CollectionFetch(
-						(SessionFactoryImplementor) attributeNode.entityManagerFactory().getSessionFactory(),
-						LockMode.NONE,
-						fetchOwner,
-						new FetchStrategy( FetchTiming.IMMEDIATE, FetchStyle.SELECT ),
-						attributeNode.getAttributeName()
-				);
-			}
-			else {
-				return new EntityFetch(
-						(SessionFactoryImplementor) attributeNode.entityManagerFactory().getSessionFactory(),
-						LockMode.NONE,
-						fetchOwner,
-						attributeNode.getAttributeName(),
-						new FetchStrategy( FetchTiming.IMMEDIATE, FetchStyle.SELECT )
-				);
-			}
-		}
-		else {
-			return new CompositeFetch(
-					(SessionFactoryImplementor) attributeNode.entityManagerFactory().getSessionFactory(),
-					fetchOwner,
-					attributeNode.getAttributeName()
-			);
-		}
+		throw new NotYetImplementedException();
+//		if ( attributeNode.getAttribute().isAssociation() ) {
+//			if ( attributeNode.getAttribute().isCollection() ) {
+//				return new CollectionFetch(
+//						(SessionFactoryImplementor) attributeNode.entityManagerFactory().getSessionFactory(),
+//						LockMode.NONE,
+//						fetchOwner,
+//						new FetchStrategy( FetchTiming.IMMEDIATE, FetchStyle.SELECT ),
+//						attributeNode.getAttributeName()
+//				);
+//			}
+//			else {
+//				return new EntityFetch(
+//						(SessionFactoryImplementor) attributeNode.entityManagerFactory().getSessionFactory(),
+//						LockMode.NONE,
+//						fetchOwner,
+//						attributeNode.getAttributeName(),
+//						new FetchStrategy( FetchTiming.IMMEDIATE, FetchStyle.SELECT )
+//				);
+//			}
+//		}
+//		else {
+//			return new CompositeFetch(
+//					(SessionFactoryImplementor) attributeNode.entityManagerFactory().getSessionFactory(),
+//					fetchOwner,
+//					attributeNode.getAttributeName()
+//			);
+//		}
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/graph/internal/advisor/ReturnGraphVisitationStrategyImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/graph/internal/advisor/ReturnGraphVisitationStrategyImpl.java
index fcecaf5697..d85721a271 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/graph/internal/advisor/ReturnGraphVisitationStrategyImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/graph/internal/advisor/ReturnGraphVisitationStrategyImpl.java
@@ -1,101 +1,105 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.graph.internal.advisor;
 
 import java.util.ArrayDeque;
 
+import org.hibernate.cfg.NotYetImplementedException;
 import org.hibernate.jpa.graph.internal.EntityGraphImpl;
 import org.hibernate.loader.plan.spi.CollectionFetch;
 import org.hibernate.loader.plan.spi.CompositeFetch;
 import org.hibernate.loader.plan.spi.EntityFetch;
 import org.hibernate.loader.plan.spi.EntityReturn;
 import org.hibernate.loader.plan.spi.FetchOwner;
 import org.hibernate.loader.plan.spi.Return;
 import org.hibernate.loader.plan.spi.visit.ReturnGraphVisitationStrategyAdapter;
 
 /**
  * The visitor strategy for visiting the return graph of the load plan being advised.
  *
  * @author Steve Ebersole
  */
 public class ReturnGraphVisitationStrategyImpl extends ReturnGraphVisitationStrategyAdapter {
 	private ArrayDeque<AdviceNodeDescriptor> nodeStack = new ArrayDeque<AdviceNodeDescriptor>();
 
 	public ReturnGraphVisitationStrategyImpl(EntityReturn entityReturn, EntityGraphImpl jpaRoot) {
 		nodeStack.addFirst( new AdviceNodeDescriptorEntityReference( entityReturn, new JpaGraphRootEntityReference( jpaRoot ) ) );
 	}
 
 	@Override
 	public void finishingRootReturn(Return rootReturn) {
 		nodeStack.removeFirst();
 	}
 
 	@Override
 	public void finishingFetches(FetchOwner fetchOwner) {
 		nodeStack.peekFirst().applyMissingFetches();
 	}
 
 	@Override
 	public void startingEntityFetch(EntityFetch entityFetch) {
-		final AdviceNodeDescriptor currentNode = nodeStack.peekFirst();
-		final String attributeName = entityFetch.getOwnerPropertyName();
-		final JpaGraphReference fetchedGraphReference = currentNode.attributeProcessed( attributeName );
-
-		nodeStack.addFirst( new AdviceNodeDescriptorEntityReference( entityFetch, fetchedGraphReference ) );
+		throw new NotYetImplementedException();
+//		final AdviceNodeDescriptor currentNode = nodeStack.peekFirst();
+//		final String attributeName = entityFetch.getOwnerPropertyName();
+//		final JpaGraphReference fetchedGraphReference = currentNode.attributeProcessed( attributeName );
+//
+//		nodeStack.addFirst( new AdviceNodeDescriptorEntityReference( entityFetch, fetchedGraphReference ) );
 	}
 
 	@Override
 	public void finishingEntityFetch(EntityFetch entityFetch) {
 		nodeStack.removeFirst();
 	}
 
 	@Override
 	public void startingCollectionFetch(CollectionFetch collectionFetch) {
-		final AdviceNodeDescriptor currentNode = nodeStack.peekFirst();
-		final String attributeName = collectionFetch.getOwnerPropertyName();
-		final JpaGraphReference fetchedGraphReference = currentNode.attributeProcessed( attributeName );
-
-		nodeStack.addFirst( new AdviceNodeDescriptorCollectionReference( collectionFetch, fetchedGraphReference ) );
+		throw new NotYetImplementedException();
+//		final AdviceNodeDescriptor currentNode = nodeStack.peekFirst();
+//		final String attributeName = collectionFetch.getOwnerPropertyName();
+//		final JpaGraphReference fetchedGraphReference = currentNode.attributeProcessed( attributeName );
+//
+//		nodeStack.addFirst( new AdviceNodeDescriptorCollectionReference( collectionFetch, fetchedGraphReference ) );
 	}
 
 	@Override
 	public void finishingCollectionFetch(CollectionFetch collectionFetch) {
 		nodeStack.removeFirst();
 	}
 
 	@Override
 	public void startingCompositeFetch(CompositeFetch fetch) {
-		final AdviceNodeDescriptor currentNode = nodeStack.peekFirst();
-		final String attributeName = fetch.getOwnerPropertyName();
-		final JpaGraphReference fetchedGraphReference = currentNode.attributeProcessed( attributeName );
-
-		nodeStack.addFirst( new AdviceNodeDescriptorCompositeReference( fetch, fetchedGraphReference ) );
+		throw new NotYetImplementedException();
+//		final AdviceNodeDescriptor currentNode = nodeStack.peekFirst();
+//		final String attributeName = fetch.getOwnerPropertyName();
+//		final JpaGraphReference fetchedGraphReference = currentNode.attributeProcessed( attributeName );
+//
+//		nodeStack.addFirst( new AdviceNodeDescriptorCompositeReference( fetch, fetchedGraphReference ) );
 	}
 
 	@Override
 	public void finishingCompositeFetch(CompositeFetch fetch) {
 		nodeStack.removeFirst();
 	}
 
 }
diff --git a/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/packaging/PackagingTestCase.java b/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/packaging/PackagingTestCase.java
index af86c8aeae..fb27820b9e 100644
--- a/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/packaging/PackagingTestCase.java
+++ b/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/packaging/PackagingTestCase.java
@@ -1,410 +1,420 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.test.packaging;
 
 import java.io.File;
 import java.net.MalformedURLException;
 import java.net.URL;
 import java.net.URLClassLoader;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
 
 import org.jboss.shrinkwrap.api.ArchivePath;
 import org.jboss.shrinkwrap.api.ArchivePaths;
 import org.jboss.shrinkwrap.api.ShrinkWrap;
 import org.jboss.shrinkwrap.api.exporter.ExplodedExporter;
 import org.jboss.shrinkwrap.api.exporter.ZipExporter;
 import org.jboss.shrinkwrap.api.spec.JavaArchive;
 import org.jboss.shrinkwrap.api.spec.WebArchive;
 import org.junit.After;
 import org.junit.Before;
 
 import org.hibernate.jpa.test.Cat;
 import org.hibernate.jpa.test.Distributor;
 import org.hibernate.jpa.test.Item;
 import org.hibernate.jpa.test.Kitten;
-import org.hibernate.jpa.test.TestHelper;
 import org.hibernate.jpa.test.pack.cfgxmlpar.Morito;
 import org.hibernate.jpa.test.pack.defaultpar.ApplicationServer;
 import org.hibernate.jpa.test.pack.defaultpar.IncrementListener;
 import org.hibernate.jpa.test.pack.defaultpar.Lighter;
 import org.hibernate.jpa.test.pack.defaultpar.Money;
 import org.hibernate.jpa.test.pack.defaultpar.Mouse;
 import org.hibernate.jpa.test.pack.defaultpar.OtherIncrementListener;
 import org.hibernate.jpa.test.pack.defaultpar.Version;
 import org.hibernate.jpa.test.pack.defaultpar_1_0.ApplicationServer1;
 import org.hibernate.jpa.test.pack.defaultpar_1_0.IncrementListener1;
 import org.hibernate.jpa.test.pack.defaultpar_1_0.Lighter1;
 import org.hibernate.jpa.test.pack.defaultpar_1_0.Money1;
 import org.hibernate.jpa.test.pack.defaultpar_1_0.Mouse1;
 import org.hibernate.jpa.test.pack.defaultpar_1_0.Version1;
 import org.hibernate.jpa.test.pack.excludehbmpar.Caipirinha;
 import org.hibernate.jpa.test.pack.explodedpar.Carpet;
 import org.hibernate.jpa.test.pack.explodedpar.Elephant;
 import org.hibernate.jpa.test.pack.externaljar.Scooter;
 import org.hibernate.jpa.test.pack.spacepar.Bug;
 import org.hibernate.jpa.test.pack.various.Airplane;
 import org.hibernate.jpa.test.pack.various.Seat;
 
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
 import static org.junit.Assert.fail;
 
 /**
  * @author Hardy Ferentschik
  * @author Brett Meyer
  */
 public abstract class PackagingTestCase extends BaseCoreFunctionalTestCase {
 	protected static ClassLoader originalClassLoader = Thread.currentThread().getContextClassLoader();
 	protected static ClassLoader bundleClassLoader;
 	protected static File packageTargetDir;
 
 	static {
 		// get a URL reference to something we now is part of the classpath (us)
 		URL myUrl = originalClassLoader.getResource(
 				PackagingTestCase.class.getName().replace( '.', '/' ) + ".class"
 		);
-		int index;
-		if (myUrl.getFile().contains( "target" )) {
+
+		if ( myUrl == null ) {
+			fail( "Unable to setup packaging test : could not resolve 'known class' url" );
+		}
+
+		int index = -1;
+		if ( myUrl.getFile().contains( "target" ) ) {
 			// assume there's normally a /target
 			index = myUrl.getFile().lastIndexOf( "target" );
-		} else {
+		}
+		else if ( myUrl.getFile().contains( "bin" ) ) {
 			// if running in some IDEs, may be in /bin instead
 			index = myUrl.getFile().lastIndexOf( "bin" );
 		}
-		
-		if ( index == -1 ) {
-			fail( "Unable to setup packaging test" );
+		else if ( myUrl.getFile().contains( "out/test" ) ) {
+			// intellij... intellij sets up project outputs little different
+			int outIndex = myUrl.getFile().lastIndexOf( "out/test" );
+			index = myUrl.getFile().lastIndexOf( '/', outIndex+1 );
+		}
+
+		if ( index < 0 ) {
+			fail( "Unable to setup packaging test : could not interpret url" );
 		}
 
 		String baseDirPath = myUrl.getFile().substring( 0, index );
 		File baseDir = new File( baseDirPath );
 
 		File testPackagesDir = new File( baseDir, "target/bundles" );
 		try {
 			bundleClassLoader = new URLClassLoader( new URL[] { testPackagesDir.toURL() }, originalClassLoader );
 		}
 		catch ( MalformedURLException e ) {
 			fail( "Unable to build custom class loader" );
 		}
 		packageTargetDir = new File( baseDir, "target/packages" );
 		packageTargetDir.mkdirs();
 	}
 
 	@Before
 	public void prepareTCCL() {
 		// add the bundle class loader in order for ShrinkWrap to build the test package
 		Thread.currentThread().setContextClassLoader( bundleClassLoader );
 	}
 
 	@After
 	public void resetTCCL() throws Exception {
 		// reset the classloader
 		Thread.currentThread().setContextClassLoader( originalClassLoader );
 	}
 
 	protected void addPackageToClasspath(File... files) throws MalformedURLException {
 		List<URL> urlList = new ArrayList<URL>();
 		for ( File file : files ) {
 			urlList.add( file.toURL() );
 		}
 		URLClassLoader classLoader = new URLClassLoader(
 				urlList.toArray( new URL[urlList.size()] ), originalClassLoader
 		);
 		Thread.currentThread().setContextClassLoader( classLoader );
 	}
 
 	protected void addPackageToClasspath(URL... urls) throws MalformedURLException {
 		List<URL> urlList = new ArrayList<URL>();
 		urlList.addAll( Arrays.asList( urls ) );
 		URLClassLoader classLoader = new URLClassLoader(
 				urlList.toArray( new URL[urlList.size()] ), originalClassLoader
 		);
 		Thread.currentThread().setContextClassLoader( classLoader );
 	}
 
 	protected File buildDefaultPar() {
 		String fileName = "defaultpar.par";
 		JavaArchive archive = ShrinkWrap.create(  JavaArchive.class, fileName );
 		archive.addClasses(
 				ApplicationServer.class,
 				Lighter.class,
 				Money.class,
 				Mouse.class,
 				OtherIncrementListener.class,
 				IncrementListener.class,
 				Version.class
 		);
 		ArchivePath path = ArchivePaths.create( "META-INF/orm.xml" );
 		archive.addAsResource( "defaultpar/META-INF/orm.xml", path );
 
 		path = ArchivePaths.create( "META-INF/persistence.xml" );
 		archive.addAsResource( "defaultpar/META-INF/persistence.xml", path );
 
 		path = ArchivePaths.create( "org/hibernate/jpa/test/pack/defaultpar/Mouse.hbm.xml" );
 		archive.addAsResource( "defaultpar/org/hibernate/jpa/test/pack/defaultpar/Mouse.hbm.xml", path );
 
 		path = ArchivePaths.create( "org/hibernate/jpa/test/pack/defaultpar/package-info.class" );
 		archive.addAsResource( "org/hibernate/jpa/test/pack/defaultpar/package-info.class", path );
 
 
 		File testPackage = new File( packageTargetDir, fileName );
 		archive.as( ZipExporter.class ).exportTo ( testPackage, true );
 		return testPackage;
 	}
 
 	protected File buildDefaultPar_1_0() {
 		String fileName = "defaultpar_1_0.par";
 		JavaArchive archive = ShrinkWrap.create(  JavaArchive.class,fileName );
 		archive.addClasses(
 				ApplicationServer1.class,
 				Lighter1.class,
 				Money1.class,
 				Mouse1.class,
 				IncrementListener1.class,
 				Version1.class
 		);
 		ArchivePath path = ArchivePaths.create( "META-INF/orm.xml" );
 		archive.addAsResource( "defaultpar_1_0/META-INF/orm.xml", path );
 
 		path = ArchivePaths.create( "META-INF/persistence.xml" );
 		archive.addAsResource( "defaultpar_1_0/META-INF/persistence.xml", path );
 
 		path = ArchivePaths.create( "org/hibernate/jpa/test/pack/defaultpar_1_0/Mouse.hbm.xml" );
 		archive.addAsResource( "defaultpar_1_0/org/hibernate/jpa/test/pack/defaultpar_1_0/Mouse1.hbm.xml", path );
 
 		path = ArchivePaths.create( "org/hibernate/jpa/test/pack/defaultpar_1_0/package-info.class" );
 		archive.addAsResource( "org/hibernate/jpa/test/pack/defaultpar_1_0/package-info.class", path );
 
 
 		File testPackage = new File( packageTargetDir, fileName );
 		archive.as( ZipExporter.class ).exportTo( testPackage, true );
 		return testPackage;
 	}
 
 	protected File buildExplicitPar() {
 		// explicitpar/persistence.xml references externaljar.jar so build that from here.
 		// this is the reason for tests failing after clean at least on my (Steve) local system
 		buildExternalJar();
 
 		String fileName = "explicitpar.par";
 		JavaArchive archive = ShrinkWrap.create( JavaArchive.class, fileName );
 		archive.addClasses(
 				Airplane.class,
 				Seat.class,
 				Cat.class,
 				Kitten.class,
 				Distributor.class,
 				Item.class
 		);
 
 		ArchivePath path = ArchivePaths.create( "META-INF/orm.xml" );
 		archive.addAsResource( "explicitpar/META-INF/orm.xml", path );
 
 		path = ArchivePaths.create( "META-INF/persistence.xml" );
 		archive.addAsResource( "explicitpar/META-INF/persistence.xml", path );
 
 		File testPackage = new File( packageTargetDir, fileName );
 		archive.as( ZipExporter.class ).exportTo( testPackage, true );
 		return testPackage;
 	}
 
 	protected File buildExplodedPar() {
 		String fileName = "explodedpar";
 		JavaArchive archive = ShrinkWrap.create(  JavaArchive.class,fileName );
 		archive.addClasses(
 				Elephant.class,
 				Carpet.class
 		);
 
 		ArchivePath path = ArchivePaths.create( "META-INF/persistence.xml" );
 		archive.addAsResource( "explodedpar/META-INF/persistence.xml", path );
 
 		path = ArchivePaths.create( "org/hibernate/jpa/test/pack/explodedpar/Elephant.hbm.xml" );
 		archive.addAsResource( "explodedpar/org/hibernate/jpa/test/pack/explodedpar/Elephant.hbm.xml", path );
 
 		path = ArchivePaths.create( "org/hibernate/jpa/test/pack/explodedpar/package-info.class" );
 		archive.addAsResource( "org/hibernate/jpa/test/pack/explodedpar/package-info.class", path );
 
 		File testPackage = new File( packageTargetDir, fileName );
 		archive.as( ExplodedExporter.class ).exportExploded( packageTargetDir );
 		return testPackage;
 	}
 
 	protected File buildExcludeHbmPar() {
 		String fileName = "excludehbmpar.par";
 		JavaArchive archive = ShrinkWrap.create( JavaArchive.class,fileName );
 		archive.addClasses(
 				Caipirinha.class
 		);
 
 		ArchivePath path = ArchivePaths.create( "META-INF/orm2.xml" );
 		archive.addAsResource( "excludehbmpar/META-INF/orm2.xml", path );
 
 		path = ArchivePaths.create( "META-INF/persistence.xml" );
 		archive.addAsResource( "excludehbmpar/META-INF/persistence.xml", path );
 
 		path = ArchivePaths.create( "org/hibernate/jpa/test/pack/excludehbmpar/Mouse.hbm.xml" );
 		archive.addAsResource( "excludehbmpar/org/hibernate/jpa/test/pack/excludehbmpar/Mouse.hbm.xml", path );
 
 		File testPackage = new File( packageTargetDir, fileName );
 		archive.as( ZipExporter.class ).exportTo( testPackage, true );
 		return testPackage;
 	}
 
 	protected File buildCfgXmlPar() {
 		String fileName = "cfgxmlpar.par";
 		JavaArchive archive = ShrinkWrap.create( JavaArchive.class,fileName );
 		archive.addClasses(
 				Morito.class,
 				Item.class
 		);
 
 		ArchivePath path = ArchivePaths.create( "META-INF/persistence.xml" );
 		archive.addAsResource( "cfgxmlpar/META-INF/persistence.xml", path );
 
 		path = ArchivePaths.create( "org/hibernate/jpa/test/pack/cfgxmlpar/hibernate.cfg.xml" );
 		archive.addAsResource( "cfgxmlpar/org/hibernate/jpa/test/pack/cfgxmlpar/hibernate.cfg.xml", path );
 
 		File testPackage = new File( packageTargetDir, fileName );
 		archive.as( ZipExporter.class ).exportTo( testPackage, true );
 		return testPackage;
 	}
 
 	protected File buildSpacePar() {
 		String fileName = "space par.par";
 		JavaArchive archive = ShrinkWrap.create( JavaArchive.class, fileName );
 		archive.addClasses(
 				Bug.class
 		);
 
 		ArchivePath path = ArchivePaths.create( "META-INF/persistence.xml" );
 		archive.addAsResource( "space par/META-INF/persistence.xml", path );
 
 		File testPackage = new File( packageTargetDir, fileName );
 		archive.as( ZipExporter.class ).exportTo( testPackage, true );
 		return testPackage;
 	}
 
 	protected File buildOverridenPar() {
 		String fileName = "overridenpar.jar";
 		JavaArchive archive = ShrinkWrap.create( JavaArchive.class, fileName );
 		archive.addClasses(
 				org.hibernate.jpa.test.pack.overridenpar.Bug.class
 		);
 
 		ArchivePath path = ArchivePaths.create( "META-INF/persistence.xml" );
 		archive.addAsResource( "overridenpar/META-INF/persistence.xml", path );
 
 		path = ArchivePaths.create( "overridenpar.properties" );
 		archive.addAsResource( "overridenpar/overridenpar.properties", path );
 
 		File testPackage = new File( packageTargetDir, fileName );
 		archive.as( ZipExporter.class ).exportTo( testPackage, true );
 		return testPackage;
 	}
 
 	protected File buildExternalJar() {
 		String fileName = "externaljar.jar";
 		JavaArchive archive = ShrinkWrap.create( JavaArchive.class, fileName );
 		archive.addClasses(
 				Scooter.class
 		);
 
 		ArchivePath path = ArchivePaths.create( "META-INF/orm.xml" );
 		archive.addAsResource( "externaljar/META-INF/orm.xml", path );
 
 		File testPackage = new File( packageTargetDir, fileName );
 		archive.as( ZipExporter.class ).exportTo( testPackage, true );
 		return testPackage;
 	}
 
 	protected File buildLargeJar() {
 		String fileName = "large.jar";
 		JavaArchive archive = ShrinkWrap.create( JavaArchive.class, fileName );
 		// Build a large jar by adding a lorem ipsum file repeatedly.
 		for ( int i = 0; i < 100; i++ ) {
 			ArchivePath path = ArchivePaths.create( "META-INF/file" + i );
 			archive.addAsResource(
 					"org/hibernate/jpa/test/packaging/loremipsum.txt",
 					path
 			);
 		}
 
 		File testPackage = new File( packageTargetDir, fileName );
 		archive.as( ZipExporter.class ).exportTo( testPackage, true );
 		return testPackage;
 	}
 
 	protected File buildWar() {
 		String fileName = "war.war";
 		WebArchive archive = ShrinkWrap.create( WebArchive.class, fileName );
 		archive.addClasses(
 				org.hibernate.jpa.test.pack.war.ApplicationServer.class,
 				org.hibernate.jpa.test.pack.war.IncrementListener.class,
 				org.hibernate.jpa.test.pack.war.Lighter.class,
 				org.hibernate.jpa.test.pack.war.Money.class,
 				org.hibernate.jpa.test.pack.war.Mouse.class,
 				org.hibernate.jpa.test.pack.war.OtherIncrementListener.class,
 				org.hibernate.jpa.test.pack.war.Version.class
 		);
 
 		ArchivePath path = ArchivePaths.create( "WEB-INF/classes/META-INF/orm.xml" );
 		archive.addAsResource( "war/WEB-INF/classes/META-INF/orm.xml", path );
 
 		path = ArchivePaths.create( "WEB-INF/classes/META-INF/persistence.xml" );
 		archive.addAsResource( "war/WEB-INF/classes/META-INF/persistence.xml", path );
 
 		path = ArchivePaths.create( "WEB-INF/classes/org/hibernate/jpa/test/pack/war/Mouse.hbm.xml" );
 		archive.addAsResource( "war/WEB-INF/classes/org/hibernate/jpa/test/pack/war/Mouse.hbm.xml", path );
 
 		File testPackage = new File( packageTargetDir, fileName );
 		archive.as( ZipExporter.class ).exportTo( testPackage, true );
 		return testPackage;
 	}
 
 	protected File buildNestedEar(File includeFile) {
 		String fileName = "nestedjar.ear";
 		JavaArchive archive = ShrinkWrap.create( JavaArchive.class, fileName );
 		archive.addAsResource( includeFile );
 
 		File testPackage = new File( packageTargetDir, fileName );
 		archive.as( ZipExporter.class ).exportTo( testPackage, true );
 		return testPackage;
 	}
 
 	protected File buildNestedEarDir(File includeFile) {
 		String fileName = "nesteddir.ear";
 		JavaArchive archive = ShrinkWrap.create( JavaArchive.class, fileName );
 		archive.addAsResource( includeFile );
 
 		File testPackage = new File( packageTargetDir, fileName );
 		archive.as( ExplodedExporter.class ).exportExploded( packageTargetDir );
 		return testPackage;
 	}
 
 }
 
 
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/util/TestPathHelper.java b/hibernate-testing/src/main/java/org/hibernate/testing/util/TestPathHelper.java
new file mode 100644
index 0000000000..78ac808ca8
--- /dev/null
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/util/TestPathHelper.java
@@ -0,0 +1,108 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.testing.util;
+
+import java.io.File;
+import java.net.MalformedURLException;
+import java.net.URISyntaxException;
+import java.net.URL;
+
+import static java.io.File.separatorChar;
+
+/**
+ * @author Steve Ebersole
+ */
+public class TestPathHelper {
+	/**
+	 * Useful in cases where we need to deal with files/resources in the test compilation output dir of the
+	 * project.  This gets a reference to the compilation output directory into which the given class was compiled.
+	 *
+	 * @param knownClass Reference to a Class known to be in the compilation output dir.
+	 *
+	 * @return The root URL
+	 */
+	public static URL resolveRootUrl(Class knownClass) {
+		final String knownClassFileName = '/' + knownClass.getName().replace( '.', separatorChar ) + ".class";
+		final URL knownClassFileUrl = knownClass.getResource( knownClassFileName );
+		final String knownClassFileUrlString = knownClassFileUrl.toExternalForm();
+
+		// to start, strip off the class file name
+		String rootUrlString = knownClassFileUrlString.substring( 0, knownClassFileUrlString.lastIndexOf( separatorChar ) );
+
+		// then strip off each package dir
+		final String packageName = knownClass.getPackage().getName();
+		for ( String packageNamePart : packageName.split( "\\." ) ) {
+			rootUrlString = rootUrlString.substring( 0, rootUrlString.lastIndexOf( separatorChar ) );
+		}
+
+		try {
+			return new URL( rootUrlString );
+		}
+		catch (MalformedURLException e) {
+			throw new RuntimeException( "Could not convert class base url as string to URL ref", e );
+		}
+	}
+
+	/**
+	 * Essentially the same as {@link #resolveRootUrl(Class)}, but here we convert the root URL to a File
+	 * (directory) reference.  In fact we delegate to {@link #resolveRootUrl(Class)} and simply convert its
+	 * return into a File reference.
+	 *
+	 * @param knownClass Reference to a Class known to be in the compilation output dir.
+	 *
+	 * @return The root directory
+	 */
+	public static File resolveRootDirectory(Class knownClass) {
+		try {
+			return new File( resolveRootUrl( knownClass ).toURI() );
+		}
+		catch (URISyntaxException e) {
+			throw new RuntimeException( "Could not convert class root URL to a URI", e );
+		}
+	}
+
+	/**
+	 * Essentially the same as {@link #resolveRootUrl(Class)}, but here we convert the root URL to a File
+	 * (directory) reference.  In fact we delegate to {@link #resolveRootUrl(Class)} and simply convert its
+	 * return into a File reference.
+	 *
+	 * @param knownClass Reference to a Class known to be in the compilation output dir.
+	 *
+	 * @return The root directory
+	 */
+	public static File resolveClassFile(Class knownClass) {
+		final String knownClassFileName = '/' + knownClass.getName().replace( '.', separatorChar ) + ".class";
+		final URL knownClassFileUrl = knownClass.getResource( knownClassFileName );
+
+		try {
+			return new File( knownClassFileUrl.toURI() );
+		}
+		catch (URISyntaxException e) {
+			throw new RuntimeException( "Could not convert class root URL to a URI", e );
+		}
+	}
+
+	private TestPathHelper() {
+	}
+}
